domain,layer,file,symbol,signature,called_by,calls,imports,side_effects,async,lines,docstring,intent,intent_confidence,intent_reason
_models,L7,alert_config,AlertConfig.can_send_alert,can_send_alert(run_alert_count: int) -> bool,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,is_throttled,pydantic | sqlmodel,pure,no,3,"Check if alert can be sent (not throttled, not exceeded max).",Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'can_')
_models,L7,alert_config,AlertConfig.email_recipients,email_recipients() -> list[str],?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,loads,pydantic | sqlmodel,pure,no,5,Get email recipients as list.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.email_recipients,email_recipients(value: list[str]) -> None,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,dumps,pydantic | sqlmodel,pure,no,3,Set email recipients from list.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.enabled_channels,enabled_channels() -> list[AlertChannel],?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,AlertChannel | loads,pydantic | sqlmodel,pure,no,5,Get enabled channels as list.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.enabled_channels,enabled_channels(value: list[AlertChannel]) -> None,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,dumps,pydantic | sqlmodel,pure,no,3,Set enabled channels from list.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.is_throttled,is_throttled() -> bool,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,now | total_seconds,pydantic | sqlmodel,pure,no,6,Check if alerts are currently throttled.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.record_alert_sent,record_alert_sent() -> None,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,now,pydantic | sqlmodel,pure,no,4,Record that an alert was sent.,Operation,high,called by L4 orchestrator
_models,L7,alert_config,AlertConfig.should_alert,should_alert(current_percentage: float) -> bool,?:alert_emitter | L4:alert_emitter | ?:test_multi_tier_alerts,,pydantic | sqlmodel,pure,no,6,Check if alert should be sent based on percentage.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'should_')
_models,L7,audit_ledger,generate_uuid,generate_uuid() -> str,L7:__init__ | ?:incident_write_engine | ?:overview_facade | ?:policy_proposal | ?:logs_facade | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,str | uuid4,postgresql | sqlalchemy | sqlmodel,pure,no,3,Generate a UUID string (PIN-413).,Unclassified,low,no classification rules matched
_models,L7,audit_ledger,utc_now,utc_now() -> datetime,L7:__init__ | ?:incident_write_engine | ?:overview_facade | ?:policy_proposal | ?:logs_facade | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,now,postgresql | sqlalchemy | sqlmodel,pure,no,3,Return current UTC time (PIN-413).,Unclassified,low,no classification rules matched
_models,L7,contract,ContractCreate.validate_confidence,validate_confidence(v: Decimal) -> Decimal,?:founder_contract_review | L7:__init__ | ?:founder_review | ?:rollout_projection | ?:contract_service | ?:audit_service | ?:governance_orchestrator | ?:llm_invoke_v2 | ?:json_transform_v2 | L3:claude_adapter,ValueError | field_validator,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,5,"CONTRACT-007: confidence_score range [0,1].",Policy/Decision,medium,name matches 'validate'
_models,L7,contract,ContractImmutableError.__init__,"__init__(contract_id: UUID, status: ContractStatus)",?:founder_contract_review | L7:__init__ | ?:founder_review | ?:rollout_projection | ?:contract_service | ?:audit_service | ?:governance_orchestrator | ?:llm_invoke_v2 | ?:json_transform_v2 | L3:claude_adapter,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,4,,Internal Helper,high,dunder method
_models,L7,contract,InvalidTransitionError.__init__,"__init__(from_status: ContractStatus, to_status: ContractStatus, reason: str)",?:founder_contract_review | L7:__init__ | ?:founder_review | ?:rollout_projection | ?:contract_service | ?:audit_service | ?:governance_orchestrator | ?:llm_invoke_v2 | ?:json_transform_v2 | L3:claude_adapter,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,10,,Internal Helper,high,dunder method
_models,L7,contract,MayNotVerdictError.__init__,__init__(reason: str),?:founder_contract_review | L7:__init__ | ?:founder_review | ?:rollout_projection | ?:contract_service | ?:audit_service | ?:governance_orchestrator | ?:llm_invoke_v2 | ?:json_transform_v2 | L3:claude_adapter,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,3,,Internal Helper,high,dunder method
_models,L7,costsim_cb,CostSimAlertQueueModel.to_dict,"to_dict() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,isoformat,orm | postgresql | sqlalchemy,pure,no,14,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,costsim_cb,CostSimCBIncidentModel.get_details,"get_details() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,loads,orm | postgresql | sqlalchemy,pure,no,5,Parse details JSON.,Unclassified,low,no classification rules matched
_models,L7,costsim_cb,CostSimCBIncidentModel.to_dict,"to_dict() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,get_details | isoformat,orm | postgresql | sqlalchemy,pure,no,18,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,costsim_cb,CostSimCBStateModel.to_dict,"to_dict() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,isoformat,orm | postgresql | sqlalchemy,pure,no,14,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,costsim_cb,CostSimCanaryReportModel.get_artifact_paths,get_artifact_paths() -> list,L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,loads,orm | postgresql | sqlalchemy,pure,no,5,Parse artifact paths JSON.,Unclassified,low,no classification rules matched
_models,L7,costsim_cb,CostSimCanaryReportModel.get_failure_reasons,get_failure_reasons() -> list,L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,loads,orm | postgresql | sqlalchemy,pure,no,5,Parse failure reasons JSON.,Unclassified,low,no classification rules matched
_models,L7,costsim_cb,CostSimCanaryReportModel.to_dict,"to_dict() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,get_artifact_paths | get_failure_reasons | isoformat,orm | postgresql | sqlalchemy,pure,no,20,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,costsim_cb,CostSimProvenanceModel.to_dict,"to_dict() -> Dict[str, Any]",L7:governance | L7:external_response | L7:__init__ | L7:execution_envelope | L7:contract | L7:governance_job | ?:alert_worker | ?:provenance_async | ?:circuit_breaker_async | L6:provenance_async,isoformat,orm | postgresql | sqlalchemy,pure,no,18,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,cus_models,CusIntegration.disable,disable() -> None,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,utc_now,postgresql | sqlalchemy | sqlmodel,pure,no,8,Disable this integration (user-initiated pause).,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.enable,enable() -> None,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,ValueError | utc_now,postgresql | sqlalchemy | sqlmodel,pure,no,10,Enable this integration for use.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.has_budget_limit,has_budget_limit() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if budget limit is configured.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.has_rate_limit,has_rate_limit() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if rate limit is configured.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.has_token_limit,has_token_limit() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if token limit is configured.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.is_deleted,is_deleted() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if integration is soft-deleted.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.is_usable,is_usable() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,7,Check if integration can be used for LLM calls.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.mark_error,mark_error(message: str) -> None,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,utc_now,postgresql | sqlalchemy | sqlmodel,pure,no,11,Mark integration as errored (system-detected issue).,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusIntegration.update_health,"update_health(state: CusHealthState, message: Optional[str]) -> None",?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,utc_now,postgresql | sqlalchemy | sqlmodel,pure,no,10,Update health state from health check result.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusLLMUsage.is_error,is_error() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if this call resulted in an error.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusLLMUsage.total_tokens,total_tokens() -> int,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Total tokens (input + output).,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusLLMUsage.was_blocked,was_blocked() -> bool,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if this call was blocked by policy.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusUsageDaily.cost_dollars,cost_dollars() -> float,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Total cost in dollars.,Unclassified,low,no classification rules matched
_models,L7,cus_models,CusUsageDaily.success_rate,success_rate() -> float,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,6,"Percentage of successful calls (non-error, non-blocked).",Unclassified,low,no classification rules matched
_models,L7,cus_models,CusUsageDaily.total_tokens,total_tokens() -> int,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Total tokens (input + output).,Unclassified,low,no classification rules matched
_models,L7,cus_models,generate_uuid,generate_uuid() -> str,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,str | uuid4,postgresql | sqlalchemy | sqlmodel,pure,no,3,Generate a new UUID string.,Unclassified,low,no classification rules matched
_models,L7,cus_models,utc_now,utc_now() -> datetime,?:cus_schemas | ?:cus_health_driver | ?:cus_health_engine | ?:cus_enforcement_driver | ?:cus_integration_engine | ?:cus_integration_driver | ?:cus_telemetry_driver | L5s:cus_schemas | L5:cus_health_engine | ?:cus_usage_aggregator,now,postgresql | sqlalchemy | sqlmodel,pure,no,3,Return current UTC time with timezone info.,Unclassified,low,no classification rules matched
_models,L7,execution_envelope,ExecutionEnvelopeModel.to_dict,"to_dict() -> Dict[str, Any]",?:evidence_sink | ?:invocation_context | ?:kernel | L5:kernel | ?:test_execution_envelope,isoformat,costsim_cb | postgresql | sqlalchemy,pure,no,50,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,execution_envelope,ExecutionEnvelopeStats.to_dict,"to_dict() -> Dict[str, Any]",?:evidence_sink | ?:invocation_context | ?:kernel | L5:kernel | ?:test_execution_envelope,isoformat,costsim_cb | postgresql | sqlalchemy,pure,no,15,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,export_bundles,generate_bundle_id,generate_bundle_id(prefix: str) -> str,L7:__init__ | ?:export_bundle_service | ?:pdf_renderer | L5:pdf_renderer | L6:export_bundle_driver | L3:export_bundle_adapter | ?:test_export_scope_resolution,uuid4,pydantic,pure,no,3,Generate unique bundle ID.,Unclassified,low,no classification rules matched
_models,L7,export_bundles,utc_now,utc_now() -> datetime,L7:__init__ | ?:export_bundle_service | ?:pdf_renderer | L5:pdf_renderer | L6:export_bundle_driver | L3:export_bundle_adapter | ?:test_export_scope_resolution,now,pydantic,pure,no,3,Return timezone-aware UTC datetime.,Unclassified,low,no classification rules matched
_models,L7,governance_job,InvalidJobTransitionError.__init__,"__init__(from_status: JobStatus, to_status: JobStatus, reason: str)",L7:__init__ | ?:job_executor | ?:governance_orchestrator | L4:job_executor | L4:governance_orchestrator | ?:test_orchestrator_invariants | ?:test_executor_invariants,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,10,,Internal Helper,high,dunder method
_models,L7,governance_job,JobImmutableError.__init__,"__init__(job_id: UUID, status: JobStatus)",L7:__init__ | ?:job_executor | ?:governance_orchestrator | L4:job_executor | L4:governance_orchestrator | ?:test_orchestrator_invariants | ?:test_executor_invariants,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,4,,Internal Helper,high,dunder method
_models,L7,governance_job,OrphanJobError.__init__,__init__(reason: str),L7:__init__ | ?:job_executor | ?:governance_orchestrator | L4:job_executor | L4:governance_orchestrator | ?:test_orchestrator_invariants | ?:test_executor_invariants,__init__ | super,costsim_cb | postgresql | pydantic | sqlalchemy,pure,no,3,,Internal Helper,high,dunder method
_models,L7,killswitch,DefaultGuardrail.evaluate,"evaluate(context: Dict[str, Any]) -> tuple[bool, Optional[str]]",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,get | get_rule_config | lower,pydantic | sqlmodel,pure,no,39,Evaluate this guardrail against context.,Policy/Decision,medium,name matches 'evaluate'
_models,L7,killswitch,DefaultGuardrail.get_rule_config,"get_rule_config() -> Dict[str, Any]",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,loads,pydantic | sqlmodel,pure,no,3,Get rule configuration from JSON.,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.acknowledge,acknowledge(by: str),?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,utc_now,pydantic | sqlmodel,pure,no,5,Mark incident as acknowledged (PIN-412).,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.add_related_call,add_related_call(call_id: str),?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,append | dumps | get_related_call_ids | len,pydantic | sqlmodel,pure,no,7,Add a related call ID.,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.get_inflection_context,get_inflection_context() -> dict,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,loads,pydantic | sqlmodel,pure,no,5,Get inflection context from JSON (GAP-024).,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.get_related_call_ids,get_related_call_ids() -> List[str],?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,loads,pydantic | sqlmodel,pure,no,5,Get list of related call IDs.,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.resolve,"resolve(by: str, resolution_method: Optional[str])",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,int | total_seconds | utc_now,pydantic | sqlmodel,pure,no,17,Mark incident as resolved.,Coordinator/Aggregator,medium,name matches 'resolve'
_models,L7,killswitch,Incident.set_inflection_context,set_inflection_context(context: dict) -> None,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,dumps,pydantic | sqlmodel,pure,no,3,Set inflection context as JSON (GAP-024).,Unclassified,low,no classification rules matched
_models,L7,killswitch,Incident.set_inflection_point,"set_inflection_point(step_index: Optional[int], timestamp: Optional[datetime], context: Optional[dict]) -> None",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,set_inflection_context | utc_now,pydantic | sqlmodel,pure,no,23,Set inflection point metadata (GAP-024).,Unclassified,low,no classification rules matched
_models,L7,killswitch,IncidentEvent.get_data,"get_data() -> Dict[str, Any]",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,loads,pydantic | sqlmodel,pure,no,5,Get event data from JSON.,Unclassified,low,no classification rules matched
_models,L7,killswitch,IncidentEvent.set_data,"set_data(data: Dict[str, Any])",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,dumps,pydantic | sqlmodel,pure,no,3,Set event data as JSON.,Unclassified,low,no classification rules matched
_models,L7,killswitch,KillSwitchState.freeze,"freeze(by: str, reason: str, auto: bool, trigger: Optional[str])",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,utc_now,pydantic | sqlmodel,pure,no,11,Freeze this entity.,Unclassified,low,no classification rules matched
_models,L7,killswitch,KillSwitchState.unfreeze,unfreeze(by: str),?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,utc_now,pydantic | sqlmodel,pure,no,6,Unfreeze this entity.,Unclassified,low,no classification rules matched
_models,L7,killswitch,ProxyCall.get_policy_decisions,"get_policy_decisions() -> List[Dict[str, Any]]",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,loads,pydantic | sqlmodel,pure,no,5,Get policy decisions from JSON.,Unclassified,low,no classification rules matched
_models,L7,killswitch,ProxyCall.hash_request,hash_request(request_body: dict) -> str,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,dumps | encode | hexdigest | sha256,pydantic | sqlmodel,pure,no,4,Generate deterministic hash of request for matching.,Unclassified,low,no classification rules matched
_models,L7,killswitch,ProxyCall.hash_response,hash_response(response_body: dict) -> str,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,dumps | encode | hexdigest | sha256,pydantic | sqlmodel,pure,no,4,Generate deterministic hash of response.,Unclassified,low,no classification rules matched
_models,L7,killswitch,ProxyCall.set_policy_decisions,"set_policy_decisions(decisions: List[Dict[str, Any]])",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,dumps,pydantic | sqlmodel,pure,no,3,Set policy decisions as JSON.,Unclassified,low,no classification rules matched
_models,L7,killswitch,generate_uuid,generate_uuid() -> str,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,str | uuid4,pydantic | sqlmodel,pure,no,2,,Unclassified,low,no classification rules matched
_models,L7,killswitch,utc_now,utc_now() -> datetime,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,now,pydantic | sqlmodel,pure,no,2,,Unclassified,low,no classification rules matched
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.allows_modifications,allows_modifications() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,is_onboarding | is_operational,,pure,no,3,Check if the knowledge plane configuration can be modified.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'allow')
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.allows_new_runs,allows_new_runs() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if new runs can use this knowledge plane.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'allow')
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.allows_policy_binding,allows_policy_binding() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,6,Check if policies can be bound to this knowledge plane.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'allow')
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.allows_queries,allows_queries() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if queries against this knowledge plane are allowed.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'allow')
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.is_failed,is_failed() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if state is a failure state.,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.is_offboarding,is_offboarding() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if state is in offboarding phase.,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.is_onboarding,is_onboarding() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if state is in onboarding phase.,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.is_operational,is_operational() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if state is operational (ACTIVE).,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.is_terminal,is_terminal() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,3,Check if state is terminal (no further transitions except FAILED).,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.requires_async_job,requires_async_job() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,7,Check if this state involves an async background job.,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,KnowledgePlaneLifecycleState.requires_policy_gate,requires_policy_gate() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,7,Check if transition FROM this state requires policy gate (GAP-087).,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,TransitionResult.__bool__,__bool__() -> bool,?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,,,pure,no,2,,Internal Helper,high,dunder method
_models,L7,knowledge_lifecycle,get_action_for_transition,"get_action_for_transition(from_state: KnowledgePlaneLifecycleState, to_state: KnowledgePlaneLifecycleState) -> Optional[str]",?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,items,,pure,no,9,"Get the action name for a given transition, if valid.",Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,get_next_offboarding_state,get_next_offboarding_state(current: KnowledgePlaneLifecycleState) -> Optional[KnowledgePlaneLifecycleState],?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,index | len,,pure,no,18,"Get the next state in the offboarding path, if applicable.",Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,get_next_onboarding_state,get_next_onboarding_state(current: KnowledgePlaneLifecycleState) -> Optional[KnowledgePlaneLifecycleState],?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,index | len,,pure,no,21,"Get the next state in the onboarding path, if applicable.",Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,get_transition_for_action,"get_transition_for_action(action: str, current_state: KnowledgePlaneLifecycleState) -> Optional[KnowledgePlaneLifecycleState]",?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,get_next_onboarding_state,,pure,no,18,"Get the target state for an action from current state, if valid.",Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,get_valid_transitions,get_valid_transitions(from_state: KnowledgePlaneLifecycleState) -> Set[KnowledgePlaneLifecycleState],?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,copy | get | set,,pure,no,5,Get all valid target states from a given state.,Operation,high,called by L4 orchestrator
_models,L7,knowledge_lifecycle,is_valid_transition,"is_valid_transition(from_state: KnowledgePlaneLifecycleState, to_state: KnowledgePlaneLifecycleState) -> bool",?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,get | set,,pure,no,12,Check if a lifecycle transition is valid.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'is_valid')
_models,L7,knowledge_lifecycle,validate_transition,"validate_transition(from_state: KnowledgePlaneLifecycleState, to_state: KnowledgePlaneLifecycleState) -> TransitionResult",?:lifecycle_worker | ?:knowledge_lifecycle_manager | ?:knowledge_sdk | ?:onboarding | ?:offboarding | ?:base | L4:lifecycle_stages_base | L4:onboarding | L4:offboarding | ?:test_async_job_coordination,TransitionResult | get_valid_transitions | is_valid_transition | requires_async_job | requires_policy_gate,,pure,no,40,Validate a lifecycle transition and return detailed result.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate')
_models,L7,log_exports,generate_uuid,generate_uuid() -> str,?:logs_facade | L6:logs_domain_store,str | uuid4,sqlmodel,pure,no,3,Generate a UUID string.,Unclassified,low,no classification rules matched
_models,L7,log_exports,utc_now,utc_now() -> datetime,?:logs_facade | L6:logs_domain_store,now,sqlmodel,pure,no,3,Return current UTC time.,Unclassified,low,no classification rules matched
_models,L7,logs_records,generate_uuid,generate_uuid() -> str,?:pool | ?:runner | L7:__init__ | ?:logs_facade | ?:main | L6:logs_domain_store,str | uuid4,postgresql | sqlalchemy | sqlmodel,pure,no,3,Generate a UUID string.,Unclassified,low,no classification rules matched
_models,L7,logs_records,utc_now,utc_now() -> datetime,?:pool | ?:runner | L7:__init__ | ?:logs_facade | ?:main | L6:logs_domain_store,now,postgresql | sqlalchemy | sqlmodel,pure,no,3,Return current UTC time.,Unclassified,low,no classification rules matched
_models,L7,m10_recovery,SuggestionAction.matches_error,matches_error(error_code: str) -> bool,?:test_m10_recovery_enhanced,any | startswith | upper,orm | postgresql | sql | sqlalchemy,pure,no,6,Check if action applies to given error code.,Unclassified,low,no classification rules matched
_models,L7,m10_recovery,SuggestionAction.matches_skill,matches_skill(skill_id: str) -> bool,?:test_m10_recovery_enhanced,,orm | postgresql | sql | sqlalchemy,pure,no,6,Check if action applies to given skill.,Unclassified,low,no classification rules matched
_models,L7,m10_recovery,SuggestionAction.to_dict,"to_dict() -> Dict[str, Any]",?:test_m10_recovery_enhanced,isoformat,orm | postgresql | sql | sqlalchemy,pure,no,24,Serialize to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,m10_recovery,SuggestionInput.to_dict,"to_dict() -> Dict[str, Any]",?:test_m10_recovery_enhanced,isoformat,orm | postgresql | sql | sqlalchemy,pure,no,14,Serialize to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,m10_recovery,SuggestionProvenance.to_dict,"to_dict() -> Dict[str, Any]",?:test_m10_recovery_enhanced,isoformat,orm | postgresql | sql | sqlalchemy,pure,no,16,Serialize to dictionary.,Internal Helper,medium,name matches 'to_'
_models,L7,monitor_config,MonitorConfig.allowed_rag_sources,allowed_rag_sources() -> list[str],?:test_monitor_enhancements | ?:test_inspection_constraints,loads,pydantic | sqlmodel,pure,no,5,Get allowed RAG sources as list.,Policy/Decision,medium,name matches 'allow'
_models,L7,monitor_config,MonitorConfig.allowed_rag_sources,allowed_rag_sources(value: list[str]) -> None,?:test_monitor_enhancements | ?:test_inspection_constraints,dumps,pydantic | sqlmodel,pure,no,3,Set allowed RAG sources from list.,Policy/Decision,medium,name matches 'allow'
_models,L7,monitor_config,MonitorConfig.enabled_metrics,enabled_metrics() -> list[MonitorMetric],?:test_monitor_enhancements | ?:test_inspection_constraints,append,pydantic | sqlmodel,pure,no,18,Get list of enabled monitor metrics.,Unclassified,low,no classification rules matched
_models,L7,monitor_config,MonitorConfig.is_metric_monitored,is_metric_monitored(metric: MonitorMetric) -> bool,?:test_monitor_enhancements | ?:test_inspection_constraints,,pydantic | sqlmodel,pure,no,3,Check if a specific metric is being monitored.,Unclassified,low,no classification rules matched
_models,L7,monitor_config,MonitorConfig.to_snapshot,to_snapshot() -> dict,?:test_monitor_enhancements | ?:test_inspection_constraints,,pydantic | sqlmodel,pure,no,14,Convert to snapshot dict for immutable storage.,Internal Helper,medium,name matches 'to_'
_models,L7,override_authority,OverrideAuthority.allowed_roles,allowed_roles() -> list[str],?:test_override_authority,loads,pydantic | sqlmodel,pure,no,5,Get allowed roles as list.,Policy/Decision,medium,name matches 'allow'
_models,L7,override_authority,OverrideAuthority.allowed_roles,allowed_roles(value: list[str]) -> None,?:test_override_authority,dumps,pydantic | sqlmodel,pure,no,3,Set allowed roles from list.,Policy/Decision,medium,name matches 'allow'
_models,L7,override_authority,OverrideAuthority.apply_override,"apply_override(user_id: str, user_role: str, reason: str, duration_seconds: Optional[int]) -> tuple[bool, str]",?:test_override_authority,can_override | date | now | replace,pydantic | sqlmodel,pure,no,36,Apply an override to the policy.,Unclassified,low,no classification rules matched
_models,L7,override_authority,OverrideAuthority.can_override,"can_override(user_role: str) -> tuple[bool, str]",?:test_override_authority,,pydantic | sqlmodel,pure,no,17,Check if user with given role can override.,Policy/Decision,medium,name matches 'can_'
_models,L7,override_authority,OverrideAuthority.clear_override,clear_override() -> None,?:test_override_authority,now,pydantic | sqlmodel,pure,no,8,Clear the current override.,Unclassified,low,no classification rules matched
_models,L7,override_authority,OverrideAuthority.is_override_active,is_override_active() -> bool,?:test_override_authority,now,pydantic | sqlmodel,pure,no,7,Check if an override is currently active.,Unclassified,low,no classification rules matched
_models,L7,override_authority,OverrideAuthority.reset_daily_count,reset_daily_count() -> None,?:test_override_authority,,pydantic | sqlmodel,pure,no,3,Reset the daily override count (called by scheduler).,Unclassified,low,no classification rules matched
_models,L7,override_authority,OverrideRecord.create_record,"create_record(policy_id: str, tenant_id: str, override_by: str, override_role: str, reason: str, duration_seconds: int, run_id: Optional[str]) -> 'OverrideRecord'",?:test_override_authority,cls | now | replace,pydantic | sqlmodel,pure,no,23,Create an override record.,Unclassified,low,no classification rules matched
_models,L7,policy_control_plane,PolicyRule.retire,"retire(by: str, reason: str, superseded_by_id: Optional[str]) -> None",?:policy | ?:policy_limits_crud | L7:__init__ | ?:llm_threshold_service | ?:policies_facade | ?:cross_domain | ?:overview_facade | ?:policy_rules_service | ?:policy_limits_service | ?:simulation_driver,utc_now,postgresql | sqlalchemy | sqlmodel,pure,no,8,Retire this rule (PIN-412).,Unclassified,low,no classification rules matched
_models,L7,policy_control_plane,generate_uuid,generate_uuid() -> str,?:policy | ?:policy_limits_crud | L7:__init__ | ?:llm_threshold_service | ?:policies_facade | ?:cross_domain | ?:overview_facade | ?:policy_rules_service | ?:policy_limits_service | ?:simulation_driver,str | uuid4,postgresql | sqlalchemy | sqlmodel,pure,no,3,Generate a UUID string (PIN-412).,Unclassified,low,no classification rules matched
_models,L7,policy_control_plane,utc_now,utc_now() -> datetime,?:policy | ?:policy_limits_crud | L7:__init__ | ?:llm_threshold_service | ?:policies_facade | ?:cross_domain | ?:overview_facade | ?:policy_rules_service | ?:policy_limits_service | ?:simulation_driver,now,postgresql | sqlalchemy | sqlmodel,pure,no,3,Return current UTC time (PIN-412).,Unclassified,low,no classification rules matched
_models,L7,policy_precedence,PolicyPrecedence.to_snapshot,to_snapshot() -> dict,?:arbitrator | L6:arbitrator | ?:test_control_action_enhancements,,pydantic | sqlmodel,pure,no,9,Convert to snapshot dict for immutable storage.,Internal Helper,medium,name matches 'to_'
_models,L7,policy_scope,PolicyScope.agent_ids,agent_ids() -> list[str],?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,loads,pydantic | sqlmodel,pure,no,5,Get agent IDs as list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.agent_ids,agent_ids(value: list[str]) -> None,?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,dumps,pydantic | sqlmodel,pure,no,3,Set agent IDs from list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.api_key_ids,api_key_ids() -> list[str],?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,loads,pydantic | sqlmodel,pure,no,5,Get API key IDs as list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.api_key_ids,api_key_ids(value: list[str]) -> None,?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,dumps,pydantic | sqlmodel,pure,no,3,Set API key IDs from list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.create_agent_scope,"create_agent_scope(policy_id: str, tenant_id: str, agent_ids: list[str], created_by: Optional[str]) -> 'PolicyScope'",?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,cls,pydantic | sqlmodel,pure,no,16,Factory method for AGENT scope.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.create_all_runs_scope,"create_all_runs_scope(policy_id: str, tenant_id: str, created_by: Optional[str]) -> 'PolicyScope'",?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,cls,pydantic | sqlmodel,pure,no,13,Factory method for ALL_RUNS scope.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.create_api_key_scope,"create_api_key_scope(policy_id: str, tenant_id: str, api_key_ids: list[str], created_by: Optional[str]) -> 'PolicyScope'",?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,cls,pydantic | sqlmodel,pure,no,16,Factory method for API_KEY scope.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.create_human_actor_scope,"create_human_actor_scope(policy_id: str, tenant_id: str, human_actor_ids: list[str], created_by: Optional[str]) -> 'PolicyScope'",?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,cls,pydantic | sqlmodel,pure,no,16,Factory method for HUMAN_ACTOR scope.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.human_actor_ids,human_actor_ids() -> list[str],?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,loads,pydantic | sqlmodel,pure,no,5,Get human actor IDs as list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.human_actor_ids,human_actor_ids(value: list[str]) -> None,?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,dumps,pydantic | sqlmodel,pure,no,3,Set human actor IDs from list.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.matches,"matches(agent_id: Optional[str], api_key_id: Optional[str], human_actor_id: Optional[str]) -> bool",?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,ScopeType,pydantic | sqlmodel,pure,no,32,Check if this scope matches the given run context.,Unclassified,low,no classification rules matched
_models,L7,policy_scope,PolicyScope.to_snapshot,to_snapshot() -> dict,?:scope_resolver | L6:scope_resolver | ?:test_export_scope_resolution | ?:test_scope_selector,,pydantic | sqlmodel,pure,no,9,Convert to snapshot dict for immutable storage.,Internal Helper,medium,name matches 'to_'
_models,L7,policy_snapshot,PolicySnapshot.create_snapshot,"create_snapshot(tenant_id: str, policies: list[dict[str, Any]], thresholds: dict[str, Any], policy_version: Optional[str]) -> 'PolicySnapshot'",?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,cls | dumps | encode | hexdigest | len | sha256,pydantic | sqlmodel,pure,no,43,Create immutable snapshot with content hash.,Unclassified,low,no classification rules matched
_models,L7,policy_snapshot,PolicySnapshot.get_policies,"get_policies() -> list[dict[str, Any]]",?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,loads,pydantic | sqlmodel,pure,no,3,Deserialize policies from JSON.,Unclassified,low,no classification rules matched
_models,L7,policy_snapshot,PolicySnapshot.get_threshold_hash,get_threshold_hash() -> str,?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,encode | hexdigest | sha256,pydantic | sqlmodel,pure,no,6,Get or compute threshold hash (GAP-022).,Unclassified,low,no classification rules matched
_models,L7,policy_snapshot,PolicySnapshot.get_thresholds,"get_thresholds() -> dict[str, Any]",?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,loads,pydantic | sqlmodel,pure,no,3,Deserialize thresholds from JSON.,Unclassified,low,no classification rules matched
_models,L7,policy_snapshot,PolicySnapshot.verify_integrity,verify_integrity() -> bool,?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,encode | hexdigest | sha256,pydantic | sqlmodel,pure,no,5,Verify content hash matches stored data.,Policy/Decision,medium,name matches 'verify'
_models,L7,policy_snapshot,PolicySnapshot.verify_threshold_integrity,verify_threshold_integrity() -> bool,?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,encode | hexdigest | sha256,pydantic | sqlmodel,pure,no,6,Verify threshold hash matches stored threshold data (GAP-022).,Policy/Decision,medium,name matches 'verify'
_models,L7,policy_snapshot,utc_now,utc_now() -> datetime,?:prevention_engine | L7:__init__ | L5:prevention_engine | ?:test_threshold_snapshot_hash,now,pydantic | sqlmodel,pure,no,3,Return timezone-aware UTC datetime.,Unclassified,low,no classification rules matched
_models,L7,retrieval_evidence,RetrievalEvidence.doc_count,doc_count() -> int,?:test_retrieval_evidence,len,postgresql | sqlalchemy | sqlmodel,pure,no,3,Number of documents returned.,Unclassified,low,no classification rules matched
_models,L7,retrieval_evidence,RetrievalEvidence.is_complete,is_complete() -> bool,?:test_retrieval_evidence,,postgresql | sqlalchemy | sqlmodel,pure,no,3,Check if the retrieval has completed.,Unclassified,low,no classification rules matched
_models,L7,retrieval_evidence,generate_uuid,generate_uuid() -> str,?:test_retrieval_evidence,str | uuid4,postgresql | sqlalchemy | sqlmodel,pure,no,3,Generate a new UUID string.,Unclassified,low,no classification rules matched
_models,L7,retrieval_evidence,utc_now,utc_now() -> datetime,?:test_retrieval_evidence,now,postgresql | sqlalchemy | sqlmodel,pure,no,3,Return current UTC time with timezone info.,Unclassified,low,no classification rules matched
_models,L7,run_lifecycle,get_lifecycle_state,get_lifecycle_state(status: RunStatus) -> RunLifecycleState,L7:__init__,,pydantic,pure,no,4,Map run status to lifecycle state.,Unclassified,low,no classification rules matched
_models,L7,tenant,APIKey.generate_key,"generate_key() -> tuple[str, str, str]",?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,encode | hexdigest | sha256 | token_urlsafe,onboarding_state | sqlmodel | tier_gating,pure,no,8,"Generate a new API key. Returns (full_key, prefix, hash).",Unclassified,low,no classification rules matched
_models,L7,tenant,APIKey.hash_key,hash_key(key: str) -> str,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,encode | hexdigest | sha256,onboarding_state | sqlmodel | tier_gating,pure,no,3,Hash a key for comparison.,Unclassified,low,no classification rules matched
_models,L7,tenant,APIKey.is_valid,is_valid() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,utc_now,onboarding_state | sqlmodel | tier_gating,pure,no,7,"Check if key is valid (not revoked, not expired).",Policy/Decision,medium,name matches 'is_valid'
_models,L7,tenant,APIKey.record_usage,record_usage(),?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,utc_now,onboarding_state | sqlmodel | tier_gating,pure,no,4,Record that this key was used.,Unclassified,low,no classification rules matched
_models,L7,tenant,FounderAction.is_reversal,is_reversal() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,3,Check if this action is a reversal action.,Unclassified,low,no classification rules matched
_models,L7,tenant,Invitation.generate_token,"generate_token() -> tuple[str, str]",?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,encode | hexdigest | sha256 | token_urlsafe,onboarding_state | sqlmodel | tier_gating,pure,no,5,"Generate invitation token. Returns (token, hash).",Unclassified,low,no classification rules matched
_models,L7,tenant,Invitation.is_valid,is_valid() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,utc_now,onboarding_state | sqlmodel | tier_gating,pure,no,7,Check if invitation is valid (pending and not expired).,Policy/Decision,medium,name matches 'is_valid'
_models,L7,tenant,Tenant.can_access_endpoint,can_access_endpoint(required_state: int) -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,7,Check if tenant's onboarding state allows access to an endpoint.,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,Tenant.can_create_run,"can_create_run() -> tuple[bool, str]",?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,7,Check if tenant can create a new run.,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,Tenant.can_use_tokens,"can_use_tokens(tokens: int) -> tuple[bool, str]",?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,5,Check if tenant can use given tokens.,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,Tenant.get_available_features,get_available_features() -> list[str],?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,get_tier_features,onboarding_state | sqlmodel | tier_gating,pure,no,5,Get list of all features available to this tenant.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.has_completed_onboarding,has_completed_onboarding() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,5,Check if tenant has completed onboarding.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.has_feature,has_feature(feature: str) -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,check_tier_access,onboarding_state | sqlmodel | tier_gating,pure,no,10,Check if tenant has access to a feature based on their tier.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.increment_usage,increment_usage(tokens: int),?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,utc_now,onboarding_state | sqlmodel | tier_gating,pure,no,6,Increment usage counters.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.onboarding,onboarding() -> 'OnboardingState',?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,OnboardingState,onboarding_state | sqlmodel | tier_gating,pure,no,10,Get the tenant's onboarding state as an enum.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.retention_days,retention_days() -> int,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,get,onboarding_state | sqlmodel | tier_gating,pure,no,5,Get log retention days based on tier.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.tier,tier() -> 'TenantTier',?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,resolve_tier,onboarding_state | sqlmodel | tier_gating,pure,no,10,Get the tenant's tier from their plan.,Unclassified,low,no classification rules matched
_models,L7,tenant,Tenant.tier_marketing_name,tier_marketing_name() -> str,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,get,onboarding_state | sqlmodel | tier_gating,pure,no,5,Get the marketing name for the tenant's tier.,Unclassified,low,no classification rules matched
_models,L7,tenant,TenantMembership.can_change_roles,can_change_roles() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,3,Check if this member can change other users' roles.,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,TenantMembership.can_manage_keys,can_manage_keys() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,2,,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,TenantMembership.can_manage_users,can_manage_users() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,3,Check if this member can invite/manage other users.,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,TenantMembership.can_run_workers,can_run_workers() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,2,,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,TenantMembership.can_view_runs,can_view_runs() -> bool,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,,onboarding_state | sqlmodel | tier_gating,pure,no,2,,Policy/Decision,medium,name matches 'can_'
_models,L7,tenant,User.get_preferences,get_preferences() -> dict,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,loads,onboarding_state | sqlmodel | tier_gating,pure,no,9,"Parse preferences JSON, return empty dict if None.",Unclassified,low,no classification rules matched
_models,L7,tenant,User.set_preferences,set_preferences(prefs: dict) -> None,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,dumps,onboarding_state | sqlmodel | tier_gating,pure,no,4,Set preferences from dict.,Unclassified,low,no classification rules matched
_models,L7,tenant,generate_uuid,generate_uuid() -> str,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,str | uuid4,onboarding_state | sqlmodel | tier_gating,pure,no,2,,Unclassified,low,no classification rules matched
_models,L7,tenant,utc_now,utc_now() -> datetime,?:gateway_audit | ?:api_key_driver | ?:role_guard | ?:onboarding_gate | ?:onboarding_transitions | ?:tenant_auth | ?:predictions | ?:aos_accounts | ?:guard | ?:v1_proxy,utcnow,onboarding_state | sqlmodel | tier_gating,pure,no,7,Return current UTC time as a naive datetime (no timezone info).,Unclassified,low,no classification rules matched
_models,L7,threshold_signal,ThresholdSignal.acknowledge,acknowledge(user_id: str) -> None,?:alert_emitter | L4:alert_emitter | ?:test_control_action_enhancements | ?:test_limit_enhancements,now,pydantic | sqlmodel,pure,no,5,Acknowledge a NEAR signal.,Operation,high,called by L4 orchestrator
_models,L7,threshold_signal,ThresholdSignal.create_breach_signal,"create_breach_signal(run_id: str, policy_id: str, tenant_id: str, metric: ThresholdMetric, current_value: float, threshold_value: float, action_taken: str, step_index: Optional[int]) -> 'ThresholdSignal'",?:alert_emitter | L4:alert_emitter | ?:test_control_action_enhancements | ?:test_limit_enhancements,cls,pydantic | sqlmodel,pure,no,25,Factory method for BREACH threshold signals.,Operation,high,called by L4 orchestrator
_models,L7,threshold_signal,ThresholdSignal.create_near_signal,"create_near_signal(run_id: str, policy_id: str, tenant_id: str, metric: ThresholdMetric, current_value: float, threshold_value: float, step_index: Optional[int]) -> 'ThresholdSignal'",?:alert_emitter | L4:alert_emitter | ?:test_control_action_enhancements | ?:test_limit_enhancements,cls,pydantic | sqlmodel,pure,no,23,Factory method for NEAR threshold signals.,Operation,high,called by L4 orchestrator
_models,L7,threshold_signal,ThresholdSignal.mark_alert_sent,mark_alert_sent(channels: list[str]) -> None,?:alert_emitter | L4:alert_emitter | ?:test_control_action_enhancements | ?:test_limit_enhancements,dumps | now,pydantic | sqlmodel,pure,no,7,Mark alert as sent via specified channels.,Operation,high,called by L4 orchestrator
_models,L7,threshold_signal,ThresholdSignal.to_evidence,to_evidence() -> dict,?:alert_emitter | L4:alert_emitter | ?:test_control_action_enhancements | ?:test_limit_enhancements,isoformat,pydantic | sqlmodel,pure,no,13,Convert to evidence dict for export bundles.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
account,L5,accounts_facade,AccountsFacade.__init__,__init__(driver: AccountsFacadeDriver | None) -> None,?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,get_accounts_facade_driver,__future__ | accounts_facade_driver | asyncio,pure,no,3,Initialize facade with optional driver injection.,Internal Helper,high,dunder method
account,L5,accounts_facade,AccountsFacade.accept_invitation,"async accept_invitation(session: AsyncSession, invitation_id: str, token: str) -> AcceptInvitationResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AcceptInvitationResult | encode | fetch_invitation_by_id_and_token | fetch_membership | fetch_user_by_email | hexdigest | insert_membership | insert_user | now | sha256 | split | update_invitation_accepted | update_invitation_expired,__future__ | accounts_facade_driver | asyncio,pure,yes,67,Accept an invitation to join a tenant. Public endpoint.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.create_support_ticket,"async create_support_ticket(session: AsyncSession, tenant_id: str, user_id: str) -> SupportTicketResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,SupportTicketResult | insert_support_ticket,__future__ | accounts_facade_driver | asyncio,pure,yes,35,Create a support ticket.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_billing_invoices,"async get_billing_invoices(session: AsyncSession, tenant_id: str) -> InvoiceListResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | InvoiceListResult | fetch_tenant_detail | lower,__future__ | accounts_facade_driver | asyncio,pure,yes,31,Get billing invoice history.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_billing_summary,"async get_billing_summary(session: AsyncSession, tenant_id: str) -> BillingSummaryResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | BillingSummaryResult | fetch_subscription | fetch_tenant_detail | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,55,Get billing summary for the tenant.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_profile,"async get_profile(session: AsyncSession, tenant_id: str, clerk_user_id: Optional[str]) -> ProfileResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,ProfileResult | fetch_profile | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,21,Get current user profile.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_project_detail,"async get_project_detail(session: AsyncSession, tenant_id: str, project_id: str) -> Optional[ProjectDetailResult]",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,ProjectDetailResult | fetch_tenant_detail | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,36,Get project detail. User can only see their own tenant/project.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_support_contact,get_support_contact() -> SupportContactResult,?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,SupportContactResult,__future__ | accounts_facade_driver | asyncio,pure,no,7,Get support contact information.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.get_user_detail,"async get_user_detail(session: AsyncSession, tenant_id: str, user_id: str) -> Optional[UserDetailResult]",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,UserDetailResult | fetch_user_detail | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,30,Get user detail. Tenant isolation enforced.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.invite_user,"async invite_user(session: AsyncSession, tenant_id: str, caller_user_id: str) -> InvitationResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | InvitationResult | can_manage_users | encode | fetch_invitation_by_email | fetch_membership | hexdigest | insert_invitation | now | sha256 | timedelta | token_urlsafe,__future__ | accounts_facade_driver | asyncio,pure,yes,60,Invite a user to join the tenant. Requires owner or admin role.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.list_invitations,"async list_invitations(session: AsyncSession, tenant_id: str, caller_user_id: str) -> InvitationListResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | InvitationListResult | InvitationResult | can_manage_users | fetch_invitations | fetch_membership | len,__future__ | accounts_facade_driver | asyncio,pure,yes,41,List invitations for the tenant. Requires owner or admin role.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.list_projects,"async list_projects(session: AsyncSession, tenant_id: str) -> ProjectsListResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,ProjectSummaryResult | ProjectsListResult | count_tenants | fetch_tenants | len | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,39,"List projects (tenants). In current architecture, Tenant = Project.",Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.list_support_tickets,"async list_support_tickets(session: AsyncSession, tenant_id: str) -> SupportTicketListResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,SupportTicketListResult | SupportTicketResult | fetch_support_tickets | len,__future__ | accounts_facade_driver | asyncio,pure,yes,31,List support tickets for the tenant.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.list_tenant_users,"async list_tenant_users(session: AsyncSession, tenant_id: str) -> TenantUsersListResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,TenantUserResult | TenantUsersListResult | fetch_tenant_memberships | len,__future__ | accounts_facade_driver | asyncio,pure,yes,22,List users in the current tenant.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.list_users,"async list_users(session: AsyncSession, tenant_id: str) -> UsersListResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,UserSummaryResult | UsersListResult | count_users | fetch_users | len | upper,__future__ | accounts_facade_driver | asyncio,pure,yes,44,List users in the tenant.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.remove_user,"async remove_user(session: AsyncSession, tenant_id: str, caller_user_id: str, target_user_id: str) -> dict[str, str] | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | can_manage_users | delete_membership | fetch_membership,__future__ | accounts_facade_driver | asyncio,pure,yes,52,Remove a user from the tenant. Requires owner or admin role.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.update_profile,"async update_profile(session: AsyncSession, user_id: str) -> ProfileUpdateResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | ProfileUpdateResult | fetch_user_by_id | get | get_preferences | update_user_profile,__future__ | accounts_facade_driver | asyncio,pure,yes,37,Update current user's profile and preferences.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,AccountsFacade.update_user_role,"async update_user_role(session: AsyncSession, tenant_id: str, caller_user_id: str, target_user_id: str, new_role: str) -> TenantUserResult | AccountsErrorResult",?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsErrorResult | TenantUserResult | can_change_roles | fetch_membership | fetch_membership_with_user | update_membership_role,__future__ | accounts_facade_driver | asyncio,pure,yes,64,Update a user's role in the tenant. Requires owner role.,Operation,high,called by L4 orchestrator
account,L5,accounts_facade,get_accounts_facade,get_accounts_facade() -> AccountsFacade,?:aos_accounts | L5:__init__ | L2:aos_accounts | L4:account_handler,AccountsFacade,__future__ | accounts_facade_driver | asyncio,pure,no,6,Get the singleton AccountsFacade instance.,Operation,high,called by L4 orchestrator
account,L5,billing_provider,BillingProvider.get_billing_state,get_billing_state(tenant_id: str) -> BillingState,,,limits | plan | state,pure,no,11,Get the billing state for a tenant.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,BillingProvider.get_limits,get_limits(plan: Plan) -> Limits,,,limits | plan | state,pure,no,13,Derive limits from a plan.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,BillingProvider.get_plan,get_plan(tenant_id: str) -> Plan,,,limits | plan | state,pure,no,11,Get the plan for a tenant.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,BillingProvider.is_limit_exceeded,"is_limit_exceeded(tenant_id: str, limit_name: str, current_value: float) -> bool",,,limits | plan | state,pure,no,15,Check if a specific limit is exceeded.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.__init__,__init__() -> None,,,limits | plan | state,pure,no,5,Initialize mock provider with in-memory state.,Internal Helper,high,dunder method
account,L5,billing_provider,MockBillingProvider.get_billing_state,get_billing_state(tenant_id: str) -> BillingState,,default | get,limits | plan | state,pure,no,7,Get the billing state for a tenant.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.get_limits,get_limits(plan: Plan) -> Limits,,derive_limits,limits | plan | state,pure,no,7,Derive limits from a plan.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.get_plan,get_plan(tenant_id: str) -> Plan,,get,limits | plan | state,pure,no,7,Get the plan for a tenant.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.is_limit_exceeded,"is_limit_exceeded(tenant_id: str, limit_name: str, current_value: float) -> bool",,get_limits | get_plan | getattr,limits | plan | state,pure,no,25,Check if a specific limit is exceeded.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.reset,reset() -> None,,clear,limits | plan | state,pure,no,4,Reset all mock state (for testing).,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.set_billing_state,"set_billing_state(tenant_id: str, state: BillingState) -> None",,info,limits | plan | state,pure,no,10,Set billing state for a tenant (mock/test only).,Internal Helper,low,pure function with no callers
account,L5,billing_provider,MockBillingProvider.set_plan,"set_plan(tenant_id: str, plan: Plan) -> None",,info,limits | plan | state,pure,no,10,Set plan for a tenant (mock/test only).,Internal Helper,low,pure function with no callers
account,L5,billing_provider,get_billing_provider,get_billing_provider() -> BillingProvider,,MockBillingProvider,limits | plan | state,pure,no,11,Get the billing provider instance.,Internal Helper,low,pure function with no callers
account,L5,billing_provider,set_billing_provider,set_billing_provider(provider: BillingProvider) -> None,,,limits | plan | state,pure,no,8,Set the billing provider instance.,Internal Helper,low,pure function with no callers
account,L5,crm_validator_engine,ValidatorService.__init__,__init__(capability_registry: Optional[list[str]]),L4:contract_engine | L4:__init__,frozenset,,pure,no,9,Initialize validator with optional capability registry.,Internal Helper,high,dunder method
account,L5,crm_validator_engine,ValidatorService._build_reason,"_build_reason(issue_type: IssueType, severity: Severity, action: RecommendedAction, confidence: Decimal) -> str",L4:contract_engine | L4:__init__,Decimal | append | float | join,,pure,no,26,Build human-readable reason for verdict.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._calculate_confidence,"_calculate_confidence(source: str, type_confidence: Decimal, capabilities: list[str]) -> Decimal",L4:contract_engine | L4:__init__,Decimal | _get_capability_confidence | _get_source_weight | max | min,,pure,no,26,Calculate overall confidence score.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._classify_issue_type,"_classify_issue_type(text: str) -> tuple[IssueType, Decimal, dict[str, Any]]",L4:contract_engine | L4:__init__,Decimal | append | max | min,,pure,no,65,Classify issue type from text.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._classify_severity,"_classify_severity(text: str, issue_type: IssueType) -> tuple[Severity, Decimal]",L4:contract_engine | L4:__init__,Decimal | min | sum,,pure,no,34,Classify severity from text and issue type.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._create_fallback_verdict,"_create_fallback_verdict(error_type: ValidatorErrorType, message: str) -> ValidatorVerdict",L4:contract_engine | L4:__init__,Decimal | ValidatorVerdict | now,,pure,no,19,Create fallback verdict on error.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._determine_action,"_determine_action(issue_type: IssueType, severity: Severity, confidence: Decimal) -> RecommendedAction",L4:contract_engine | L4:__init__,Decimal,,pure,no,37,Determine recommended action.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._do_validate,_do_validate(input: ValidatorInput) -> ValidatorVerdict,L4:contract_engine | L4:__init__,ValidatorVerdict | _build_reason | _calculate_confidence | _classify_issue_type | _classify_severity | _determine_action | _extract_capabilities | _extract_text | _find_severity_indicators | _get_capability_confidence | _get_source_weight | float | list | lower | now,,pure,no,52,Internal validation logic.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._extract_capabilities,"_extract_capabilities(text: str, hints: Optional[list[str]]) -> list[str]",L4:contract_engine | L4:__init__,add | escape | lower | search | set | sorted | update,,db_write,no,29,Extract affected capabilities from text.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._extract_text,"_extract_text(payload: dict[str, Any]) -> str",L4:contract_engine | L4:__init__,append | isinstance | join | str,,pure,no,23,Extract searchable text from payload.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._find_severity_indicators,"_find_severity_indicators(text: str) -> dict[str, list[str]]",L4:contract_engine | L4:__init__,,,pure,no,7,Find severity indicators in text for evidence.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._get_capability_confidence,_get_capability_confidence(capabilities: list[str]) -> Decimal,L4:contract_engine | L4:__init__,Decimal | all | any,,pure,no,14,Get confidence modifier based on capability matches.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService._get_source_weight,_get_source_weight(source: str) -> Decimal,L4:contract_engine | L4:__init__,Decimal | get,,pure,no,14,Get confidence weight for source.,Internal Helper,medium,private function
account,L5,crm_validator_engine,ValidatorService.validate,validate(input: ValidatorInput) -> ValidatorVerdict,L4:contract_engine | L4:__init__,_create_fallback_verdict | _do_validate | str,,pure,no,24,Validate an issue and produce a verdict.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate')
account,L5,email_verification,EmailVerificationError.__init__,"__init__(message: str, error_code: str)",L5:__init__,__init__ | super,httpx | redis,pure,no,4,,Internal Helper,high,dunder method
account,L5,email_verification,EmailVerificationService.__init__,__init__(redis_client: Optional[Redis]),L5:__init__,from_url,httpx | redis,pure,no,6,,Internal Helper,high,dunder method
account,L5,email_verification,EmailVerificationService._attempts_key,_attempts_key(email: str) -> str,L5:__init__,encode | hexdigest | lower | sha256,httpx | redis,pure,no,4,Generate Redis key for attempt tracking.,Internal Helper,medium,private function
account,L5,email_verification,EmailVerificationService._cooldown_key,_cooldown_key(email: str) -> str,L5:__init__,encode | hexdigest | lower | sha256,httpx | redis,pure,no,4,Generate Redis key for cooldown tracking.,Internal Helper,medium,private function
account,L5,email_verification,EmailVerificationService._generate_otp,_generate_otp() -> str,L5:__init__,choice | join | range,httpx | redis,pure,no,3,Generate a cryptographically secure OTP.,Internal Helper,medium,private function
account,L5,email_verification,EmailVerificationService._otp_key,_otp_key(email: str) -> str,L5:__init__,encode | hexdigest | lower | sha256,httpx | redis,pure,no,4,Generate Redis key for OTP storage.,Internal Helper,medium,private function
account,L5,email_verification,EmailVerificationService._send_otp_email,"async _send_otp_email(email: str, otp: str, name: Optional[str])",L5:__init__,AsyncClient | EmailVerificationError | error | post | warning,httpx | redis,external_api,yes,74,Send OTP email via Resend.,Internal Helper,medium,private function
account,L5,email_verification,EmailVerificationService.send_otp,"async send_otp(email: str, name: Optional[str]) -> dict",L5:__init__,EmailVerificationError | _attempts_key | _cooldown_key | _generate_otp | _otp_key | _send_otp_email | delete | exists | info | lower | setex | strip | ttl,httpx | redis,db_write,yes,46,Generate and send OTP to email address.,Unclassified,low,no classification rules matched
account,L5,email_verification,EmailVerificationService.verify_otp,"verify_otp(email: str, otp: str) -> VerificationResult",L5:__init__,VerificationResult | _attempts_key | _otp_key | delete | expire | get | incr | int | lower | max | split | strip,httpx | redis,db_write,no,58,Verify OTP code.,Policy/Decision,medium,name matches 'verify'
account,L5,email_verification,get_email_verification_service,get_email_verification_service() -> EmailVerificationService,L5:__init__,EmailVerificationService,httpx | redis,pure,no,6,Get email verification service singleton.,Unclassified,low,no classification rules matched
account,L5,identity_resolver,APIKeyIdentityResolver.provider,provider() -> IdentityProvider,?:__init__,,iam_service | jwt,pure,no,2,,Unclassified,low,no classification rules matched
account,L5,identity_resolver,APIKeyIdentityResolver.resolve,"async resolve(credential: str, tenant_id: Optional[str]) -> Optional[Identity]",?:__init__,Identity | len,iam_service | jwt,pure,yes,19,Resolve identity from API key.,Coordinator/Aggregator,medium,name matches 'resolve'
account,L5,identity_resolver,ClerkIdentityResolver.__init__,__init__(clerk_secret_key: Optional[str]),?:__init__,getenv,iam_service | jwt,pure,no,3,,Internal Helper,high,dunder method
account,L5,identity_resolver,ClerkIdentityResolver.provider,provider() -> IdentityProvider,?:__init__,,iam_service | jwt,pure,no,2,,Unclassified,low,no classification rules matched
account,L5,identity_resolver,ClerkIdentityResolver.resolve,"async resolve(credential: str, tenant_id: Optional[str]) -> Optional[Identity]",?:__init__,Identity | decode | get | set | warning,iam_service | jwt,pure,yes,28,Resolve identity from Clerk JWT.,Coordinator/Aggregator,medium,name matches 'resolve'
account,L5,identity_resolver,IdentityChain.resolve,"async resolve(credential: str, provider_hint: Optional[IdentityProvider], tenant_id: Optional[str]) -> Optional[Identity]",?:__init__,debug | resolve,iam_service | jwt,pure,yes,36,Resolve identity using the resolver chain.,Coordinator/Aggregator,medium,name matches 'resolve'
account,L5,identity_resolver,IdentityResolver.provider,provider() -> IdentityProvider,?:__init__,,iam_service | jwt,pure,no,3,Get the provider type.,Unclassified,low,no classification rules matched
account,L5,identity_resolver,IdentityResolver.resolve,"async resolve(credential: str, tenant_id: Optional[str]) -> Optional[Identity]",?:__init__,,iam_service | jwt,pure,yes,7,Resolve an identity from a credential.,Coordinator/Aggregator,medium,name matches 'resolve'
account,L5,identity_resolver,SystemIdentityResolver.provider,provider() -> IdentityProvider,?:__init__,,iam_service | jwt,pure,no,2,,Unclassified,low,no classification rules matched
account,L5,identity_resolver,SystemIdentityResolver.resolve,"async resolve(credential: str, tenant_id: Optional[str]) -> Optional[Identity]",?:__init__,Identity,iam_service | jwt,pure,yes,13,Create a system identity.,Coordinator/Aggregator,medium,name matches 'resolve'
account,L5,identity_resolver,create_default_identity_chain,create_default_identity_chain() -> IdentityChain,?:__init__,APIKeyIdentityResolver | ClerkIdentityResolver | IdentityChain | SystemIdentityResolver,iam_service | jwt,pure,no,9,Create the default identity resolver chain.,Unclassified,low,no classification rules matched
account,L5,notifications_facade,ChannelInfo.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:account_handler,,,pure,no,9,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
account,L5,notifications_facade,NotificationInfo.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:account_handler,,,pure,no,16,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
account,L5,notifications_facade,NotificationPreferences.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:account_handler,,,pure,no,8,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
account,L5,notifications_facade,NotificationsFacade.__init__,__init__(),L5:__init__ | L4:account_handler,ChannelInfo,,pure,no,44,Initialize facade.,Internal Helper,high,dunder method
account,L5,notifications_facade,NotificationsFacade.get_channel,async get_channel(channel_id: str) -> Optional[ChannelInfo],L5:__init__ | L4:account_handler,get,,pure,yes,11,Get a specific channel.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.get_notification,"async get_notification(notification_id: str, tenant_id: str) -> Optional[NotificationInfo]",L5:__init__ | L4:account_handler,get,,pure,yes,19,Get a specific notification.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.get_preferences,"async get_preferences(tenant_id: str, user_id: str) -> NotificationPreferences",L5:__init__ | L4:account_handler,NotificationPreferences,,pure,yes,25,Get notification preferences.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.list_channels,async list_channels() -> List[ChannelInfo],L5:__init__ | L4:account_handler,list | values,,pure,yes,8,List available notification channels.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.list_notifications,"async list_notifications(tenant_id: str, channel: Optional[str], status: Optional[str], recipient: Optional[str], limit: int, offset: int) -> List[NotificationInfo]",L5:__init__ | L4:account_handler,append | sort | values,,pure,yes,39,List notifications.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.mark_as_read,"async mark_as_read(notification_id: str, tenant_id: str) -> Optional[NotificationInfo]",L5:__init__ | L4:account_handler,get | isoformat | now,,pure,yes,22,Mark notification as read.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.send_notification,"async send_notification(tenant_id: str, channel: str, recipient: str, message: str, subject: Optional[str], priority: str, metadata: Optional[Dict[str, Any]]) -> NotificationInfo",L5:__init__ | L4:account_handler,NotificationInfo | get | info | isoformat | now | str | uuid4,,pure,yes,65,Send a notification.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,NotificationsFacade.update_preferences,"async update_preferences(tenant_id: str, user_id: str, channels: Optional[Dict[str, bool]], priorities: Optional[Dict[str, List[str]]]) -> NotificationPreferences",L5:__init__ | L4:account_handler,get_preferences | update,,pure,yes,29,Update notification preferences.,Operation,high,called by L4 orchestrator
account,L5,notifications_facade,get_notifications_facade,get_notifications_facade() -> NotificationsFacade,L5:__init__ | L4:account_handler,NotificationsFacade,,pure,no,14,Get the notifications facade instance.,Operation,high,called by L4 orchestrator
account,L5,profile,GovernanceConfig.to_dict,"to_dict() -> Dict[str, object]",?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,,,pure,no,14,Serialize for logging.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
account,L5,profile,GovernanceConfigError.__init__,"__init__(message: str, violations: List[str])",?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,__init__ | join | super,,pure,no,3,,Internal Helper,high,dunder method
account,L5,profile,_get_bool_env,"_get_bool_env(name: str, default: bool) -> bool",?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,getenv | lower,,pure,no,6,Get boolean from environment variable.,Internal Helper,medium,private function
account,L5,profile,get_governance_config,get_governance_config() -> GovernanceConfig,?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,load_governance_config | validate_governance_config,,pure,no,14,Get the validated governance configuration singleton.,Operation,high,called by L4 orchestrator
account,L5,profile,get_governance_profile,get_governance_profile() -> GovernanceProfile,?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,GovernanceProfile | getenv | upper | warning,,pure,no,20,Get the current governance profile from environment.,Operation,high,called by L4 orchestrator
account,L5,profile,load_governance_config,load_governance_config() -> GovernanceConfig,?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,GovernanceConfig | _get_bool_env | get_governance_profile | info | to_dict,,pure,no,48,Load complete governance configuration.,Operation,high,called by L4 orchestrator
account,L5,profile,reset_governance_config,reset_governance_config() -> None,?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,,,pure,no,4,Reset the singleton (for testing).,Operation,high,called by L4 orchestrator
account,L5,profile,validate_governance_at_startup,validate_governance_at_startup() -> None,?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,get_governance_config | info,,pure,no,22,Validate governance configuration at application startup.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
account,L5,profile,validate_governance_config,validate_governance_config(config: Optional[GovernanceConfig]) -> List[str],?:aos_accounts | ?:failure_mode_handler | ?:boot_guard | ?:profile | ?:reactor_initializer | ?:main | L2:aos_accounts | L4:profile_policy_mode | ?:test_stubs,GovernanceConfigError | all | append | error | get | info | len | load_governance_config | warning,,pure,no,76,Validate governance configuration for invalid combinations.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
account,L5,tenant_engine,QuotaExceededError.__init__,"__init__(quota_name: str, limit: int, current: int)",L5:__init__,__init__ | super,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,5,,Internal Helper,high,dunder method
account,L5,tenant_engine,TenantEngine.__init__,"__init__(session: Session, driver: TenantDriver | None)",L5:__init__,get_tenant_driver,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,3,,Internal Helper,high,dunder method
account,L5,tenant_engine,TenantEngine._maybe_reset_daily_counter,_maybe_reset_daily_counter(tenant: Tenant) -> None,L5:__init__,date | update_tenant_usage | utc_now,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,15,Reset daily run counter if new day (temporal logic).,Internal Helper,medium,private function
account,L5,tenant_engine,TenantEngine.check_run_quota,"check_run_quota(tenant_id: str) -> Tuple[bool, str]",L5:__init__,_maybe_reset_daily_counter | count_running_runs | fetch_tenant_by_id,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,33,Check if tenant can create a new run.,Policy/Decision,medium,name matches 'check'
account,L5,tenant_engine,TenantEngine.check_token_quota,"check_token_quota(tenant_id: str, tokens_needed: int) -> Tuple[bool, str]",L5:__init__,fetch_tenant_by_id,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,20,Check if tenant has token budget for operation.,Policy/Decision,medium,name matches 'check'
account,L5,tenant_engine,TenantEngine.complete_run,"complete_run(run_id: str, success: bool, output_json: Optional[str], replay_token_json: Optional[str], total_tokens: int, total_latency_ms: int, stages_completed: int, recoveries: int, policy_violations: int, cost_cents: int, error: Optional[str]) -> WorkerRun",L5:__init__,TenantEngineError | fetch_run_by_id | fetch_tenant_by_id | record_usage | update_run_completed | update_tenant_usage,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,64,Mark a run as completed and record usage.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.create_api_key,"create_api_key(tenant_id: str, name: str, user_id: Optional[str], permissions: Optional[List[str]], allowed_workers: Optional[List[str]], expires_in_days: Optional[int], rate_limit_rpm: Optional[int], max_concurrent_runs: Optional[int]) -> Tuple[str, APIKey]",L5:__init__,QuotaExceededError | TenantEngineError | count_active_api_keys | fetch_tenant_by_id | generate_key | info | insert_api_key | insert_audit_log | timedelta | utc_now,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,69,Create a new API key for a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.create_membership_with_default,"create_membership_with_default(tenant: Tenant, user_id: str, role: str, set_as_default: bool) -> TenantMembership",L5:__init__,info | insert_membership,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,25,Create a tenant membership and optionally set as user's default tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.create_run,"create_run(tenant_id: str, worker_id: str, task: str, api_key_id: Optional[str], user_id: Optional[str], input_json: Optional[str]) -> WorkerRun",L5:__init__,QuotaExceededError | check_run_quota | increment_usage | insert_run,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,29,Create a new worker run (with quota check).,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.create_tenant,"create_tenant(name: str, slug: str, clerk_org_id: Optional[str], plan: str, billing_email: Optional[str]) -> Tenant",L5:__init__,TenantEngineError | fetch_tenant_by_slug | get | info | insert_tenant,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,33,Create a new tenant with plan quotas.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.get_tenant,get_tenant(tenant_id: str) -> Optional[Tenant],L5:__init__,fetch_tenant_by_id,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,3,Get tenant by ID.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.get_tenant_by_slug,get_tenant_by_slug(slug: str) -> Optional[Tenant],L5:__init__,fetch_tenant_by_slug,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,3,Get tenant by slug.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.get_usage_summary,"get_usage_summary(tenant_id: str, start_date: Optional[Any], end_date: Optional[Any]) -> dict",L5:__init__,fetch_usage_records | isoformat | len | replace | utc_now,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,31,Get usage summary for a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.increment_usage,"increment_usage(tenant_id: str, tokens: int) -> None",L5:__init__,_maybe_reset_daily_counter | fetch_tenant_by_id | increment_tenant_usage,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,11,Increment usage counters for a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.list_api_keys,"list_api_keys(tenant_id: str, include_revoked: bool) -> List[APIKey]",L5:__init__,fetch_api_keys,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,3,List API keys for a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.list_runs,"list_runs(tenant_id: str, limit: int, offset: int, status: Optional[str], worker_id: Optional[str]) -> List[WorkerRun]",L5:__init__,fetch_runs,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,16,List runs for a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.record_usage,"record_usage(tenant_id: str, meter_name: str, amount: int, unit: str, worker_id: Optional[str], api_key_id: Optional[str], metadata: Optional[dict]) -> None",L5:__init__,insert_usage_record,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,20,Record a usage event for billing.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.revoke_api_key,"revoke_api_key(key_id: str, reason: str, user_id: Optional[str]) -> APIKey",L5:__init__,TenantEngineError | fetch_api_key_by_id | info | insert_audit_log | update_api_key_revoked,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,28,Revoke an API key.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.suspend,"suspend(tenant_id: str, reason: str) -> Tenant",L5:__init__,TenantEngineError | fetch_tenant_by_id | update_tenant_status | warning,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,11,Suspend a tenant.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,TenantEngine.update_plan,"update_plan(tenant_id: str, plan: str) -> Tenant",L5:__init__,TenantEngineError | fetch_tenant_by_id | get | info | update_tenant_plan,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,22,Update tenant plan and quotas.,Unclassified,low,no classification rules matched
account,L5,tenant_engine,get_tenant_engine,get_tenant_engine(session: Session) -> TenantEngine,L5:__init__,TenantEngine,__future__ | sqlmodel | tenant | tenant_driver | time,pure,no,3,Get a TenantEngine instance.,Unclassified,low,no classification rules matched
account,L5,user_write_engine,UserWriteService.__init__,__init__(session: 'Session'),L5:__init__,get_user_write_driver,sqlmodel | tenant | user_write_driver,pure,no,2,,Internal Helper,high,dunder method
account,L5,user_write_engine,UserWriteService.create_user,"create_user(email: str, clerk_user_id: str, name: Optional[str], avatar_url: Optional[str], status: str) -> 'User'",L5:__init__,create_user,sqlmodel | tenant | user_write_driver,pure,no,16,Delegate to driver.,Unclassified,low,no classification rules matched
account,L5,user_write_engine,UserWriteService.update_user_login,update_user_login(user: 'User') -> 'User',L5:__init__,update_user_login,sqlmodel | tenant | user_write_driver,pure,no,3,Delegate to driver.,Unclassified,low,no classification rules matched
account,L5,user_write_engine,UserWriteService.user_to_dict,user_to_dict(user: 'User') -> Dict,L5:__init__,user_to_dict,sqlmodel | tenant | user_write_driver,pure,no,3,Delegate to driver.,Internal Helper,medium,name matches 'to_'
account,L5,validator_engine,ValidatorService.__init__,__init__(capability_registry: Optional[list[str]]),?:__init__ | ?:aurora_semantic_validator,frozenset,,pure,no,9,Initialize validator with optional capability registry.,Internal Helper,high,dunder method
account,L5,validator_engine,ValidatorService._build_reason,"_build_reason(issue_type: IssueType, severity: Severity, action: RecommendedAction, confidence: Decimal) -> str",?:__init__ | ?:aurora_semantic_validator,Decimal | append | float | join,,pure,no,26,Build human-readable reason for verdict.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._calculate_confidence,"_calculate_confidence(source: str, type_confidence: Decimal, capabilities: list[str]) -> Decimal",?:__init__ | ?:aurora_semantic_validator,Decimal | _get_capability_confidence | _get_source_weight | max | min,,pure,no,26,Calculate overall confidence score.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._classify_issue_type,"_classify_issue_type(text: str) -> tuple[IssueType, Decimal, dict[str, Any]]",?:__init__ | ?:aurora_semantic_validator,Decimal | append | max | min,,pure,no,65,Classify issue type from text.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._classify_severity,"_classify_severity(text: str, issue_type: IssueType) -> tuple[Severity, Decimal]",?:__init__ | ?:aurora_semantic_validator,Decimal | min | sum,,pure,no,34,Classify severity from text and issue type.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._create_fallback_verdict,"_create_fallback_verdict(error_type: ValidatorErrorType, message: str) -> ValidatorVerdict",?:__init__ | ?:aurora_semantic_validator,Decimal | ValidatorVerdict | now,,pure,no,19,Create fallback verdict on error.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._determine_action,"_determine_action(issue_type: IssueType, severity: Severity, confidence: Decimal) -> RecommendedAction",?:__init__ | ?:aurora_semantic_validator,Decimal,,pure,no,37,Determine recommended action.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._do_validate,_do_validate(input: ValidatorInput) -> ValidatorVerdict,?:__init__ | ?:aurora_semantic_validator,ValidatorVerdict | _build_reason | _calculate_confidence | _classify_issue_type | _classify_severity | _determine_action | _extract_capabilities | _extract_text | _find_severity_indicators | _get_capability_confidence | _get_source_weight | float | list | lower | now,,pure,no,52,Internal validation logic.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._extract_capabilities,"_extract_capabilities(text: str, hints: Optional[list[str]]) -> list[str]",?:__init__ | ?:aurora_semantic_validator,add | escape | lower | search | set | sorted | update,,db_write,no,29,Extract affected capabilities from text.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._extract_text,"_extract_text(payload: dict[str, Any]) -> str",?:__init__ | ?:aurora_semantic_validator,append | isinstance | join | str,,pure,no,23,Extract searchable text from payload.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._find_severity_indicators,"_find_severity_indicators(text: str) -> dict[str, list[str]]",?:__init__ | ?:aurora_semantic_validator,,,pure,no,7,Find severity indicators in text for evidence.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._get_capability_confidence,_get_capability_confidence(capabilities: list[str]) -> Decimal,?:__init__ | ?:aurora_semantic_validator,Decimal | all | any,,pure,no,14,Get confidence modifier based on capability matches.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService._get_source_weight,_get_source_weight(source: str) -> Decimal,?:__init__ | ?:aurora_semantic_validator,Decimal | get,,pure,no,14,Get confidence weight for source.,Internal Helper,medium,private function
account,L5,validator_engine,ValidatorService.validate,validate(input: ValidatorInput) -> ValidatorVerdict,?:__init__ | ?:aurora_semantic_validator,_create_fallback_verdict | _do_validate | str,,pure,no,24,Validate an issue and produce a verdict.,Policy/Decision,medium,name matches 'validate'
account,L6,accounts_facade_driver,AccountsFacadeDriver.count_tenants,"async count_tenants(session: AsyncSession, tenant_id: str) -> int",L6:__init__ | L5:accounts_facade,count | execute | scalar | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,14,Count tenants.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.count_users,"async count_users(session: AsyncSession, tenant_id: str) -> int",L6:__init__ | L5:accounts_facade,count | execute | join | scalar | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,21,Count users in a tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.delete_membership,"async delete_membership(session: AsyncSession, membership: TenantMembership) -> bool",L6:__init__ | L5:accounts_facade,delete,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,9,Delete a membership.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_invitation_by_email,"async fetch_invitation_by_email(session: AsyncSession, tenant_id: str, email: str, status: str) -> Optional[Invitation]",L6:__init__ | L5:accounts_facade,execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,15,Fetch pending invitation by email.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_invitation_by_id_and_token,"async fetch_invitation_by_id_and_token(session: AsyncSession, invitation_id: str, token_hash: str) -> Optional[Invitation]",L6:__init__ | L5:accounts_facade,execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,14,Fetch invitation by ID and token hash.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_invitations,"async fetch_invitations(session: AsyncSession, tenant_id: str) -> list[InvitationSnapshot]",L6:__init__ | L5:accounts_facade,InvitationSnapshot | all | desc | execute | order_by | scalars | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,31,Fetch invitations for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_membership,"async fetch_membership(session: AsyncSession, tenant_id: str, user_id: str) -> Optional[TenantMembership]",L6:__init__ | L5:accounts_facade,execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,13,Fetch a specific membership (returns ORM model for mutations).,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_membership_with_user,"async fetch_membership_with_user(session: AsyncSession, tenant_id: str, user_id: str) -> Optional[tuple[TenantMembership, User]]",L6:__init__ | L5:accounts_facade,execute | join | one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,18,Fetch membership with user data.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_profile,"async fetch_profile(session: AsyncSession, tenant_id: str, clerk_user_id: Optional[str]) -> ProfileSnapshot",L6:__init__ | L5:accounts_facade,ProfileSnapshot | execute | now | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,56,Fetch user profile.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_subscription,"async fetch_subscription(session: AsyncSession, tenant_id: str) -> Optional[SubscriptionSnapshot]",L6:__init__ | L5:accounts_facade,SubscriptionSnapshot | desc | execute | limit | order_by | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,25,Fetch latest subscription for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_support_tickets,"async fetch_support_tickets(session: AsyncSession, tenant_id: str) -> list[TicketSnapshot]",L6:__init__ | L5:accounts_facade,TicketSnapshot | all | desc | execute | order_by | scalars | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,32,Fetch support tickets for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_tenant,"async fetch_tenant(session: AsyncSession, tenant_id: str) -> Optional[TenantSnapshot]",L6:__init__ | L5:accounts_facade,TenantSnapshot | execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,22,Fetch a tenant by ID.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_tenant_detail,"async fetch_tenant_detail(session: AsyncSession, tenant_id: str) -> Optional[TenantDetailSnapshot]",L6:__init__ | L5:accounts_facade,TenantDetailSnapshot | execute | has_completed_onboarding | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,32,Fetch detailed tenant data.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_tenant_memberships,"async fetch_tenant_memberships(session: AsyncSession, tenant_id: str) -> list[MembershipSnapshot]",L6:__init__ | L5:accounts_facade,MembershipSnapshot | all | execute | join | order_by | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,26,Fetch all memberships for a tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_tenants,"async fetch_tenants(session: AsyncSession, tenant_id: str) -> list[TenantSnapshot]",L6:__init__ | L5:accounts_facade,TenantSnapshot | all | execute | limit | offset | scalars | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,31,Fetch tenants (filtered by tenant_id for isolation).,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_user_by_email,"async fetch_user_by_email(session: AsyncSession, email: str) -> Optional[User]",L6:__init__ | L5:accounts_facade,execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,9,Fetch user by email.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_user_by_id,"async fetch_user_by_id(session: AsyncSession, user_id: str) -> Optional[User]",L6:__init__ | L5:accounts_facade,execute | scalar_one_or_none | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,9,Fetch user by ID (returns ORM model for mutations).,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_user_detail,"async fetch_user_detail(session: AsyncSession, tenant_id: str, user_id: str) -> Optional[UserDetailSnapshot]",L6:__init__ | L5:accounts_facade,UserDetailSnapshot | can_manage_keys | can_run_workers | can_view_runs | execute | first | join | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,41,Fetch detailed user data with membership.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.fetch_users,"async fetch_users(session: AsyncSession, tenant_id: str) -> list[UserSnapshot]",L6:__init__ | L5:accounts_facade,UserSnapshot | all | execute | join | limit | offset | order_by | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,47,Fetch users in a tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.insert_invitation,"async insert_invitation(session: AsyncSession, tenant_id: str, email: str, role: str, token_hash: str, invited_by: str, expires_at: datetime) -> InvitationSnapshot",L6:__init__ | L5:accounts_facade,Invitation | InvitationSnapshot | add | generate_uuid | refresh | utc_now,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,39,Insert a new invitation.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.insert_membership,"async insert_membership(session: AsyncSession, tenant_id: str, user_id: str, role: str) -> TenantMembership",L6:__init__ | L5:accounts_facade,TenantMembership | add | generate_uuid | utc_now,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,18,Insert a new membership.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.insert_support_ticket,"async insert_support_ticket(session: AsyncSession, tenant_id: str, user_id: str) -> TicketSnapshot",L6:__init__ | L5:accounts_facade,SupportTicket | TicketSnapshot | add | generate_uuid | refresh | utc_now,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,42,Insert a new support ticket.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.insert_user,"async insert_user(session: AsyncSession, email: str, name: str) -> User",L6:__init__ | L5:accounts_facade,User | add | flush | generate_uuid | utc_now,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,18,Insert a new user.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.update_invitation_accepted,"async update_invitation_accepted(session: AsyncSession, invitation: Invitation) -> InvitationSnapshot",L6:__init__ | L5:accounts_facade,InvitationSnapshot | utc_now,__future__ | asyncio | sqlalchemy | tenant,pure,yes,22,Mark invitation as accepted.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.update_invitation_expired,"async update_invitation_expired(session: AsyncSession, invitation: Invitation) -> None",L6:__init__ | L5:accounts_facade,,__future__ | asyncio | sqlalchemy | tenant,pure,yes,7,Mark invitation as expired.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.update_membership_role,"async update_membership_role(session: AsyncSession, membership: TenantMembership, new_role: str) -> MembershipSnapshot",L6:__init__ | L5:accounts_facade,MembershipSnapshot | execute | scalar_one | select | where,__future__ | asyncio | sqlalchemy | tenant,db_write,yes,22,Update membership role.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,AccountsFacadeDriver.update_user_profile,"async update_user_profile(session: AsyncSession, user: User) -> User",L6:__init__ | L5:accounts_facade,get_preferences | refresh | set_preferences | update | utc_now,__future__ | asyncio | sqlalchemy | tenant,pure,yes,25,Update user profile fields.,Persistence/Driver,high,L6 layer = persistence
account,L6,accounts_facade_driver,get_accounts_facade_driver,get_accounts_facade_driver() -> AccountsFacadeDriver,L6:__init__ | L5:accounts_facade,AccountsFacadeDriver,__future__ | asyncio | sqlalchemy | tenant,pure,no,6,Get the singleton AccountsFacadeDriver instance.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.__init__,__init__(session: Session),L6:__init__ | L5:tenant_engine,,__future__ | sqlmodel | tenant | time,pure,no,2,,Internal Helper,high,dunder method
account,L6,tenant_driver,TenantDriver.count_active_api_keys,count_active_api_keys(tenant_id: str) -> int,L6:__init__ | L5:tenant_engine,count | exec | one | select | where,__future__ | sqlmodel | tenant | time,pure,no,9,Count active API keys for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.count_running_runs,count_running_runs(tenant_id: str) -> int,L6:__init__ | L5:tenant_engine,cast | count | exec | in_ | one | select | where,__future__ | sqlmodel | tenant | time,pure,no,9,Count queued or running runs for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_api_key_by_id,fetch_api_key_by_id(key_id: str) -> Optional[APIKey],L6:__init__ | L5:tenant_engine,get,__future__ | sqlmodel | tenant | time,pure,no,3,Fetch API key by ID.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_api_keys,"fetch_api_keys(tenant_id: str, include_revoked: bool) -> List[APIKey]",L6:__init__ | L5:tenant_engine,exec | list | select | where,__future__ | sqlmodel | tenant | time,pure,no,10,Fetch API keys for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_run_by_id,fetch_run_by_id(run_id: str) -> Optional[WorkerRun],L6:__init__ | L5:tenant_engine,get,__future__ | sqlmodel | tenant | time,pure,no,3,Fetch run by ID.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_runs,"fetch_runs(tenant_id: str, limit: int, offset: int, status: Optional[str], worker_id: Optional[str]) -> List[WorkerRun]",L6:__init__ | L5:tenant_engine,cast | desc | exec | limit | list | offset | order_by | select | where,__future__ | sqlmodel | tenant | time,pure,no,16,Fetch runs for tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_tenant_by_id,fetch_tenant_by_id(tenant_id: str) -> Optional[Tenant],L6:__init__ | L5:tenant_engine,get,__future__ | sqlmodel | tenant | time,pure,no,3,Fetch tenant by ID (returns ORM model for mutations).,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_tenant_by_slug,fetch_tenant_by_slug(slug: str) -> Optional[Tenant],L6:__init__ | L5:tenant_engine,exec | first | select | where,__future__ | sqlmodel | tenant | time,pure,no,3,Fetch tenant by slug.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_tenant_snapshot,fetch_tenant_snapshot(tenant_id: str) -> Optional[TenantCoreSnapshot],L6:__init__ | L5:tenant_engine,TenantCoreSnapshot | fetch_tenant_by_id,__future__ | sqlmodel | tenant | time,pure,no,23,Fetch tenant as snapshot.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.fetch_usage_records,"fetch_usage_records(tenant_id: str, start_date: datetime, end_date: datetime) -> List[UsageRecord]",L6:__init__ | L5:tenant_engine,exec | list | select | where,__future__ | sqlmodel | tenant | time,pure,no,13,Fetch usage records for period.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.increment_tenant_usage,"increment_tenant_usage(tenant: Tenant, tokens: int) -> None",L6:__init__ | L5:tenant_engine,add | increment_usage,__future__ | sqlmodel | tenant | time,db_write,no,4,Increment usage counters.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_api_key,"insert_api_key(tenant_id: str, name: str, key_prefix: str, key_hash: str, user_id: Optional[str], permissions: Optional[List[str]], allowed_workers: Optional[List[str]], expires_at: Optional[datetime], rate_limit_rpm: Optional[int], max_concurrent_runs: Optional[int]) -> APIKey",L6:__init__ | L5:tenant_engine,APIKey | add | dumps | flush | refresh,__future__ | sqlmodel | tenant | time,db_write,no,30,Insert a new API key.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_audit_log,"insert_audit_log(action: str, resource_type: str, tenant_id: Optional[str], user_id: Optional[str], api_key_id: Optional[str], resource_id: Optional[str], old_value: Optional[dict], new_value: Optional[dict], ip_address: Optional[str], user_agent: Optional[str], request_id: Optional[str]) -> None",L6:__init__ | L5:tenant_engine,AuditLog | add | dumps,__future__ | sqlmodel | tenant | time,db_write,no,29,Insert an audit log entry.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_membership,"insert_membership(tenant_id: str, user_id: str, role: str, set_as_default: bool) -> TenantMembership",L6:__init__ | L5:tenant_engine,TenantMembership | add | get,__future__ | sqlmodel | tenant | time,db_write,no,23,Insert a new membership.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_run,"insert_run(tenant_id: str, worker_id: str, task: str, api_key_id: Optional[str], user_id: Optional[str], input_json: Optional[str]) -> WorkerRun",L6:__init__ | L5:tenant_engine,WorkerRun | add | flush | refresh,__future__ | sqlmodel | tenant | time,db_write,no,23,Insert a new worker run.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_tenant,"insert_tenant(name: str, slug: str, plan: str, max_workers: int, max_runs_per_day: int, max_concurrent_runs: int, max_tokens_per_month: int, max_api_keys: int, clerk_org_id: Optional[str], billing_email: Optional[str]) -> Tenant",L6:__init__ | L5:tenant_engine,Tenant | add | flush | refresh,__future__ | sqlmodel | tenant | time,db_write,no,30,Insert a new tenant.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.insert_usage_record,"insert_usage_record(tenant_id: str, meter_name: str, amount: int, unit: str, worker_id: Optional[str], api_key_id: Optional[str], metadata: Optional[dict]) -> UsageRecord",L6:__init__ | L5:tenant_engine,UsageRecord | add | dumps | replace | timedelta | utc_now,__future__ | sqlmodel | tenant | time,db_write,no,29,Insert a usage record.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.update_api_key_revoked,"update_api_key_revoked(api_key: APIKey, reason: str) -> APIKey",L6:__init__ | L5:tenant_engine,add | utc_now,__future__ | sqlmodel | tenant | time,db_write,no,12,Mark API key as revoked.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.update_run_completed,"update_run_completed(run: WorkerRun, success: bool, output_json: Optional[str], replay_token_json: Optional[str], total_tokens: int, total_latency_ms: int, stages_completed: int, recoveries: int, policy_violations: int, cost_cents: int, error: Optional[str]) -> WorkerRun",L6:__init__ | L5:tenant_engine,add | utc_now,__future__ | sqlmodel | tenant | time,db_write,no,30,Update run as completed.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.update_tenant_plan,"update_tenant_plan(tenant: Tenant, plan: str, max_workers: int, max_runs_per_day: int, max_concurrent_runs: int, max_tokens_per_month: int, max_api_keys: int) -> Tenant",L6:__init__ | L5:tenant_engine,add | utc_now,__future__ | sqlmodel | tenant | time,db_write,no,21,Update tenant plan and quotas.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.update_tenant_status,"update_tenant_status(tenant: Tenant, status: str, suspended_reason: Optional[str]) -> Tenant",L6:__init__ | L5:tenant_engine,add | utc_now,__future__ | sqlmodel | tenant | time,db_write,no,14,Update tenant status.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,TenantDriver.update_tenant_usage,"update_tenant_usage(tenant: Tenant, runs_today: Optional[int], runs_this_month: Optional[int], tokens_this_month: Optional[int], last_run_reset_at: Optional[datetime]) -> Tenant",L6:__init__ | L5:tenant_engine,add,__future__ | sqlmodel | tenant | time,db_write,no,20,Update tenant usage counters.,Persistence/Driver,high,L6 layer = persistence
account,L6,tenant_driver,get_tenant_driver,get_tenant_driver(session: Session) -> TenantDriver,L6:__init__ | L5:tenant_engine,TenantDriver,__future__ | sqlmodel | tenant | time,pure,no,3,Get a TenantDriver instance.,Persistence/Driver,high,L6 layer = persistence
account,L6,user_write_driver,UserWriteDriver.__init__,__init__(session: Session),L6:__init__ | L5:user_write_engine,,sqlmodel | tenant | time,pure,no,2,,Internal Helper,high,dunder method
account,L6,user_write_driver,UserWriteDriver.create_user,"create_user(email: str, clerk_user_id: str, name: Optional[str], avatar_url: Optional[str], status: str) -> User",L6:__init__ | L5:user_write_engine,User | add | flush | refresh,sqlmodel | tenant | time,db_write,no,32,Create a new user and persist.,Persistence/Driver,high,L6 layer = persistence
account,L6,user_write_driver,UserWriteDriver.update_user_login,update_user_login(user: User) -> User,L6:__init__ | L5:user_write_engine,add | flush | refresh | utc_now,sqlmodel | tenant | time,db_write,no,17,Update user's last_login_at timestamp and persist.,Persistence/Driver,high,L6 layer = persistence
account,L6,user_write_driver,UserWriteDriver.user_to_dict,user_to_dict(user: User) -> Dict,L6:__init__ | L5:user_write_engine,,sqlmodel | tenant | time,pure,no,15,Convert user to dict for response.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
account,L6,user_write_driver,get_user_write_driver,get_user_write_driver(session: Session) -> UserWriteDriver,L6:__init__ | L5:user_write_engine,UserWriteDriver,sqlmodel | tenant | time,pure,no,3,Factory function to get UserWriteDriver instance.,Persistence/Driver,high,L6 layer = persistence
activity,L5,activity_enums,SeverityLevel.from_risk_level,from_risk_level(risk_level: str) -> 'SeverityLevel',L5:activity_facade,,,pure,no,7,Convert risk level string to severity level.,Internal Helper,medium,name matches 'from_'
activity,L5,activity_enums,SeverityLevel.from_score,from_score(score: float) -> 'SeverityLevel',L5:activity_facade,,,pure,no,7,Convert numeric severity score (0.0-1.0) to level.,Internal Helper,medium,name matches 'from_'
activity,L5,activity_facade,ActivityFacade.__init__,__init__() -> None,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Initialize facade.,Internal Helper,high,dunder method
activity,L5,activity_facade,ActivityFacade._compute_severity,"_compute_severity(row: dict[str, Any]) -> str",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,from_risk_level | get | upper,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,9,Compute severity level from run data.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._compute_signal_summary,"_compute_signal_summary(row: dict[str, Any], signal_type: str) -> str",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,get,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,5,Compute signal summary from run data.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._compute_signal_type,"_compute_signal_type(row: dict[str, Any]) -> str",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,get,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,25,Compute signal type from run data.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_attention_service,_get_attention_service(session: AsyncSession) -> AttentionRankingService,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,AttentionRankingService,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Get attention ranking service for this session.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_cost_service,_get_cost_service(session: AsyncSession) -> CostAnalysisService,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,CostAnalysisService,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Get cost analysis service for this session.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_driver,_get_driver(session: AsyncSession) -> ActivityReadDriver,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,get_activity_read_driver,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Get activity read driver for this session.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_feedback_service,_get_feedback_service(session: AsyncSession) -> SignalFeedbackService,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,SignalFeedbackService,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Get signal feedback service for this session.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_pattern_service,_get_pattern_service(session: AsyncSession) -> PatternDetectionService,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,PatternDetectionService,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,3,Get pattern detection service for this session.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade._get_runs_with_policy_context,"async _get_runs_with_policy_context(session: AsyncSession, tenant_id: str, state: str) -> dict[str, Any]",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,PolicyContextResult | RunSummaryV2Result | _get_driver | append | count_runs | fetch_runs_with_policy_context | float | get | join | len | lower,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,92,Internal helper to get runs with policy context.,Internal Helper,medium,private function
activity,L5,activity_facade,ActivityFacade.acknowledge_signal,"async acknowledge_signal(session: AsyncSession, tenant_id: str, signal_id: str, acknowledged_by: str | None) -> AcknowledgeResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,_get_feedback_service | acknowledge_signal,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,25,Acknowledge a signal.,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_attention_queue,"async get_attention_queue(session: AsyncSession, tenant_id: str) -> AttentionQueueResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,_get_attention_service | get_attention_queue,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,28,Get attention ranking (SIG-O5).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_completed_runs,"async get_completed_runs(session: AsyncSession, tenant_id: str) -> CompletedRunsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunsResult | _get_runs_with_policy_context,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,46,Get completed runs with policy context (V2).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_cost_analysis,"async get_cost_analysis(session: AsyncSession, tenant_id: str) -> CostAnalysisResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,_get_cost_service | analyze_costs,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,31,Analyze cost anomalies (SIG-O4).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_live_runs,"async get_live_runs(session: AsyncSession, tenant_id: str) -> LiveRunsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunsResult | _get_runs_with_policy_context,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,46,Get live runs with policy context (V2).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_metrics,"async get_metrics(session: AsyncSession, tenant_id: str) -> MetricsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,MetricsResult | _get_driver | append | fetch_metrics | join,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,63,Get activity metrics (V2).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_patterns,"async get_patterns(session: AsyncSession, tenant_id: str) -> PatternDetectionResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,_get_pattern_service | detect_patterns,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,31,Detect instability patterns (SIG-O3).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_risk_signals,"async get_risk_signals(session: AsyncSession, tenant_id: str) -> RiskSignalsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RiskSignalsResult | get_metrics,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,32,Get risk signal aggregates.,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_run_detail,"async get_run_detail(session: AsyncSession, tenant_id: str, run_id: str) -> RunDetailResult | None",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunDetailResult | _get_driver | fetch_run_detail | float | get,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,52,Get run detail (O3).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_run_evidence,"async get_run_evidence(session: AsyncSession, tenant_id: str, run_id: str) -> RunEvidenceResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunEvidenceResult,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,21,Get run evidence context (O4).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_run_proof,"async get_run_proof(session: AsyncSession, tenant_id: str, run_id: str, include_payloads: bool) -> RunProofResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunProofResult,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,31,Get run integrity proof (O5).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_runs,"async get_runs(session: AsyncSession, tenant_id: str) -> RunListResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,RunListResult | RunSummaryResult | _get_driver | append | count_runs | fetch_runs | float | isoformat | join | len | lower,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,181,List runs with filters.,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_signals,"async get_signals(session: AsyncSession, tenant_id: str) -> SignalsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,PolicyContextResult | SignalProjectionResult | SignalsResult | _compute_severity | _compute_signal_summary | _compute_signal_type | _get_driver | append | compute_signal_fingerprint_from_row | count_runs | dict | fetch_at_risk_runs | float | get | items,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,96,Get synthesized attention signals (V2).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_status_summary,"async get_status_summary(session: AsyncSession, tenant_id: str, project_id: str | None) -> StatusSummaryResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,StatusCount | StatusSummaryResult | _get_driver | append | fetch_status_summary | join | sum,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,36,Get summary by status (COMP-O3).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.get_threshold_signals,"async get_threshold_signals(session: AsyncSession, tenant_id: str) -> ThresholdSignalsResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,PolicyContextResult | ThresholdSignalResult | ThresholdSignalsResult | _get_driver | append | count_runs | fetch_threshold_signals | float | get | items | join,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,84,Get threshold proximity signals (V2).,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,ActivityFacade.suppress_signal,"async suppress_signal(session: AsyncSession, tenant_id: str, signal_id: str, suppressed_by: str | None, duration_hours: int, reason: str | None) -> SuppressResult",?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,_get_feedback_service | suppress_signal,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,yes,31,Suppress a signal.,Operation,high,called by L4 orchestrator
activity,L5,activity_facade,get_activity_facade,get_activity_facade() -> ActivityFacade,?:activity | L3:customer_activity_adapter | L5:__init__ | L5:customer_activity_adapter | L4:activity_handler,ActivityFacade,__future__ | activity_enums | activity_read_driver | asyncio | attention_ranking_engine | cost_analysis_engine | pattern_detection_engine | signal_feedback_engine | signal_identity,pure,no,6,Get the singleton ActivityFacade instance.,Operation,high,called by L4 orchestrator
activity,L5,attention_ranking_engine,AttentionRankingService.__init__,__init__() -> None,L5:activity_facade,,time,pure,no,2,,Internal Helper,high,dunder method
activity,L5,attention_ranking_engine,AttentionRankingService.compute_attention_score,"async compute_attention_score(signal_type: str, severity: float, recency_hours: float, pattern_frequency: int) -> float",L5:activity_facade,max | min,time,pure,yes,14,Compute attention score for a signal.,Unclassified,low,no classification rules matched
activity,L5,attention_ranking_engine,AttentionRankingService.get_attention_queue,async get_attention_queue(tenant_id: str) -> AttentionQueueResult,L5:activity_facade,AttentionQueueResult | utc_now,time,pure,yes,15,Get prioritized attention queue for tenant.,Unclassified,low,no classification rules matched
activity,L5,cost_analysis_engine,CostAnalysisService.__init__,__init__() -> None,L5:activity_facade,,time,pure,no,2,,Internal Helper,high,dunder method
activity,L5,cost_analysis_engine,CostAnalysisService.analyze_costs,async analyze_costs(tenant_id: str) -> CostAnalysisResult,L5:activity_facade,CostAnalysisResult | utc_now,time,pure,yes,15,Analyze costs and detect anomalies.,Unclassified,low,no classification rules matched
activity,L5,cost_analysis_engine,CostAnalysisService.get_cost_breakdown,"async get_cost_breakdown(tenant_id: str) -> dict[str, float]",L5:activity_facade,,time,pure,yes,9,Get cost breakdown by dimension.,Unclassified,low,no classification rules matched
activity,L5,cus_telemetry_service,get_cus_telemetry_service,get_cus_telemetry_service() -> CusTelemetryService,?:cus_telemetry | ?:cus_telemetry_service | L4:activity_handler | ?:shim_guard,get_cus_telemetry_engine,cus_telemetry_engine,pure,no,11,Get the CusTelemetryService instance.,Operation,high,called by L4 orchestrator
activity,L5,pattern_detection_engine,PatternDetectionService.__init__,__init__() -> None,L5:activity_facade,,time,pure,no,2,,Internal Helper,high,dunder method
activity,L5,pattern_detection_engine,PatternDetectionService.detect_patterns,async detect_patterns(tenant_id: str) -> PatternDetectionResult,L5:activity_facade,PatternDetectionResult | utc_now,time,pure,yes,16,Detect patterns in recent activity.,Unclassified,low,no classification rules matched
activity,L5,pattern_detection_engine,PatternDetectionService.get_pattern_detail,"async get_pattern_detail(tenant_id: str, pattern_id: str) -> Optional[DetectedPattern]",L5:activity_facade,,time,pure,yes,7,Get details of a specific pattern.,Unclassified,low,no classification rules matched
activity,L5,signal_feedback_engine,SignalFeedbackService.__init__,__init__() -> None,L5:activity_facade | L4:activity_handler,,time,pure,no,2,,Internal Helper,high,dunder method
activity,L5,signal_feedback_engine,SignalFeedbackService.acknowledge_signal,"async acknowledge_signal(tenant_id: str, signal_id: str) -> AcknowledgeResult",L5:activity_facade | L4:activity_handler,AcknowledgeResult | utc_now,time,pure,yes,15,Acknowledge a signal.,Operation,high,called by L4 orchestrator
activity,L5,signal_feedback_engine,SignalFeedbackService.get_bulk_signal_feedback,"async get_bulk_signal_feedback(tenant_id: str, signal_ids: list[str]) -> dict[str, SignalFeedbackStatus]",L5:activity_facade | L4:activity_handler,,time,pure,yes,14,Get feedback status for multiple signals in bulk.,Operation,high,called by L4 orchestrator
activity,L5,signal_feedback_engine,SignalFeedbackService.get_signal_feedback_status,"async get_signal_feedback_status(tenant_id: str, signal_id: str) -> dict[str, bool]",L5:activity_facade | L4:activity_handler,,time,pure,yes,10,Get current feedback status for a signal.,Operation,high,called by L4 orchestrator
activity,L5,signal_feedback_engine,SignalFeedbackService.suppress_signal,"async suppress_signal(tenant_id: str, signal_id: str) -> SuppressResult",L5:activity_facade | L4:activity_handler,SuppressResult | timedelta | utc_now,time,pure,yes,23,Suppress a signal for a duration.,Operation,high,called by L4 orchestrator
activity,L5,signal_identity,compute_signal_fingerprint,"compute_signal_fingerprint(signal_type: str, dimension: str, source: str, tenant_id: str) -> str",?:activity | ?:__init__ | ?:activity_facade | L5:activity_facade | L4:activity_handler | ?:test_signal_feedback,compute_signal_fingerprint_from_row,,pure,no,24,Compute a stable fingerprint for signal identity fields.,Operation,high,called by L4 orchestrator
activity,L5,signal_identity,compute_signal_fingerprint_from_row,"compute_signal_fingerprint_from_row(row: dict[str, Any]) -> str",?:activity | ?:__init__ | ?:activity_facade | L5:activity_facade | L4:activity_handler | ?:test_signal_feedback,dumps | encode | get | hexdigest | sha256,,pure,no,28,Compute a stable fingerprint for a signal row.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
activity,L6,activity_read_driver,ActivityReadDriver.__init__,__init__(session: AsyncSession),L5:activity_facade,,asyncio | sqlalchemy,pure,no,3,Initialize driver with async session.,Internal Helper,high,dunder method
activity,L6,activity_read_driver,ActivityReadDriver.count_runs,"async count_runs(where_sql: str, params: dict[str, Any]) -> int",L5:activity_facade,execute | scalar | text,asyncio | sqlalchemy,db_write,yes,18,Count runs matching filters.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_at_risk_runs,"async fetch_at_risk_runs(where_sql: str, params: dict[str, Any], limit: int, offset: int) -> list[dict[str, Any]]",L5:activity_facade,all | dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,42,Fetch at-risk runs for signal synthesis.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_metrics,"async fetch_metrics(where_sql: str, params: dict[str, Any]) -> dict[str, Any]",L5:activity_facade,dict | execute | first | mappings | text,asyncio | sqlalchemy,db_write,yes,36,Fetch aggregated metrics.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_run_detail,"async fetch_run_detail(tenant_id: str, run_id: str) -> dict[str, Any] | None",L5:activity_facade,dict | execute | first | mappings | text,asyncio | sqlalchemy,db_write,yes,25,Fetch single run detail.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_runs,"async fetch_runs(where_sql: str, params: dict[str, Any], sort_by: str, sort_dir: str, limit: int, offset: int) -> list[dict[str, Any]]",L5:activity_facade,all | dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,38,Fetch runs matching filters.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_runs_with_policy_context,"async fetch_runs_with_policy_context(where_sql: str, params: dict[str, Any], sort_by: str, sort_dir: str, limit: int, offset: int) -> list[dict[str, Any]]",L5:activity_facade,all | dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,49,Fetch runs with policy context columns.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_status_summary,"async fetch_status_summary(where_sql: str, params: dict[str, Any]) -> list[dict[str, Any]]",L5:activity_facade,all | dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,24,Fetch runs grouped by status.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,ActivityReadDriver.fetch_threshold_signals,"async fetch_threshold_signals(where_sql: str, params: dict[str, Any], limit: int, offset: int) -> list[dict[str, Any]]",L5:activity_facade,all | dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,41,Fetch threshold proximity signals.,Persistence/Driver,high,L6 layer = persistence
activity,L6,activity_read_driver,get_activity_read_driver,get_activity_read_driver(session: AsyncSession) -> ActivityReadDriver,L5:activity_facade,ActivityReadDriver,asyncio | sqlalchemy,pure,no,3,Get an ActivityReadDriver instance.,Persistence/Driver,high,L6 layer = persistence
activity,L6,orphan_recovery,detect_orphaned_runs,"async detect_orphaned_runs(session: AsyncSession, threshold_minutes: int) -> list[WorkerRun]",?:main | ?:check_priority5_intent,all | asc | execute | in_ | list | order_by | scalars | select | timedelta | utcnow | where,asyncio | db | infra | sqlalchemy | tenant,db_write,yes,23,Detect runs that appear to be orphaned.,Persistence/Driver,high,L6 layer = persistence
activity,L6,orphan_recovery,get_crash_recovery_summary,async get_crash_recovery_summary() -> dict,?:main | ?:check_priority5_intent,all | count | desc | execute | get_async_session | isoformat | limit | order_by | scalar | scalars | select | select_from | where,asyncio | db | infra | sqlalchemy | tenant,db_write,yes,35,Get a summary of crashed runs for operator visibility.,Persistence/Driver,high,L6 layer = persistence
activity,L6,orphan_recovery,mark_run_as_crashed,"async mark_run_as_crashed(session: AsyncSession, run: WorkerRun, reason: str) -> bool",?:main | ?:check_priority5_intent,error | execute | info | isoformat | str | update | utcnow | values | where,asyncio | db | infra | sqlalchemy | tenant,db_write,yes,44,Mark a run as crashed.,Persistence/Driver,high,L6 layer = persistence
activity,L6,orphan_recovery,recover_orphaned_runs,async recover_orphaned_runs(threshold_minutes: Optional[int]) -> dict,?:main | ?:check_priority5_intent,append | detect_orphaned_runs | error | get_async_session | info | len | mark_run_as_crashed | str | warning,asyncio | db | infra | sqlalchemy | tenant,pure,yes,86,Main recovery function - called on startup.,Persistence/Driver,high,L6 layer = persistence
activity,L6,run_signal_service,RunSignalService.__init__,__init__(session: Any),?:llm_threshold_service | L6:threshold_driver,,sqlalchemy,pure,no,8,Initialize with a sync SQLAlchemy Session.,Internal Helper,high,dunder method
activity,L6,run_signal_service,RunSignalService.get_risk_level,get_risk_level(run_id: str) -> int,?:llm_threshold_service | L6:threshold_driver,execute | fetchone | str | text | warning,sqlalchemy,db_write,no,35,Get current risk level for a run.,Persistence/Driver,high,L6 layer = persistence
activity,L6,run_signal_service,RunSignalService.update_risk_level,"update_risk_level(run_id: str, signals: List[Any]) -> None",?:llm_threshold_service | L6:threshold_driver,debug | error | execute | get | hasattr | info | len | max | str | text,sqlalchemy,db_write,no,63,Update risk level for a run based on threshold signals.,Persistence/Driver,high,L6 layer = persistence
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.__init__,"__init__(spec_loader: Optional[PanelSpecLoader], signal_collector: Optional[PanelSignalCollector], metrics_emitter: Optional[PanelMetricsEmitter], api_base_url: Optional[str])",?:__init__,PanelDependencyResolver | PanelSlotEvaluator | PanelVerificationEngine | create_consistency_checker | create_response_assembler | create_signal_collector | get | get_panel_metrics_emitter | get_panel_spec_loader | info | len | load,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,no,30,,Internal Helper,high,dunder method
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine._create_short_circuit_response,"_create_short_circuit_response(panel_id: str, panel_spec, blocking_upstream: str, params: Dict[str, Any], start_time: float) -> Dict[str, Any]",?:__init__,assemble | check | evaluate_missing | perf_counter | values,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,no,30,Create response when short-circuiting due to upstream failure.,Internal Helper,medium,private function
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine._evaluate_panel_slots,"async _evaluate_panel_slots(panel_spec, params: Dict[str, Any]) -> List[PanelSlotResult]",?:__init__,append | check_determinism_rule | collect_for_slot | determine_authority | determine_state | error | evaluate | evaluate_missing | get | items | str | verify_inputs | warning,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,70,Evaluate all slots in a panel.,Internal Helper,medium,private function
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.close,async close(),?:__init__,close,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,3,Clean up resources.,Unclassified,low,no classification rules matched
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.evaluate_all_panels,"async evaluate_all_panels(params: Optional[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]",?:__init__,evaluate_panel | get_all_tiers,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,22,Evaluate all panels in dependency order.,Policy/Decision,medium,name matches 'evaluate'
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.evaluate_panel,"async evaluate_panel(panel_id: str, params: Optional[Dict[str, Any]]) -> Dict[str, Any]",?:__init__,_create_short_circuit_response | _evaluate_panel_slots | any | assemble | assemble_error | can_short_circuit | check | debug | error | get | info | items | measure_evaluation | perf_counter | record_error,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,82,Evaluate a panel and return spec-compliant response.,Policy/Decision,medium,name matches 'evaluate'
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.get_panel_ids,async get_panel_ids() -> List[str],?:__init__,keys | list,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,3,Get all registered panel IDs.,Unclassified,low,no classification rules matched
analytics,L5,ai_console_panel_engine,AIConsolePanelEngine.get_panel_spec,"async get_panel_spec(panel_id: str) -> Optional[Dict[str, Any]]",?:__init__,get | keys | len | list,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,16,Get spec for a specific panel.,Unclassified,low,no classification rules matched
analytics,L5,ai_console_panel_engine,create_panel_engine,async create_panel_engine(api_base_url: Optional[str]) -> AIConsolePanelEngine,?:__init__,AIConsolePanelEngine,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,5,Create and initialize panel engine.,Unclassified,low,no classification rules matched
analytics,L5,ai_console_panel_engine,get_panel_engine,async get_panel_engine() -> AIConsolePanelEngine,?:__init__,create_panel_engine,panel_consistency_checker | panel_dependency_resolver | panel_metrics_emitter | panel_response_assembler | panel_signal_collector | panel_slot_evaluator | panel_spec_loader | panel_types | panel_verification_engine,pure,yes,6,Get singleton panel engine.,Unclassified,low,no classification rules matched
analytics,L5,analytics_facade,AnalyticsFacade.__init__,__init__() -> None,?:analytics | L2:analytics | L4:analytics_handler,,__future__ | analytics_read_driver | asyncio,pure,no,3,Initialize facade.,Internal Helper,high,dunder method
analytics,L5,analytics_facade,AnalyticsFacade._calculate_freshness,_calculate_freshness(series: list[UsageDataPointResult]) -> int,?:analytics | L2:analytics | L4:analytics_handler,fromisoformat | int | now | replace | total_seconds,__future__ | analytics_read_driver | asyncio,pure,no,13,Calculate data freshness in seconds.,Internal Helper,medium,private function
analytics,L5,analytics_facade,AnalyticsFacade._calculate_freshness_from_cost,_calculate_freshness_from_cost(series: list[CostDataPointResult]) -> int,?:analytics | L2:analytics | L4:analytics_handler,fromisoformat | int | now | replace | total_seconds,__future__ | analytics_read_driver | asyncio,pure,no,13,Calculate data freshness in seconds from cost series.,Internal Helper,medium,private function
analytics,L5,analytics_facade,AnalyticsFacade.get_cost_statistics,"async get_cost_statistics(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime) -> CostStatisticsResult",?:analytics | L2:analytics | L4:analytics_handler,CostByFeatureResult | CostByModelResult | CostDataPointResult | CostStatisticsResult | CostTotalsResult | SignalSourceResult | TimeWindowResult | _calculate_freshness_from_cost | append | fetch_cost_by_feature | fetch_cost_by_model | fetch_cost_spend | get | max | round,__future__ | analytics_read_driver | asyncio,pure,yes,115,Get cost statistics for the specified time window.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,AnalyticsFacade.get_status,get_status() -> AnalyticsStatusResult,?:analytics | L2:analytics | L4:analytics_handler,AnalyticsStatusResult | TopicStatusResult,__future__ | analytics_read_driver | asyncio,pure,no,23,Get analytics domain capability status.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,AnalyticsFacade.get_usage_statistics,"async get_usage_statistics(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime) -> UsageStatisticsResult",?:analytics | L2:analytics | L4:analytics_handler,SignalSourceResult | TimeWindowResult | UsageDataPointResult | UsageStatisticsResult | UsageTotalsResult | _calculate_freshness | append | fetch_cost_metrics | fetch_llm_usage | fetch_worker_execution | get | keys | max | sorted | split,__future__ | analytics_read_driver | asyncio,pure,yes,117,Get usage statistics for the specified time window.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_cost_by_feature,"async fetch_cost_by_feature(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_cost_by_feature | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,14,Fetch cost breakdown by feature tag from cost_records table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_cost_by_model,"async fetch_cost_by_model(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_cost_by_model | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,14,Fetch cost breakdown by model from cost_records table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_cost_metrics,"async fetch_cost_metrics(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime, resolution: ResolutionType) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_cost_metrics | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,16,Fetch cost metrics from cost_records table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_cost_spend,"async fetch_cost_spend(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime, resolution: ResolutionType) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_cost_spend | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,16,Fetch cost spend data from cost_records table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_llm_usage,"async fetch_llm_usage(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime, resolution: ResolutionType) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_llm_usage | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,16,Fetch LLM usage from runs table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,SignalAdapter.fetch_worker_execution,"async fetch_worker_execution(session: AsyncSession, tenant_id: str, from_ts: datetime, to_ts: datetime, resolution: ResolutionType) -> dict[str, Any]",?:analytics | L2:analytics | L4:analytics_handler,fetch_worker_execution | get_analytics_read_driver | str | warning,__future__ | analytics_read_driver | asyncio,pure,yes,16,Fetch worker execution metrics from aos_traces table.,Operation,high,called by L4 orchestrator
analytics,L5,analytics_facade,get_analytics_facade,get_analytics_facade() -> AnalyticsFacade,?:analytics | L2:analytics | L4:analytics_handler,AnalyticsFacade,__future__ | analytics_read_driver | asyncio,pure,no,6,Get the singleton AnalyticsFacade instance.,Operation,high,called by L4 orchestrator
analytics,L5,canary,CanaryRunner.__init__,__init__(config: Optional[CanaryRunConfig]),?:__init__ | ?:test_canary,CanaryRunConfig | CostSimV2Adapter | CostSimulator | Path | get_config | mkdir,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,no,25,Initialize canary runner.,Internal Helper,high,dunder method
analytics,L5,canary,CanaryRunner._approximate_kl_divergence,"_approximate_kl_divergence(p: List[int], q: List[int], bins: int) -> float",?:__init__ | ?:test_canary,int | log | max | min | round | sum | zip,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,no,55,Approximate KL divergence between two cost distributions.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._calculate_metrics,"_calculate_metrics(comparisons: List[ComparisonResult]) -> Dict[str, Any]",?:__init__ | ?:test_canary,_approximate_kl_divergence | abs | float | int | len | sorted | sum,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,no,46,Calculate aggregate metrics from comparisons.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._compare_with_golden,"async _compare_with_golden(samples: List[CanarySample], comparisons: List[ComparisonResult]) -> Dict[str, Any]",?:__init__ | ?:test_canary,,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,11,Compare results against golden reference dataset.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._evaluate_results,"_evaluate_results(metrics: Dict[str, Any], golden_comparison: Optional[Dict[str, Any]]) -> Tuple[bool, List[str]]",?:__init__ | ?:test_canary,append | len,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,no,27,Evaluate results and determine pass/fail.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._generate_synthetic_samples,_generate_synthetic_samples() -> List[CanarySample],?:__init__ | ?:test_canary,CanarySample | append,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,no,48,Generate synthetic test samples.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._load_samples,async _load_samples() -> List[CanarySample],?:__init__ | ?:test_canary,CanarySample | _generate_synthetic_samples | append | error | get | get_decompressed_input | get_provenance_logger | now | query | timedelta | warning,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,41,Load samples from recent provenance logs.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._run_internal,"async _run_internal(run_id: str, start_time: datetime, samples: Optional[List[CanarySample]]) -> CanaryReport",?:__init__ | ?:test_canary,CanaryReport | _calculate_metrics | _compare_with_golden | _evaluate_results | _load_samples | _run_single | _save_artifacts | append | error | exists | gather | get_circuit_breaker | info | isinstance | len,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,128,Internal canary run logic (called after leader election).,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._run_single,"async _run_single(sample: CanarySample) -> Tuple[ComparisonResult, Optional[DiffResult]]",?:__init__ | ?:test_canary,CostSimV2Adapter | DiffResult | compute_output_hash | simulate_with_comparison,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,27,Run comparison for a single sample.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner._save_artifacts,"async _save_artifacts(report: CanaryReport, comparisons: List[ComparisonResult], diffs: List[DiffResult]) -> List[str]",?:__init__ | ?:test_canary,append | dump | dumps | error | open | str | strftime | to_dict | write,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,file_io,yes,36,Save canary run artifacts.,Internal Helper,medium,private function
analytics,L5,canary,CanaryRunner.run,async run(samples: Optional[List[CanarySample]]) -> CanaryReport,?:__init__ | ?:test_canary,CanaryReport | _run_internal | info | leader_election | now | str | uuid4,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,48,Run canary validation.,Unclassified,low,no classification rules matched
analytics,L5,canary,run_canary,"async run_canary(sample_count: int, drift_threshold: float) -> CanaryReport",?:__init__ | ?:test_canary,CanaryRunConfig | CanaryRunner | run,__future__ | circuit_breaker | circuit_breaker_async | config | leader | models | provenance | simulate | v2_adapter,pure,yes,20,Convenience function to run canary.,Unclassified,low,no classification rules matched
analytics,L5,config,CostSimConfig.from_env,from_env() -> 'CostSimConfig',?:jwt_auth | ?:costsim | ?:retry_policy | ?:llm_invoke_governed | ?:__init__ | ?:s1_rollback | ?:artifact | L3:webhook_adapter | ?:storage | ?:cus_health_driver,cls | float | getenv | int | lower,__future__ | subprocess,pure,no,26,Load configuration from environment variables.,Internal Helper,medium,name matches 'from_'
analytics,L5,config,get_commit_sha,get_commit_sha() -> str,?:jwt_auth | ?:costsim | ?:retry_policy | ?:llm_invoke_governed | ?:__init__ | ?:s1_rollback | ?:artifact | L3:webhook_adapter | ?:storage | ?:cus_health_driver,getenv | run | strip,__future__ | subprocess,pure,no,16,Get current git commit SHA.,Unclassified,low,no classification rules matched
analytics,L5,config,get_config,get_config() -> CostSimConfig,?:jwt_auth | ?:costsim | ?:retry_policy | ?:llm_invoke_governed | ?:__init__ | ?:s1_rollback | ?:artifact | L3:webhook_adapter | ?:storage | ?:cus_health_driver,from_env,__future__ | subprocess,pure,no,6,Get the global CostSim configuration.,Unclassified,low,no classification rules matched
analytics,L5,config,is_v2_disabled_by_drift,is_v2_disabled_by_drift() -> bool,?:jwt_auth | ?:costsim | ?:retry_policy | ?:llm_invoke_governed | ?:__init__ | ?:s1_rollback | ?:artifact | L3:webhook_adapter | ?:storage | ?:cus_health_driver,exists | get_config,__future__ | subprocess,pure,no,4,Check if V2 was auto-disabled due to drift.,Unclassified,low,no classification rules matched
analytics,L5,config,is_v2_sandbox_enabled,is_v2_sandbox_enabled() -> bool,?:jwt_auth | ?:costsim | ?:retry_policy | ?:llm_invoke_governed | ?:__init__ | ?:s1_rollback | ?:artifact | L3:webhook_adapter | ?:storage | ?:cus_health_driver,exists | get_config | warning,__future__ | subprocess,pure,no,19,Check if V2 sandbox is enabled.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationError.__init__,"__init__(message: str, envelope_id: str)",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,__init__ | super,audit_persistence | envelope | infra | sqlmodel,pure,no,4,,Internal Helper,high,dunder method
analytics,L5,coordinator,CoordinationManager.__init__,"__init__(db: Optional[Session], emit_traces: bool, tenant_id: Optional[str]) -> None",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,,audit_persistence | envelope | infra | sqlmodel,pure,no,33,Initialize CoordinationManager.,Internal Helper,high,dunder method
analytics,L5,coordinator,CoordinationManager._emit_audit_record,"_emit_audit_record(envelope: Envelope, decision: CoordinationDecisionType, reason: str, conflicting_envelope_id: Optional[str], preempting_envelope_id: Optional[str]) -> CoordinationAuditRecord",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,CoordinationAuditRecord | append | info | now | persist_audit_record | str | uuid4,audit_persistence | envelope | infra | sqlmodel,pure,no,67,Emit a coordination audit record (I-C4-7).,Internal Helper,medium,private function
analytics,L5,coordinator,CoordinationManager._find_preemption_targets,_find_preemption_targets(incoming: Envelope) -> List[Envelope],?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,append | has_higher_priority | values,audit_persistence | envelope | infra | sqlmodel,pure,no,23,Find envelopes that would be preempted by the incoming envelope.,Internal Helper,medium,private function
analytics,L5,coordinator,CoordinationManager._get_parameter_key,_get_parameter_key(envelope: Envelope) -> str,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,,audit_persistence | envelope | infra | sqlmodel,pure,no,3,Get the canonical key for parameter indexing.,Internal Helper,medium,private function
analytics,L5,coordinator,CoordinationManager._revert_envelope,"_revert_envelope(envelope: Envelope, reason: RevertReason, preempting_envelope_id: Optional[str]) -> None",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,_emit_audit_record | _get_parameter_key | info | now,audit_persistence | envelope | infra | sqlmodel,pure,no,41,Revert a single envelope.,Internal Helper,medium,private function
analytics,L5,coordinator,CoordinationManager.active_envelope_count,active_envelope_count() -> int,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,len,audit_persistence | envelope | infra | sqlmodel,pure,no,3,Get count of currently active envelopes.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.apply,"apply(envelope: Envelope) -> Tuple[bool, Optional[List[str]]]",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,CoordinationError | _emit_audit_record | _find_preemption_targets | _get_parameter_key | _revert_envelope | append | check_allowed | info | len | now,audit_persistence | envelope | infra | sqlmodel,pure,no,63,Apply an envelope after coordination check.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.check_allowed,check_allowed(envelope: Envelope) -> CoordinationDecision,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,CoordinationDecision | _emit_audit_record | _find_preemption_targets | _get_parameter_key,audit_persistence | envelope | infra | sqlmodel,pure,no,74,Check if an envelope is allowed to apply (I-C4-1).,Policy/Decision,medium,name matches 'check'
analytics,L5,coordinator,CoordinationManager.expire_envelope,expire_envelope(envelope_id: str) -> bool,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,_get_parameter_key | info | now,audit_persistence | envelope | infra | sqlmodel,pure,no,32,Mark an envelope as expired (timebox ended).,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.get_active_envelopes,get_active_envelopes() -> List[Envelope],?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,list | values,audit_persistence | envelope | infra | sqlmodel,pure,no,3,Get list of currently active envelopes (read-only copy).,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.get_audit_trail,get_audit_trail() -> List[CoordinationAuditRecord],?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,list,audit_persistence | envelope | infra | sqlmodel,pure,no,3,Get audit trail (read-only copy).,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.get_coordination_stats,get_coordination_stats() -> Dict,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,get_envelopes_by_class | keys | len | list,audit_persistence | envelope | infra | sqlmodel,pure,no,18,Get current coordination statistics.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.get_envelope_for_parameter,"get_envelope_for_parameter(subsystem: str, parameter: str) -> Optional[Envelope]",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,get,audit_persistence | envelope | infra | sqlmodel,pure,no,20,Get the active envelope controlling a specific parameter.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.get_envelopes_by_class,get_envelopes_by_class(envelope_class: EnvelopeClass) -> List[Envelope],?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,values,audit_persistence | envelope | infra | sqlmodel,pure,no,11,Get all active envelopes of a specific class.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.is_kill_switch_active,is_kill_switch_active() -> bool,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,,audit_persistence | envelope | infra | sqlmodel,pure,no,3,Check if kill-switch is currently active.,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.kill_switch,kill_switch() -> List[str],?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,_revert_envelope | append | len | list | values | warning,audit_persistence | envelope | infra | sqlmodel,pure,no,31,Activate kill-switch: revert ALL active envelopes atomically (I-C4-6).,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.reset_kill_switch,reset_kill_switch() -> None,?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,warning,audit_persistence | envelope | infra | sqlmodel,pure,no,9,Reset kill-switch state (for testing/recovery).,Unclassified,low,no classification rules matched
analytics,L5,coordinator,CoordinationManager.revert,"revert(envelope_id: str, reason: RevertReason) -> bool",?:__init__ | ?:check_priority4_intent | ?:test_c4_s1_coordination,_revert_envelope | warning,audit_persistence | envelope | infra | sqlmodel,pure,no,21,Explicitly revert a single envelope.,Unclassified,low,no classification rules matched
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.__init__,__init__(session: Session),?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,get_cost_anomaly_driver | today,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,8,,Internal Helper,high,dunder method
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._check_budget_threshold,"_check_budget_threshold(budget_type: str, entity_id: Optional[str], period: str, current_cents: float, limit_cents: int, warn_threshold_pct: int) -> Optional[DetectedAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,DetectedAnomaly | float | title,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,47,Check if budget threshold is breached.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._derive_cause,"_derive_cause(tenant_id: str, entity_type: str, entity_id: str) -> DerivedCause",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,combine | fetch_feature_concentration | fetch_prompt_comparison | fetch_request_comparison | fetch_retry_comparison | time | timedelta,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,78,Derive the cause of a cost anomaly.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._detect_entity_spikes,"async _detect_entity_spikes(tenant_id: str, entity_type: str, column_name: str, lookback_days: int) -> List[DetectedAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,DetectedAnomaly | _derive_cause | _format_spike_message | _record_breach_and_get_consecutive_count | _reset_breach_history | append | classify_severity | combine | fetch_entity_baseline | fetch_entity_today_spend | get | items | time | timedelta,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,87,Detect spikes for a specific entity type (user or feature).,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._detect_tenant_spike,"async _detect_tenant_spike(tenant_id: str, lookback_days: int) -> List[DetectedAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,DetectedAnomaly | _derive_cause | _format_spike_message | _record_breach_and_get_consecutive_count | _reset_breach_history | append | classify_severity | combine | fetch_tenant_baseline | fetch_tenant_today_spend | time | timedelta,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,75,Detect tenant-level absolute spikes.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._format_spike_message,"_format_spike_message(entity_type: str, entity_id: str, deviation_pct: float, breach_count: int) -> str",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,title,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,13,Format human-readable spike message.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._record_breach_and_get_consecutive_count,"_record_breach_and_get_consecutive_count(tenant_id: str, entity_type: str, entity_id: str, breach_type: str, deviation_pct: float, current_value: float, baseline_value: float) -> int",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,fetch_breach_exists_today | fetch_consecutive_breaches | insert_breach_history | utc_now | uuid4,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,49,Record a breach and return the consecutive breach count.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._reset_breach_history,"_reset_breach_history(tenant_id: str, entity_type: str, entity_id: str, breach_type: str) -> None",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,11,Reset breach history when entity is no longer breaching.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._reset_drift_tracking,"_reset_drift_tracking(tenant_id: str, entity_type: str, entity_id: str) -> None",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,reset_drift_tracking | utc_now,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,17,Mark drift tracking as inactive.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector._update_drift_tracking,"_update_drift_tracking(tenant_id: str, entity_type: str, entity_id: str, rolling_avg: float, baseline_avg: float, drift_pct: float) -> int",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,fetch_drift_tracking | insert_drift_tracking | int | timedelta | update_drift_tracking | utc_now | uuid4,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,61,Update drift tracking and return days count.,Internal Helper,medium,private function
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.detect_absolute_spikes,"async detect_absolute_spikes(tenant_id: str, lookback_days: int) -> List[DetectedAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,_detect_entity_spikes | _detect_tenant_spike | extend,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,29,Detect absolute spikes with consecutive interval logic.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.detect_all,async detect_all(tenant_id: str) -> List[DetectedAnomaly],?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,detect_absolute_spikes | detect_budget_issues | detect_sustained_drift | extend,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,17,Run all anomaly detection checks for a tenant.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.detect_budget_issues,async detect_budget_issues(tenant_id: str) -> List[DetectedAnomaly],?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,_check_budget_threshold | all | append | combine | exec | fetch_daily_spend | fetch_monthly_spend | replace | select | time | where,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,68,Detect budget warnings and exceeded budgets.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.detect_sustained_drift,async detect_sustained_drift(tenant_id: str) -> List[DetectedAnomaly],?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,DetectedAnomaly | _derive_cause | _reset_drift_tracking | _update_drift_tracking | append | classify_severity | fetch_baseline_avg | fetch_rolling_avg | timedelta,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,84,Detect sustained drift anomalies.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,CostAnomalyDetector.persist_anomalies,"async persist_anomalies(tenant_id: str, anomalies: List[DetectedAnomaly]) -> List[CostAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,CostAnomaly | add | append | combine | exec | first | flush | info | len | refresh | select | time | where,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,db_write,yes,63,Persist detected anomalies to database.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,classify_severity,classify_severity(deviation_pct: float) -> AnomalySeverity,?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,no,20,Classify severity based on percentage deviation.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,run_anomaly_detection,"async run_anomaly_detection(session: Session, tenant_id: str) -> List[CostAnomaly]",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,CostAnomalyDetector | debug | detect_all | info | len | persist_anomalies,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,14,Run anomaly detection and persist results.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,run_anomaly_detection_with_facts,"async run_anomaly_detection_with_facts(session: Session, tenant_id: str) -> dict",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,CostAnomalyFact | append | float | info | int | run_anomaly_detection | str,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,67,Run anomaly detection and emit CostAnomalyFact for HIGH anomalies.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_anomaly_detector,run_anomaly_detection_with_governance,"async run_anomaly_detection_with_governance(session: Session, tenant_id: str) -> dict",?:cost_intelligence | ?:facade | L5:detection_facade | L2:cost_intelligence | ?:anomaly_severity | ?:test_m26_prevention | ?:test_category4_cost_intelligence,AnomalyIncidentBridge | append | ingest | run_anomaly_detection_with_facts,__future__ | anomaly_bridge | cost_anomaly_driver | db | sqlmodel,pure,yes,47,DEPRECATED: Use run_anomaly_detection_with_facts + AnomalyIncidentBridge.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,cost_model_engine,calculate_cumulative_risk,"calculate_cumulative_risk(risks: List[Dict[str, float]]) -> float",?:v2_adapter | L3:v2_adapter,values,,pure,no,17,Calculate cumulative risk from individual risk factors (L4 domain function).,Unclassified,low,no classification rules matched
analytics,L5,cost_model_engine,check_feasibility,"check_feasibility(estimated_cost_cents: int, budget_cents: int, permission_gaps: List[str], cumulative_risk: float, risk_threshold: float) -> FeasibilityResult",?:v2_adapter | L3:v2_adapter,FeasibilityResult | len,,pure,no,44,Check if a plan is feasible (L4 domain function).,Policy/Decision,medium,name matches 'check'
analytics,L5,cost_model_engine,classify_drift,"classify_drift(v1_cost_cents: int, v2_cost_cents: int, v1_feasible: bool, v2_feasible: bool) -> DriftAnalysis",?:v2_adapter | L3:v2_adapter,DriftAnalysis | abs | max | min | round,,pure,no,56,Classify drift between V1 and V2 simulation results (L4 domain function).,Unclassified,low,no classification rules matched
analytics,L5,cost_model_engine,estimate_step_cost,"estimate_step_cost(step_index: int, skill_id: str, params: Dict[str, Any]) -> StepCostEstimate",?:v2_adapter | L3:v2_adapter,StepCostEstimate | get | get_skill_coefficients | len | min | split | startswith | str,,pure,no,93,Estimate cost and latency for a single step (L4 domain function).,Unclassified,low,no classification rules matched
analytics,L5,cost_model_engine,get_skill_coefficients,"get_skill_coefficients(skill_id: str) -> Dict[str, float]",?:v2_adapter | L3:v2_adapter,get,,pure,no,11,Get cost model coefficients for a skill (L4 domain function).,Unclassified,low,no classification rules matched
analytics,L5,cost_model_engine,is_significant_risk,is_significant_risk(probability: float) -> bool,?:v2_adapter | L3:v2_adapter,,,pure,no,3,Check if a risk factor is significant enough to report (L4 domain function).,Unclassified,low,no classification rules matched
analytics,L5,cost_snapshot_schemas,CostSnapshot.create,"create(tenant_id: str, snapshot_type: SnapshotType, period_start: datetime, period_end: datetime) -> 'CostSnapshot'",L5:cost_snapshots | L5s:__init__,cls | encode | hexdigest | isoformat | sha256,__future__,pure,no,17,Create a new snapshot in pending status.,Unclassified,low,no classification rules matched
analytics,L5,cost_snapshot_schemas,CostSnapshot.to_dict,"to_dict() -> dict[str, Any]",L5:cost_snapshots | L5s:__init__,isinstance | isoformat,__future__,pure,no,15,,Internal Helper,medium,name matches 'to_'
analytics,L5,cost_snapshot_schemas,SnapshotAggregate.create,"create(snapshot_id: str, tenant_id: str, entity_type: EntityType, entity_id: str | None, total_cost_cents: float, request_count: int, total_input_tokens: int, total_output_tokens: int) -> 'SnapshotAggregate'",L5:cost_snapshots | L5s:__init__,cls | encode | hexdigest | sha256,__future__,pure,no,28,,Unclassified,low,no classification rules matched
analytics,L5,cost_snapshot_schemas,SnapshotBaseline.create,"create(tenant_id: str, entity_type: EntityType, entity_id: str | None, window_days: int, avg_daily_cost_cents: float, avg_daily_requests: float, samples_count: int, stddev: float | None, max_cost: float | None, min_cost: float | None, last_snapshot_id: str | None) -> 'SnapshotBaseline'",L5:cost_snapshots | L5s:__init__,cls | date | encode | hexdigest | isoformat | now | sha256 | timedelta,__future__,pure,no,34,,Unclassified,low,no classification rules matched
analytics,L5,cost_snapshots,BaselineComputer.__init__,__init__(session: AsyncSession),,,__future__ | asyncio | cost_snapshot_schemas,pure,no,2,,Internal Helper,high,dunder method
analytics,L5,cost_snapshots,BaselineComputer._insert_baseline,async _insert_baseline(baseline: SnapshotBaseline) -> None,,__import__ | execute | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,59,"Insert baseline, marking old ones as not current.",Internal Helper,medium,private function
analytics,L5,cost_snapshots,BaselineComputer.compute_baselines,"async compute_baselines(tenant_id: str, window_days: int) -> list[SnapshotBaseline]",,EntityType | __import__ | _insert_baseline | append | create | execute | fetchall | float | int | replace | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,53,Compute baselines for all entities from historical snapshots.,Unclassified,low,no classification rules matched
analytics,L5,cost_snapshots,SnapshotAnomalyDetector.__init__,__init__(session: AsyncSession),,,__future__ | asyncio | cost_snapshot_schemas,pure,no,2,,Internal Helper,high,dunder method
analytics,L5,cost_snapshots,SnapshotAnomalyDetector._create_anomaly_from_evaluation,"async _create_anomaly_from_evaluation(evaluation: AnomalyEvaluation, snapshot: CostSnapshot) -> str",,__import__ | encode | execute | get | hexdigest | info | sha256 | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,50,Create cost anomaly from evaluation (bridges to M26).,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotAnomalyDetector._get_snapshot,async _get_snapshot(snapshot_id: str) -> CostSnapshot | None,,CostSnapshot | SnapshotStatus | SnapshotType | __import__ | execute | fetchone | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,19,Get snapshot by ID.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotAnomalyDetector._insert_evaluation,async _insert_evaluation(evaluation: AnomalyEvaluation) -> None,,__import__ | execute | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,32,Persist evaluation record.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotAnomalyDetector.evaluate_snapshot,"async evaluate_snapshot(snapshot_id: str, threshold_pct: float) -> list[AnomalyEvaluation]",,AnomalyEvaluation | EntityType | __import__ | _create_anomaly_from_evaluation | _get_snapshot | _insert_evaluation | append | encode | execute | fetchall | hexdigest | sha256 | text | warning,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,74,Evaluate all aggregates in a snapshot for anomalies.,Policy/Decision,medium,name matches 'evaluate'
analytics,L5,cost_snapshots,SnapshotComputer.__init__,__init__(session: AsyncSession),,,__future__ | asyncio | cost_snapshot_schemas,pure,no,2,,Internal Helper,high,dunder method
analytics,L5,cost_snapshots,SnapshotComputer._aggregate_cost_records,"async _aggregate_cost_records(tenant_id: str, snapshot_id: str, period_start: datetime, period_end: datetime) -> list[SnapshotAggregate]",,__import__ | append | create | execute | fetchall | fetchone | float | int | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,157,Aggregate cost records by entity type.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer._compute_snapshot,"async _compute_snapshot(tenant_id: str, snapshot_type: SnapshotType, period_start: datetime, period_end: datetime) -> CostSnapshot",,_aggregate_cost_records | _get_current_baseline | _insert_aggregate | _insert_snapshot | _update_snapshot | create | error | info | int | now | str | sum | time,__future__ | asyncio | cost_snapshot_schemas,pure,yes,69,Internal snapshot computation.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer._get_current_baseline,"async _get_current_baseline(tenant_id: str, entity_type: EntityType, entity_id: str | None, window_days: int) -> SnapshotBaseline | None",,EntityType | SnapshotBaseline | __import__ | execute | fetchone | isinstance | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,47,Get current baseline for an entity.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer._insert_aggregate,async _insert_aggregate(agg: SnapshotAggregate) -> None,,__import__ | execute | isinstance | now | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,44,Insert aggregate record.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer._insert_snapshot,async _insert_snapshot(snapshot: CostSnapshot) -> None,,__import__ | execute | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,26,Insert snapshot record.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer._update_snapshot,async _update_snapshot(snapshot: CostSnapshot) -> None,,__import__ | execute | text,__future__ | asyncio | cost_snapshot_schemas,db_write,yes,22,Update snapshot record.,Internal Helper,medium,private function
analytics,L5,cost_snapshots,SnapshotComputer.compute_daily_snapshot,"async compute_daily_snapshot(tenant_id: str, date: datetime | None) -> CostSnapshot",,_compute_snapshot | now | replace | timedelta,__future__ | asyncio | cost_snapshot_schemas,pure,yes,29,Compute daily snapshot for a tenant.,Internal Helper,low,pure function with no callers
analytics,L5,cost_snapshots,SnapshotComputer.compute_hourly_snapshot,"async compute_hourly_snapshot(tenant_id: str, hour: datetime | None) -> CostSnapshot",,_compute_snapshot | now | replace | timedelta,__future__ | asyncio | cost_snapshot_schemas,pure,yes,27,Compute hourly snapshot for a tenant.,Internal Helper,low,pure function with no callers
analytics,L5,cost_snapshots,run_daily_snapshot_and_baseline_job,"async run_daily_snapshot_and_baseline_job(session: AsyncSession, tenant_ids: list[str]) -> dict",,BaselineComputer | SnapshotAnomalyDetector | SnapshotComputer | append | compute_baselines | compute_daily_snapshot | evaluate_snapshot | len,__future__ | asyncio | cost_snapshot_schemas,pure,yes,44,Run daily snapshot and baseline computation for multiple tenants.,Internal Helper,low,pure function with no callers
analytics,L5,cost_snapshots,run_hourly_snapshot_job,"async run_hourly_snapshot_job(session: AsyncSession, tenant_ids: list[str]) -> dict",,SnapshotComputer | append | compute_hourly_snapshot | str,__future__ | asyncio | cost_snapshot_schemas,pure,yes,19,Run hourly snapshot job for multiple tenants.,Internal Helper,low,pure function with no callers
analytics,L5,cost_write_engine,CostWriteService.__init__,__init__(session: 'Session'),,get_cost_write_driver,cost_write_driver | db | sqlmodel,pure,no,2,,Internal Helper,high,dunder method
analytics,L5,cost_write_engine,CostWriteService.create_cost_record,"create_cost_record(tenant_id: str, user_id: Optional[str], feature_tag: Optional[str], request_id: Optional[str], workflow_id: Optional[str], skill_id: Optional[str], model: str, input_tokens: int, output_tokens: int, cost_cents: int) -> 'CostRecord'",,create_cost_record,cost_write_driver | db | sqlmodel,pure,no,26,Delegate to driver.,Internal Helper,low,pure function with no callers
analytics,L5,cost_write_engine,CostWriteService.create_feature_tag,"create_feature_tag(tenant_id: str, tag: str, display_name: str, description: Optional[str], budget_cents: Optional[int]) -> 'FeatureTag'",,create_feature_tag,cost_write_driver | db | sqlmodel,pure,no,16,Delegate to driver.,Internal Helper,low,pure function with no callers
analytics,L5,cost_write_engine,CostWriteService.create_or_update_budget,"create_or_update_budget(existing_budget: Optional['CostBudget'], tenant_id: str, budget_type: str, entity_id: Optional[str], daily_limit_cents: Optional[int], monthly_limit_cents: Optional[int], warn_threshold_pct: int, hard_limit_enabled: bool) -> 'CostBudget'",,create_or_update_budget,cost_write_driver | db | sqlmodel,pure,no,22,Delegate to driver.,Internal Helper,low,pure function with no callers
analytics,L5,cost_write_engine,CostWriteService.update_feature_tag,"update_feature_tag(feature_tag: 'FeatureTag', display_name: Optional[str], description: Optional[str], budget_cents: Optional[int], is_active: Optional[bool]) -> 'FeatureTag'",,update_feature_tag,cost_write_driver | db | sqlmodel,pure,no,16,Delegate to driver.,Internal Helper,low,pure function with no callers
analytics,L5,costsim_models,CanaryReport.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,__future__,pure,no,19,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,costsim_models,ComparisonResult.to_dict,"to_dict() -> Dict[str, Any]",,,__future__,pure,no,17,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,costsim_models,DiffResult.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,__future__,pure,no,13,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,costsim_models,DivergenceReport.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,__future__,pure,no,15,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,costsim_models,V2SimulationResult.compute_output_hash,compute_output_hash() -> str,,dumps | encode | hexdigest | sha256,__future__,pure,no,12,Compute deterministic hash of output.,Internal Helper,low,pure function with no callers
analytics,L5,costsim_models,V2SimulationResult.to_dict,"to_dict() -> Dict[str, Any]",,,__future__,pure,no,16,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,costsim_models,ValidationResult.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,__future__,pure,no,15,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
analytics,L5,datasets,DatasetValidator.__init__,__init__(),?:costsim | L2:costsim,_build_datasets,__future__ | models | random | v2_adapter,pure,no,3,Initialize validator with built-in datasets.,Internal Helper,high,dunder method
analytics,L5,datasets,DatasetValidator._build_datasets,"_build_datasets() -> Dict[str, ReferenceDataset]",?:costsim | L2:costsim,_build_high_variance_dataset | _build_historical_dataset | _build_low_variance_dataset | _build_mixed_city_dataset | _build_noise_injected_dataset,__future__ | models | random | v2_adapter,pure,no,9,Build all reference datasets.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._build_high_variance_dataset,_build_high_variance_dataset() -> ReferenceDataset,?:costsim | L2:costsim,DatasetSample | ReferenceDataset | append | choice | enumerate | randint | range,__future__ | models | random | v2_adapter,pure,no,81,Build high variance dataset.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._build_historical_dataset,_build_historical_dataset() -> ReferenceDataset,?:costsim | L2:costsim,DatasetSample | ReferenceDataset | append,__future__ | models | random | v2_adapter,pure,no,100,Build historical dataset.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._build_low_variance_dataset,_build_low_variance_dataset() -> ReferenceDataset,?:costsim | L2:costsim,DatasetSample | ReferenceDataset | append | range,__future__ | models | random | v2_adapter,pure,no,77,Build low variance dataset.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._build_mixed_city_dataset,_build_mixed_city_dataset() -> ReferenceDataset,?:costsim | L2:costsim,DatasetSample | ReferenceDataset | append | range,__future__ | models | random | v2_adapter,pure,no,84,Build mixed city dataset.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._build_noise_injected_dataset,_build_noise_injected_dataset() -> ReferenceDataset,?:costsim | L2:costsim,DatasetSample | ReferenceDataset | append | range,__future__ | models | random | v2_adapter,pure,no,117,Build noise-injected dataset.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator._calculate_drift_score,"_calculate_drift_score(mean_error: float, median_error: float, std_deviation: float, outlier_pct: float, thresholds: Dict[str, float]) -> float",?:costsim | L2:costsim,min,__future__ | models | random | v2_adapter,pure,no,19,Calculate overall drift score.,Internal Helper,medium,private function
analytics,L5,datasets,DatasetValidator.get_dataset,get_dataset(dataset_id: str) -> Optional[ReferenceDataset],?:costsim | L2:costsim,get,__future__ | models | random | v2_adapter,pure,no,3,Get a dataset by ID.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,datasets,DatasetValidator.list_datasets,"list_datasets() -> List[Dict[str, Any]]",?:costsim | L2:costsim,to_dict | values,__future__ | models | random | v2_adapter,pure,no,3,List all available datasets.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,datasets,DatasetValidator.validate_all,"async validate_all() -> Dict[str, ValidationResult]",?:costsim | L2:costsim,validate_dataset,__future__ | models | random | v2_adapter,pure,yes,6,Validate V2 against all datasets.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
analytics,L5,datasets,DatasetValidator.validate_dataset,async validate_dataset(dataset_id: str) -> ValidationResult,?:costsim | L2:costsim,CostSimV2Adapter | ValidationResult | ValueError | _calculate_drift_score | abs | append | error | get | len | round | simulate | sorted | sqrt | sum,__future__ | models | random | v2_adapter,pure,yes,95,Validate V2 against a reference dataset.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
analytics,L5,datasets,ReferenceDataset.to_dict,"to_dict() -> Dict[str, Any]",?:costsim | L2:costsim,len,__future__ | models | random | v2_adapter,pure,no,9,Convert to dictionary.,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
analytics,L5,datasets,get_dataset_validator,get_dataset_validator() -> DatasetValidator,?:costsim | L2:costsim,DatasetValidator,__future__ | models | random | v2_adapter,pure,no,6,Get the global dataset validator.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,datasets,validate_all_datasets,"async validate_all_datasets() -> Dict[str, ValidationResult]",?:costsim | L2:costsim,get_dataset_validator | validate_all,__future__ | models | random | v2_adapter,pure,yes,4,Convenience function to validate all datasets.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
analytics,L5,datasets,validate_dataset,async validate_dataset(dataset_id: str) -> ValidationResult,?:costsim | L2:costsim,get_dataset_validator | validate_dataset,__future__ | models | random | v2_adapter,pure,yes,4,Convenience function to validate a dataset.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
analytics,L5,detection_facade,AnomalyInfo.to_dict,"to_dict() -> Dict[str, Any]",L4:analytics_handler | ?:anomaly_severity,,cost_anomaly_detector,pure,no,21,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
analytics,L5,detection_facade,DetectionFacade.__init__,__init__(),L4:analytics_handler | ?:anomaly_severity,,cost_anomaly_detector,pure,no,7,Initialize facade with lazy-loaded services.,Internal Helper,high,dunder method
analytics,L5,detection_facade,DetectionFacade._run_cost_detection,"async _run_cost_detection(tenant_id: str, session) -> DetectionResult",L4:analytics_handler | ?:anomaly_severity,AnomalyInfo | DetectionResult | error | get | hasattr | isoformat | len | now | run_anomaly_detection_with_governance | str,cost_anomaly_detector,pure,yes,89,Run cost anomaly detection.,Internal Helper,medium,private function
analytics,L5,detection_facade,DetectionFacade.acknowledge_anomaly,"async acknowledge_anomaly(anomaly_id: str, tenant_id: str, actor: Optional[str]) -> Optional[AnomalyInfo]",L4:analytics_handler | ?:anomaly_severity,get | isoformat | now,cost_anomaly_detector,pure,yes,27,Acknowledge an anomaly (mark as seen but not resolved).,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionFacade.cost_detector,cost_detector(),L4:analytics_handler | ?:anomaly_severity,warning,cost_anomaly_detector,pure,no,10,Lazy-load CostAnomalyDetector.,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionFacade.get_anomaly,"async get_anomaly(anomaly_id: str, tenant_id: str) -> Optional[AnomalyInfo]",L4:analytics_handler | ?:anomaly_severity,get,cost_anomaly_detector,pure,yes,19,Get a specific anomaly.,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionFacade.get_detection_status,get_detection_status() -> DetectionStatusInfo,L4:analytics_handler | ?:anomaly_severity,DetectionStatusInfo | isoformat,cost_anomaly_detector,pure,no,30,Get detection engine status.,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionFacade.list_anomalies,"async list_anomalies(tenant_id: str, detection_type: Optional[str], severity: Optional[str], status: Optional[str], limit: int, offset: int) -> List[AnomalyInfo]",L4:analytics_handler | ?:anomaly_severity,append | debug | sort | values,cost_anomaly_detector,pure,yes,46,List anomalies for a tenant.,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionFacade.resolve_anomaly,"async resolve_anomaly(anomaly_id: str, tenant_id: str, resolution: str, notes: Optional[str], actor: Optional[str]) -> Optional[AnomalyInfo]",L4:analytics_handler | ?:anomaly_severity,get | info | isoformat | now,cost_anomaly_detector,pure,yes,43,Resolve an anomaly.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
analytics,L5,detection_facade,DetectionFacade.run_detection,"async run_detection(tenant_id: str, detection_type: str, session) -> DetectionResult",L4:analytics_handler | ?:anomaly_severity,DetectionResult | _run_cost_detection | error | info | isoformat | now | str,cost_anomaly_detector,pure,yes,56,Run anomaly detection on demand.,Operation,high,called by L4 orchestrator
analytics,L5,detection_facade,DetectionResult.to_dict,"to_dict() -> Dict[str, Any]",L4:analytics_handler | ?:anomaly_severity,,cost_anomaly_detector,pure,no,12,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
analytics,L5,detection_facade,DetectionStatusInfo.to_dict,"to_dict() -> Dict[str, Any]",L4:analytics_handler | ?:anomaly_severity,,cost_anomaly_detector,pure,no,8,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
analytics,L5,detection_facade,get_detection_facade,get_detection_facade() -> DetectionFacade,L4:analytics_handler | ?:anomaly_severity,DetectionFacade,cost_anomaly_detector,pure,no,14,Get the detection facade instance.,Operation,high,called by L4 orchestrator
analytics,L5,divergence,DivergenceAnalyzer.__init__,"__init__(outlier_threshold: float, major_drift_threshold: float)",?:costsim | ?:__init__ | L2:costsim,,__future__ | config | models | provenance,pure,no,14,Initialize divergence analyzer.,Internal Helper,high,dunder method
analytics,L5,divergence,DivergenceAnalyzer._calculate_kl_divergence,"_calculate_kl_divergence(p: List[int], q: List[int], bins: int) -> float",?:costsim | ?:__init__ | L2:costsim,int | log | max | min | sum | zip,__future__ | config | models | provenance,pure,no,50,Calculate KL divergence between two distributions.,Internal Helper,medium,private function
analytics,L5,divergence,DivergenceAnalyzer._calculate_metrics,"_calculate_metrics(samples: List[DivergenceSample]) -> Dict[str, Any]",?:costsim | ?:__init__ | L2:costsim,_calculate_kl_divergence | abs | float | int | len | round | sorted | sum,__future__ | config | models | provenance,pure,no,46,Calculate divergence metrics from samples.,Internal Helper,medium,private function
analytics,L5,divergence,DivergenceAnalyzer._load_samples,"async _load_samples(start_date: datetime, end_date: datetime, tenant_id: Optional[str], max_samples: int) -> List[DivergenceSample]",?:costsim | ?:__init__ | L2:costsim,_parse_provenance_log | append | error | get_provenance_logger | query | warning,__future__ | config | models | provenance,pure,yes,31,Load samples from provenance logs.,Internal Helper,medium,private function
analytics,L5,divergence,DivergenceAnalyzer._parse_provenance_log,_parse_provenance_log(log: ProvenanceLog) -> Optional[DivergenceSample],?:costsim | ?:__init__ | L2:costsim,DivergenceSample | get | get_decompressed_output | warning,__future__ | config | models | provenance,pure,no,40,Parse a provenance log into a divergence sample.,Internal Helper,medium,private function
analytics,L5,divergence,DivergenceAnalyzer.generate_report,"async generate_report(start_date: Optional[datetime], end_date: Optional[datetime], tenant_id: Optional[str], max_samples: int) -> DivergenceReport",?:costsim | ?:__init__ | L2:costsim,DivergenceReport | _calculate_metrics | _load_samples | get_config | isoformat | len | now | timedelta,__future__ | config | models | provenance,pure,yes,79,Generate a divergence report for the specified time range.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,divergence,generate_divergence_report,"async generate_divergence_report(start_date: Optional[datetime], end_date: Optional[datetime], tenant_id: Optional[str]) -> DivergenceReport",?:costsim | ?:__init__ | L2:costsim,DivergenceAnalyzer | generate_report,__future__ | config | models | provenance,pure,yes,22,Convenience function to generate a divergence report.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,envelope,EnvelopeValidationError.__init__,"__init__(rule_id: str, message: str)",?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,__init__ | super,,pure,no,4,,Internal Helper,high,dunder method
analytics,L5,envelope,calculate_bounded_value,"calculate_bounded_value(baseline: float, bounds: EnvelopeBounds, prediction_confidence: float) -> float",?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,min,,pure,no,47,Calculate the bounded value based on prediction confidence.,Unclassified,low,no classification rules matched
analytics,L5,envelope,create_audit_record,"create_audit_record(envelope: Envelope, baseline_value: float) -> EnvelopeAuditRecord",?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,EnvelopeAuditRecord | now,,pure,no,14,Create an audit record for envelope application.,Unclassified,low,no classification rules matched
analytics,L5,envelope,get_envelope_priority,get_envelope_priority(envelope_class: EnvelopeClass) -> int,?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,,,pure,no,3,Get the priority of an envelope class (lower number = higher priority).,Unclassified,low,no classification rules matched
analytics,L5,envelope,has_higher_priority,"has_higher_priority(class_a: EnvelopeClass, class_b: EnvelopeClass) -> bool",?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,get_envelope_priority,,pure,no,3,Check if class_a has higher priority than class_b.,Unclassified,low,no classification rules matched
analytics,L5,envelope,validate_envelope,validate_envelope(envelope: Envelope) -> None,?:coordinator | ?:manager | ?:__init__ | ?:s1_retry_backoff | ?:s2_cost_smoothing | ?:logs | ?:s1_rollback | L5:coordinator | L5:s1_retry_backoff | L5:s2_cost_smoothing,EnvelopeValidationError | info | issubset | set,,pure,no,74,Validate envelope against hard gate rules (V1-V5 + CI-C4-1).,Policy/Decision,medium,name matches 'validate'
analytics,L5,metrics,CostSimMetrics.__init__,__init__(prefix: str),?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,_init_metrics | warning,__future__ | config | prometheus_client,pure,no,14,Initialize metrics.,Internal Helper,high,dunder method
analytics,L5,metrics,CostSimMetrics._init_metrics,_init_metrics() -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,Counter | Gauge | Histogram | Info | get_config | info,__future__ | config | prometheus_client,pure,no,140,Initialize Prometheus metrics.,Internal Helper,medium,private function
analytics,L5,metrics,CostSimMetrics.record_alert_send_failure,"record_alert_send_failure(alert_type: str, error_type: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,19,Record alert send failure.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_auto_recovery,record_auto_recovery() -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc,__future__ | config | prometheus_client,pure,no,6,Record auto-recovery event after TTL expiry.,Internal Helper,medium,name matches 'to_'
analytics,L5,metrics,CostSimMetrics.record_canary_run,record_canary_run(status: str) -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,11,Record canary run completion.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_cb_disabled,"record_cb_disabled(reason: str, severity: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,16,Record circuit breaker disable event.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_cb_enabled,record_cb_enabled(reason: str) -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,11,Record circuit breaker enable (recovery) event.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_cb_incident,"record_cb_incident(severity: str, resolved: bool) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels | lower | str,__future__ | config | prometheus_client,pure,no,19,Record circuit breaker incident.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_cost_delta,"record_cost_delta(delta_cents: int, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,abs | labels | observe,__future__ | config | prometheus_client,pure,no,16,Record cost delta.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_drift,"record_drift(drift_score: float, verdict: str, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels | observe,__future__ | config | prometheus_client,pure,no,22,Record drift observation.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_provenance_log,record_provenance_log(tenant_id: str) -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,6,Record provenance log entry.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_schema_error,"record_schema_error(error_type: str, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,19,Record schema validation error.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_simulation,"record_simulation(status: str, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,inc | labels,__future__ | config | prometheus_client,pure,no,19,Record simulation completion.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.record_simulation_duration,"record_simulation_duration(duration_ms: int, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,labels | observe,__future__ | config | prometheus_client,pure,no,16,Record simulation duration.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.set_alert_queue_depth,set_alert_queue_depth(depth: int) -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,set,__future__ | config | prometheus_client,pure,no,11,Set current alert queue depth.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.set_circuit_breaker_state,"set_circuit_breaker_state(is_open: bool, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,labels | set,__future__ | config | prometheus_client,pure,no,16,Set circuit breaker state.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.set_consecutive_failures,set_consecutive_failures(count: int) -> None,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,set,__future__ | config | prometheus_client,pure,no,11,Set current consecutive failure count.,Unclassified,low,no classification rules matched
analytics,L5,metrics,CostSimMetrics.set_kl_divergence,"set_kl_divergence(kl_divergence: float, tenant_id: str) -> None",?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,labels | set,__future__ | config | prometheus_client,pure,no,16,Set latest KL divergence.,Unclassified,low,no classification rules matched
analytics,L5,metrics,get_alert_rules,get_alert_rules() -> str,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,,__future__ | config | prometheus_client,pure,no,3,Get Prometheus alert rules YAML.,Unclassified,low,no classification rules matched
analytics,L5,metrics,get_metrics,get_metrics() -> CostSimMetrics,?:rbac_middleware | ?:rbac_integration | ?:tier_gating | ?:incidents | ?:activity | ?:recovery | ?:analytics | ?:recovery_ingest | ?:governance | ?:__init__,CostSimMetrics,__future__ | config | prometheus_client,pure,no,6,Get the global CostSim metrics instance.,Unclassified,low,no classification rules matched
analytics,L5,pattern_detection,compute_error_signature,compute_error_signature(error: str) -> str,,encode | hexdigest | lower | sha256 | strip | sub,db | feedback | pattern_detection_driver | time,pure,no,21,Compute a stable signature for an error message.,Internal Helper,low,pure function with no callers
analytics,L5,pattern_detection,detect_cost_spikes,"async detect_cost_spikes(driver: PatternDetectionDriver, tenant_id: Optional[UUID], spike_threshold_percent: float, min_runs: int) -> list[dict]",,append | fetch_completed_runs_with_costs | info | items | len | round | str | sum,db | feedback | pattern_detection_driver | time,pure,yes,74,Detect abnormal cost increases.,Internal Helper,low,pure function with no callers
analytics,L5,pattern_detection,detect_failure_patterns,"async detect_failure_patterns(driver: PatternDetectionDriver, tenant_id: Optional[UUID], threshold: int, window_hours: int) -> list[dict]",,append | compute_error_signature | fetch_failed_runs | info | items | len | str | timedelta | utc_now,db | feedback | pattern_detection_driver | time,pure,yes,61,Detect repeated failure patterns.,Internal Helper,low,pure function with no callers
analytics,L5,pattern_detection,emit_feedback,"async emit_feedback(driver: PatternDetectionDriver, feedback: PatternFeedbackCreate) -> dict",,UUID | info | insert_feedback | isinstance | len | str | utc_now,db | feedback | pattern_detection_driver | time,pure,yes,46,Emit a feedback record.,Internal Helper,low,pure function with no callers
analytics,L5,pattern_detection,get_feedback_summary,"async get_feedback_summary(tenant_id: Optional[UUID], acknowledged: Optional[bool], limit: int) -> dict",,fetch_feedback_records | get | get_async_session | get_pattern_detection_driver | isoformat | len | str,db | feedback | pattern_detection_driver | time,pure,yes,44,Get feedback summary for ops visibility.,Internal Helper,low,pure function with no callers
analytics,L5,pattern_detection,run_pattern_detection,async run_pattern_detection(tenant_id: Optional[UUID]) -> dict,,PatternFeedbackCreate | append | detect_cost_spikes | detect_failure_patterns | emit_feedback | error | get_async_session | get_pattern_detection_driver | str,db | feedback | pattern_detection_driver | time,pure,yes,81,Run full pattern detection cycle.,Internal Helper,low,pure function with no callers
analytics,L5,prediction,emit_prediction,"async emit_prediction(driver: 'PredictionDriver', tenant_id: str, prediction_type: str, subject_type: str, subject_id: str, confidence_score: float, prediction_value: dict, contributing_factors: list, notes: Optional[str], valid_until: Optional['datetime']) -> 'PredictionEvent'",?:predictions | ?:prediction | ?:api | L6:prediction_driver | L2:predictions | ?:test_pb_s5_prediction,info | insert_prediction | str | timedelta | utc_now,db | prediction | prediction_driver | time,pure,yes,53,Emit a prediction event.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,prediction,get_prediction_summary,"async get_prediction_summary(tenant_id: Optional[UUID], prediction_type: Optional[str], include_expired: bool, limit: int) -> dict",?:predictions | ?:prediction | ?:api | L6:prediction_driver | L2:predictions | ?:test_pb_s5_prediction,fetch_predictions | get | get_async_session | get_prediction_driver | isoformat | len | str | utc_now,db | prediction | prediction_driver | time,pure,yes,54,Get prediction summary for ops visibility.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,prediction,predict_cost_overrun,"async predict_cost_overrun(driver: 'PredictionDriver', tenant_id: Optional[UUID], worker_id: Optional[str]) -> list[dict]",?:predictions | ?:prediction | ?:api | L6:prediction_driver | L2:predictions | ?:test_pb_s5_prediction,append | fetch_cost_runs | info | items | len | min | round | sorted | str | sum | timedelta | utc_now,db | prediction | prediction_driver | time,pure,yes,97,Predict likelihood of cost overrun for upcoming runs.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,prediction,predict_failure_likelihood,"async predict_failure_likelihood(driver: 'PredictionDriver', tenant_id: Optional[UUID], worker_id: Optional[str]) -> list[dict]",?:predictions | ?:prediction | ?:api | L6:prediction_driver | L2:predictions | ?:test_pb_s5_prediction,append | fetch_failed_runs | fetch_failure_patterns | fetch_run_totals | get | info | items | len | list | min | round | set | str | timedelta | utc_now,db | prediction | prediction_driver | time,pure,yes,97,Predict likelihood of failure for upcoming runs.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,prediction,run_prediction_cycle,async run_prediction_cycle(tenant_id: Optional[UUID]) -> dict,?:predictions | ?:prediction | ?:api | L6:prediction_driver | L2:predictions | ?:test_pb_s5_prediction,append | emit_prediction | error | get_async_session | get_prediction_driver | predict_cost_overrun | predict_failure_likelihood | str,db | prediction | prediction_driver | time,pure,yes,79,Run full prediction cycle.,Operation,medium,called by L2 (gap  should route via L4)
analytics,L5,provenance,ProvenanceLog.from_dict,"from_dict(data: Dict[str, Any]) -> 'ProvenanceLog'",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,cls | fromisoformat | get,__future__ | config | gzip,pure,no,19,Create from dictionary.,Internal Helper,medium,name matches 'from_'
analytics,L5,provenance,ProvenanceLog.get_decompressed_input,"get_decompressed_input() -> Dict[str, Any]",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,b64decode | decompress | loads,__future__ | config | gzip,pure,no,7,Get decompressed input JSON.,Unclassified,low,no classification rules matched
analytics,L5,provenance,ProvenanceLog.get_decompressed_output,"get_decompressed_output() -> Dict[str, Any]",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,b64decode | decompress | loads,__future__ | config | gzip,pure,no,7,Get decompressed output JSON.,Unclassified,low,no classification rules matched
analytics,L5,provenance,ProvenanceLog.to_dict,"to_dict() -> Dict[str, Any]",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,isoformat,__future__ | config | gzip,pure,no,19,Convert to dictionary for storage.,Internal Helper,medium,name matches 'to_'
analytics,L5,provenance,ProvenanceLogger.__init__,"__init__(storage_path: Optional[str], db_enabled: bool, file_enabled: bool)",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,Lock | Path | get_config | mkdir,__future__ | config | gzip,pure,no,28,Initialize provenance logger.,Internal Helper,high,dunder method
analytics,L5,provenance,ProvenanceLogger._flush,async _flush() -> None,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,_write_to_db | _write_to_file | clear | copy,__future__ | config | gzip,pure,yes,15,Flush buffer to storage.,Internal Helper,medium,private function
analytics,L5,provenance,ProvenanceLogger._store,async _store(log_entry: ProvenanceLog) -> None,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,_flush | append | len,__future__ | config | gzip,pure,yes,7,Store a provenance log entry.,Internal Helper,medium,private function
analytics,L5,provenance,ProvenanceLogger._write_to_db,async _write_to_db(entries: List[ProvenanceLog]) -> None,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,,__future__ | config | gzip,pure,yes,5,Write entries to database.,Internal Helper,medium,private function
analytics,L5,provenance,ProvenanceLogger._write_to_file,async _write_to_file(entries: List[ProvenanceLog]) -> None,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,append | dumps | error | items | open | strftime | to_dict | write,__future__ | config | gzip,file_io,yes,20,Write entries to file storage.,Internal Helper,medium,private function
analytics,L5,provenance,ProvenanceLogger.close,async close() -> None,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,_flush,__future__ | config | gzip,pure,yes,4,Flush remaining entries and close.,Unclassified,low,no classification rules matched
analytics,L5,provenance,ProvenanceLogger.log,"async log(input_data: Any, output_data: Any, runtime_ms: int, status: str, tenant_id: Optional[str], run_id: Optional[str]) -> ProvenanceLog",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,ProvenanceLog | _store | compress_json | compute_hash | dumps | get_commit_sha | get_config | now | str | uuid4,__future__ | config | gzip,pure,yes,62,Log a provenance entry.,Unclassified,low,no classification rules matched
analytics,L5,provenance,ProvenanceLogger.query,"async query(start_date: Optional[datetime], end_date: Optional[datetime], input_hash: Optional[str], status: Optional[str], tenant_id: Optional[str], limit: int) -> List[ProvenanceLog]",?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,append | error | from_dict | glob | len | loads | open | sorted,__future__ | config | gzip,file_io,yes,57,Query provenance logs.,Unclassified,low,no classification rules matched
analytics,L5,provenance,compress_json,compress_json(data: Any) -> str,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,b64encode | compress | decode | dumps | encode,__future__ | config | gzip,pure,no,5,Compress JSON data to base64-encoded gzip.,Unclassified,low,no classification rules matched
analytics,L5,provenance,compute_hash,compute_hash(data: Any) -> str,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,dumps | encode | hexdigest | isinstance | sha256 | str,__future__ | config | gzip,pure,no,7,Compute SHA256 hash of data.,Unclassified,low,no classification rules matched
analytics,L5,provenance,get_provenance_logger,get_provenance_logger() -> ProvenanceLogger,?:feedback | ?:nodes | ?:panel_response_assembler | ?:pattern_detection | ?:divergence | ?:__init__ | ?:canary | ?:v2_adapter | L5:nodes | L3:v2_adapter,ProvenanceLogger,__future__ | config | gzip,pure,no,6,Get the global provenance logger.,Unclassified,low,no classification rules matched
analytics,L5,s1_retry_backoff,create_s1_envelope,"create_s1_envelope(baseline_value: float, reference_id: str) -> Envelope",?:__init__ | ?:test_c3_s3_failure_matrix | ?:test_c3_failure_scenarios,Envelope | EnvelopeBaseline | EnvelopeBounds | EnvelopeScope | EnvelopeTimebox | EnvelopeTrigger,envelope,pure,no,50,Create a fresh S1 envelope instance with specified baseline.,Unclassified,low,no classification rules matched
analytics,L5,sandbox,CostSimSandbox.__init__,"__init__(budget_cents: int, allowed_skills: Optional[List[str]], risk_threshold: float, tenant_id: Optional[str], run_id: Optional[str])",?:engine | ?:__init__,CostSimulator,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,no,33,Initialize sandbox router.,Internal Helper,high,dunder method
analytics,L5,sandbox,CostSimSandbox._get_v2_adapter,_get_v2_adapter() -> CostSimV2Adapter,?:engine | ?:__init__,CostSimV2Adapter,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,no,12,Get or create V2 adapter.,Internal Helper,medium,private function
analytics,L5,sandbox,CostSimSandbox._log_comparison,_log_comparison(comparison: ComparisonResult) -> None,?:engine | ?:__init__,debug | error | info | warning,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,no,28,Log comparison result for monitoring.,Internal Helper,medium,private function
analytics,L5,sandbox,CostSimSandbox.simulate,"async simulate(plan: List[Dict[str, Any]]) -> SandboxResult",?:engine | ?:__init__,SandboxResult | _get_v2_adapter | _log_comparison | error | is_v2_disabled | is_v2_sandbox_enabled | report_drift | simulate | simulate_with_comparison | str | warning,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,yes,73,Run simulation through sandbox.,Unclassified,low,no classification rules matched
analytics,L5,sandbox,SandboxResult.production_result,production_result() -> SimulationResult,?:engine | ?:__init__,,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,no,3,Get the production result (always V1).,Unclassified,low,no classification rules matched
analytics,L5,sandbox,get_sandbox,"get_sandbox(budget_cents: int, tenant_id: Optional[str]) -> CostSimSandbox",?:engine | ?:__init__,CostSimSandbox,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,no,31,Get a sandbox instance.,Unclassified,low,no classification rules matched
analytics,L5,sandbox,simulate_with_sandbox,"async simulate_with_sandbox(plan: List[Dict[str, Any]], budget_cents: int, allowed_skills: Optional[List[str]], tenant_id: Optional[str], run_id: Optional[str]) -> SandboxResult",?:engine | ?:__init__,CostSimSandbox | simulate,__future__ | circuit_breaker_async | config | models | simulate | v2_adapter,pure,yes,27,Convenience function for sandbox simulation.,Unclassified,low,no classification rules matched
analytics,L6,analytics_read_driver,AnalyticsReadDriver.__init__,__init__(session: AsyncSession),L5:analytics_facade,,asyncio | sqlalchemy,pure,no,3,Initialize driver with async session.,Internal Helper,high,dunder method
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_cost_by_feature,"async fetch_cost_by_feature(tenant_id: str, from_ts: datetime, to_ts: datetime) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | float | text,asyncio | sqlalchemy,db_write,yes,48,Fetch cost breakdown by feature tag from cost_records table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_cost_by_model,"async fetch_cost_by_model(tenant_id: str, from_ts: datetime, to_ts: datetime) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | float | text,asyncio | sqlalchemy,db_write,yes,52,Fetch cost breakdown by model from cost_records table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_cost_metrics,"async fetch_cost_metrics(tenant_id: str, from_ts: datetime, to_ts: datetime, time_trunc: str) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | isoformat | text,asyncio | sqlalchemy,db_write,yes,51,Fetch cost metrics from cost_records table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_cost_spend,"async fetch_cost_spend(tenant_id: str, from_ts: datetime, to_ts: datetime, time_trunc: str) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | float | isoformat | text,asyncio | sqlalchemy,db_write,yes,55,Fetch cost spend data from cost_records table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_llm_usage,"async fetch_llm_usage(tenant_id: str, from_ts: datetime, to_ts: datetime, time_trunc: str) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | isoformat | text,asyncio | sqlalchemy,db_write,yes,51,Fetch LLM usage from runs table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,AnalyticsReadDriver.fetch_worker_execution,"async fetch_worker_execution(tenant_id: str, from_ts: datetime, to_ts: datetime, time_trunc: str) -> list[dict[str, Any]]",L5:analytics_facade,execute | fetchall | isoformat | text,asyncio | sqlalchemy,db_write,yes,49,Fetch worker execution metrics from aos_traces table.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,analytics_read_driver,get_analytics_read_driver,get_analytics_read_driver(session: AsyncSession) -> AnalyticsReadDriver,L5:analytics_facade,AnalyticsReadDriver,asyncio | sqlalchemy,pure,no,3,Get an AnalyticsReadDriver instance.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,audit_persistence,_now_utc,_now_utc() -> datetime,?:coordinator | L5:coordinator | ?:check_priority4_intent,now,infra | sqlmodel,pure,no,3,Get current UTC timestamp.,Internal Helper,medium,private function
analytics,L6,audit_persistence,persist_audit_record,"persist_audit_record(db: Session, audit_id: str, envelope_id: str, envelope_class: str, decision: str, reason: str, decision_timestamp: datetime, conflicting_envelope_id: Optional[str], preempting_envelope_id: Optional[str], active_envelopes_count: int, tenant_id: Optional[str], emit_traces: bool) -> bool",?:coordinator | L5:coordinator | ?:check_priority4_intent,CoordinationAuditRecordDB | UUID | add | debug | error | isinstance | rollback | str,infra | sqlmodel,db_write,no,90,Persist a coordination audit record to the database.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.__init__,__init__(session: Session),L6:__init__ | L5:cost_anomaly_detector,,sqlalchemy | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_baseline_avg,"fetch_baseline_avg(tenant_id: str, baseline_start: date, baseline_end: date) -> float",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,42,Fetch 21-day baseline average cost (excluding rolling period).,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_breach_exists_today,"fetch_breach_exists_today(tenant_id: str, entity_type: str, entity_id: str, breach_type: str, today: date) -> bool",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,42,Check if breach already recorded for today.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_consecutive_breaches,"fetch_consecutive_breaches(tenant_id: str, entity_type: str, entity_id: str, breach_type: str, today: date) -> int",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,53,Count consecutive breaches ending on today.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_daily_spend,"fetch_daily_spend(tenant_id: str, today_start: datetime, budget_type: Optional[str], entity_id: Optional[str]) -> float",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,42,Fetch daily spend for budget checking.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_drift_tracking,"fetch_drift_tracking(tenant_id: str, entity_type: str, entity_id: str) -> Optional[Tuple[str, int, date, date]]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,37,Fetch active drift tracking record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_entity_baseline,"fetch_entity_baseline(tenant_id: str, column_name: str, baseline_start: date, baseline_end: date) -> Dict[str, float]",L6:__init__ | L5:cost_anomaly_detector,all | execute | text,sqlalchemy | sqlmodel,db_write,no,44,Fetch baseline daily averages per entity (user or feature).,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_entity_today_spend,"fetch_entity_today_spend(tenant_id: str, column_name: str, today_start: datetime) -> Dict[str, float]",L6:__init__ | L5:cost_anomaly_detector,all | execute | text,sqlalchemy | sqlmodel,db_write,no,37,Fetch today's spend per entity (user or feature).,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_feature_concentration,"fetch_feature_concentration(tenant_id: str, today_start: datetime) -> Tuple[Optional[float], Optional[float]]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,39,Fetch feature cost concentration for today.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_monthly_spend,"fetch_monthly_spend(tenant_id: str, month_start: date, budget_type: Optional[str], entity_id: Optional[str]) -> float",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,42,Fetch monthly spend for budget checking.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_prompt_comparison,"fetch_prompt_comparison(tenant_id: str, today_start: datetime, yesterday_start: datetime, entity_type: Optional[str], entity_id: Optional[str]) -> Tuple[Optional[float], Optional[float]]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,51,Fetch average prompt token comparison between today and yesterday.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_request_comparison,"fetch_request_comparison(tenant_id: str, today_start: datetime, yesterday_start: datetime, entity_type: Optional[str], entity_id: Optional[str]) -> Tuple[Optional[int], Optional[int]]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,51,Fetch request count comparison between today and yesterday.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_retry_comparison,"fetch_retry_comparison(tenant_id: str, today_start: datetime, yesterday_start: datetime, entity_type: Optional[str], entity_id: Optional[str]) -> Tuple[Optional[float], Optional[float]]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,53,Fetch retry ratio comparison between today and yesterday.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_rolling_avg,"fetch_rolling_avg(tenant_id: str, rolling_start: date, rolling_end: date) -> float",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,36,Fetch 7-day rolling average cost.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_tenant_baseline,"fetch_tenant_baseline(tenant_id: str, baseline_start: date, baseline_end: date) -> Optional[float]",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,36,Fetch tenant-level baseline daily average.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.fetch_tenant_today_spend,"fetch_tenant_today_spend(tenant_id: str, today_start: datetime) -> float",L6:__init__ | L5:cost_anomaly_detector,execute | first | text,sqlalchemy | sqlmodel,db_write,no,32,Fetch tenant-level today's spend.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.insert_breach_history,"insert_breach_history(breach_id: str, tenant_id: str, entity_type: str, entity_id: str, breach_type: str, breach_date: date, deviation_pct: float, current_value: float, baseline_value: float, created_at: datetime) -> None",L6:__init__ | L5:cost_anomaly_detector,execute | text,sqlalchemy | sqlmodel,db_write,no,54,Insert or update breach history record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.insert_drift_tracking,"insert_drift_tracking(drift_id: str, tenant_id: str, entity_type: str, entity_id: str, rolling_avg: float, baseline_avg: float, drift_pct: float, today: date, created_at: datetime) -> None",L6:__init__ | L5:cost_anomaly_detector,execute | text,sqlalchemy | sqlmodel,db_write,no,49,Insert new drift tracking record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.reset_drift_tracking,"reset_drift_tracking(tenant_id: str, entity_type: str, entity_id: str, updated_at: datetime) -> None",L6:__init__ | L5:cost_anomaly_detector,execute | text,sqlalchemy | sqlmodel,db_write,no,34,Mark drift tracking as inactive.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,CostAnomalyDriver.update_drift_tracking,"update_drift_tracking(drift_id: str, rolling_avg: float, baseline_avg: float, drift_pct: float, drift_days_count: int, today: date, updated_at: datetime) -> None",L6:__init__ | L5:cost_anomaly_detector,execute | text,sqlalchemy | sqlmodel,db_write,no,45,Update existing drift tracking record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_anomaly_driver,get_cost_anomaly_driver,get_cost_anomaly_driver(session: Session) -> CostAnomalyDriver,L6:__init__ | L5:cost_anomaly_detector,CostAnomalyDriver,sqlalchemy | sqlmodel,pure,no,3,Factory function to get CostAnomalyDriver instance.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_write_driver,CostWriteDriver.__init__,__init__(session: Session),L5:cost_write_engine,,db | sqlmodel | time,pure,no,2,,Internal Helper,high,dunder method
analytics,L6,cost_write_driver,CostWriteDriver.create_cost_record,"create_cost_record(tenant_id: str, user_id: Optional[str], feature_tag: Optional[str], request_id: Optional[str], workflow_id: Optional[str], skill_id: Optional[str], model: str, input_tokens: int, output_tokens: int, cost_cents: int) -> CostRecord",L5:cost_write_engine,CostRecord | add,db | sqlmodel | time,db_write,no,46,Create a new cost record and persist.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_write_driver,CostWriteDriver.create_feature_tag,"create_feature_tag(tenant_id: str, tag: str, display_name: str, description: Optional[str], budget_cents: Optional[int]) -> FeatureTag",L5:cost_write_engine,FeatureTag | add | flush | refresh,db | sqlmodel | time,db_write,no,32,Create a new feature tag and persist.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_write_driver,CostWriteDriver.create_or_update_budget,"create_or_update_budget(existing_budget: Optional[CostBudget], tenant_id: str, budget_type: str, entity_id: Optional[str], daily_limit_cents: Optional[int], monthly_limit_cents: Optional[int], warn_threshold_pct: int, hard_limit_enabled: bool) -> CostBudget",L5:cost_write_engine,CostBudget | add | flush | refresh | utc_now,db | sqlmodel | time,db_write,no,49,Create a new budget or update existing one and persist.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_write_driver,CostWriteDriver.update_feature_tag,"update_feature_tag(feature_tag: FeatureTag, display_name: Optional[str], description: Optional[str], budget_cents: Optional[int], is_active: Optional[bool]) -> FeatureTag",L5:cost_write_engine,add | flush | refresh | utc_now,db | sqlmodel | time,db_write,no,36,Update a feature tag and persist.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,cost_write_driver,get_cost_write_driver,get_cost_write_driver(session: Session) -> CostWriteDriver,L5:cost_write_engine,CostWriteDriver,db | sqlmodel | time,pure,no,3,Factory function to get CostWriteDriver instance.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,LeaderContext.__aenter__,async __aenter__() -> bool,?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,AsyncSessionLocal | error | try_acquire_leader_lock | wait_for | warning,__future__ | asyncio | db_async | sqlalchemy,pure,yes,24,Enter context and attempt to acquire leadership.,Internal Helper,high,dunder method
analytics,L6,leader,LeaderContext.__aexit__,"async __aexit__(exc_type, _exc_val, _exc_tb) -> None",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,close | error,__future__ | asyncio | db_async | sqlalchemy,pure,yes,11,Exit context and release leadership.,Internal Helper,high,dunder method
analytics,L6,leader,LeaderContext.__init__,"__init__(lock_id: int, session: Optional[AsyncSession], timeout_seconds: float)",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,,__future__ | asyncio | db_async | sqlalchemy,pure,no,19,Initialize leader context.,Internal Helper,high,dunder method
analytics,L6,leader,LeaderContext.is_leader,is_leader() -> bool,?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,,__future__ | asyncio | db_async | sqlalchemy,pure,no,3,Check if we currently hold leadership.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,is_lock_held,"async is_lock_held(session: AsyncSession, lock_id: int) -> bool",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,execute | fetchone | text,__future__ | asyncio | db_async | sqlalchemy,db_write,yes,31,Check if a lock is currently held by any session.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,leader_election,"async leader_election(lock_id: int, timeout_seconds: float) -> AsyncGenerator[bool, None]",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,AsyncSessionLocal | close | error | try_acquire_leader_lock | wait_for | warning,__future__ | asyncio | db_async | sqlalchemy,pure,yes,47,Context manager for leader election.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,release_leader_lock,"async release_leader_lock(session: AsyncSession, lock_id: int) -> bool",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,debug | execute | fetchone | info | text,__future__ | asyncio | db_async | sqlalchemy,db_write,yes,30,Explicitly release an advisory lock.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,try_acquire_leader_lock,"async try_acquire_leader_lock(session: AsyncSession, lock_id: int) -> bool",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,debug | execute | fetchone | info | text,__future__ | asyncio | db_async | sqlalchemy,db_write,yes,30,Try to acquire an advisory lock (non-blocking).,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,with_alert_worker_lock,"async with_alert_worker_lock(callback, *args, **kwargs)",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,with_leader_lock,__future__ | asyncio | db_async | sqlalchemy,pure,yes,3,Execute callback with alert worker lock.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,with_archiver_lock,"async with_archiver_lock(callback, *args, **kwargs)",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,with_leader_lock,__future__ | asyncio | db_async | sqlalchemy,pure,yes,3,Execute callback with provenance archiver lock.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,with_canary_lock,"async with_canary_lock(callback, *args, **kwargs)",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,with_leader_lock,__future__ | asyncio | db_async | sqlalchemy,pure,yes,3,Execute callback with canary runner lock.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,leader,with_leader_lock,"async with_leader_lock(lock_id: int, callback, *args, **kwargs)",?:leader | ?:alert_worker | ?:__init__ | ?:canary | L5:canary | ?:test_integration_real_db | ?:test_leader,callback | leader_election,__future__ | asyncio | db_async | sqlalchemy,pure,yes,34,Execute callback only if we can acquire leadership.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,pattern_detection_driver,PatternDetectionDriver.__init__,__init__(session: AsyncSession),L5:pattern_detection,,asyncio | feedback | sqlalchemy | tenant,pure,no,3,Initialize driver with async session.,Internal Helper,high,dunder method
analytics,L6,pattern_detection_driver,PatternDetectionDriver.fetch_completed_runs_with_costs,async fetch_completed_runs_with_costs(tenant_id: Optional[UUID]) -> list[WorkerRun],L5:pattern_detection,all | desc | execute | isnot | list | order_by | scalars | select | where,asyncio | feedback | sqlalchemy | tenant,db_write,yes,26,Fetch completed runs that have cost data.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,pattern_detection_driver,PatternDetectionDriver.fetch_failed_runs,"async fetch_failed_runs(window_start: datetime, tenant_id: Optional[UUID]) -> list[WorkerRun]",L5:pattern_detection,all | execute | isnot | list | scalars | select | where,asyncio | feedback | sqlalchemy | tenant,db_write,yes,27,Fetch failed runs within a time window.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,pattern_detection_driver,PatternDetectionDriver.fetch_feedback_records,"async fetch_feedback_records(tenant_id: Optional[UUID], acknowledged: Optional[bool], limit: int) -> list[PatternFeedback]",L5:pattern_detection,all | desc | execute | limit | list | order_by | scalars | select | where,asyncio | feedback | sqlalchemy | tenant,db_write,yes,28,Fetch pattern feedback records.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,pattern_detection_driver,PatternDetectionDriver.insert_feedback,"async insert_feedback(tenant_id: UUID, pattern_type: str, severity: str, description: str, signature: str, provenance: list[str], occurrence_count: int, time_window_minutes: int, threshold_used: str, extra_data: Optional[dict[str, Any]], detected_at: datetime, created_at: datetime) -> PatternFeedback",L5:pattern_detection,PatternFeedback | add | flush,asyncio | feedback | sqlalchemy | tenant,db_write,yes,54,Insert a pattern feedback record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,pattern_detection_driver,get_pattern_detection_driver,get_pattern_detection_driver(session: AsyncSession) -> PatternDetectionDriver,L5:pattern_detection,PatternDetectionDriver,asyncio | feedback | sqlalchemy | tenant,pure,no,3,Get a PatternDetectionDriver instance.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:prediction,,asyncio | feedback | prediction | sqlalchemy | tenant,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
analytics,L6,prediction_driver,PredictionDriver.fetch_cost_runs,"async fetch_cost_runs(since: datetime, tenant_id: Optional[UUID], worker_id: Optional[str], limit: int) -> List[WorkerRun]",L6:__init__ | L5:prediction,all | desc | execute | isnot | limit | list | order_by | scalars | select | where,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,36,Fetch completed runs with cost data.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.fetch_failed_runs,"async fetch_failed_runs(since: datetime, tenant_id: Optional[UUID], worker_id: Optional[str], limit: int) -> List[WorkerRun]",L6:__init__ | L5:prediction,all | desc | execute | limit | list | order_by | scalars | select | where,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,34,Fetch failed worker runs.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.fetch_failure_patterns,"async fetch_failure_patterns(tenant_id: Optional[UUID], limit: int) -> List[PatternFeedback]",L6:__init__ | L5:prediction,all | desc | execute | limit | list | order_by | scalars | select | str | where,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,27,Fetch failure pattern feedback records.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.fetch_predictions,"async fetch_predictions(tenant_id: Optional[UUID], prediction_type: Optional[str], valid_after: Optional[datetime], limit: int) -> List[PredictionEvent]",L6:__init__ | L5:prediction,all | desc | execute | is_ | limit | list | order_by | scalars | select | str | where,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,35,Fetch prediction events.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.fetch_run_totals,"async fetch_run_totals(since: datetime, tenant_id: Optional[UUID]) -> Dict[str, int]",L6:__init__ | L5:prediction,count | execute | group_by | label | select | str | where,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,26,Fetch total run counts grouped by worker.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,PredictionDriver.insert_prediction,"async insert_prediction(tenant_id: str, prediction_type: str, subject_type: str, subject_id: str, confidence_score: float, prediction_value: Dict[str, Any], contributing_factors: List[Dict[str, Any]], valid_until: datetime, created_at: datetime, notes: Optional[str]) -> PredictionEvent",L6:__init__ | L5:prediction,PredictionEvent | add | flush,asyncio | feedback | prediction | sqlalchemy | tenant,db_write,yes,49,Insert a new prediction event.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,prediction_driver,get_prediction_driver,get_prediction_driver(session: AsyncSession) -> PredictionDriver,L6:__init__ | L5:prediction,PredictionDriver,asyncio | feedback | prediction | sqlalchemy | tenant,pure,no,3,Factory function to get PredictionDriver instance.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,backfill_v1_baseline,"async backfill_v1_baseline(records: List[Dict[str, Any]], batch_size: int) -> Dict[str, int]",?:provenance_async | ?:test_integration_real_db,check_duplicate | error | get | info | len | range | write_provenance,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,pure,yes,46,Backfill V1 baseline records from historical data.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,check_duplicate,async check_duplicate(input_hash: str) -> bool,?:provenance_async | ?:test_integration_real_db,async_session_context | execute | first | limit | scalars | select | where,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,15,Check if a record with this input hash already exists.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
analytics,L6,provenance_async,compute_input_hash,"compute_input_hash(payload: Dict[str, Any]) -> str",?:provenance_async | ?:test_integration_real_db,dumps | encode | hexdigest | sha256,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,pure,no,13,Compute deterministic hash of input payload.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,count_provenance,"async count_provenance(tenant_id: Optional[str], variant_slug: Optional[str], start_date: Optional[datetime], end_date: Optional[datetime]) -> int",?:provenance_async | ?:test_integration_real_db,and_ | append | async_session_context | count | execute | scalar | select | select_from | where,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,37,Count provenance records matching filters.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,get_drift_stats,"async get_drift_stats(start_date: Optional[datetime], end_date: Optional[datetime]) -> Dict[str, Any]",?:provenance_async | ?:test_integration_real_db,and_ | append | async_session_context | avg | count | execute | fetchone | float | isnot | label | max | min | select | stddev | where,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,52,Get drift statistics between V1 and V2 costs.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,query_provenance,"async query_provenance(tenant_id: Optional[str], variant_slug: Optional[str], source: Optional[str], input_hash: Optional[str], start_date: Optional[datetime], end_date: Optional[datetime], limit: int, offset: int) -> List[Dict[str, Any]]",?:provenance_async | ?:test_integration_real_db,and_ | append | async_session_context | desc | execute | limit | offset | order_by | scalars | select | to_dict | where,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,52,Query provenance records.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,write_provenance,"async write_provenance(run_id: Optional[str], tenant_id: Optional[str], variant_slug: str, source: str, model_version: Optional[str], adapter_version: Optional[str], commit_sha: Optional[str], input_hash: Optional[str], output_hash: Optional[str], v1_cost: Optional[float], v2_cost: Optional[float], payload: Optional[Dict[str, Any]], runtime_ms: Optional[int], session: Optional[AsyncSession]) -> int",?:provenance_async | ?:test_integration_real_db,AsyncSessionLocal | CostSimProvenanceModel | add | close | debug | error | flush | refresh,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,82,Write a single provenance record.,Persistence/Driver,high,L6 layer = persistence
analytics,L6,provenance_async,write_provenance_batch,"async write_provenance_batch(records: List[Dict[str, Any]], session: Optional[AsyncSession]) -> List[int]",?:provenance_async | ?:test_integration_real_db,AsyncSessionLocal | CostSimProvenanceModel | add | close | error | get | info | len | list | range,__future__ | asyncio | costsim_cb | db_async | sqlalchemy,db_write,yes,69,Write multiple provenance records in a single transaction.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'batch')
api_keys,L5,api_keys_facade,APIKeysFacade.__init__,__init__() -> None,?:aos_api_key | ?:__init__ | L5:__init__ | L4:api_keys_handler,APIKeysFacadeDriver,__future__ | api_keys_facade_driver | asyncio,pure,no,3,Initialize the facade with its driver.,Internal Helper,high,dunder method
api_keys,L5,api_keys_facade,APIKeysFacade.get_api_key_detail,"async get_api_key_detail(session: AsyncSession, tenant_id: str, key_id: str) -> Optional[APIKeyDetailResult]",?:aos_api_key | ?:__init__ | L5:__init__ | L4:api_keys_handler,APIKeyDetailResult | fetch_api_key_by_id | loads | upper,__future__ | api_keys_facade_driver | asyncio,pure,yes,34,Get API key detail. Tenant isolation enforced.,Operation,high,called by L4 orchestrator
api_keys,L5,api_keys_facade,APIKeysFacade.list_api_keys,"async list_api_keys(session: AsyncSession, tenant_id: str) -> APIKeysListResult",?:aos_api_key | ?:__init__ | L5:__init__ | L4:api_keys_handler,APIKeySummaryResult | APIKeysListResult | count_api_keys | fetch_api_keys | len | upper,__future__ | api_keys_facade_driver | asyncio,pure,yes,42,List API keys for the tenant. Excludes synthetic keys.,Operation,high,called by L4 orchestrator
api_keys,L5,api_keys_facade,get_api_keys_facade,get_api_keys_facade() -> APIKeysFacade,?:aos_api_key | ?:__init__ | L5:__init__ | L4:api_keys_handler,APIKeysFacade,__future__ | api_keys_facade_driver | asyncio,pure,no,6,Get the singleton APIKeysFacade instance.,Operation,high,called by L4 orchestrator
api_keys,L5,keys_engine,KeysReadEngine.__init__,__init__(session: Session),L3:customer_keys_adapter | L5:customer_keys_adapter,get_keys_driver,__future__ | keys_driver | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
api_keys,L5,keys_engine,KeysReadEngine.get_key,"get_key(key_id: str, tenant_id: str) -> Optional[KeySnapshot]",L3:customer_keys_adapter | L5:customer_keys_adapter,fetch_key_by_id,__future__ | keys_driver | sqlmodel,pure,no,16,Get a single API key by ID with tenant isolation.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,KeysReadEngine.get_key_usage_today,"get_key_usage_today(key_id: str, today_start: datetime) -> KeyUsageSnapshot",L3:customer_keys_adapter | L5:customer_keys_adapter,fetch_key_usage,__future__ | keys_driver | sqlmodel,pure,no,16,Get today's usage for an API key.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,KeysReadEngine.list_keys,"list_keys(tenant_id: str, limit: int, offset: int) -> Tuple[List[KeySnapshot], int]",L3:customer_keys_adapter | L5:customer_keys_adapter,count_keys | fetch_keys,__future__ | keys_driver | sqlmodel,pure,no,20,List API keys for a tenant.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,KeysWriteEngine.__init__,__init__(session: Session),L3:customer_keys_adapter | L5:customer_keys_adapter,get_keys_driver,__future__ | keys_driver | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
api_keys,L5,keys_engine,KeysWriteEngine.freeze_key,"freeze_key(key_id: str, tenant_id: str) -> Optional[KeySnapshot]",L3:customer_keys_adapter | L5:customer_keys_adapter,fetch_key_for_update | now | update_key_frozen,__future__ | keys_driver | sqlmodel,pure,no,30,Freeze an API key.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,KeysWriteEngine.unfreeze_key,"unfreeze_key(key_id: str, tenant_id: str) -> Optional[KeySnapshot]",L3:customer_keys_adapter | L5:customer_keys_adapter,fetch_key_for_update | update_key_unfrozen,__future__ | keys_driver | sqlmodel,pure,no,27,Unfreeze an API key.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,get_keys_read_engine,get_keys_read_engine(session: Session) -> KeysReadEngine,L3:customer_keys_adapter | L5:customer_keys_adapter,KeysReadEngine,__future__ | keys_driver | sqlmodel,pure,no,3,Factory function to get KeysReadEngine instance.,Unclassified,low,no classification rules matched
api_keys,L5,keys_engine,get_keys_write_engine,get_keys_write_engine(session: Session) -> KeysWriteEngine,L3:customer_keys_adapter | L5:customer_keys_adapter,KeysWriteEngine,__future__ | keys_driver | sqlmodel,pure,no,3,Factory function to get KeysWriteEngine instance.,Unclassified,low,no classification rules matched
api_keys,L6,api_keys_facade_driver,APIKeysFacadeDriver.count_api_keys,"async count_api_keys(session: AsyncSession, tenant_id: str) -> int",L5:api_keys_facade,count | execute | scalar | select | where,asyncio | sqlalchemy | tenant,db_write,yes,19,Count API keys for tenant. Excludes synthetic keys.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,api_keys_facade_driver,APIKeysFacadeDriver.fetch_api_key_by_id,"async fetch_api_key_by_id(session: AsyncSession, tenant_id: str, key_id: str) -> Optional[APIKeyDetailSnapshot]",L5:api_keys_facade,APIKeyDetailSnapshot | execute | scalar_one_or_none | select | where,asyncio | sqlalchemy | tenant,db_write,yes,36,Fetch API key detail by ID. Tenant isolation enforced.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,api_keys_facade_driver,APIKeysFacadeDriver.fetch_api_keys,"async fetch_api_keys(session: AsyncSession, tenant_id: str) -> List[APIKeySnapshot]",L5:api_keys_facade,APIKeySnapshot | all | desc | execute | limit | offset | order_by | scalars | select | where,asyncio | sqlalchemy | tenant,db_write,yes,38,Fetch API keys for tenant. Excludes synthetic keys.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.__init__,__init__(session: Session),L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
api_keys,L6,keys_driver,KeysDriver.count_keys,count_keys(tenant_id: str) -> int,L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,count | exec | first | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,5,Count API keys for a tenant.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.fetch_key_by_id,"fetch_key_by_id(key_id: str, tenant_id: str) -> Optional[KeySnapshot]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeySnapshot | and_ | exec | first | hasattr | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,32,Fetch a single API key by ID with tenant isolation.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.fetch_key_for_update,"fetch_key_for_update(key_id: str, tenant_id: str) -> Optional[APIKey]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,and_ | exec | first | hasattr | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,14,Fetch raw APIKey model for update operations.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.fetch_key_usage,"fetch_key_usage(key_id: str, since: datetime) -> KeyUsageSnapshot",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeyUsageSnapshot | and_ | coalesce | count | exec | first | select | sum | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,23,Fetch usage statistics for an API key since a given time.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.fetch_keys,"fetch_keys(tenant_id: str, limit: int, offset: int) -> List[KeySnapshot]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeySnapshot | all | desc | exec | hasattr | limit | offset | order_by | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,33,Fetch API keys for a tenant.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.update_key_frozen,"update_key_frozen(key: APIKey, frozen_at: datetime) -> KeySnapshot",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeySnapshot | add | flush | refresh,killswitch | sqlalchemy | sqlmodel | tenant,db_write,no,25,Update key to frozen state.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,KeysDriver.update_key_unfrozen,update_key_unfrozen(key: APIKey) -> KeySnapshot,L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeySnapshot | add | flush | refresh,killswitch | sqlalchemy | sqlmodel | tenant,db_write,no,24,Update key to unfrozen state.,Persistence/Driver,high,L6 layer = persistence
api_keys,L6,keys_driver,get_keys_driver,get_keys_driver(session: Session) -> KeysDriver,L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeysDriver,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,3,Factory function to get KeysDriver instance.,Persistence/Driver,high,L6 layer = persistence
apis,L6,keys_driver,KeysDriver.__init__,__init__(session: Session),L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
apis,L6,keys_driver,KeysDriver.fetch_key_by_id,"fetch_key_by_id(key_id: str, tenant_id: str) -> Optional[APIKey]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,and_ | exec | first | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,23,Fetch a single API key by ID with tenant isolation.,Persistence/Driver,high,L6 layer = persistence
apis,L6,keys_driver,KeysDriver.fetch_key_usage_today,"fetch_key_usage_today(key_id: str, today_start: datetime) -> Tuple[int, int]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,and_ | coalesce | count | exec | first | select | sum | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,28,Fetch today's usage for an API key.,Persistence/Driver,high,L6 layer = persistence
apis,L6,keys_driver,KeysDriver.fetch_keys_paginated,"fetch_keys_paginated(tenant_id: str, limit: int, offset: int) -> Tuple[List[APIKey], int]",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,all | count | desc | exec | first | hasattr | limit | offset | order_by | select | where,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,33,Fetch API keys for a tenant with pagination.,Persistence/Driver,high,L6 layer = persistence
apis,L6,keys_driver,KeysDriver.update_key_frozen,"update_key_frozen(key: APIKey, is_frozen: bool) -> APIKey",L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,add | flush | now | refresh,killswitch | sqlalchemy | sqlmodel | tenant,db_write,no,21,Update the frozen status of an API key.,Persistence/Driver,high,L6 layer = persistence
apis,L6,keys_driver,get_keys_driver,get_keys_driver(session: Session) -> KeysDriver,L3:customer_keys_adapter | L5:keys_shim | L5:keys_engine,KeysDriver,killswitch | sqlalchemy | sqlmodel | tenant,pure,no,3,Factory function for KeysDriver.,Persistence/Driver,high,L6 layer = persistence
controls,L5,alert_fatigue,AlertCheckResult.to_dict,"to_dict() -> Dict[str, Any]",?:alert_fatigue,isoformat,,pure,no,9,Serialize for logging.,Internal Helper,medium,name matches 'to_'
controls,L5,alert_fatigue,AlertFatigueController.__init__,__init__(redis_client),?:alert_fatigue,Lock | info,,pure,no,22,Initialize fatigue controller.,Internal Helper,high,dunder method
controls,L5,alert_fatigue,AlertFatigueController._check_deduplication,"_check_deduplication(alert_key: str, tenant_id: str, domain: str, settings: TenantFatigueSettings) -> AlertCheckResult",?:alert_fatigue,AlertCheckResult | encode | get | hexdigest | now | sha256 | timedelta,,pure,no,31,Check for duplicate alerts within dedup window.,Internal Helper,medium,private function
controls,L5,alert_fatigue,AlertFatigueController._check_domain_cooldown,"_check_domain_cooldown(tenant_id: str, domain: str, settings: TenantFatigueSettings) -> AlertCheckResult",?:alert_fatigue,AlertCheckResult | get | get_domain_cooldown | now | timedelta,,pure,no,33,Check domain-specific cooldown.,Internal Helper,medium,private function
controls,L5,alert_fatigue,AlertFatigueController._check_tenant_rate_limit,"_check_tenant_rate_limit(tenant_id: str, settings: TenantFatigueSettings) -> AlertCheckResult",?:alert_fatigue,AlertCheckResult | get | now | sorted | sum | timedelta,,pure,no,39,Check tenant rate limit (sliding window).,Internal Helper,medium,private function
controls,L5,alert_fatigue,AlertFatigueController._cleanup_old_records,_cleanup_old_records(tenant_id: str) -> None,?:alert_fatigue,now | timedelta,,pure,no,11,Remove old records outside the tracking window.,Internal Helper,medium,private function
controls,L5,alert_fatigue,AlertFatigueController._get_tenant_settings,_get_tenant_settings(tenant_id: str) -> TenantFatigueSettings,?:alert_fatigue,TenantFatigueSettings,,pure,no,5,Get settings for a tenant (with defaults).,Internal Helper,medium,private function
controls,L5,alert_fatigue,AlertFatigueController.check_alert,"check_alert(alert_key: str, tenant_id: str, domain: str) -> AlertCheckResult",?:alert_fatigue,AlertCheckResult | _check_deduplication | _check_domain_cooldown | _check_tenant_rate_limit | _get_tenant_settings,,pure,no,59,Check if an alert should be sent.,Policy/Decision,medium,name matches 'check'
controls,L5,alert_fatigue,AlertFatigueController.get_tenant_stats,"get_tenant_stats(tenant_id: str) -> Dict[str, Any]",?:alert_fatigue,_get_tenant_settings | get | len | now | timedelta,,pure,no,30,Get fatigue statistics for a tenant.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,AlertFatigueController.record_alert_sent,"record_alert_sent(alert_key: str, tenant_id: str, domain: str) -> None",?:alert_fatigue,AlertRecord | _cleanup_old_records | append | debug,,pure,no,45,Record that an alert was sent.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,AlertFatigueController.set_tenant_settings,"set_tenant_settings(tenant_id: str, settings: TenantFatigueSettings) -> None",?:alert_fatigue,info,,pure,no,23,Set custom fatigue settings for a tenant.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,AlertFatigueController.should_send_alert,"should_send_alert(alert_key: str, tenant_id: str, domain: str) -> bool",?:alert_fatigue,check_alert,,pure,no,18,Simple check if alert should be sent (convenience method).,Policy/Decision,medium,name matches 'should_'
controls,L5,alert_fatigue,AlertRecord.__post_init__,__post_init__(),?:alert_fatigue,encode | hexdigest | sha256,,pure,no,5,Compute alert hash for deduplication.,Internal Helper,high,dunder method
controls,L5,alert_fatigue,AlertRecord.age,age() -> timedelta,?:alert_fatigue,now,,pure,no,3,Time since alert was sent.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,TenantFatigueSettings.get_domain_cooldown,get_domain_cooldown(domain: str) -> int,?:alert_fatigue,get,,pure,no,5,Get cooldown for a domain.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,get_alert_fatigue_controller,get_alert_fatigue_controller(redis_client) -> AlertFatigueController,?:alert_fatigue,AlertFatigueController,,pure,no,14,Get or create AlertFatigueController singleton.,Unclassified,low,no classification rules matched
controls,L5,alert_fatigue,reset_alert_fatigue_controller,reset_alert_fatigue_controller() -> None,?:alert_fatigue,,,pure,no,4,Reset the singleton (for testing).,Unclassified,low,no classification rules matched
controls,L5,budget_enforcement_engine,BudgetEnforcementEngine.__init__,__init__(),?:main,get,budget_enforcement_driver | decisions,pure,no,3,Initialize the budget enforcement engine.,Internal Helper,high,dunder method
controls,L5,budget_enforcement_engine,BudgetEnforcementEngine._parse_budget_from_error,_parse_budget_from_error(error_message: str) -> Optional[dict],?:main,group | int | search,budget_enforcement_driver | decisions,pure,no,16,Parse budget information from error message.,Internal Helper,medium,private function
controls,L5,budget_enforcement_engine,BudgetEnforcementEngine.emit_decision_for_halt,"emit_decision_for_halt(run_id: str, budget_limit_cents: int, budget_consumed_cents: int, step_cost_cents: int, completed_steps: int, total_steps: int, tenant_id: str) -> bool",?:main,debug | emit_budget_enforcement_decision | error | info | str,budget_enforcement_driver | decisions,pure,no,72,Emit budget enforcement decision for a halted run.,Unclassified,low,no classification rules matched
controls,L5,budget_enforcement_engine,BudgetEnforcementEngine.process_pending_halts,process_pending_halts() -> int,?:main,_parse_budget_from_error | dispose | emit_decision_for_halt | error | fetch_pending_budget_halts | get | get_budget_enforcement_driver | info | len | loads | str | warning,budget_enforcement_driver | decisions,pure,no,96,Process runs halted for budget that don't have decision records.,Unclassified,low,no classification rules matched
controls,L5,budget_enforcement_engine,emit_budget_halt_decision,"emit_budget_halt_decision(run_id: str, budget_limit_cents: int, budget_consumed_cents: int, step_cost_cents: int, completed_steps: int, total_steps: int, tenant_id: str) -> bool",?:main,BudgetEnforcementEngine | emit_decision_for_halt,budget_enforcement_driver | decisions,pure,no,40,Convenience function to emit a budget enforcement decision.,Unclassified,low,no classification rules matched
controls,L5,budget_enforcement_engine,process_pending_budget_decisions,async process_pending_budget_decisions() -> int,?:main,BudgetEnforcementEngine | process_pending_halts,budget_enforcement_driver | decisions,pure,yes,15,Process all pending budget halt decisions.,Unclassified,low,no classification rules matched
controls,L5,cb_sync_wrapper,_get_executor,_get_executor() -> concurrent.futures.ThreadPoolExecutor,?:__init__ | ?:circuit_breaker_async | ?:cb_sync_wrapper | L6:circuit_breaker_async | ?:test_integration_real_db,ThreadPoolExecutor,__future__ | circuit_breaker_async | futures,pure,no,6,Get or create the shared thread pool executor.,Internal Helper,medium,private function
controls,L5,cb_sync_wrapper,_run_async_in_thread,"_run_async_in_thread(coro, timeout: float)",?:__init__ | ?:circuit_breaker_async | ?:cb_sync_wrapper | L6:circuit_breaker_async | ?:test_integration_real_db,_get_executor | close | new_event_loop | result | run_until_complete | set_event_loop | submit,__future__ | circuit_breaker_async | futures,pure,no,32,Run an async coroutine in a separate thread with its own event loop.,Internal Helper,medium,private function
controls,L5,cb_sync_wrapper,get_state_sync,get_state_sync(timeout: float),?:__init__ | ?:circuit_breaker_async | ?:cb_sync_wrapper | L6:circuit_breaker_async | ?:test_integration_real_db,_run_async_in_thread | error | get_running_loop | get_state | run,__future__ | circuit_breaker_async | futures,pure,no,27,Sync wrapper for get_state().,Unclassified,low,no classification rules matched
controls,L5,cb_sync_wrapper,is_v2_disabled_sync,is_v2_disabled_sync(timeout: float) -> bool,?:__init__ | ?:circuit_breaker_async | ?:cb_sync_wrapper | L6:circuit_breaker_async | ?:test_integration_real_db,_run_async_in_thread | bool | error | get_running_loop | is_v2_disabled | run,__future__ | circuit_breaker_async | futures,pure,no,37,Sync wrapper for is_v2_disabled().,Unclassified,low,no classification rules matched
controls,L5,cb_sync_wrapper,shutdown_executor,shutdown_executor(),?:__init__ | ?:circuit_breaker_async | ?:cb_sync_wrapper | L6:circuit_breaker_async | ?:test_integration_real_db,shutdown,__future__ | circuit_breaker_async | futures,pure,no,6,Shutdown the thread pool executor gracefully.,Unclassified,low,no classification rules matched
controls,L5,controls_facade,ControlConfig.to_dict,"to_dict() -> Dict[str, Any]",L4:controls_handler,,,pure,no,18,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
controls,L5,controls_facade,ControlStatusSummary.to_dict,"to_dict() -> Dict[str, Any]",L4:controls_handler,,,pure,no,12,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
controls,L5,controls_facade,ControlsFacade.__init__,__init__(),L4:controls_handler,,,pure,no,3,Initialize facade with default controls.,Internal Helper,high,dunder method
controls,L5,controls_facade,ControlsFacade._ensure_default_controls,_ensure_default_controls(tenant_id: str) -> None,L4:controls_handler,ControlConfig | isoformat | now | str | uuid4,,pure,no,28,Ensure default controls exist for tenant.,Internal Helper,medium,private function
controls,L5,controls_facade,ControlsFacade.disable_control,"async disable_control(control_id: str, tenant_id: str, actor: str) -> Optional[ControlConfig]",L4:controls_handler,_ensure_default_controls | info | isoformat | now | values,,pure,yes,40,Disable a control.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,ControlsFacade.enable_control,"async enable_control(control_id: str, tenant_id: str, actor: str) -> Optional[ControlConfig]",L4:controls_handler,_ensure_default_controls | info | isoformat | now | values,,pure,yes,40,Enable a control.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,ControlsFacade.get_control,"async get_control(control_id: str, tenant_id: str) -> Optional[ControlConfig]",L4:controls_handler,_ensure_default_controls | values,,pure,yes,21,Get a specific control.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,ControlsFacade.get_status,async get_status(tenant_id: str) -> ControlStatusSummary,L4:controls_handler,ControlStatusSummary | _ensure_default_controls | isoformat | now | values,,pure,yes,48,Get overall control status.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,ControlsFacade.list_controls,"async list_controls(tenant_id: str, control_type: Optional[str], state: Optional[str], limit: int, offset: int) -> List[ControlConfig]",L4:controls_handler,_ensure_default_controls | append | sort | values,,pure,yes,35,List controls for a tenant.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,ControlsFacade.update_control,"async update_control(control_id: str, tenant_id: str, conditions: Optional[Dict[str, Any]], metadata: Optional[Dict[str, Any]]) -> Optional[ControlConfig]",L4:controls_handler,_ensure_default_controls | isoformat | now | update | values,,pure,yes,39,Update a control.,Operation,high,called by L4 orchestrator
controls,L5,controls_facade,get_controls_facade,get_controls_facade() -> ControlsFacade,L4:controls_handler,ControlsFacade,,pure,no,14,Get the controls facade instance.,Operation,high,called by L4 orchestrator
controls,L5,cost_safety_rails,CostSafetyRails.__init__,"__init__(config: SafetyConfig | None, redis_client, db_session)",?:test_m27_cost_loop,SafetyConfig,__future__ | cost_bridges,pure,no,13,,Internal Helper,high,dunder method
controls,L5,cost_safety_rails,CostSafetyRails._get_action_count,"async _get_action_count(tenant_id: str, action_type: str) -> int",?:test_m27_cost_loop,get | int | warning,__future__ | cost_bridges,external_api,yes,14,Get current action count for tenant.,Internal Helper,medium,private function
controls,L5,cost_safety_rails,CostSafetyRails.can_auto_apply_policy,"async can_auto_apply_policy(tenant_id: str, policy_action: str, severity: str) -> tuple[bool, str]",?:test_m27_cost_loop,_get_action_count | get | now | total_seconds | upper,__future__ | cost_bridges,pure,yes,32,Check if a policy can be auto-applied.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_')
controls,L5,cost_safety_rails,CostSafetyRails.can_auto_apply_recovery,"async can_auto_apply_recovery(tenant_id: str, recovery_action: str, affected_count: int) -> tuple[bool, str]",?:test_m27_cost_loop,_get_action_count,__future__ | cost_bridges,pure,yes,24,Check if a recovery action can be auto-applied.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_')
controls,L5,cost_safety_rails,CostSafetyRails.can_auto_apply_routing,"async can_auto_apply_routing(tenant_id: str, adjustment_type: str, magnitude: float) -> tuple[bool, str]",?:test_m27_cost_loop,_get_action_count,__future__ | cost_bridges,pure,yes,24,Check if a routing adjustment can be auto-applied.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_')
controls,L5,cost_safety_rails,CostSafetyRails.get_status,"get_status(tenant_id: str) -> dict[str, Any]",?:test_m27_cost_loop,get | max,__future__ | cost_bridges,pure,no,29,Get current safety rail status for tenant.,Unclassified,low,no classification rules matched
controls,L5,cost_safety_rails,CostSafetyRails.record_action,"async record_action(tenant_id: str, action_type: str, action_name: str) -> None",?:test_m27_cost_loop,expire | incr | info | now | warning,__future__ | cost_bridges,pure,yes,32,Record an auto-applied action.,Unclassified,low,no classification rules matched
controls,L5,cost_safety_rails,SafeCostLoopOrchestrator.__init__,"__init__(db_session, safety_config: SafetyConfig | None, redis_client)",?:test_m27_cost_loop,CostLoopOrchestrator | CostSafetyRails | ValueError,__future__ | cost_bridges,pure,no,21,Initialize safe orchestrator with database session.,Internal Helper,high,dunder method
controls,L5,cost_safety_rails,SafeCostLoopOrchestrator.process_anomaly_safe,"async process_anomaly_safe(anomaly) -> dict[str, Any]",?:test_m27_cost_loop,append | can_auto_apply_policy | can_auto_apply_routing | get | get_status | len | process_anomaly,__future__ | cost_bridges,pure,yes,50,Process anomaly with safety rails enforced.,Unclassified,low,no classification rules matched
controls,L5,cost_safety_rails,SafetyConfig.production,production() -> 'SafetyConfig',?:test_m27_cost_loop,cls,__future__ | cost_bridges,pure,no,13,Conservative production defaults.,Unclassified,low,no classification rules matched
controls,L5,cost_safety_rails,SafetyConfig.testing,testing() -> 'SafetyConfig',?:test_m27_cost_loop,cls,__future__ | cost_bridges,pure,no,13,Relaxed testing defaults.,Unclassified,low,no classification rules matched
controls,L5,cost_safety_rails,get_safety_rails,get_safety_rails(config: SafetyConfig | None) -> CostSafetyRails,?:test_m27_cost_loop,CostSafetyRails,__future__ | cost_bridges,pure,no,6,Get or create default safety rails instance.,Unclassified,low,no classification rules matched
controls,L5,customer_killswitch_read_engine,CustomerKillswitchReadService.__init__,__init__(session: Optional['Session']),L3:customer_killswitch_adapter,get_killswitch_read_driver,killswitch_read_driver | pydantic | sqlmodel,pure,no,3,Initialize service with optional session (passed to driver).,Internal Helper,high,dunder method
controls,L5,customer_killswitch_read_engine,CustomerKillswitchReadService.get_killswitch_status,get_killswitch_status(tenant_id: str) -> KillswitchStatusInfo,L3:customer_killswitch_adapter,IncidentStats | KillswitchState | KillswitchStatusInfo | get_killswitch_status,killswitch_read_driver | pydantic | sqlmodel,pure,no,34,Get complete killswitch status for a tenant.,Unclassified,low,no classification rules matched
controls,L5,customer_killswitch_read_engine,get_customer_killswitch_read_service,get_customer_killswitch_read_service() -> CustomerKillswitchReadService,L3:customer_killswitch_adapter,CustomerKillswitchReadService,killswitch_read_driver | pydantic | sqlmodel,pure,no,14,Get the singleton CustomerKillswitchReadService instance.,Unclassified,low,no classification rules matched
controls,L5,decisions,AnomalySignal.to_signal_response,to_signal_response() -> dict,?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,,,pure,no,12,Convert to signal format.,Internal Helper,medium,name matches 'to_'
controls,L5,decisions,Decision.blocks_request,blocks_request() -> bool,?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,,,pure,no,3,Check if this decision blocks the request.,Unclassified,low,no classification rules matched
controls,L5,decisions,Decision.is_warning_only,is_warning_only() -> bool,?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,,,pure,no,3,Check if this is a non-blocking warning.,Unclassified,low,no classification rules matched
controls,L5,decisions,ProtectionResult.to_error_response,to_error_response() -> dict,?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,,,pure,no,28,Convert to error response format.,Internal Helper,medium,name matches 'to_'
controls,L5,decisions,allow,allow() -> ProtectionResult,?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,ProtectionResult,,pure,no,3,Create an ALLOW result.,Policy/Decision,medium,name matches 'allow'
controls,L5,decisions,reject_cost_limit,"reject_cost_limit(current_value: float, allowed_value: float, message: Optional[str]) -> ProtectionResult",?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,ProtectionResult,,pure,no,11,Create a REJECT result for cost limit.,Unclassified,low,no classification rules matched
controls,L5,decisions,reject_rate_limit,"reject_rate_limit(dimension: str, retry_after_ms: int, message: Optional[str]) -> ProtectionResult",?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,ProtectionResult,,pure,no,10,Create a REJECT result for rate limiting.,Unclassified,low,no classification rules matched
controls,L5,decisions,throttle,"throttle(dimension: str, retry_after_ms: int, message: Optional[str]) -> ProtectionResult",?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,ProtectionResult,,pure,no,10,Create a THROTTLE result.,Unclassified,low,no classification rules matched
controls,L5,decisions,warn,"warn(dimension: str, message: Optional[str]) -> ProtectionResult",?:overview | ?:protection_gate | ?:protection_dependencies | ?:workers | ?:engine | ?:__init__ | ?:provider | ?:memory_service | ?:care | ?:budget_tracker,ProtectionResult,,pure,no,7,Create a WARN result (non-blocking).,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.__init__,__init__(),?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,Lock,,pure,no,5,,Internal Helper,high,dunder method
controls,L5,killswitch,KillSwitch.activate,"activate(reason: str, triggered_by: KillSwitchTrigger, active_envelopes_count: int) -> KillSwitchEvent",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,KillSwitchEvent | append | callback | error | list | str | warning,,pure,no,64,Activate kill-switch. Immediately disables all optimization.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.get_events,get_events() -> List[KillSwitchEvent],?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,list,,pure,no,4,Get all kill-switch events for audit.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.get_last_event,get_last_event() -> Optional[KillSwitchEvent],?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,,,pure,no,4,Get most recent kill-switch event.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.is_disabled,is_disabled() -> bool,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,,,pure,no,3,True if optimization is blocked.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.is_enabled,is_enabled() -> bool,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,,,pure,no,3,True if optimization is allowed.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.mark_rollback_complete,"mark_rollback_complete(event_id: str, status: RollbackStatus) -> None",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,info | isoformat | now,,pure,no,27,Mark rollback as complete for a kill-switch event.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.on_activate,"on_activate(callback: Callable[[KillSwitchEvent], None]) -> None",?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,append,,pure,no,4,Register callback to be called when kill-switch activates.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.rearm,rearm(reason: str) -> None,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,warning,,pure,no,16,Re-enable optimization. Requires EXPLICIT human action.,Unclassified,low,no classification rules matched
controls,L5,killswitch,KillSwitch.state,state() -> KillSwitchState,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,,,pure,no,4,Current kill-switch state.,Unclassified,low,no classification rules matched
controls,L5,killswitch,get_killswitch,get_killswitch() -> KillSwitch,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,KillSwitch,,pure,no,7,Get the global kill-switch instance.,Unclassified,low,no classification rules matched
controls,L5,killswitch,reset_killswitch_for_testing,reset_killswitch_for_testing() -> None,?:manager | ?:__init__ | ?:incidents | ?:guard | ?:v1_proxy | ?:ops | ?:v1_killswitch | ?:replay | L3:customer_killswitch_adapter | ?:incident_write_engine,KillSwitch,,pure,no,5,Reset kill-switch state. FOR TESTING ONLY.,Unclassified,low,no classification rules matched
controls,L5,killswitch_read_driver,KillswitchReadDriver.__init__,__init__(session: Optional[Session]),L5:__init__ | L5:customer_killswitch_read_engine,,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,3,Initialize driver with optional session (lazy loaded).,Internal Helper,high,dunder method
controls,L5,killswitch_read_driver,KillswitchReadDriver._get_active_guardrails,_get_active_guardrails(session: Session) -> List[str],L5:__init__ | L5:customer_killswitch_read_engine,all | exec | hasattr | select | where,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,8,Get list of active guardrail names.,Internal Helper,medium,private function
controls,L5,killswitch_read_driver,KillswitchReadDriver._get_incident_stats,"_get_incident_stats(session: Session, tenant_id: str) -> IncidentStatsDTO",L5:__init__ | L5:customer_killswitch_read_engine,IncidentStatsDTO | and_ | count | desc | exec | first | limit | now | order_by | select | timedelta | where,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,27,Get incident statistics for a tenant.,Internal Helper,medium,private function
controls,L5,killswitch_read_driver,KillswitchReadDriver._get_killswitch_state,"_get_killswitch_state(session: Session, tenant_id: str) -> KillswitchStateDTO",L5:__init__ | L5:customer_killswitch_read_engine,KillswitchStateDTO | and_ | exec | first | select | where,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,20,Get killswitch state for a tenant.,Internal Helper,medium,private function
controls,L5,killswitch_read_driver,KillswitchReadDriver._get_session,_get_session() -> Session,L5:__init__ | L5:customer_killswitch_read_engine,get_session | next,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,5,Get the database session (lazy loaded).,Internal Helper,medium,private function
controls,L5,killswitch_read_driver,KillswitchReadDriver.get_killswitch_status,get_killswitch_status(tenant_id: str) -> KillswitchStatusDTO,L5:__init__ | L5:customer_killswitch_read_engine,KillswitchStatusDTO | ValueError | _get_active_guardrails | _get_incident_stats | _get_killswitch_state | _get_session,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,35,Get complete killswitch status for a tenant.,Unclassified,low,no classification rules matched
controls,L5,killswitch_read_driver,get_killswitch_read_driver,get_killswitch_read_driver(session: Optional[Session]) -> KillswitchReadDriver,L5:__init__ | L5:customer_killswitch_read_engine,KillswitchReadDriver,db | killswitch | pydantic | sqlalchemy | sqlmodel,pure,no,11,Get KillswitchReadDriver instance.,Unclassified,low,no classification rules matched
controls,L5,overrides,LimitOverrideRequest.validate_override_value,validate_override_value(v: Decimal) -> Decimal,?:override | ?:__init__ | ?:override_service | L6:override_driver | L2:override,ValueError | field_validator,pydantic,pure,no,5,Override value must be positive.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
controls,L5,overrides,OverrideApprovalRequest.validate_rejection_reason,"validate_rejection_reason(v: Optional[str], info) -> Optional[str]",?:override | ?:__init__ | ?:override_service | L6:override_driver | L2:override,field_validator,pydantic,pure,no,4,Rejection reason required when rejecting.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
controls,L5,policy_limits,CreatePolicyLimitRequest.validate_reset_period,"validate_reset_period(v: Optional[ResetPeriodEnum], info) -> Optional[ResetPeriodEnum]",?:policy_limits_crud | ?:__init__ | ?:policy_limits_service | L5:policy_limits_engine | L2:policy_limits_crud | ?:test_limit_enhancements,field_validator,pydantic,pure,no,5,Reset period required for BUDGET limits.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
controls,L5,policy_limits,CreatePolicyLimitRequest.validate_window_seconds,"validate_window_seconds(v: Optional[int], info) -> Optional[int]",?:policy_limits_crud | ?:__init__ | ?:policy_limits_service | L5:policy_limits_engine | L2:policy_limits_crud | ?:test_limit_enhancements,field_validator,pydantic,pure,no,3,Window seconds required for RATE limits.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
controls,L5,s2_cost_smoothing,calculate_s2_bounded_value,"calculate_s2_bounded_value(baseline: float, max_decrease_pct: float, prediction_confidence: float) -> float",?:__init__ | ?:test_c3_s3_failure_matrix | ?:test_c3_s2_cost_smoothing,max,envelope,pure,no,30,Calculate the bounded value for S2 (decrease only).,Unclassified,low,no classification rules matched
controls,L5,s2_cost_smoothing,create_s2_envelope,"create_s2_envelope(baseline_value: float, reference_id: str) -> Envelope",?:__init__ | ?:test_c3_s3_failure_matrix | ?:test_c3_s2_cost_smoothing,Envelope | EnvelopeBaseline | EnvelopeBounds | EnvelopeScope | EnvelopeTimebox | EnvelopeTrigger,envelope,pure,no,50,Create a fresh S2 envelope instance with specified baseline.,Unclassified,low,no classification rules matched
controls,L5,s2_cost_smoothing,validate_s2_envelope,validate_s2_envelope(envelope: Envelope) -> None,?:__init__ | ?:test_c3_s3_failure_matrix | ?:test_c3_s2_cost_smoothing,EnvelopeValidationError,envelope,pure,no,33,Validate S2-specific rules (additive to V1-V5).,Policy/Decision,medium,name matches 'validate'
controls,L5,threshold_engine,LLMRunEvaluator.__init__,__init__(resolver: LLMRunThresholdResolver),?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,no,2,,Internal Helper,high,dunder method
controls,L5,threshold_engine,LLMRunEvaluator.evaluate_completed_run,"async evaluate_completed_run(run_id: str, tenant_id: str, status: str, execution_time_ms: int, tokens_used: int, cost_usd: float, agent_id: Optional[str], project_id: Optional[str]) -> ThresholdEvaluationResult",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdEvaluationResult | append | info | model_dump | now | resolve,pydantic | threshold_driver,pure,yes,77,Evaluate a completed LLM run.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
controls,L5,threshold_engine,LLMRunEvaluator.evaluate_live_run,"async evaluate_live_run(run_id: str, tenant_id: str, started_at_ms: int, tokens_used: int, agent_id: Optional[str], project_id: Optional[str]) -> ThresholdEvaluationResult",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdEvaluationResult | append | info | int | model_dump | now | resolve | timestamp,pydantic | threshold_driver,pure,yes,59,Evaluate a live (running) LLM run.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
controls,L5,threshold_engine,LLMRunEvaluatorSync.__init__,__init__(resolver: LLMRunThresholdResolverSync),?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,no,2,,Internal Helper,high,dunder method
controls,L5,threshold_engine,LLMRunEvaluatorSync.evaluate_completed_run,"evaluate_completed_run(run_id: str, tenant_id: str, status: str, execution_time_ms: int, tokens_used: int, cost_usd: float, agent_id: Optional[str], project_id: Optional[str]) -> ThresholdEvaluationResult",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdEvaluationResult | append | info | model_dump | now | resolve,pydantic | threshold_driver,pure,no,60,Evaluate a completed LLM run (sync version).,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
controls,L5,threshold_engine,LLMRunThresholdResolver.__init__,__init__(driver: 'ThresholdDriver'),?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,no,8,Initialize resolver with a driver.,Internal Helper,high,dunder method
controls,L5,threshold_engine,LLMRunThresholdResolver.resolve,"async resolve(tenant_id: str, agent_id: Optional[str], project_id: Optional[str]) -> ThresholdParams",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdParams | copy | debug | get_active_threshold_limits | items | str | warning,pydantic | threshold_driver,pure,yes,64,Resolve effective threshold params for a run.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
controls,L5,threshold_engine,LLMRunThresholdResolverSync.__init__,__init__(driver: 'ThresholdDriverSync'),?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,no,8,Initialize resolver with a sync driver.,Internal Helper,high,dunder method
controls,L5,threshold_engine,LLMRunThresholdResolverSync.resolve,"resolve(tenant_id: str, agent_id: Optional[str], project_id: Optional[str]) -> ThresholdParams",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdParams | copy | debug | get_active_threshold_limits | items | str | warning,pydantic | threshold_driver,pure,no,55,Resolve effective threshold params for a run (sync version).,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
controls,L5,threshold_engine,ThresholdDriverProtocol.get_active_threshold_limits,async get_active_threshold_limits(tenant_id: str) -> list['LimitSnapshot'],?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,yes,5,Query active threshold limits for a tenant.,Operation,high,called by L4 orchestrator
controls,L5,threshold_engine,ThresholdDriverSyncProtocol.get_active_threshold_limits,get_active_threshold_limits(tenant_id: str) -> list['LimitSnapshot'],?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,,pydantic | threshold_driver,pure,no,5,Query active threshold limits for a tenant (sync).,Operation,high,called by L4 orchestrator
controls,L5,threshold_engine,ThresholdParams.coerce_decimal_to_float,coerce_decimal_to_float(v),?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,field_validator | float | isinstance,pydantic | threshold_driver,pure,no,5,Handle Decimal input from database.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
controls,L5,threshold_engine,collect_signals_from_evaluation,"collect_signals_from_evaluation(evaluation: ThresholdEvaluationResult, tenant_id: str, state: str) -> list[ThresholdSignalRecord]",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,append | create_threshold_signal_record,pydantic | threshold_driver,pure,no,28,Collect all signals from an evaluation result into records.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'collect'); Internal Helper(name matches 'from_')
controls,L5,threshold_engine,create_threshold_signal_record,"create_threshold_signal_record(tenant_id: str, run_id: str, state: str, signal: ThresholdSignal, params_used: dict) -> ThresholdSignalRecord",?:policy_limits_crud | ?:runner | L5:__init__ | L6:threshold_driver | L4:controls_handler,ThresholdSignalRecord | info | now,pydantic | threshold_driver,pure,no,41,Create a threshold signal record for activity domain.,Operation,high,called by L4 orchestrator
controls,L6,budget_enforcement_driver,BudgetEnforcementDriver.__init__,__init__(db_url: Optional[str]),L5:budget_enforcement_engine,get,sqlalchemy,pure,no,4,Initialize driver with database URL.,Internal Helper,high,dunder method
controls,L6,budget_enforcement_driver,BudgetEnforcementDriver._get_engine,_get_engine(),L5:budget_enforcement_engine,RuntimeError | create_engine,sqlalchemy,pure,no,7,Lazy engine creation.,Internal Helper,medium,private function
controls,L6,budget_enforcement_driver,BudgetEnforcementDriver.dispose,dispose() -> None,L5:budget_enforcement_engine,dispose,sqlalchemy,pure,no,5,Dispose of the engine connection pool.,Persistence/Driver,high,L6 layer = persistence
controls,L6,budget_enforcement_driver,BudgetEnforcementDriver.fetch_pending_budget_halts,"fetch_pending_budget_halts(limit: int) -> list[dict[str, Any]]",L5:budget_enforcement_engine,_get_engine | append | connect | error | execute | text,sqlalchemy,pure,no,48,Fetch runs halted for budget that don't have decision records.,Persistence/Driver,high,L6 layer = persistence
controls,L6,budget_enforcement_driver,get_budget_enforcement_driver,get_budget_enforcement_driver(db_url: Optional[str]) -> BudgetEnforcementDriver,L5:budget_enforcement_engine,BudgetEnforcementDriver,sqlalchemy,pure,no,3,Get a BudgetEnforcementDriver instance.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'enforce')
controls,L6,circuit_breaker,CircuitBreaker.__init__,"__init__(session: Session, failure_threshold: Optional[int], drift_threshold: Optional[float], name: str)",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,Path | get | getLogger | get_config | mkdir | warning,__future__ | config | db | httpx | infra | sqlmodel,pure,no,45,Initialize circuit breaker.,Internal Helper,high,dunder method
controls,L6,circuit_breaker,CircuitBreaker._auto_recover,async _auto_recover(session: Session) -> None,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_get_or_create_state | _resolve_incident_db | _send_alert_enable | info | log_status_change | now,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,47,Auto-recover circuit breaker after TTL expires.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._get_or_create_state,_get_or_create_state(session: Session) -> CostSimCBState,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,CostSimCBState | add | exec | first | flush | hasattr | refresh | select | where | with_for_update,__future__ | config | db | httpx | infra | sqlmodel,db_write,no,31,Get or create circuit breaker state row.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._post_alertmanager,"async _post_alertmanager(payload: List[Dict[str, Any]]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,AsyncClient | error | get | info | post | raise_for_status | range | sleep | warning,__future__ | config | db | httpx | infra | sqlmodel,external_api,yes,44,Post alert to Alertmanager with retry logic.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._resolve_incident_db,"_resolve_incident_db(session: Session, incident_id: str, resolved_by: str, resolution_notes: str) -> None",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,exec | first | hasattr | now | select | where,__future__ | config | db | httpx | infra | sqlmodel,pure,no,23,Resolve an incident in the database.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._save_incident_file,_save_incident_file(incident: Incident) -> None,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,dump | error | open | to_dict,__future__ | config | db | httpx | infra | sqlmodel,file_io,no,8,Save incident to file (legacy backup).,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._send_alert_disable,"async _send_alert_disable(incident: Incident, disabled_until: Optional[datetime]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_post_alertmanager | isoformat | lower | now | warning,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,37,Send P1/P2/P3 alert when circuit breaker trips.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._send_alert_enable,"async _send_alert_enable(enabled_by: str, reason: Optional[str]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_post_alertmanager | isoformat | now | warning,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,32,Send resolved alert when circuit breaker is re-enabled.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker._trip,"async _trip(session: Session, reason: str, drift_score: float, sample_count: int, details: Optional[Dict[str, Any]], severity: str, disabled_by: str, disabled_until: Optional[datetime]) -> Incident",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,CostSimCBIncident | Incident | _get_or_create_state | _save_incident_file | _send_alert_disable | add | dumps | error | isoformat | log_status_change | now | str | timedelta | uuid4,__future__ | config | db | httpx | infra | sqlmodel,db_write,yes,107,Trip the circuit breaker.,Internal Helper,medium,private function
controls,L6,circuit_breaker,CircuitBreaker.disable_v2,"async disable_v2(reason: str, disabled_by: str, disabled_until: Optional[datetime]) -> Tuple[bool, Optional[Incident]]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_get_or_create_state | _trip,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,42,Manually disable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.enable_v2,"async enable_v2(enabled_by: str, reason: Optional[str]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,reset,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,18,Manually enable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.get_incidents,"get_incidents(include_resolved: bool, limit: int) -> List[Incident]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,Incident | append | cast | desc | exec | get_details | limit | order_by | select | where,__future__ | config | db | httpx | infra | sqlmodel,pure,no,46,Get recent incidents from database.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.get_state,get_state() -> CircuitBreakerState,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,CircuitBreakerState | _get_or_create_state,__future__ | config | db | httpx | infra | sqlmodel,pure,no,14,Get current circuit breaker state.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.is_closed,is_closed() -> bool,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,is_open,__future__ | config | db | httpx | infra | sqlmodel,file_io,no,3,Check if circuit breaker is closed (V2 enabled).,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.is_disabled,async is_disabled() -> bool,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_auto_recover | _get_or_create_state | now | replace,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,33,Check if V2 is disabled.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.is_open,is_open() -> bool,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_get_or_create_state,__future__ | config | db | httpx | infra | sqlmodel,file_io,no,9,Synchronous check if circuit breaker is open (V2 disabled).,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.report_drift,"async report_drift(drift_score: float, sample_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_get_or_create_state | _trip | info | now | warning,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,54,Report drift observation.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.report_schema_error,"async report_schema_error(error_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_trip,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,28,Report schema validation errors.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreaker.reset,"async reset(reason: Optional[str], reset_by: Optional[str]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,_get_or_create_state | _resolve_incident_db | _send_alert_enable | info | log_status_change | now,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,72,Reset the circuit breaker.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,CircuitBreakerState.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,isoformat,__future__ | config | db | httpx | infra | sqlmodel,pure,no,12,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
controls,L6,circuit_breaker,Incident.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,isoformat,__future__ | config | db | httpx | infra | sqlmodel,pure,no,17,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
controls,L6,circuit_breaker,create_circuit_breaker,"create_circuit_breaker(session: Session, failure_threshold: Optional[int], drift_threshold: Optional[float], name: str) -> CircuitBreaker",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,CircuitBreaker,__future__ | config | db | httpx | infra | sqlmodel,pure,no,27,Create CircuitBreaker with required session.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,disable_v2,"async disable_v2(session: Session, reason: str, disabled_by: str, disabled_until: Optional[datetime]) -> Tuple[bool, Optional[Incident]]",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,create_circuit_breaker | disable_v2,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,13,Disable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,enable_v2,"async enable_v2(session: Session, enabled_by: str, reason: Optional[str]) -> bool",?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,create_circuit_breaker | enable_v2,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,11,Enable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker,is_v2_disabled,async is_v2_disabled(session: Session) -> bool,?:__init__ | ?:canary | ?:circuit_breaker | L5:canary | ?:check_priority5_intent | ?:conftest | ?:test_circuit_breaker,create_circuit_breaker | is_disabled,__future__ | config | db | httpx | infra | sqlmodel,pure,yes,4,Check if CostSim V2 is disabled.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.__init__,"__init__(failure_threshold: Optional[int], drift_threshold: Optional[float], name: str)",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,get_config,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,11,,Internal Helper,high,dunder method
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.disable_v2,"async disable_v2(reason: str, disabled_by: str, disabled_until: Optional[datetime]) -> Tuple[bool, Optional[Incident]]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,disable_v2,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,8,Disable V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.enable_v2,"async enable_v2(enabled_by: str, reason: Optional[str]) -> bool",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,enable_v2,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,7,Enable V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.get_incidents,"get_incidents(include_resolved: bool, limit: int) -> List[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,get_event_loop | get_incidents | is_running | run | run_until_complete | warning,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,16,Get incidents (runs async in sync context).,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.get_state,async get_state() -> CircuitBreakerState,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,get_state,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,3,Get current state.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.is_closed,is_closed() -> bool,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,is_open,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,file_io,no,3,Check if circuit breaker is closed.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.is_disabled,async is_disabled() -> bool,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,is_v2_disabled,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,3,Check if V2 is disabled.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.is_open,is_open() -> bool,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,is_v2_disabled_sync,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,file_io,no,10,Sync check if circuit breaker is open.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.report_drift,"async report_drift(drift_score: float, sample_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,report_drift,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,8,Report drift observation.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.report_schema_error,"async report_schema_error(error_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,report_schema_error,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,7,Report schema errors.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.reset,"async reset(reason: Optional[str], reset_by: Optional[str]) -> bool",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,enable_v2,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,7,Reset circuit breaker.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,AsyncCircuitBreaker.reset_v2,"async reset_v2(reason: Optional[str], reset_by: Optional[str]) -> bool",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,reset,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,7,Reset circuit breaker (alias for reset).,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,CircuitBreakerState.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,isoformat,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,12,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
controls,L6,circuit_breaker_async,Incident.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,isoformat,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,17,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
controls,L6,circuit_breaker_async,_auto_recover,"async _auto_recover(session: AsyncSession, state: CostSimCBStateModel) -> None",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,_build_enable_alert_payload | _enqueue_alert | _resolve_incident | info | now,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,45,Legacy auto-recover function (deprecated).,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_build_disable_alert_payload,"_build_disable_alert_payload(incident: Incident, disabled_until: Optional[datetime]) -> List[Dict[str, Any]]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,get_config | isoformat | lower | now,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,30,Build Alertmanager payload for disable alert.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_build_enable_alert_payload,"_build_enable_alert_payload(enabled_by: str, reason: Optional[str]) -> List[Dict[str, Any]]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,get_config | isoformat | now,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,25,Build Alertmanager payload for enable/resolved alert.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_enqueue_alert,"async _enqueue_alert(session: AsyncSession, alert_type: str, payload: List[Dict[str, Any]], incident_id: Optional[str]) -> None",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,CostSimAlertQueueModel | add | debug | flush,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,26,Enqueue alert for reliable delivery.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_get_or_create_state,"async _get_or_create_state(session: AsyncSession, lock: bool) -> CostSimCBStateModel",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,CostSimCBStateModel | add | execute | first | flush | now | scalars | select | where | with_for_update,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,36,Get or create circuit breaker state row.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_resolve_incident,"async _resolve_incident(session: AsyncSession, incident_id: str, resolved_by: str, resolution_notes: str) -> None",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,execute | first | now | scalars | select | where,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,15,Resolve an incident.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_trip,"async _trip(session: AsyncSession, state: CostSimCBStateModel, reason: str, drift_score: float, sample_count: int, details: Optional[Dict[str, Any]], severity: str, disabled_by: str, disabled_until: Optional[datetime]) -> Incident",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,CostSimCBIncidentModel | Incident | _build_disable_alert_payload | _enqueue_alert | add | dumps | error | flush | get_config | get_metrics | now | record_cb_disabled | record_cb_incident | set_circuit_breaker_state | str,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,91,Trip the circuit breaker.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,_try_auto_recover,async _try_auto_recover(state_id: int) -> bool,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _build_enable_alert_payload | _enqueue_alert | _resolve_incident | async_session_context | begin | error | execute | first | flush | get_metrics | info | now | record_auto_recovery | record_cb_enabled,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,90,Attempt auto-recovery with proper locking to avoid TOCTOU race.,Internal Helper,medium,private function
controls,L6,circuit_breaker_async,disable_v2,"async disable_v2(reason: str, disabled_by: str, disabled_until: Optional[datetime]) -> Tuple[bool, Optional[Incident]]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _get_or_create_state | _trip | begin,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,39,Manually disable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,enable_v2,"async enable_v2(enabled_by: str, reason: Optional[str]) -> bool",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _build_enable_alert_payload | _enqueue_alert | _get_or_create_state | _resolve_incident | begin | get_metrics | info | now | record_cb_enabled | set_circuit_breaker_state | set_consecutive_failures,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,64,Manually enable CostSim V2.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,get_async_circuit_breaker,get_async_circuit_breaker() -> AsyncCircuitBreaker,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncCircuitBreaker,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,no,6,Get the global async circuit breaker instance.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,get_incidents,"async get_incidents(include_resolved: bool, limit: int) -> List[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,Incident | append | async_session_context | desc | execute | get_details | limit | order_by | scalars | select | where,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,45,Get recent incidents.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,get_state,async get_state() -> CircuitBreakerState,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,CircuitBreakerState | _get_or_create_state | async_session_context,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,15,Get current circuit breaker state.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,is_v2_disabled,async is_v2_disabled(session: Optional[AsyncSession]) -> bool,?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _try_auto_recover | close | execute | first | get_config | limit | now | replace | scalars | select | where,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,db_write,yes,59,Check if V2 is disabled.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,report_drift,"async report_drift(drift_score: float, sample_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _get_or_create_state | _trip | begin | get_config | get_metrics | info | now | set_consecutive_failures | warning,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,60,Report drift observation.,Persistence/Driver,high,L6 layer = persistence
controls,L6,circuit_breaker_async,report_schema_error,"async report_schema_error(error_count: int, details: Optional[Dict[str, Any]]) -> Optional[Incident]",?:__init__ | ?:circuit_breaker_async | ?:sandbox | ?:canary | ?:cb_sync_wrapper | L5:sandbox | L5:canary | L5:cb_sync_wrapper | ?:check_priority5_intent | ?:test_circuit_breaker_async,AsyncSessionLocal | _get_or_create_state | _trip | begin | get_config,__future__ | asyncio | cb_sync_wrapper | config | costsim_cb | db_async | infra | metrics | sqlalchemy,pure,yes,33,Report schema validation errors.,Persistence/Driver,high,L6 layer = persistence
controls,L6,limits_read_driver,LimitsReadDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:policies_limits_query_engine,,asyncio | policy_control_plane | sqlalchemy | time,pure,no,2,,Internal Helper,high,dunder method
controls,L6,limits_read_driver,LimitsReadDriver.fetch_budget_limits,"async fetch_budget_limits(tenant_id: str, scope: Optional[str], status: str, limit: int, offset: int) -> list[dict]",L6:__init__ | L5:policies_limits_query_engine,all | and_ | desc | execute | limit | offset | order_by | scalars | select | str | where,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,40,Fetch budget definitions for tenant.,Persistence/Driver,high,L6 layer = persistence
controls,L6,limits_read_driver,LimitsReadDriver.fetch_limit_by_id,"async fetch_limit_by_id(tenant_id: str, limit_id: str) -> Optional[dict]",L6:__init__ | L5:policies_limits_query_engine,coalesce | count | execute | first | getattr | group_by | join | label | max | outerjoin | select | subquery | timedelta | utc_now | where,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,68,Fetch limit detail. Returns None if not found.,Persistence/Driver,high,L6 layer = persistence
controls,L6,limits_read_driver,LimitsReadDriver.fetch_limits,"async fetch_limits(tenant_id: str) -> tuple[list[dict], int]",L6:__init__ | L5:policies_limits_query_engine,all | and_ | coalesce | count | desc | dict | endswith | execute | group_by | join | label | limit | max | nullslast | offset,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,121,Fetch limits with filters and pagination.,Persistence/Driver,high,L6 layer = persistence
controls,L6,limits_read_driver,get_limits_read_driver,get_limits_read_driver(session: AsyncSession) -> LimitsReadDriver,L6:__init__ | L5:policies_limits_query_engine,LimitsReadDriver,asyncio | policy_control_plane | sqlalchemy | time,pure,no,3,Factory function for LimitsReadDriver.,Persistence/Driver,high,L6 layer = persistence
controls,L6,override_driver,LimitOverrideService.__init__,__init__(session: AsyncSession),L2:override,,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,no,2,,Internal Helper,high,dunder method
controls,L6,override_driver,LimitOverrideService._get_limit,"async _get_limit(tenant_id: str, limit_id: str) -> Limit",L2:override,LimitNotFoundError | and_ | execute | scalar_one_or_none | select | where,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,db_write,yes,15,Get limit by ID with tenant check.,Internal Helper,medium,private function
controls,L6,override_driver,LimitOverrideService._to_response,_to_response(data: dict) -> LimitOverrideResponse,L2:override,Decimal | LimitOverrideResponse | OverrideStatus | fromisoformat | str,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,no,20,Convert stored data to response.,Internal Helper,medium,private function
controls,L6,override_driver,LimitOverrideService.cancel_override,"async cancel_override(tenant_id: str, override_id: str, cancelled_by: str) -> LimitOverrideResponse",L2:override,OverrideNotFoundError | OverrideValidationError | _to_response | get,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,yes,16,Cancel a pending or active override.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,override_driver,LimitOverrideService.get_override,"async get_override(tenant_id: str, override_id: str) -> LimitOverrideResponse",L2:override,OverrideNotFoundError | _to_response | get,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,yes,10,Get an override by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,override_driver,LimitOverrideService.list_overrides,"async list_overrides(tenant_id: str, status: Optional[str], limit: int, offset: int) -> tuple[list[LimitOverrideResponse], int]",L2:override,_to_response | len | values,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,yes,16,List overrides for a tenant.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,override_driver,LimitOverrideService.request_override,"async request_override(tenant_id: str, request: LimitOverrideRequest, requested_by: str) -> LimitOverrideResponse",L2:override,OverrideValidationError | StackingAbuseError | _get_limit | _to_response | float | generate_uuid | isoformat | next | sum | timedelta | utc_now | values,asyncio | cross_domain | overrides | policy_control_plane | sqlalchemy | time,pure,yes,82,Request a temporary limit override.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,policy_limits_driver,PolicyLimitsDriver.__init__,__init__(session: AsyncSession),L5:policy_limits_engine,,asyncio | policy_control_plane | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
controls,L6,policy_limits_driver,PolicyLimitsDriver.add_integrity,add_integrity(integrity: 'LimitIntegrity') -> None,L5:policy_limits_engine,add,asyncio | policy_control_plane | sqlalchemy,db_write,no,8,Add an integrity record to the session.,Persistence/Driver,high,L6 layer = persistence
controls,L6,policy_limits_driver,PolicyLimitsDriver.add_limit,add_limit(limit: 'Limit') -> None,L5:policy_limits_engine,add,asyncio | policy_control_plane | sqlalchemy,db_write,no,8,Add a limit to the session.,Persistence/Driver,high,L6 layer = persistence
controls,L6,policy_limits_driver,PolicyLimitsDriver.fetch_limit_by_id,"async fetch_limit_by_id(tenant_id: str, limit_id: str) -> Optional['Limit']",L5:policy_limits_engine,execute | scalar_one_or_none | select | where,asyncio | policy_control_plane | sqlalchemy,db_write,yes,23,Fetch a limit by ID with tenant scope.,Persistence/Driver,high,L6 layer = persistence
controls,L6,policy_limits_driver,PolicyLimitsDriver.flush,async flush() -> None,L5:policy_limits_engine,flush,asyncio | policy_control_plane | sqlalchemy,db_write,yes,3,Flush pending changes without committing.,Persistence/Driver,high,L6 layer = persistence
controls,L6,policy_limits_driver,get_policy_limits_driver,get_policy_limits_driver(session: AsyncSession) -> PolicyLimitsDriver,L5:policy_limits_engine,PolicyLimitsDriver,asyncio | policy_control_plane | sqlalchemy,pure,no,3,Factory function for PolicyLimitsDriver.,Persistence/Driver,high,L6 layer = persistence
controls,L6,scoped_execution,BoundExecutionScope.can_execute,"can_execute(action: str, incident_id: str) -> tuple[bool, str]",?:recovery | ?:scoped_execution | L2:recovery,is_valid,__future__,pure,no,16,Check if action can be executed within this scope.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'can_'); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,BoundExecutionScope.consume,"consume(action: str, cost_usd: float) -> None",?:recovery | ?:scoped_execution | L2:recovery,append | isoformat | now,__future__,pure,no,20,Consume one execution attempt.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,BoundExecutionScope.is_valid,is_valid() -> bool,?:recovery | ?:scoped_execution | L2:recovery,now,__future__,pure,no,11,Check if scope is still valid for execution.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'is_valid'); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,BoundExecutionScope.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:scoped_execution | L2:recovery,isoformat | max,__future__,pure,no,18,Serialize scope for API response.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopeStore.__new__,__new__() -> 'ScopeStore',?:recovery | ?:scoped_execution | L2:recovery,__new__ | super,__future__,pure,no,8,,Internal Helper,high,dunder method
controls,L6,scoped_execution,ScopeStore.cleanup_expired,cleanup_expired() -> int,?:recovery | ?:scoped_execution | L2:recovery,items | len | now,__future__,pure,no,7,Remove expired scopes from memory.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopeStore.create_scope,"create_scope(incident_id: str, allowed_actions: List[str], max_cost_usd: float, max_attempts: int, ttl_seconds: int, intent: str, target_agents: Optional[List[str]], created_by: str) -> BoundExecutionScope",?:recovery | ?:scoped_execution | L2:recovery,BoundExecutionScope | append | info | isoformat | now | timedelta | token_hex,__future__,pure,no,44,Create a new bound execution scope.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopeStore.get_scope,get_scope(scope_id: str) -> Optional[BoundExecutionScope],?:recovery | ?:scoped_execution | L2:recovery,get,__future__,pure,no,3,Get scope by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopeStore.get_scopes_for_incident,get_scopes_for_incident(incident_id: str) -> List[BoundExecutionScope],?:recovery | ?:scoped_execution | L2:recovery,get,__future__,pure,no,4,Get all scopes for an incident.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopeStore.revoke_scope,revoke_scope(scope_id: str) -> bool,?:recovery | ?:scoped_execution | L2:recovery,get | info,__future__,pure,no,8,Revoke a scope (admin action).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,ScopedExecutionContext.__init__,"__init__(action: RecoveryAction, scope: ExecutionScope, scope_fraction: float, timeout_ms: int)",?:recovery | ?:scoped_execution | L2:recovery,max | min,__future__,pure,no,13,,Internal Helper,high,dunder method
controls,L6,scoped_execution,ScopedExecutionContext._compute_hash,"_compute_hash(data: Dict[str, Any]) -> str",?:recovery | ?:scoped_execution | L2:recovery,dumps | encode | hexdigest | sha256,__future__,pure,no,6,Compute deterministic hash of execution.,Internal Helper,medium,private function
controls,L6,scoped_execution,ScopedExecutionContext._dry_run_validate,async _dry_run_validate() -> ScopedExecutionResult,?:recovery | ?:scoped_execution | L2:recovery,ScopedExecutionResult | _compute_hash | _elapsed_ms | _estimate_cost | append | len,__future__,pure,yes,36,Validate action without actual execution.,Internal Helper,medium,private function
controls,L6,scoped_execution,ScopedExecutionContext._elapsed_ms,_elapsed_ms() -> int,?:recovery | ?:scoped_execution | L2:recovery,int | now | total_seconds,__future__,pure,no,7,Get elapsed time in milliseconds.,Internal Helper,medium,private function
controls,L6,scoped_execution,ScopedExecutionContext._estimate_cost,_estimate_cost() -> int,?:recovery | ?:scoped_execution | L2:recovery,get,__future__,pure,no,10,Estimate cost in cents for the action.,Internal Helper,medium,private function
controls,L6,scoped_execution,ScopedExecutionContext._execute_scoped,async _execute_scoped() -> ScopedExecutionResult,?:recovery | ?:scoped_execution | L2:recovery,ScopedExecutionResult | _compute_hash | _elapsed_ms | int,__future__,pure,yes,31,Execute action on scoped subset.,Internal Helper,medium,private function
controls,L6,scoped_execution,ScopedExecutionContext.execute,async execute() -> ScopedExecutionResult,?:recovery | ?:scoped_execution | L2:recovery,ScopedExecutionResult | _compute_hash | _dry_run_validate | _elapsed_ms | _execute_scoped | error | now | str,__future__,pure,yes,32,Execute action in scoped context.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,create_recovery_scope,"async create_recovery_scope(incident_id: str, action: str, intent: str, max_cost_usd: float, max_attempts: int, ttl_seconds: int, target_agents: Optional[List[str]], created_by: str) -> Dict[str, Any]",?:recovery | ?:scoped_execution | L2:recovery,create_scope | get_scope_store | to_dict,__future__,pure,yes,33,Create a bound execution scope for recovery action.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,execute_with_scope,"async execute_with_scope(scope_id: str, action: str, incident_id: str, parameters: Optional[Dict[str, Any]]) -> Dict[str, Any]",?:recovery | ?:scoped_execution | L2:recovery,ScopeActionMismatch | ScopeExhausted | ScopeExpired | ScopeIncidentMismatch | ScopeNotFound | ScopedExecutionRequired | can_execute | consume | get_scope | get_scope_store | info | isoformat | lower | max | now,__future__,pure,yes,55,Execute a recovery action within a valid scope.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,get_scope_store,get_scope_store() -> ScopeStore,?:recovery | ?:scoped_execution | L2:recovery,,__future__,pure,no,3,Get the global scope store.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,requires_scoped_execution,requires_scoped_execution(risk_threshold: RiskClass),?:recovery | ?:scoped_execution | L2:recovery,ScopedExecutionRequired | func | get | index | isinstance | pop | wraps,__future__,pure,no,37,Decorator to enforce scoped pre-execution for risky recovery actions.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,test_recovery_scope,"async test_recovery_scope(action_id: str, action_name: str, action_type: str, risk_class: str, parameters: Dict[str, Any], scope_type: str, scope_fraction: float) -> Dict[str, Any]",?:recovery | ?:scoped_execution | L2:recovery,ExecutionScope | RecoveryAction | RiskClass | ScopedExecutionContext | execute,__future__,pure,yes,39,Test a recovery action in scoped execution.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
controls,L6,scoped_execution,validate_scope_required,"async validate_scope_required(incident_id: str, action: str) -> None",?:recovery | ?:scoped_execution | L2:recovery,ScopedExecutionRequired,__future__,pure,yes,15,Validate that execution without scope should fail.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
controls,L6,threshold_driver,ThresholdDriver.__init__,__init__(session: AsyncSession),?:runner | L6:__init__ | L5:threshold_engine,,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,pure,no,2,,Internal Helper,high,dunder method
controls,L6,threshold_driver,ThresholdDriver.get_active_threshold_limits,async get_active_threshold_limits(tenant_id: str) -> list[LimitSnapshot],?:runner | L6:__init__ | L5:threshold_engine,LimitSnapshot | all | execute | order_by | scalars | select | str | where,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,db_write,yes,36,Query active threshold limits for a tenant.,Persistence/Driver,high,L6 layer = persistence
controls,L6,threshold_driver,ThresholdDriver.get_threshold_limit_by_scope,"async get_threshold_limit_by_scope(tenant_id: str, scope: str, scope_id: Optional[str]) -> Optional[LimitSnapshot]",?:runner | L6:__init__ | L5:threshold_engine,LimitSnapshot | execute | scalar_one_or_none | select | str | where,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,db_write,yes,43,Query a single threshold limit by scope.,Persistence/Driver,high,L6 layer = persistence
controls,L6,threshold_driver,ThresholdDriverSync.__init__,__init__(session: Any),?:runner | L6:__init__ | L5:threshold_engine,,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,pure,no,8,Initialize with a sync SQLAlchemy Session.,Internal Helper,high,dunder method
controls,L6,threshold_driver,ThresholdDriverSync.get_active_threshold_limits,get_active_threshold_limits(tenant_id: str) -> list[LimitSnapshot],?:runner | L6:__init__ | L5:threshold_engine,LimitSnapshot | execute | fetchall | str | text,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,db_write,no,37,Query active threshold limits for a tenant (sync version).,Persistence/Driver,high,L6 layer = persistence
controls,L6,threshold_driver,emit_and_persist_threshold_signal,"emit_and_persist_threshold_signal(session: Any, tenant_id: str, run_id: str, state: str, signals: list, params_used: dict) -> None",?:runner | L6:__init__ | L5:threshold_engine,RunSignalService | emit_threshold_signal_sync | info | len | update_risk_level,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,pure,no,54,Emit threshold signals to both Founder and Customer consoles.,Persistence/Driver,high,L6 layer = persistence
controls,L6,threshold_driver,emit_threshold_signal_sync,"emit_threshold_signal_sync(session: Any, tenant_id: str, run_id: str, state: str, signal: Any, params_used: dict) -> None",?:runner | L6:__init__ | L5:threshold_engine,EventEmitter | OpsEvent | UUID | emit | get | info | isinstance,asyncio | event_emitter | policy_control_plane | run_signal_service | sqlalchemy | sqlmodel | threshold_engine,pure,no,69,Emit a threshold signal to ops_events table (sync).,Persistence/Driver,high,L6 layer = persistence
incidents,L5,anomaly_bridge,AnomalyIncidentBridge.__init__,__init__(session),L5:cost_anomaly_detector,get_incident_write_driver,governance | incident_write_driver | metrics | sqlalchemy,pure,no,9,Initialize bridge with database session.,Internal Helper,high,dunder method
incidents,L5,anomaly_bridge,AnomalyIncidentBridge._build_incident_insert_sql,_build_incident_insert_sql(),L5:cost_anomaly_detector,text,governance | incident_write_driver | metrics | sqlalchemy,pure,no,24,Build SQL for incident insert.,Internal Helper,medium,private function
incidents,L5,anomaly_bridge,AnomalyIncidentBridge._check_existing_incident,_check_existing_incident(fact: CostAnomalyFact) -> Optional[str],L5:cost_anomaly_detector,,governance | incident_write_driver | metrics | sqlalchemy,pure,no,10,Check for existing unresolved incident for this anomaly.,Internal Helper,medium,private function
incidents,L5,anomaly_bridge,AnomalyIncidentBridge._create_incident,_create_incident(fact: CostAnomalyFact) -> str,L5:cost_anomaly_detector,Decimal | GovernanceError | _build_incident_insert_sql | execute | get | inc | info | labels | now | str | upper | uuid4,governance | incident_write_driver | metrics | sqlalchemy,db_write,no,91,Create an incident from the cost anomaly fact.,Internal Helper,medium,private function
incidents,L5,anomaly_bridge,AnomalyIncidentBridge._is_suppressed,_is_suppressed(fact: CostAnomalyFact) -> bool,L5:cost_anomaly_detector,fetch_suppressing_policy,governance | incident_write_driver | metrics | sqlalchemy,pure,no,16,Check if an active policy suppresses this anomaly type.,Internal Helper,medium,private function
incidents,L5,anomaly_bridge,AnomalyIncidentBridge._meets_severity_threshold,_meets_severity_threshold(severity: str) -> bool,L5:cost_anomaly_detector,upper,governance | incident_write_driver | metrics | sqlalchemy,pure,no,4,Check if severity meets threshold for incident creation.,Internal Helper,medium,private function
incidents,L5,anomaly_bridge,AnomalyIncidentBridge.ingest,ingest(fact: CostAnomalyFact) -> Optional[str],L5:cost_anomaly_detector,_check_existing_incident | _create_incident | _is_suppressed | _meets_severity_threshold | debug | info,governance | incident_write_driver | metrics | sqlalchemy,pure,no,43,Process a cost anomaly fact and create an incident if warranted.,Unclassified,low,no classification rules matched
incidents,L5,anomaly_bridge,get_anomaly_incident_bridge,get_anomaly_incident_bridge(session) -> AnomalyIncidentBridge,L5:cost_anomaly_detector,AnomalyIncidentBridge,governance | incident_write_driver | metrics | sqlalchemy,pure,no,3,Factory function to get AnomalyIncidentBridge instance.,Unclassified,low,no classification rules matched
incidents,L5,hallucination_detector,HallucinationDetector.__init__,__init__(config: Optional[HallucinationConfig]),?:hallucination_hook | ?:__init__,HallucinationConfig | compile,,pure,no,26,Initialize detector with config.,Internal Helper,high,dunder method
incidents,L5,hallucination_detector,HallucinationDetector._detect_contradictions,_detect_contradictions(content: str) -> list[HallucinationIndicator],?:hallucination_hook | ?:__init__,HallucinationIndicator | append | group | lower | search,,pure,no,25,Detect self-contradictions in content.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationDetector._detect_suspicious_citations,_detect_suspicious_citations(content: str) -> list[HallucinationIndicator],?:hallucination_hook | ?:__init__,HallucinationIndicator | append | findall | int | list | now,,pure,no,39,Detect potentially fabricated academic citations.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationDetector._detect_suspicious_urls,_detect_suspicious_urls(content: str) -> list[HallucinationIndicator],?:hallucination_hook | ?:__init__,HallucinationIndicator | append | findall | search,,pure,no,27,Detect potentially fabricated URLs.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationDetector._detect_temporal_issues,"_detect_temporal_issues(content: str, context: Optional[dict[str, Any]]) -> list[HallucinationIndicator]",?:hallucination_hook | ?:__init__,HallucinationIndicator | append | compile | findall | lower | now,,pure,no,27,Detect temporal impossibilities.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationDetector._hash_content,_hash_content(content: str) -> str,?:hallucination_hook | ?:__init__,encode | hexdigest | sha256,,pure,no,3,Generate hash of content for evidence tracking.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationDetector.detect,"detect(content: str, context: Optional[dict[str, Any]], customer_blocking_opted_in: bool) -> HallucinationResult",?:hallucination_hook | ?:__init__,HallucinationResult | _detect_contradictions | _detect_suspicious_citations | _detect_suspicious_urls | _detect_temporal_issues | _hash_content | extend | get | len | min | sum,,pure,no,81,Detect potential hallucinations in content.,Unclassified,low,no classification rules matched
incidents,L5,hallucination_detector,HallucinationIndicator.to_dict,"to_dict() -> dict[str, Any]",?:hallucination_hook | ?:__init__,,,pure,no,10,Convert to dictionary for serialization.,Internal Helper,medium,name matches 'to_'
incidents,L5,hallucination_detector,HallucinationResult._derive_severity,_derive_severity() -> HallucinationSeverity,?:hallucination_hook | ?:__init__,any,,pure,no,17,Derive overall severity from indicators.,Internal Helper,medium,private function
incidents,L5,hallucination_detector,HallucinationResult.to_incident_data,"to_incident_data() -> dict[str, Any]",?:hallucination_hook | ?:__init__,_derive_severity | isoformat | to_dict,,pure,no,15,Convert to incident creation data.,Internal Helper,medium,name matches 'to_'
incidents,L5,hallucination_detector,create_detector_for_tenant,"create_detector_for_tenant(tenant_config: Optional[dict[str, Any]]) -> HallucinationDetector",?:hallucination_hook | ?:__init__,HallucinationConfig | HallucinationDetector | get,,pure,no,23,Create a detector configured for a specific tenant.,Unclassified,low,no classification rules matched
incidents,L5,incident_driver,IncidentDriver.__init__,__init__(db_url: Optional[str]),?:incident_driver | ?:__init__ | L4:transaction_coordinator,,audit_store | incident_engine | rac_models,pure,no,10,Initialize driver with optional database URL.,Internal Helper,high,dunder method
incidents,L5,incident_driver,IncidentDriver._emit_ack,"_emit_ack(run_id: str, result_id: Optional[str], error: Optional[str]) -> None",?:incident_driver | ?:__init__ | L4:transaction_coordinator,DomainAck | UUID | add_ack | debug | get_audit_store | warning,audit_store | incident_engine | rac_models,pure,no,39,Emit RAC acknowledgment for incident creation.,Internal Helper,medium,private function
incidents,L5,incident_driver,IncidentDriver._engine,_engine(),?:incident_driver | ?:__init__ | L4:transaction_coordinator,IncidentEngine,audit_store | incident_engine | rac_models,pure,no,7,Lazy-load incident engine.,Internal Helper,medium,private function
incidents,L5,incident_driver,IncidentDriver.check_and_create_incident,"check_and_create_incident(run_id: str, status: str, error_message: Optional[str], tenant_id: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:incident_driver | ?:__init__ | L4:transaction_coordinator,check_and_create_incident | debug,audit_store | incident_engine | rac_models,pure,no,41,Check if an incident should be created for a run and create it.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
incidents,L5,incident_driver,IncidentDriver.create_incident_for_run,"create_incident_for_run(run_id: str, tenant_id: str, run_status: str, error_code: Optional[str], error_message: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:incident_driver | ?:__init__ | L4:transaction_coordinator,_emit_ack | create_incident_for_run | debug | error | str,audit_store | incident_engine | rac_models,pure,no,63,Create an incident record for any run (success or failure).,Operation,high,called by L4 orchestrator
incidents,L5,incident_driver,IncidentDriver.get_incidents_for_run,"get_incidents_for_run(run_id: str) -> List[Dict[str, Any]]",?:incident_driver | ?:__init__ | L4:transaction_coordinator,get_incidents_for_run,audit_store | incident_engine | rac_models,pure,no,11,Get all incidents associated with a run.,Operation,high,called by L4 orchestrator
incidents,L5,incident_driver,get_incident_driver,get_incident_driver(db_url: Optional[str]) -> IncidentDriver,?:incident_driver | ?:__init__ | L4:transaction_coordinator,IncidentDriver,audit_store | incident_engine | rac_models,pure,no,19,Get the incident driver instance.,Operation,high,called by L4 orchestrator
incidents,L5,incident_engine,IncidentEngine.__init__,"__init__(db_url: Optional[str], driver: Optional[IncidentWriteDriver])",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,get,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,11,Initialize the incident engine.,Internal Helper,high,dunder method
incidents,L5,incident_engine,IncidentEngine._check_policy_suppression,"_check_policy_suppression(tenant_id: str, error_code: Optional[str], category: str) -> Optional[Dict[str, Any]]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_get_driver | fetch_suppressing_policy | warning,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,35,Check if an active policy_rule suppresses this incident pattern.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine._extract_error_code,_extract_error_code(error_message: Optional[str]) -> str,?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,keys | upper,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,11,Extract error code from error message.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine._generate_title,"_generate_title(error_code: Optional[str], run_id: str) -> str",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,16,Generate human-readable incident title.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine._get_driver,_get_driver() -> IncidentWriteDriver,?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,RuntimeError | SessionLocal | create_engine | get_incident_write_driver | sessionmaker,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,24,Get or create the write driver.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine._maybe_create_policy_proposal,"_maybe_create_policy_proposal(incident_id: str, tenant_id: str, severity: str, category: str, error_code: Optional[str], run_id: str, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_get_driver | get | info | insert_policy_proposal | replace | str | title | utc_now | uuid4 | warning,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,93,Create a policy proposal for high-severity incidents.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine._write_prevention_record,"_write_prevention_record(policy_id: str, run_id: str, tenant_id: str, error_code: Optional[str], source_incident_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> str",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_get_driver | info | insert_prevention_record | utc_now | uuid4,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,51,Write a prevention_record when a run is suppressed by an active policy.,Internal Helper,medium,private function
incidents,L5,incident_engine,IncidentEngine.check_and_create_incident,"check_and_create_incident(run_id: str, status: str, error_message: Optional[str], tenant_id: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_extract_error_code | create_incident_for_failed_run | warning,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,51,Check if a run status warrants an incident and create one if so.,Policy/Decision,medium,name matches 'check'
incidents,L5,incident_engine,IncidentEngine.create_incident_for_all_runs,"create_incident_for_all_runs(run_id: str, status: str, error_message: Optional[str], tenant_id: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_extract_error_code | create_incident_for_run | warning,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,46,Create an incident for ANY run (PIN-407: Success as First-Class Data).,Unclassified,low,no classification rules matched
incidents,L5,incident_engine,IncidentEngine.create_incident_for_failed_run,"create_incident_for_failed_run(run_id: str, tenant_id: str, error_code: Optional[str], error_message: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,PyUUID | _check_policy_suppression | _generate_title | _get_driver | _get_lessons_learned_engine | _maybe_create_policy_proposal | _write_prevention_record | debug | detect_lesson_from_failure | error | get | info | insert_incident | isinstance | update_run_incident_count,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,159,Create an incident for a failed run.,Unclassified,low,no classification rules matched
incidents,L5,incident_engine,IncidentEngine.create_incident_for_run,"create_incident_for_run(run_id: str, tenant_id: str, run_status: str, error_code: Optional[str], error_message: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,PyUUID | _check_policy_suppression | _generate_title | _get_driver | _get_lessons_learned_engine | _maybe_create_policy_proposal | _write_prevention_record | detect_lesson_from_failure | error | get | info | insert_incident | isinstance | lower | update_run_incident_count,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,176,Create an incident for ANY run (PIN-407: Success as First-Class Data).,Unclassified,low,no classification rules matched
incidents,L5,incident_engine,IncidentEngine.get_incidents_for_run,"get_incidents_for_run(run_id: str) -> List[Dict[str, Any]]",?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,_get_driver | error | fetch_incidents_by_run_id,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,21,Get all incidents linked to a run.,Unclassified,low,no classification rules matched
incidents,L5,incident_engine,_get_lessons_learned_engine,_get_lessons_learned_engine(),?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,get_lessons_learned_engine,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,4,Get the LessonsLearnedEngine singleton (lazy import).,Internal Helper,medium,private function
incidents,L5,incident_engine,get_incident_engine,get_incident_engine() -> IncidentEngine,?:hallucination_detector | ?:incident_driver | L5:incident_driver | L5:hallucination_detector | ?:inject_synthetic,IncidentEngine,incident_write_driver | lessons_engine | orm | sqlalchemy | sqlmodel | time,pure,no,6,Get or create singleton incident engine instance.,Unclassified,low,no classification rules matched
incidents,L5,incident_pattern_engine,IncidentPatternService.__init__,"__init__(session: 'AsyncSession', driver: Optional[IncidentPatternDriver])",L5:incidents_facade,get_incident_pattern_driver,asyncio | incident_pattern_driver | time,pure,no,14,Initialize with session and optional driver.,Internal Helper,high,dunder method
incidents,L5,incident_pattern_engine,IncidentPatternService._detect_cascade_failures,"async _detect_cascade_failures(tenant_id: str, window_start: datetime, limit: int) -> list[PatternMatch]",L5:incidents_facade,PatternMatch | append | fetch_cascade_failures | min | round,asyncio | incident_pattern_driver | time,pure,yes,31,Detect multiple incidents from same source run.,Internal Helper,medium,private function
incidents,L5,incident_pattern_engine,IncidentPatternService._detect_category_clusters,"async _detect_category_clusters(tenant_id: str, window_start: datetime, limit: int) -> list[PatternMatch]",L5:incidents_facade,PatternMatch | append | fetch_category_clusters | min | round,asyncio | incident_pattern_driver | time,pure,yes,31,Detect categories with multiple incidents.,Internal Helper,medium,private function
incidents,L5,incident_pattern_engine,IncidentPatternService._detect_severity_spikes,"async _detect_severity_spikes(tenant_id: str, limit: int) -> list[PatternMatch]",L5:incidents_facade,PatternMatch | append | fetch_severity_spikes | min | round,asyncio | incident_pattern_driver | time,pure,yes,33,Detect multiple high/critical incidents in short window.,Internal Helper,medium,private function
incidents,L5,incident_pattern_engine,IncidentPatternService.detect_patterns,"async detect_patterns(tenant_id: str, window_hours: int, limit: int) -> PatternResult",L5:incidents_facade,PatternResult | _detect_cascade_failures | _detect_category_clusters | _detect_severity_spikes | extend | fetch_incidents_count | min | timedelta | utc_now,asyncio | incident_pattern_driver | time,pure,yes,53,Detect all patterns within the time window.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,IncidentReadService.__init__,__init__(session: 'Session'),L5:customer_incidents_adapter | L3:customer_incidents_adapter,get_incident_read_driver,incident_read_driver | killswitch | sqlmodel,pure,no,3,Initialize with database session (passed to driver).,Internal Helper,high,dunder method
incidents,L5,incident_read_engine,IncidentReadService.count_incidents_since,"count_incidents_since(tenant_id: str, since: datetime) -> int",L5:customer_incidents_adapter | L3:customer_incidents_adapter,count_incidents_since,incident_read_driver | killswitch | sqlmodel,pure,no,11,Count incidents since a given time.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,IncidentReadService.get_incident,"get_incident(incident_id: str, tenant_id: str) -> Optional['Incident']",L5:customer_incidents_adapter | L3:customer_incidents_adapter,get_incident,incident_read_driver | killswitch | sqlmodel,pure,no,11,Get a single incident by ID with tenant isolation.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,IncidentReadService.get_incident_events,get_incident_events(incident_id: str) -> List['IncidentEvent'],L5:customer_incidents_adapter | L3:customer_incidents_adapter,get_incident_events,incident_read_driver | killswitch | sqlmodel,pure,no,10,Get timeline events for an incident.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,IncidentReadService.get_last_incident,get_last_incident(tenant_id: str) -> Optional['Incident'],L5:customer_incidents_adapter | L3:customer_incidents_adapter,get_last_incident,incident_read_driver | killswitch | sqlmodel,pure,no,10,Get the most recent incident for a tenant.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,IncidentReadService.list_incidents,"list_incidents(tenant_id: str, status: Optional[str], severity: Optional[str], from_date: Optional[datetime], to_date: Optional[datetime], limit: int, offset: int) -> Tuple[List['Incident'], int]",L5:customer_incidents_adapter | L3:customer_incidents_adapter,list_incidents,incident_read_driver | killswitch | sqlmodel,pure,no,24,List incidents for a tenant with optional filters.,Unclassified,low,no classification rules matched
incidents,L5,incident_read_engine,get_incident_read_service,get_incident_read_service(session: 'Session') -> IncidentReadService,L5:customer_incidents_adapter | L3:customer_incidents_adapter,IncidentReadService,incident_read_driver | killswitch | sqlmodel,pure,no,3,Factory function to get IncidentReadService instance.,Unclassified,low,no classification rules matched
incidents,L5,incident_severity_engine,IncidentSeverityEngine.__init__,__init__(config: SeverityConfig | None),L6:incident_aggregator,default,killswitch,pure,no,2,,Internal Helper,high,dunder method
incidents,L5,incident_severity_engine,IncidentSeverityEngine.calculate_severity_for_calls,calculate_severity_for_calls(calls_affected: int) -> str,L6:incident_aggregator,,killswitch,pure,no,22,Calculate severity based on number of affected calls.,Unclassified,low,no classification rules matched
incidents,L5,incident_severity_engine,IncidentSeverityEngine.get_initial_severity,get_initial_severity(trigger_type: str) -> str,L6:incident_aggregator,get,killswitch,pure,no,13,Get initial severity based on trigger type.,Unclassified,low,no classification rules matched
incidents,L5,incident_severity_engine,IncidentSeverityEngine.should_escalate,"should_escalate(current_severity: str, calls_affected: int) -> Tuple[bool, str]",L6:incident_aggregator,calculate_severity_for_calls | index,killswitch,pure,no,35,Determine if an incident should be escalated.,Policy/Decision,medium,name matches 'should_'
incidents,L5,incident_severity_engine,SeverityConfig.default,default() -> 'SeverityConfig',L6:incident_aggregator,cls,killswitch,pure,no,10,Default severity thresholds.,Unclassified,low,no classification rules matched
incidents,L5,incident_severity_engine,generate_incident_title,"generate_incident_title(trigger_type: str, trigger_value: str) -> str",L6:incident_aggregator,get,killswitch,pure,no,22,Generate human-readable incident title.,Unclassified,low,no classification rules matched
incidents,L5,incident_write_engine,IncidentWriteService.__init__,__init__(session: 'Session'),?:incident_write_service | L5:customer_incidents_adapter | L3:customer_incidents_adapter,AuditLedgerService | get_incident_write_driver,audit_ledger | audit_ledger_service | incident_write_driver | killswitch | sqlmodel,pure,no,5,Initialize with database session (passed to driver and audit).,Internal Helper,high,dunder method
incidents,L5,incident_write_engine,IncidentWriteService.acknowledge_incident,"acknowledge_incident(incident: 'Incident', acknowledged_by: str, actor_type: ActorType, reason: Optional[str]) -> 'Incident'",?:incident_write_service | L5:customer_incidents_adapter | L3:customer_incidents_adapter,begin | create_incident_event | incident_acknowledged | now | refresh_incident | str | update_incident_acknowledged,audit_ledger | audit_ledger_service | incident_write_driver | killswitch | sqlmodel,pure,no,57,Acknowledge an incident and create a timeline event.,Unclassified,low,no classification rules matched
incidents,L5,incident_write_engine,IncidentWriteService.manual_close_incident,"manual_close_incident(incident: 'Incident', closed_by: str, reason: Optional[str], actor_type: ActorType) -> 'Incident'",?:incident_write_service | L5:customer_incidents_adapter | L3:customer_incidents_adapter,begin | create_incident_event | hasattr | incident_manually_closed | isoformat | now | refresh_incident | str | update_incident_resolved,audit_ledger | audit_ledger_service | incident_write_driver | killswitch | sqlmodel,pure,no,83,Manually close an incident without resolution workflow.,Unclassified,low,no classification rules matched
incidents,L5,incident_write_engine,IncidentWriteService.resolve_incident,"resolve_incident(incident: 'Incident', resolved_by: str, resolution_notes: Optional[str], resolution_method: Optional[str], actor_type: ActorType, reason: Optional[str]) -> 'Incident'",?:incident_write_service | L5:customer_incidents_adapter | L3:customer_incidents_adapter,begin | create_incident_event | incident_resolved | now | refresh_incident | str | update_incident_resolved,audit_ledger | audit_ledger_service | incident_write_driver | killswitch | sqlmodel,pure,no,70,Resolve an incident and create a timeline event.,Coordinator/Aggregator,medium,name matches 'resolve'
incidents,L5,incident_write_engine,get_incident_write_service,get_incident_write_service(session: 'Session') -> IncidentWriteService,?:incident_write_service | L5:customer_incidents_adapter | L3:customer_incidents_adapter,IncidentWriteService,audit_ledger | audit_ledger_service | incident_write_driver | killswitch | sqlmodel,pure,no,3,Factory function to get IncidentWriteService instance.,Unclassified,low,no classification rules matched
incidents,L5,incidents_facade,IncidentsFacade._snapshot_to_summary,_snapshot_to_summary(snapshot: IncidentSnapshot) -> IncidentSummaryResult,?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentSummaryResult,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,no,18,Convert snapshot to summary result. Applies business defaults.,Internal Helper,medium,private function
incidents,L5,incidents_facade,IncidentsFacade.analyze_cost_impact,"async analyze_cost_impact(session: 'AsyncSession', tenant_id: str) -> CostImpactResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,CostImpactResult | CostImpactSummaryResult | IncidentsFacadeDriver | append | fetch_cost_impact_data | min | now,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,37,Analyze cost impact across incidents.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.analyze_recurrence,"async analyze_recurrence(session: 'AsyncSession', tenant_id: str) -> RecurrenceAnalysisResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,RecurrenceAnalysisResult | RecurrenceAnalysisService | RecurrenceGroupResult | analyze_recurrence,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,44,Analyze recurring incident types.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.detect_patterns,"async detect_patterns(session: 'AsyncSession', tenant_id: str) -> PatternDetectionResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentPatternService | PatternDetectionResult | PatternMatchResult | detect_patterns,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,43,Detect incident patterns.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.get_incident_detail,"async get_incident_detail(session: 'AsyncSession', tenant_id: str, incident_id: str) -> Optional[IncidentDetailResult]",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentDetailResult | IncidentsFacadeDriver | fetch_incident_by_id,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,37,Get incident detail. Tenant isolation enforced.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.get_incident_learnings,"async get_incident_learnings(session: 'AsyncSession', tenant_id: str, incident_id: str) -> Optional[LearningsResult]",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,LearningInsightResult | LearningsResult | PostMortemService | ResolutionSummaryResult | get_incident_learnings,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,60,Extract post-mortem learnings from an incident.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.get_incidents_for_run,"async get_incidents_for_run(session: 'AsyncSession', tenant_id: str, run_id: str) -> IncidentsByRunResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentsByRunResult | IncidentsFacadeDriver | _snapshot_to_summary | fetch_incidents_by_run | len,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,21,Get all incidents linked to a specific run.,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.get_metrics,"async get_metrics(session: 'AsyncSession', tenant_id: str) -> IncidentMetricsResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentMetricsResult | IncidentsFacadeDriver | fetch_metrics_aggregates | now | round,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,60,"Get incident metrics. Backend-computed, deterministic.",Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.list_active_incidents,"async list_active_incidents(session: 'AsyncSession', tenant_id: str) -> IncidentListResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentListResult | IncidentsFacadeDriver | PaginationResult | _snapshot_to_summary | fetch_active_incidents | isoformat | len,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,61,List active incidents (ACTIVE + ACKED states).,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.list_historical_incidents,"async list_historical_incidents(session: 'AsyncSession', tenant_id: str) -> IncidentListResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentListResult | IncidentsFacadeDriver | PaginationResult | _snapshot_to_summary | fetch_historical_incidents | isoformat | len | now | timedelta,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,54,List historical incidents (resolved beyond retention window).,Operation,high,called by L4 orchestrator
incidents,L5,incidents_facade,IncidentsFacade.list_resolved_incidents,"async list_resolved_incidents(session: 'AsyncSession', tenant_id: str) -> IncidentListResult",?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentListResult | IncidentsFacadeDriver | PaginationResult | _snapshot_to_summary | fetch_resolved_incidents | isoformat | len,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,yes,61,List resolved incidents.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
incidents,L5,incidents_facade,get_incidents_facade,get_incidents_facade() -> IncidentsFacade,?:incidents | L4:incidents_handler | ?:learning_insight_result | ?:recurrence_group_result | ?:recurrence_analysis_result | ?:resolution_summary_result | ?:pattern_match_result | ?:learnings_result | ?:pattern_detection_result,IncidentsFacade,asyncio | incident_pattern_engine | incidents_facade_driver | postmortem_engine | recurrence_analysis_engine,pure,no,6,Get the singleton IncidentsFacade instance.,Operation,high,called by L4 orchestrator
incidents,L5,llm_failure_engine,LLMFailureFact.__post_init__,__post_init__(),?:llm_failure_service,ValueError | generate_uuid | utc_now,asyncio | llm_failure_driver | runtime,pure,no,10,,Internal Helper,high,dunder method
incidents,L5,llm_failure_engine,LLMFailureService.__init__,"__init__(session: 'AsyncSession', uuid_fn: UuidFn, clock_fn: ClockFn, driver: Optional[LLMFailureDriver])",?:llm_failure_service,get_llm_failure_driver,asyncio | llm_failure_driver | runtime,pure,no,20,Constructor requires explicit DI - no get_llm_failure_service() factory.,Internal Helper,high,dunder method
incidents,L5,llm_failure_engine,LLMFailureService._capture_evidence,"async _capture_evidence(failure: LLMFailureFact, timestamp: datetime) -> str",?:llm_failure_service,_uuid_fn | insert_evidence | isoformat,asyncio | llm_failure_driver | runtime,pure,yes,31,Capture evidence for the failure (mandatory per Invariant 4).,Internal Helper,medium,private function
incidents,L5,llm_failure_engine,LLMFailureService._mark_run_failed,"async _mark_run_failed(failure: LLMFailureFact, timestamp: datetime) -> bool",?:llm_failure_service,update_run_failed,asyncio | llm_failure_driver | runtime,pure,yes,17,Mark the run as FAILED.,Internal Helper,medium,private function
incidents,L5,llm_failure_engine,LLMFailureService._persist_failure,"async _persist_failure(failure: LLMFailureFact, timestamp: datetime) -> None",?:llm_failure_service,ValueError | insert_failure,asyncio | llm_failure_driver | runtime,pure,yes,22,Persist failure fact to run_failures table.,Internal Helper,medium,private function
incidents,L5,llm_failure_engine,LLMFailureService._verify_no_contamination,async _verify_no_contamination(failure: LLMFailureFact) -> None,?:llm_failure_service,RuntimeError | fetch_contamination_check,asyncio | llm_failure_driver | runtime,pure,yes,26,Verify no downstream artifacts were created (AC-4).,Internal Helper,medium,private function
incidents,L5,llm_failure_engine,LLMFailureService.get_failure_by_run_id,"async get_failure_by_run_id(run_id: str, tenant_id: str) -> Optional[LLMFailureFact]",?:llm_failure_service,LLMFailureFact | fetch_failure_by_run_id | loads,asyncio | llm_failure_driver | runtime,pure,yes,29,Retrieve failure fact by run ID (with tenant isolation).,Unclassified,low,no classification rules matched
incidents,L5,llm_failure_engine,LLMFailureService.persist_failure_and_mark_run,"async persist_failure_and_mark_run(failure: LLMFailureFact, auto_action: str) -> LLMFailureResult",?:llm_failure_service,LLMFailureResult | _capture_evidence | _clock_fn | _mark_run_failed | _persist_failure | _verify_no_contamination,asyncio | llm_failure_driver | runtime,pure,yes,48,"Persist failure fact to DB, then mark run as FAILED.",Unclassified,low,no classification rules matched
incidents,L5,policy_violation_engine,PolicyViolationService.__init__,"__init__(session: 'AsyncSession', driver: Optional[PolicyViolationDriver])",,get_policy_violation_driver,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,no,14,Initialize with async session and optional driver.,Internal Helper,high,dunder method
incidents,L5,policy_violation_engine,PolicyViolationService.check_incident_exists,"async check_incident_exists(run_id: str, policy_id: str, tenant_id: str) -> Optional[str]",,fetch_incident_by_violation,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,7,"Idempotency check: Only one incident per (run_id, policy_id).",Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
incidents,L5,policy_violation_engine,PolicyViolationService.check_policy_enabled,"async check_policy_enabled(tenant_id: str, policy_id: str) -> bool",,fetch_policy_enabled,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,7,AC-2 prerequisite: Policy must be explicitly enabled for tenant.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
incidents,L5,policy_violation_engine,PolicyViolationService.check_violation_persisted,async check_violation_persisted(violation_id: str) -> bool,,fetch_violation_exists,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,3,Check if a violation fact has been persisted.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
incidents,L5,policy_violation_engine,PolicyViolationService.create_incident_from_violation,"async create_incident_from_violation(violation: ViolationFact, auto_action: Optional[str]) -> str",,Decimal | RuntimeError | Session | check_violation_persisted | create_incident_aggregator | get_or_create_incident | info | items | list | str,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,68,Create an incident from a persisted violation.,Internal Helper,medium,name matches 'from_'
incidents,L5,policy_violation_engine,PolicyViolationService.persist_evidence,"async persist_evidence(violation_id: str, incident_id: str, evidence: Dict[str, Any]) -> str",,generate_uuid | info | insert_evidence_event,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,27,AC-3: Persist evidence linked to violation.,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,PolicyViolationService.persist_violation_and_create_incident,"async persist_violation_and_create_incident(violation: ViolationFact, auto_action: Optional[str]) -> ViolationIncident",,RuntimeError | ViolationIncident | check_incident_exists | create_incident_from_violation | info | persist_evidence | persist_violation_fact,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,56,Full S3 flow: Violation  Persistence  Incident  Evidence.,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,PolicyViolationService.persist_violation_fact,async persist_violation_fact(violation: ViolationFact) -> str,,ValueError | info | insert_violation_record,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,37,Persist a violation fact to the database.,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,PolicyViolationService.verify_violation_truth,"async verify_violation_truth(run_id: str, tenant_id: str, policy_id: str) -> Dict[str, Any]",,all | fetch_violation_truth_check | values,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,60,Verify that a violation satisfies S3 truth requirements.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'verify'); Internal Helper(pure function with no callers)
incidents,L5,policy_violation_engine,create_policy_evaluation_record,"async create_policy_evaluation_record(session: 'AsyncSession', run_id: str, tenant_id: str, outcome: str, policies_checked: int, reason: str, draft_candidate: bool, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> str",,generate_uuid | get_policy_violation_driver | info | insert_policy_evaluation | now,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,65,Create a policy evaluation record for ANY run (PIN-407).,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,create_policy_evaluation_sync,"create_policy_evaluation_sync(run_id: str, tenant_id: str, run_status: str, policies_checked: int, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",,debug | error | generate_uuid | getenv | info | insert_policy_evaluation_sync | lower | now,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,no,80,Create a policy evaluation record for ANY run (PIN-407) - SYNC VERSION.,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,handle_policy_evaluation_for_run,"async handle_policy_evaluation_for_run(session: 'AsyncSession', run_id: str, tenant_id: str, run_status: str, policies_checked: int, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> str",,create_policy_evaluation_record | lower,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,54,Create a policy evaluation record for ANY run (PIN-407).,Internal Helper,low,pure function with no callers
incidents,L5,policy_violation_engine,handle_policy_violation,"async handle_policy_violation(session: 'AsyncSession', run_id: str, tenant_id: str, policy_type: str, policy_id: str, violated_rule: str, reason: str, severity: str, evidence: Optional[Dict[str, Any]]) -> Optional[ViolationIncident]",,PolicyViolationService | ViolationFact | persist_violation_and_create_incident,asyncio | db | incident_aggregator | policy_violation_driver | runtime | sqlmodel,pure,yes,35,Handle a policy violation with S3 truth guarantees.,Internal Helper,low,pure function with no callers
incidents,L5,postmortem_engine,PostMortemService.__init__,"__init__(session: 'AsyncSession', driver: Optional[PostMortemDriver])",L5:incidents_facade,get_postmortem_driver,asyncio | postmortem_driver,pure,no,14,Initialize with session and optional driver.,Internal Helper,high,dunder method
incidents,L5,postmortem_engine,PostMortemService._extract_insights,"async _extract_insights(tenant_id: str, resolution: ResolutionSummary, similar: list[ResolutionSummary]) -> list[LearningInsight]",L5:incidents_facade,LearningInsight | append | int | len | min | round | sum,asyncio | postmortem_driver,pure,yes,72,Extract insights from incident and similar incidents.,Internal Helper,medium,private function
incidents,L5,postmortem_engine,PostMortemService._find_similar_incidents,"async _find_similar_incidents(tenant_id: str, exclude_incident_id: str, category: Optional[str], limit: int) -> list[ResolutionSummary]",L5:incidents_facade,ResolutionSummary | fetch_similar_incidents | int,asyncio | postmortem_driver,pure,yes,32,Find similar resolved incidents.,Internal Helper,medium,private function
incidents,L5,postmortem_engine,PostMortemService._generate_category_insights,"_generate_category_insights(category: str, total_incidents: int, resolved_count: int, avg_resolution_time_ms: Optional[float], common_methods: list[tuple[str, int]], recurrence_rate: float) -> list[LearningInsight]",L5:incidents_facade,LearningInsight | append | min | round,asyncio | postmortem_driver,pure,no,55,Generate insights based on category statistics.,Internal Helper,medium,private function
incidents,L5,postmortem_engine,PostMortemService._get_resolution_summary,"async _get_resolution_summary(tenant_id: str, incident_id: str) -> Optional[ResolutionSummary]",L5:incidents_facade,ResolutionSummary | fetch_resolution_summary | int,asyncio | postmortem_driver,pure,yes,24,Get resolution summary for an incident.,Internal Helper,medium,private function
incidents,L5,postmortem_engine,PostMortemService.get_category_learnings,"async get_category_learnings(tenant_id: str, category: str, baseline_days: int) -> Optional[CategoryLearnings]",L5:incidents_facade,CategoryLearnings | _generate_category_insights | fetch_category_stats | fetch_recurrence_data | fetch_resolution_methods | float | max | min | round,asyncio | postmortem_driver,pure,yes,63,Get aggregated learnings for a category.,Unclassified,low,no classification rules matched
incidents,L5,postmortem_engine,PostMortemService.get_incident_learnings,"async get_incident_learnings(tenant_id: str, incident_id: str) -> Optional[PostMortemResult]",L5:incidents_facade,PostMortemResult | _extract_insights | _find_similar_incidents | _get_resolution_summary | now,asyncio | postmortem_driver,pure,yes,42,Get post-mortem learnings for a specific incident.,Unclassified,low,no classification rules matched
incidents,L5,prevention_engine,BaseValidator.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,db_async | policy_violation_service | prometheus_client,pure,no,3,Validate and return list of violations. Empty list = pass.,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,BudgetValidator.__init__,"__init__(max_tokens: int, max_cost_usd: float)",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,db_async | policy_violation_service | prometheus_client,pure,no,3,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,BudgetValidator.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | append,db_async | policy_violation_service | prometheus_client,pure,no,41,,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,ContentAccuracyValidatorV2.__init__,__init__(strict_mode: bool),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,compile,db_async | policy_violation_service | prometheus_client,pure,no,4,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,ContentAccuracyValidatorV2._extract_claim,"_extract_claim(text: str, terms: List[str]) -> str",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,any | escape | search | split | strip,db_async | policy_violation_service | prometheus_client,pure,no,6,,Internal Helper,medium,private function
incidents,L5,prevention_engine,ContentAccuracyValidatorV2._get_value,"_get_value(data: Dict[str, Any], key: str) -> Any",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,get | isinstance | split,db_async | policy_violation_service | prometheus_client,pure,no,10,,Internal Helper,medium,private function
incidents,L5,prevention_engine,ContentAccuracyValidatorV2.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | _extract_claim | _get_value | any | append | escape | items | lower | search,db_async | policy_violation_service | prometheus_client,pure,no,46,,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,HallucinationValidator.__init__,__init__(context_required_fields: Optional[List[str]]),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,compile,db_async | policy_violation_service | prometheus_client,pure,no,3,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,HallucinationValidator._claim_in_context,"_claim_in_context(claim: str, context: Dict[str, Any]) -> bool",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,findall | len | lower | str | sum,db_async | policy_violation_service | prometheus_client,pure,no,8,Check if claim can be found anywhere in context.,Internal Helper,medium,private function
incidents,L5,prevention_engine,HallucinationValidator.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | _claim_in_context | append | group | search,db_async | policy_violation_service | prometheus_client,pure,no,27,,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,PIIValidator.__init__,__init__(allowed_pii: Optional[Set[str]]),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,compile | items | set,db_async | policy_violation_service | prometheus_client,pure,no,5,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,PIIValidator._redact,_redact(value: str) -> str,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,len,db_async | policy_violation_service | prometheus_client,pure,no,4,,Internal Helper,medium,private function
incidents,L5,prevention_engine,PIIValidator.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | _redact | append | findall | items | len | upper,db_async | policy_violation_service | prometheus_client,pure,no,26,,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,PolicyViolation.to_dict,"to_dict() -> Dict[str, Any]",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,db_async | policy_violation_service | prometheus_client,pure,no,12,,Internal Helper,medium,name matches 'to_'
incidents,L5,prevention_engine,PreventionContext.hash_output,hash_output() -> str,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,encode | hexdigest | sha256,db_async | policy_violation_service | prometheus_client,pure,no,3,Generate deterministic hash of output for replay verification.,Unclassified,low,no classification rules matched
incidents,L5,prevention_engine,PreventionEngine.__init__,"__init__(validators: Optional[List[BaseValidator]], strict_mode: bool, block_on_critical: bool, modify_on_high: bool, emit_metrics: bool)",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,BudgetValidator | ContentAccuracyValidatorV2 | HallucinationValidator | PIIValidator | SafetyValidator,db_async | policy_violation_service | prometheus_client,pure,no,21,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,PreventionEngine._emit_metrics,"_emit_metrics(ctx: PreventionContext, result: PreventionResult) -> None",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,Counter | Histogram | inc | labels | observe,db_async | policy_violation_service | prometheus_client,pure,no,41,Emit Prometheus metrics for prevention results.,Internal Helper,medium,private function
incidents,L5,prevention_engine,PreventionEngine._generate_safe_response,"_generate_safe_response(ctx: PreventionContext, violations: List[PolicyViolation]) -> str",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,db_async | policy_violation_service | prometheus_client,pure,no,40,Generate a safe response based on the violation type.,Internal Helper,medium,private function
incidents,L5,prevention_engine,PreventionEngine.evaluate,evaluate(ctx: PreventionContext) -> PreventionResult,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | PreventionResult | _emit_metrics | _generate_safe_response | append | extend | get | int | len | sort | str | time | validate,db_async | policy_violation_service | prometheus_client,pure,no,69,Evaluate all policies and return result.,Policy/Decision,medium,name matches 'evaluate'
incidents,L5,prevention_engine,PreventionResult.highest_severity,highest_severity() -> Optional[Severity],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,any,db_async | policy_violation_service | prometheus_client,pure,no,8,,Unclassified,low,no classification rules matched
incidents,L5,prevention_engine,PreventionResult.primary_violation,primary_violation() -> Optional[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,db_async | policy_violation_service | prometheus_client,pure,no,4,,Unclassified,low,no classification rules matched
incidents,L5,prevention_engine,PreventionResult.to_dict,"to_dict() -> Dict[str, Any]",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,to_dict,db_async | policy_violation_service | prometheus_client,pure,no,11,,Internal Helper,medium,name matches 'to_'
incidents,L5,prevention_engine,SafetyValidator.__init__,__init__(),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,compile | items,db_async | policy_violation_service | prometheus_client,pure,no,4,,Internal Helper,high,dunder method
incidents,L5,prevention_engine,SafetyValidator.validate,validate(ctx: PreventionContext) -> List[PolicyViolation],?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolation | append | group | items | search | upper,db_async | policy_violation_service | prometheus_client,pure,no,25,,Policy/Decision,medium,name matches 'validate'
incidents,L5,prevention_engine,_create_incident_with_service,"async _create_incident_with_service(session: Any, ctx: PreventionContext, primary: PolicyViolation, evidence: dict) -> Optional[str]",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyViolationService | ViolationFact | persist_violation_and_create_incident,db_async | policy_violation_service | prometheus_client,pure,yes,29,Helper to create incident using PolicyViolationService.,Internal Helper,medium,private function
incidents,L5,prevention_engine,create_incident_from_violation,"async create_incident_from_violation(ctx: PreventionContext, result: PreventionResult, session: Optional[Any]) -> Optional[str]",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,AsyncSessionLocal | _create_incident_with_service | getLogger | isoformat | items | list | str | warning,db_async | policy_violation_service | prometheus_client,pure,yes,59,Create an incident from prevention violation.,Internal Helper,medium,name matches 'from_'
incidents,L5,prevention_engine,evaluate_prevention,"evaluate_prevention(tenant_id: str, call_id: str, user_query: str, llm_output: str, context_data: Dict[str, Any], model: str, user_id: Optional[str]) -> PreventionResult",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PreventionContext | evaluate | get_prevention_engine,db_async | policy_violation_service | prometheus_client,pure,no,36,Convenience function to evaluate prevention.,Policy/Decision,medium,name matches 'evaluate'
incidents,L5,prevention_engine,get_prevention_engine,get_prevention_engine() -> PreventionEngine,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PreventionEngine,db_async | policy_violation_service | prometheus_client,pure,no,6,Get global prevention engine instance.,Unclassified,low,no classification rules matched
incidents,L5,recovery_rule_engine,CompositeRule.__init__,"__init__(rule_id: str, name: str, rules: List[Rule], logic: str, **kwargs)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,__init__ | lower | super,,pure,no,11,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,CompositeRule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,RuleResult | all | any | evaluate | join | max | min | sorted | to_dict,,pure,no,28,,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,ErrorCodeRule.__init__,"__init__(rule_id: str, name: str, error_patterns: List[str], action_code: str, score: float, **kwargs)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,__init__ | super | upper,,pure,no,7,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,ErrorCodeRule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,RuleResult | startswith | upper,,pure,no,22,,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,EvaluationResult.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,to_dict,,pure,no,9,,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,HistoricalPatternRule.__init__,"__init__(rule_id: str, name: str, min_occurrences: int, min_success_rate: float, **kwargs)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,__init__ | super,,pure,no,4,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,HistoricalPatternRule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,Counter | RuleResult | get | len | most_common | sum,,pure,no,64,,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,OccurrenceThresholdRule.__init__,"__init__(rule_id: str, name: str, threshold: int, action_code: str, score: float, **kwargs)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,__init__ | super,,pure,no,5,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,OccurrenceThresholdRule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,RuleResult,,pure,no,23,,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,RecoveryRuleEngine.__init__,__init__(rules: Optional[List[Rule]]),?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,copy | sort,,pure,no,10,Initialize rule engine.,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,RecoveryRuleEngine.add_rule,add_rule(rule: Rule) -> None,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,append | sort,,pure,no,4,Add a rule to the engine.,Operation,medium,called by L2 (gap  should route via L4)
incidents,L5,recovery_rule_engine,RecoveryRuleEngine.evaluate,evaluate(context: RuleContext) -> EvaluationResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,EvaluationResult | RuleResult | append | debug | evaluate | int | join | len | max | min | perf_counter | round | sort | str | sum,,pure,no,79,Evaluate all rules against the context.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,RecoveryRuleEngine.remove_rule,remove_rule(rule_id: str) -> bool,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,len,,pure,no,5,Remove a rule by ID.,Operation,medium,called by L2 (gap  should route via L4)
incidents,L5,recovery_rule_engine,Rule.__init__,"__init__(rule_id: str, name: str, priority: int, weight: float)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,11,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,Rule.__repr__,__repr__() -> str,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,2,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,Rule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,3,Evaluate rule against context. Override in subclasses.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,RuleContext.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,isoformat | len,,pure,no,11,,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,RuleResult.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,11,,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,SkillSpecificRule.__init__,"__init__(rule_id: str, name: str, skill_ids: List[str], action_code: str, score: float, **kwargs)",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,__init__ | super,,pure,no,5,,Internal Helper,high,dunder method
incidents,L5,recovery_rule_engine,SkillSpecificRule.evaluate,evaluate(context: RuleContext) -> RuleResult,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,RuleResult,,pure,no,19,,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,classify_error_category,classify_error_category(error_codes: List[str]) -> str,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,any | items | join | lower,,pure,no,19,Classify error codes into a category.,Operation,medium,called by L2 (gap  should route via L4)
incidents,L5,recovery_rule_engine,combine_confidences,"combine_confidences(rule_confidence: float, match_confidence: float) -> float",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,16,Combine rule and matcher confidence scores.,Operation,ambiguous,multi-match: Coordinator/Aggregator(name matches 'combine'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,evaluate_rules,"evaluate_rules(error_code: str, error_message: str, skill_id: Optional[str], tenant_id: Optional[str], occurrence_count: int, historical_matches: Optional[List[Dict[str, Any]]], custom_rules: Optional[List[Rule]]) -> EvaluationResult",?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,RecoveryRuleEngine | RuleContext | add_rule | evaluate,,pure,no,40,Convenience function to evaluate rules against a failure.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,should_auto_execute,should_auto_execute(confidence: float) -> bool,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,13,Determine if a recovery action should be auto-executed based on confidence.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'should_'); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,should_select_action,should_select_action(combined_confidence: float) -> bool,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,,,pure,no,15,Determine if an action should be selected based on combined confidence.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'should_'); Operation(called by L2 (gap  should route via L4))
incidents,L5,recovery_rule_engine,suggest_recovery_mode,suggest_recovery_mode(error_codes: List[str]) -> str,?:recovery | ?:failure_intelligence | ?:failure_classification_engine | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | ?:test_m10_recovery_enhanced,any | items | join | lower,,pure,no,19,Suggest a recovery mode based on error codes.,Operation,medium,called by L2 (gap  should route via L4)
incidents,L5,recurrence_analysis_engine,RecurrenceAnalysisService.__init__,__init__(session: 'AsyncSession'),L5:incidents_facade,RecurrenceAnalysisDriver,asyncio | recurrence_analysis_driver | time,pure,no,2,,Internal Helper,high,dunder method
incidents,L5,recurrence_analysis_engine,RecurrenceAnalysisService._snapshot_to_group,_snapshot_to_group(snapshot: RecurrenceGroupSnapshot) -> RecurrenceGroup,L5:incidents_facade,RecurrenceGroup,asyncio | recurrence_analysis_driver | time,pure,no,12,Convert driver snapshot to domain type. No business logic.,Internal Helper,medium,private function
incidents,L5,recurrence_analysis_engine,RecurrenceAnalysisService.analyze_recurrence,"async analyze_recurrence(tenant_id: str, baseline_days: int, recurrence_threshold: int, limit: int) -> RecurrenceResult",L5:incidents_facade,RecurrenceResult | _snapshot_to_group | append | fetch_recurrence_groups | max | min | utc_now,asyncio | recurrence_analysis_driver | time,pure,yes,47,Analyze incident recurrence patterns.,Unclassified,low,no classification rules matched
incidents,L5,recurrence_analysis_engine,RecurrenceAnalysisService.get_recurrence_for_category,"async get_recurrence_for_category(tenant_id: str, category: str, baseline_days: int) -> RecurrenceGroup | None",L5:incidents_facade,_snapshot_to_group | fetch_recurrence_for_category,asyncio | recurrence_analysis_driver | time,pure,yes,28,Get recurrence details for a specific category.,Unclassified,low,no classification rules matched
incidents,L5,semantic_failures,format_violation_message,"format_violation_message(code: FailureCode, context_msg: str) -> str",?:semantic_validator | ?:__init__,get_failure_info,semantic_types,pure,no,4,Format a violation message with context.,Internal Helper,medium,name matches 'format'
incidents,L5,semantic_failures,get_failure_info,"get_failure_info(code: FailureCode) -> Dict[str, Any]",?:semantic_validator | ?:__init__,get | hasattr | str,semantic_types,pure,no,11,Get failure taxonomy info for a code (INT-* or SEM-*).,Unclassified,low,no classification rules matched
incidents,L5,semantic_failures,get_fix_action,get_fix_action(code: FailureCode) -> str,?:semantic_validator | ?:__init__,get | get_failure_info,semantic_types,pure,no,3,Get the fix action for a failure code.,Unclassified,low,no classification rules matched
incidents,L5,semantic_failures,get_fix_owner,get_fix_owner(code: FailureCode) -> str,?:semantic_validator | ?:__init__,get | get_failure_info,semantic_types,pure,no,3,Get the fix owner for a failure code.,Unclassified,low,no classification rules matched
incidents,L5,semantic_failures,get_violation_class,get_violation_class(code: FailureCode) -> ViolationClass,?:semantic_validator | ?:__init__,get | get_failure_info,semantic_types,pure,no,3,Get the violation class for a failure code.,Unclassified,low,no classification rules matched
incidents,L6,export_bundle_driver,ExportBundleService.__init__,__init__(trace_store: Optional[TraceStore]),L2:incidents,,db | export_bundles | sqlmodel | store,pure,no,8,Initialize export bundle service.,Internal Helper,high,dunder method
incidents,L6,export_bundle_driver,ExportBundleService._assess_business_impact,"_assess_business_impact(incident: Incident, run: Optional[Run]) -> str",L2:incidents,,db | export_bundles | sqlmodel | store,pure,no,10,Assess business impact for executive summary.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService._assess_risk_level,_assess_risk_level(incident: Incident) -> str,L2:incidents,getattr,db | export_bundles | sqlmodel | store,pure,no,8,Assess risk level for executive summary.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService._compute_bundle_hash,_compute_bundle_hash(bundle: EvidenceBundle) -> str,L2:incidents,dumps | encode | hexdigest | isoformat | model_dump | sha256,db | export_bundles | sqlmodel | store,pure,no,14,Compute SHA256 hash of bundle for integrity verification.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService._generate_attestation,_generate_attestation(bundle: EvidenceBundle) -> str,L2:incidents,,db | export_bundles | sqlmodel | store,pure,no,10,Generate SOC2 attestation statement.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService._generate_incident_summary,"_generate_incident_summary(incident: Incident, run: Optional[Run]) -> str",L2:incidents,getattr,db | export_bundles | sqlmodel | store,pure,no,12,Generate non-technical incident summary.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService._generate_recommendations,"_generate_recommendations(incident: Incident, run: Optional[Run]) -> list[str]",L2:incidents,,db | export_bundles | sqlmodel | store,pure,no,10,Generate recommended actions.,Internal Helper,medium,private function
incidents,L6,export_bundle_driver,ExportBundleService.create_evidence_bundle,"async create_evidence_bundle(incident_id: str, exported_by: str, export_reason: Optional[str], include_raw_steps: bool) -> EvidenceBundle",L2:incidents,EvidenceBundle | PolicyContext | Session | TraceStepEvidence | ValueError | _compute_bundle_hash | append | enumerate | exec | first | get | get_trace_steps | get_trace_summary | getattr | info,db | export_bundles | sqlmodel | store,pure,yes,115,Create evidence bundle from incident.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
incidents,L6,export_bundle_driver,ExportBundleService.create_executive_debrief,"async create_executive_debrief(incident_id: str, prepared_for: Optional[str], prepared_by: str) -> ExecutiveDebriefBundle",L2:incidents,ExecutiveDebriefBundle | Session | ValueError | _assess_business_impact | _assess_risk_level | _generate_incident_summary | _generate_recommendations | exec | first | get | getattr | hasattr | info | int | select,db | export_bundles | sqlmodel | store,pure,yes,75,Create executive summary (non-technical).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
incidents,L6,export_bundle_driver,ExportBundleService.create_soc2_bundle,"async create_soc2_bundle(incident_id: str, exported_by: str, compliance_period_start: Optional[datetime], compliance_period_end: Optional[datetime], auditor_notes: Optional[str]) -> SOC2Bundle",L2:incidents,SOC2Bundle | _generate_attestation | create_evidence_bundle | info | len | list | now | replace,db | export_bundles | sqlmodel | store,pure,yes,70,Create SOC2-compliant bundle.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
incidents,L6,export_bundle_driver,ExportBundleService.trace_store,trace_store() -> TraceStore,L2:incidents,TraceStore,db | export_bundles | sqlmodel | store,pure,no,5,Get or create TraceStore instance.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
incidents,L6,export_bundle_driver,get_export_bundle_service,get_export_bundle_service() -> ExportBundleService,L2:incidents,ExportBundleService,db | export_bundles | sqlmodel | store,pure,no,6,Get or create ExportBundleService singleton.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
incidents,L6,incident_aggregator,IncidentAggregator.__init__,"__init__(clock: ClockFn, uuid_fn: UuidFn, config: Optional[IncidentAggregatorConfig], severity_engine: Optional[IncidentSeverityEngine])",L5:policy_violation_engine,IncidentAggregatorConfig | IncidentSeverityEngine,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,27,Construct an IncidentAggregator with explicit dependencies.,Internal Helper,high,dunder method
incidents,L6,incident_aggregator,IncidentAggregator._add_call_to_incident,"_add_call_to_incident(session: Session, incident: Incident, call_id: Optional[str], cost_delta_cents: Decimal, metadata: Optional[Dict[str, Any]]) -> None",L5:policy_violation_engine,_add_incident_event | add | add_related_call | clock | get_related_call_ids | len | should_escalate | warning,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,db_write,no,47,Add a call to an existing incident and potentially escalate.,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator._add_incident_event,"_add_incident_event(session: Session, incident: Incident, event_type: str, description: str, data: Optional[Dict[str, Any]]) -> IncidentEvent",L5:policy_violation_engine,IncidentEvent | add | set_data | uuid_fn,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,db_write,no,22,Add an event to an incident's timeline.,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator._can_create_incident,"_can_create_incident(session: Session, tenant_id: str, now: datetime) -> bool",L5:policy_violation_engine,and_ | count | exec | isinstance | one | select | timedelta | where,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,15,Check if we can create a new incident (rate limiting).,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator._create_incident,"_create_incident(session: Session, key: IncidentKey, trigger_value: str, call_id: Optional[str], cost_delta_cents: Decimal, auto_action: Optional[str], metadata: Optional[Dict[str, Any]]) -> Incident",L5:policy_violation_engine,Incident | _add_incident_event | add | add_related_call | clock | flush | generate_incident_title | get_initial_severity | info | refresh | uuid_fn,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,db_write,no,54,Create a new incident.,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator._find_open_incident,"_find_open_incident(session: Session, key: IncidentKey, now: datetime) -> Optional[Incident]",L5:policy_violation_engine,and_ | cast | desc | exec | first | limit | order_by | select | timedelta | where,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,21,Find an open incident matching the key within the current window.,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator._get_rate_limit_incident,"_get_rate_limit_incident(session: Session, tenant_id: str, now: datetime) -> Incident",L5:policy_violation_engine,Incident | add | and_ | cast | desc | exec | first | flush | limit | order_by | refresh | select | timedelta | uuid_fn | where,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,db_write,no,47,Get or create a rate-limit overflow incident.,Internal Helper,medium,private function
incidents,L6,incident_aggregator,IncidentAggregator.get_incident_stats,"get_incident_stats(session: Session, tenant_id: str, since: Optional[datetime]) -> Dict[str, Any]",L5:policy_violation_engine,and_ | clock | count | exec | isoformat | one | select | sum | timedelta | where,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,60,Get incident statistics for a tenant.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_aggregator,IncidentAggregator.get_or_create_incident,"get_or_create_incident(session: Session, tenant_id: str, trigger_type: str, trigger_value: str, call_id: Optional[str], cost_delta_cents: Decimal, auto_action: Optional[str], metadata: Optional[Dict[str, Any]]) -> Tuple[Incident, bool]",L5:policy_violation_engine,Decimal | _add_call_to_incident | _can_create_incident | _create_incident | _find_open_incident | _get_rate_limit_incident | clock | from_event | warning,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,59,Get existing incident or create new one if needed.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_aggregator,IncidentAggregator.resolve_stale_incidents,"resolve_stale_incidents(session: Session, tenant_id: Optional[str]) -> int",L5:policy_violation_engine,_add_incident_event | add | all | and_ | append | clock | exec | info | resolve | select | timedelta | where,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,db_write,no,42,Auto-resolve incidents that have been open without activity.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
incidents,L6,incident_aggregator,IncidentKey.__eq__,__eq__(other),L5:policy_violation_engine,isinstance,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,8,,Internal Helper,high,dunder method
incidents,L6,incident_aggregator,IncidentKey.__hash__,__hash__(),L5:policy_violation_engine,hash | isoformat,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,2,,Internal Helper,high,dunder method
incidents,L6,incident_aggregator,IncidentKey.from_event,"from_event(tenant_id: str, trigger_type: str, event_time: datetime, window_seconds: int) -> 'IncidentKey'",L5:policy_violation_engine,cls | fromtimestamp | int | timestamp,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,10,"Create an incident key from an event, bucketed to window.",Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'from_')
incidents,L6,incident_aggregator,create_incident_aggregator,create_incident_aggregator(config: Optional[IncidentAggregatorConfig]) -> IncidentAggregator,L5:policy_violation_engine,IncidentAggregator,incident_severity_engine | killswitch | runtime | sqlalchemy | sqlmodel,pure,no,19,Create an IncidentAggregator with canonical dependencies.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_pattern_driver,IncidentPatternDriver.__init__,__init__(session: AsyncSession),L5:incident_pattern_engine,,asyncio | sqlalchemy,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
incidents,L6,incident_pattern_driver,IncidentPatternDriver.fetch_cascade_failures,"async fetch_cascade_failures(tenant_id: str, window_start: datetime, threshold: int, limit: int) -> List[Dict[str, Any]]",L5:incident_pattern_engine,dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,42,Fetch incidents grouped by source run for cascade detection.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_pattern_driver,IncidentPatternDriver.fetch_category_clusters,"async fetch_category_clusters(tenant_id: str, window_start: datetime, threshold: int, limit: int) -> List[Dict[str, Any]]",L5:incident_pattern_engine,dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,42,Fetch incidents grouped by category for cluster detection.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_pattern_driver,IncidentPatternDriver.fetch_incidents_count,"async fetch_incidents_count(tenant_id: str, window_start: datetime) -> int",L5:incident_pattern_engine,execute | scalar | text,asyncio | sqlalchemy,db_write,yes,28,Count incidents within time window.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_pattern_driver,IncidentPatternDriver.fetch_severity_spikes,"async fetch_severity_spikes(tenant_id: str, threshold: int, limit: int) -> List[Dict[str, Any]]",L5:incident_pattern_engine,dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,45,Fetch high/critical incidents in the last hour.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_pattern_driver,get_incident_pattern_driver,get_incident_pattern_driver(session: AsyncSession) -> IncidentPatternDriver,L5:incident_pattern_engine,IncidentPatternDriver,asyncio | sqlalchemy,pure,no,3,Factory function to get IncidentPatternDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,IncidentReadDriver.__init__,__init__(session: Session),L6:__init__ | L5:incident_read_engine,,killswitch | sqlalchemy | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
incidents,L6,incident_read_driver,IncidentReadDriver.count_incidents_since,"count_incidents_since(tenant_id: str, since: datetime) -> int",L6:__init__ | L5:incident_read_engine,and_ | count | exec | first | select | where,killswitch | sqlalchemy | sqlmodel,pure,no,23,Count incidents since a given time.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,IncidentReadDriver.get_incident,"get_incident(incident_id: str, tenant_id: str) -> Optional[Incident]",L6:__init__ | L5:incident_read_engine,and_ | exec | first | select | where,killswitch | sqlalchemy | sqlmodel,pure,no,23,Get a single incident by ID with tenant isolation.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,IncidentReadDriver.get_incident_events,get_incident_events(incident_id: str) -> List[IncidentEvent],L6:__init__ | L5:incident_read_engine,all | exec | hasattr | order_by | select | where,killswitch | sqlalchemy | sqlmodel,pure,no,16,Get timeline events for an incident.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,IncidentReadDriver.get_last_incident,get_last_incident(tenant_id: str) -> Optional[Incident],L6:__init__ | L5:incident_read_engine,desc | exec | first | limit | order_by | select | where,killswitch | sqlalchemy | sqlmodel,pure,no,16,Get the most recent incident for a tenant.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,IncidentReadDriver.list_incidents,"list_incidents(tenant_id: str, status: Optional[str], severity: Optional[str], from_date: Optional[datetime], to_date: Optional[datetime], limit: int, offset: int) -> Tuple[List[Incident], int]",L6:__init__ | L5:incident_read_engine,all | and_ | append | count | desc | exec | first | hasattr | limit | min | offset | order_by | select | where,killswitch | sqlalchemy | sqlmodel,pure,no,51,List incidents for a tenant with optional filters.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_read_driver,get_incident_read_driver,get_incident_read_driver(session: Session) -> IncidentReadDriver,L6:__init__ | L5:incident_read_engine,IncidentReadDriver,killswitch | sqlalchemy | sqlmodel,pure,no,3,Factory function to get IncidentReadDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.__init__,__init__(session: Session),?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,,killswitch | sqlalchemy | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
incidents,L6,incident_write_driver,IncidentWriteDriver.create_incident_event,"create_incident_event(incident_id: str, event_type: str, description: str) -> IncidentEvent",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,IncidentEvent | add,killswitch | sqlalchemy | sqlmodel,db_write,no,24,Create a new incident timeline event.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.fetch_incidents_by_run_id,"fetch_incidents_by_run_id(run_id: str) -> List[Dict[str, Any]]",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,append | execute | isoformat | text,killswitch | sqlalchemy | sqlmodel,db_write,no,31,Get all incidents linked to a run.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.fetch_suppressing_policy,"fetch_suppressing_policy(tenant_id: str, error_code: str, category: str) -> Optional[Dict[str, Any]]",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,execute | fetchone | text,killswitch | sqlalchemy | sqlmodel,db_write,no,47,Check if an active policy_rule suppresses this incident pattern.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.insert_incident,"insert_incident(incident_id: str, tenant_id: str, title: str, severity: str, status: str, trigger_type: str, category: str, description: str, source_run_id: str, source_type: str, now: datetime, error_code: Optional[str], error_message: Optional[str], agent_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> bool",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,execute | fetchone | text,killswitch | sqlalchemy | sqlmodel,db_write,no,88,Insert a new incident record.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.insert_policy_proposal,"insert_policy_proposal(proposal_id: str, tenant_id: str, proposal_name: str, proposal_type: str, rationale: str, proposed_rule: Dict[str, Any], triggering_feedback_ids: List[str], now: datetime, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> bool",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,dumps | execute | text,killswitch | sqlalchemy | sqlmodel,db_write,no,58,Insert a policy proposal for high-severity incidents.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.insert_prevention_record,"insert_prevention_record(prevention_id: str, policy_id: str, pattern_id: str, original_incident_id: str, blocked_incident_id: str, tenant_id: str, now: datetime, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> bool",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,execute | text,killswitch | sqlalchemy | sqlmodel,db_write,no,58,Insert a prevention record when policy suppresses an incident.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.refresh_incident,refresh_incident(incident: Incident) -> Incident,?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,refresh,killswitch | sqlalchemy | sqlmodel,pure,no,12,Refresh incident from database after commit.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.update_incident_acknowledged,"update_incident_acknowledged(incident: Incident, acknowledged_at: datetime, acknowledged_by: str) -> None",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,add,killswitch | sqlalchemy | sqlmodel,db_write,no,18,Update incident to acknowledged status.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.update_incident_resolved,"update_incident_resolved(incident: Incident, resolved_at: datetime, resolved_by: str, resolution_method: str | None) -> None",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,add,killswitch | sqlalchemy | sqlmodel,db_write,no,22,Update incident to resolved status.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
incidents,L6,incident_write_driver,IncidentWriteDriver.update_run_incident_count,update_run_incident_count(run_id: str) -> bool,?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,execute | fetchone | text,killswitch | sqlalchemy | sqlmodel,db_write,no,21,Increment incident_count on the runs table.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,IncidentWriteDriver.update_trace_incident_id,"update_trace_incident_id(run_id: str, incident_id: str) -> int",?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,execute | text,killswitch | sqlalchemy | sqlmodel,db_write,no,20,Propagate incident_id to aos_traces for cross-domain correlation.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incident_write_driver,get_incident_write_driver,get_incident_write_driver(session: Session) -> IncidentWriteDriver,?:incident_write_engine | L6:__init__ | L5:incident_write_engine | L5:incident_engine | L5:anomaly_bridge,IncidentWriteDriver,killswitch | sqlalchemy | sqlmodel,pure,no,3,Factory function to get IncidentWriteDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.__init__,__init__(session: AsyncSession),L5:incidents_facade,,asyncio | killswitch | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver._to_snapshot,_to_snapshot(inc: Incident) -> IncidentSnapshot,L5:incidents_facade,IncidentSnapshot,asyncio | killswitch | sqlalchemy,pure,no,22,Convert ORM model to snapshot. No business logic.,Internal Helper,medium,private function
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_active_incidents,async fetch_active_incidents(tenant_id: str) -> IncidentListSnapshot,L5:incidents_facade,IncidentListSnapshot | _to_snapshot | all | asc | count | desc | execute | getattr | in_ | limit | offset | order_by | scalar | scalars | select,asyncio | killswitch | sqlalchemy,db_write,yes,73,Fetch active incidents (ACTIVE + ACKED states).,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_cost_impact_data,"async fetch_cost_impact_data(tenant_id: str, baseline_days: int, limit: int) -> list[CostImpactRowSnapshot]",L5:incidents_facade,CostImpactRowSnapshot | append | execute | float | mappings | text,asyncio | killswitch | sqlalchemy,db_write,yes,40,Fetch cost impact aggregates using raw SQL.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_historical_incidents,"async fetch_historical_incidents(tenant_id: str, cutoff_date: datetime) -> IncidentListSnapshot",L5:incidents_facade,IncidentListSnapshot | _to_snapshot | all | asc | count | desc | execute | getattr | limit | offset | order_by | scalar | scalars | select | where,asyncio | killswitch | sqlalchemy,db_write,yes,58,Fetch historical incidents (resolved before cutoff date).,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_incident_by_id,"async fetch_incident_by_id(tenant_id: str, incident_id: str) -> Optional[IncidentSnapshot]",L5:incidents_facade,_to_snapshot | execute | scalar_one_or_none | select | where,asyncio | killswitch | sqlalchemy,db_write,yes,19,Fetch single incident by ID with tenant isolation.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_incidents_by_run,"async fetch_incidents_by_run(tenant_id: str, run_id: str) -> list[IncidentSnapshot]",L5:incidents_facade,_to_snapshot | all | desc | execute | order_by | scalars | select | where,asyncio | killswitch | sqlalchemy,db_write,yes,17,Fetch all incidents linked to a specific run.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_metrics_aggregates,"async fetch_metrics_aggregates(tenant_id: str, window_days: int) -> Optional[MetricsSnapshot]",L5:incidents_facade,MetricsSnapshot | execute | first | mappings | text,asyncio | killswitch | sqlalchemy,db_write,yes,65,Fetch aggregated metrics using raw SQL.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'aggregate')
incidents,L6,incidents_facade_driver,IncidentsFacadeDriver.fetch_resolved_incidents,async fetch_resolved_incidents(tenant_id: str) -> IncidentListSnapshot,L5:incidents_facade,IncidentListSnapshot | _to_snapshot | all | asc | count | desc | execute | getattr | limit | offset | order_by | scalar | scalars | select | where,asyncio | killswitch | sqlalchemy,db_write,yes,71,Fetch resolved incidents.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
incidents,L6,lessons_driver,LessonsDriver.__init__,__init__(session: Session),L5:lessons_engine,,sqlalchemy | sqlmodel,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
incidents,L6,lessons_driver,LessonsDriver.fetch_debounce_count,"fetch_debounce_count(tenant_id: str, lesson_type: str, metric_type: str, hours: int, threshold_band: Optional[str]) -> int",L5:lessons_engine,execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,45,Count recent lessons for debounce check.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.fetch_expired_deferred,"fetch_expired_deferred(deferred_status: str, limit: int) -> List[tuple]",L5:lessons_engine,execute | fetchall | list | text,sqlalchemy | sqlmodel,db_write,no,28,Get deferred lessons whose deferred_until has passed.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.fetch_lesson_by_id,"fetch_lesson_by_id(lesson_id: str, tenant_id: str) -> Optional[Dict[str, Any]]",L5:lessons_engine,execute | fetchone | isoformat | str | text,sqlalchemy | sqlmodel,db_write,no,55,Get a specific lesson by ID.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.fetch_lesson_stats,fetch_lesson_stats(tenant_id: str) -> List[tuple],L5:lessons_engine,execute | fetchall | list | text,sqlalchemy | sqlmodel,db_write,no,20,Get lesson counts grouped by type and status.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.fetch_lessons_list,"fetch_lessons_list(tenant_id: str, lesson_type: Optional[str], status: Optional[str], severity: Optional[str], include_synthetic: bool, limit: int, offset: int) -> List[Dict[str, Any]]",L5:lessons_engine,append | execute | fetchall | isoformat | join | str | text,sqlalchemy | sqlmodel,db_write,no,74,List lessons with optional filters.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.insert_lesson,"insert_lesson(lesson_id: str, tenant_id: str, lesson_type: str, severity: Optional[str], source_event_id: str, source_event_type: str, source_run_id: Optional[str], title: str, description: str, proposed_action: Optional[str], detected_pattern: Optional[Dict[str, Any]], now: datetime, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> bool",L5:lessons_engine,dumps | execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,76,Insert a new lesson record.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.insert_policy_proposal_from_lesson,"insert_policy_proposal_from_lesson(proposal_id: str, tenant_id: str, title: str, description: str, proposed_action: Optional[str], source_lesson_id: str, created_at: datetime, created_by: str) -> bool",L5:lessons_engine,execute | text,sqlalchemy | sqlmodel,db_write,no,51,Insert a draft policy proposal from a lesson.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'from_')
incidents,L6,lessons_driver,LessonsDriver.update_lesson_converted,"update_lesson_converted(lesson_id: str, tenant_id: str, converted_status: str, proposal_id: str, converted_at: datetime) -> bool",L5:lessons_engine,execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,42,Update lesson to converted_to_draft status.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'convert')
incidents,L6,lessons_driver,LessonsDriver.update_lesson_deferred,"update_lesson_deferred(lesson_id: str, tenant_id: str, deferred_status: str, defer_until: datetime) -> bool",L5:lessons_engine,execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,37,Update lesson to deferred status.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.update_lesson_dismissed,"update_lesson_dismissed(lesson_id: str, tenant_id: str, dismissed_status: str, dismissed_at: datetime, dismissed_by: str, reason: str) -> bool",L5:lessons_engine,execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,46,Update lesson to dismissed status.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,LessonsDriver.update_lesson_reactivated,"update_lesson_reactivated(lesson_id: str, tenant_id: str, pending_status: str, from_status: str) -> bool",L5:lessons_engine,execute | fetchone | text,sqlalchemy | sqlmodel,db_write,no,38,Reactivate a deferred lesson to pending.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,lessons_driver,get_lessons_driver,get_lessons_driver(session: Session) -> LessonsDriver,L5:lessons_engine,LessonsDriver,sqlalchemy | sqlmodel,pure,no,3,Factory function to get LessonsDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,llm_failure_driver,LLMFailureDriver.__init__,__init__(session: AsyncSession),?:llm_failure_engine | L5:llm_failure_engine,,asyncio | sqlalchemy,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
incidents,L6,llm_failure_driver,LLMFailureDriver.fetch_contamination_check,"async fetch_contamination_check(run_id: str) -> Dict[str, int]",?:llm_failure_engine | L5:llm_failure_engine,execute | scalar | text,asyncio | sqlalchemy,db_write,yes,55,Check for downstream contamination (verification mode).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
incidents,L6,llm_failure_driver,LLMFailureDriver.fetch_failure_by_run_id,"async fetch_failure_by_run_id(run_id: str, tenant_id: str) -> Optional[Tuple]",?:llm_failure_engine | L5:llm_failure_engine,execute | fetchone | text,asyncio | sqlalchemy,db_write,yes,30,Fetch failure record by run ID.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,llm_failure_driver,LLMFailureDriver.insert_evidence,"async insert_evidence(evidence_id: str, failure_id: str, evidence_type: str, evidence_data: Dict[str, Any], is_immutable: bool, created_at: datetime) -> None",?:llm_failure_engine | L5:llm_failure_engine,dumps | execute | text,asyncio | sqlalchemy,db_write,yes,42,Insert evidence record into failure_evidence table.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,llm_failure_driver,LLMFailureDriver.insert_failure,"async insert_failure(failure_id: str, run_id: str, tenant_id: str, failure_type: str, error_code: str, error_message: str, model: str, request_id: Optional[str], duration_ms: Optional[int], metadata: Dict[str, Any], created_at: datetime) -> None",?:llm_failure_engine | L5:llm_failure_engine,dumps | execute | text,asyncio | sqlalchemy,db_write,yes,59,Insert failure fact into run_failures table.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,llm_failure_driver,LLMFailureDriver.update_run_failed,"async update_run_failed(run_id: str, tenant_id: str, error: str, completed_at: datetime) -> bool",?:llm_failure_engine | L5:llm_failure_engine,execute | fetchone | text,asyncio | sqlalchemy,db_write,yes,41,Mark run as failed in worker_runs table.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,llm_failure_driver,get_llm_failure_driver,get_llm_failure_driver(session: AsyncSession) -> LLMFailureDriver,?:llm_failure_engine | L5:llm_failure_engine,LLMFailureDriver,asyncio | sqlalchemy,pure,no,3,Factory function to get LLMFailureDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.__init__,__init__(session: AsyncSession),L5:policy_violation_engine,,asyncio | psycopg2 | sqlalchemy,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
incidents,L6,policy_violation_driver,PolicyViolationDriver.fetch_incident_by_violation,"async fetch_incident_by_violation(run_id: str, policy_id: str, tenant_id: str) -> Optional[str]",L5:policy_violation_engine,execute | scalar_one_or_none | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,33,Check for existing incident by violation pattern.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.fetch_policy_enabled,"async fetch_policy_enabled(tenant_id: str, policy_id: str) -> bool",L5:policy_violation_engine,execute | scalar_one_or_none | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,25,Check if policy is active for tenant.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.fetch_violation_exists,async fetch_violation_exists(violation_id: str) -> bool,L5:policy_violation_engine,execute | scalar_one_or_none | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,15,Check if a violation fact has been persisted.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.fetch_violation_truth_check,"async fetch_violation_truth_check(run_id: str, tenant_id: str, policy_id: str) -> Dict[str, Any]",L5:policy_violation_engine,execute | fetchone | scalar | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,90,Fetch all data needed for violation truth verification.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
incidents,L6,policy_violation_driver,PolicyViolationDriver.insert_evidence_event,"async insert_evidence_event(evidence_id: str, incident_id: str, violation_id: str, evidence: Dict[str, Any]) -> None",L5:policy_violation_engine,dumps | execute | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,39,Insert evidence capture event.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.insert_policy_evaluation,"async insert_policy_evaluation(evaluation_id: str, run_id: str, tenant_id: str, outcome: str, policies_checked: int, confidence: float, created_at: datetime, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> None",L5:policy_violation_engine,execute | replace | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,57,Insert policy evaluation record.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,PolicyViolationDriver.insert_violation_record,"async insert_violation_record(violation_id: str, policy_id: str, rule_id: str, run_id: str, tenant_id: str, created_at: datetime) -> None",L5:policy_violation_engine,execute | replace | text,asyncio | psycopg2 | sqlalchemy,db_write,yes,45,Insert a violation fact record into prevention_records.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,get_policy_violation_driver,get_policy_violation_driver(session: AsyncSession) -> PolicyViolationDriver,L5:policy_violation_engine,PolicyViolationDriver,asyncio | psycopg2 | sqlalchemy,pure,no,3,Factory function to get PolicyViolationDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,policy_violation_driver,insert_policy_evaluation_sync,"insert_policy_evaluation_sync(database_url: str, evaluation_id: str, run_id: str, tenant_id: str, outcome: str, policies_checked: int, confidence: float, created_at: datetime, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[str]",L5:policy_violation_engine,close | commit | connect | cursor | error | execute | fetchone,asyncio | psycopg2 | sqlalchemy,db_write,no,71,Insert policy evaluation record using sync psycopg2 connection.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,PostMortemDriver.__init__,__init__(session: AsyncSession),L5:postmortem_engine,,asyncio | sqlalchemy,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
incidents,L6,postmortem_driver,PostMortemDriver.fetch_category_stats,"async fetch_category_stats(tenant_id: str, category: str, baseline_days: int) -> Optional[Dict[str, Any]]",L5:postmortem_engine,dict | execute | first | mappings | text,asyncio | sqlalchemy,db_write,yes,43,Fetch category statistics.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,PostMortemDriver.fetch_recurrence_data,"async fetch_recurrence_data(tenant_id: str, category: str, baseline_days: int) -> Dict[str, int]",L5:postmortem_engine,execute | first | mappings | text,asyncio | sqlalchemy,db_write,yes,38,Fetch recurrence rate data.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,PostMortemDriver.fetch_resolution_methods,"async fetch_resolution_methods(tenant_id: str, category: str, baseline_days: int, limit: int) -> List[Dict[str, Any]]",L5:postmortem_engine,dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,41,Fetch common resolution methods for a category.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,PostMortemDriver.fetch_resolution_summary,"async fetch_resolution_summary(tenant_id: str, incident_id: str) -> Optional[Dict[str, Any]]",L5:postmortem_engine,dict | execute | first | mappings | text,asyncio | sqlalchemy,db_write,yes,44,Fetch resolution summary for an incident.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,PostMortemDriver.fetch_similar_incidents,"async fetch_similar_incidents(tenant_id: str, exclude_incident_id: str, category: str, limit: int) -> List[Dict[str, Any]]",L5:postmortem_engine,dict | execute | mappings | text,asyncio | sqlalchemy,db_write,yes,51,Fetch similar resolved incidents.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,postmortem_driver,get_postmortem_driver,get_postmortem_driver(session: AsyncSession) -> PostMortemDriver,L5:postmortem_engine,PostMortemDriver,asyncio | sqlalchemy,pure,no,3,Factory function to get PostMortemDriver instance.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,recurrence_analysis_driver,RecurrenceAnalysisDriver.__init__,__init__(session: AsyncSession),?:incidents_facade | ?:__init__ | L5:recurrence_analysis_engine,,asyncio | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
incidents,L6,recurrence_analysis_driver,RecurrenceAnalysisDriver.fetch_recurrence_for_category,"async fetch_recurrence_for_category(tenant_id: str, category: str, baseline_days: int) -> Optional[RecurrenceGroupSnapshot]",?:incidents_facade | ?:__init__ | L5:recurrence_analysis_engine,RecurrenceGroupSnapshot | execute | first | mappings | max | round | text,asyncio | sqlalchemy,db_write,yes,57,Fetch recurrence details for a specific category.,Persistence/Driver,high,L6 layer = persistence
incidents,L6,recurrence_analysis_driver,RecurrenceAnalysisDriver.fetch_recurrence_groups,"async fetch_recurrence_groups(tenant_id: str, baseline_days: int, recurrence_threshold: int, limit: int) -> list[RecurrenceGroupSnapshot]",?:incidents_facade | ?:__init__ | L5:recurrence_analysis_engine,RecurrenceGroupSnapshot | append | execute | float | mappings | text,asyncio | sqlalchemy,db_write,yes,70,Fetch recurrence groups from database.,Persistence/Driver,high,L6 layer = persistence
integrations,L5,audit_schemas,PolicyActivationAudit.to_dict,to_dict() -> dict,L6:bridges_driver | L5s:__init__ | L5:bridges,isoformat,__future__,pure,no,12,,Internal Helper,medium,name matches 'to_'
integrations,L5,bridges,BaseBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,3,Process an event and return the result event.,Unclassified,low,no classification rules matched
integrations,L5,bridges,BaseBridge.register,register(dispatcher: 'IntegrationDispatcher') -> None,?:__init__,info | register_handler,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,4,Register this bridge with the dispatcher.,Unclassified,low,no classification rules matched
integrations,L5,bridges,BaseBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,3,The stage this bridge handles.,Unclassified,low,no classification rules matched
integrations,L5,bridges,IncidentToCatalogBridge.__init__,__init__(db_session_factory),?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,bridges,IncidentToCatalogBridge._calculate_fuzzy_confidence,"_calculate_fuzzy_confidence(query_sig: dict, stored_sig: dict) -> float",?:__init__,get | isinstance | items | loads,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,24,Calculate fuzzy match confidence between signatures.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge._create_pattern,"async _create_pattern(session, signature: dict, signature_hash: str, incident_id: str, tenant_id: str) -> str",?:__init__,dumps | execute | get | info | text | uuid4,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,40,Create new failure pattern.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge._extract_signature,_extract_signature(incident: dict) -> dict,?:__init__,get | keys | sorted,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,18,Extract normalized failure signature from incident.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge._find_matching_pattern,"async _find_matching_pattern(signature: dict, signature_hash: str, incident_id: str, tenant_id: str) -> PatternMatchResult",?:__init__,_calculate_fuzzy_confidence | _create_pattern | _increment_pattern_count | db_factory | error | execute | fetchall | fetchone | from_match | get | isinstance | loads | no_match | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,92,Find matching pattern with confidence scoring.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge._hash_signature,_hash_signature(signature: dict) -> str,?:__init__,dumps | encode | hexdigest | sha256,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,4,Create deterministic hash of signature for exact matching.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge._increment_pattern_count,"async _increment_pattern_count(session, pattern_id: str) -> None",?:__init__,execute | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,15,Increment pattern occurrence count.,Internal Helper,medium,private function
integrations,L5,bridges,IncidentToCatalogBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,_extract_signature | _find_matching_pattern | _hash_signature | exception | get | info | str | to_dict,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,49,Match incident against known patterns.,Unclassified,low,no classification rules matched
integrations,L5,bridges,IncidentToCatalogBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,bridges,LoopStatusBridge.__init__,"__init__(db_session_factory, redis_client)",?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,bridges,LoopStatusBridge._build_loop_status,async _build_loop_status(event: LoopEvent) -> LoopStatus,?:__init__,LoopStatus | append | db_factory | execute | fetchall | get | isinstance | loads | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,41,Build complete loop status from event chain.,Internal Helper,medium,private function
integrations,L5,bridges,LoopStatusBridge._push_sse_update,"async _push_sse_update(tenant_id: str, incident_id: str, data: dict) -> None",?:__init__,dumps | publish,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,18,Push SSE update to connected consoles.,Internal Helper,medium,private function
integrations,L5,bridges,LoopStatusBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,_build_loop_status | _push_sse_update | exception | info | to_console_display | to_dict,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,28,Update console with final loop status.,Unclassified,low,no classification rules matched
integrations,L5,bridges,LoopStatusBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,bridges,PatternToRecoveryBridge.__init__,"__init__(db_session_factory, llm_client)",?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,bridges,PatternToRecoveryBridge._apply_recovery,async _apply_recovery(suggestion: RecoverySuggestion) -> RecoverySuggestion,?:__init__,_persist_recovery | info,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,6,Apply recovery immediately.,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge._generate_recovery,"async _generate_recovery(pattern: dict, incident_id: str, confidence_band: ConfidenceBand) -> RecoverySuggestion",?:__init__,calculate_recovery_confidence | create | get | get_confirmation_level | info | isinstance | loads | should_auto_apply,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,58,Generate recovery suggestion (LLM or heuristics).,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge._instantiate_template,"async _instantiate_template(pattern: dict, incident_id: str, confidence_band: ConfidenceBand) -> RecoverySuggestion",?:__init__,create | get | isinstance | loads,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,20,Instantiate recovery from pattern template.,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge._load_pattern,async _load_pattern(pattern_id: str) -> Optional[dict],?:__init__,db_factory | dict | execute | fetchone | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,13,Load pattern from database.,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge._persist_recovery,async _persist_recovery(suggestion: RecoverySuggestion) -> None,?:__init__,db_factory | dumps | execute | str | text | uuid4,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,39,Persist recovery suggestion to database.,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge._queue_for_review,async _queue_for_review(suggestion: RecoverySuggestion) -> RecoverySuggestion,?:__init__,_persist_recovery | info,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,6,Queue recovery for human review.,Internal Helper,medium,private function
integrations,L5,bridges,PatternToRecoveryBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,_apply_recovery | _generate_recovery | _instantiate_template | _load_pattern | _queue_for_review | exception | from_confidence | get | info | str | to_dict,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,62,Generate recovery suggestion for matched pattern.,Unclassified,low,no classification rules matched
integrations,L5,bridges,PatternToRecoveryBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,bridges,PolicyToRoutingBridge.__init__,"__init__(db_session_factory, config)",?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,4,,Internal Helper,high,dunder method
integrations,L5,bridges,PolicyToRoutingBridge._create_adjustment,"async _create_adjustment(agent_id: str, policy: PolicyRule, tenant_id: str) -> Optional[RoutingAdjustment]",?:__init__,_get_active_adjustments | _get_agent_kpi | _persist_adjustment | create | get | max | min | sum | warning,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,46,Create routing adjustment with guardrails.,Internal Helper,medium,private function
integrations,L5,bridges,PolicyToRoutingBridge._get_active_adjustments,async _get_active_adjustments(agent_id: str) -> list[RoutingAdjustment],?:__init__,RoutingAdjustment | db_factory | execute | fetchall | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,32,Get active adjustments for an agent.,Internal Helper,medium,private function
integrations,L5,bridges,PolicyToRoutingBridge._get_agent_kpi,async _get_agent_kpi(agent_id: str) -> float,?:__init__,db_factory | execute | fetchone | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,23,Get current KPI for an agent (success rate).,Internal Helper,medium,private function
integrations,L5,bridges,PolicyToRoutingBridge._identify_affected_agents,"async _identify_affected_agents(policy: PolicyRule, tenant_id: str) -> list[str]",?:__init__,db_factory | execute | fetchall | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,19,Identify agents affected by this policy.,Internal Helper,medium,private function
integrations,L5,bridges,PolicyToRoutingBridge._persist_adjustment,async _persist_adjustment(adjustment: RoutingAdjustment) -> None,?:__init__,db_factory | execute | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,28,Persist routing adjustment to database.,Internal Helper,medium,private function
integrations,L5,bridges,PolicyToRoutingBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,PolicyMode | PolicyRule | _create_adjustment | _identify_affected_agents | append | exception | from_confidence | get | info | isinstance | len | str | to_dict,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,78,Adjust CARE routing based on new policy.,Unclassified,low,no classification rules matched
integrations,L5,bridges,PolicyToRoutingBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,bridges,RecoveryToPolicyBridge.__init__,"__init__(db_session_factory, config)",?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,bridges,RecoveryToPolicyBridge._generate_policy,"_generate_policy(pattern: dict, recovery: RecoverySuggestion) -> PolicyRule",?:__init__,create | get | isinstance | loads,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,36,Generate prevention policy from pattern and recovery.,Internal Helper,medium,private function
integrations,L5,bridges,RecoveryToPolicyBridge._load_pattern,async _load_pattern(pattern_id: str) -> Optional[dict],?:__init__,db_factory | dict | execute | fetchone | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,13,Load pattern from database.,Internal Helper,medium,private function
integrations,L5,bridges,RecoveryToPolicyBridge._persist_policy,"async _persist_policy(policy: PolicyRule, tenant_id: str) -> None",?:__init__,db_factory | dumps | execute | text,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,db_write,yes,45,Persist policy to database.,Internal Helper,medium,private function
integrations,L5,bridges,RecoveryToPolicyBridge.process,async process(event: LoopEvent) -> LoopEvent,?:__init__,RecoverySuggestion | _generate_policy | _load_pattern | _persist_policy | exception | from_confidence | get | getattr | info | isinstance | str | to_dict,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,yes,82,Generate prevention policy from applied recovery.,Unclassified,low,no classification rules matched
integrations,L5,bridges,RecoveryToPolicyBridge.stage,stage() -> LoopStage,?:__init__,,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,bridges,_check_frozen,_check_frozen() -> None,?:__init__,info,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,6,Log that frozen mechanics are in use.,Internal Helper,medium,private function
integrations,L5,bridges,create_bridges,"create_bridges(db_session_factory, redis_client, config) -> list[BaseBridge]",?:__init__,IncidentToCatalogBridge | LoopStatusBridge | PatternToRecoveryBridge | PolicyToRoutingBridge | RecoveryToPolicyBridge,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,13,Create all bridges with shared configuration.,Unclassified,low,no classification rules matched
integrations,L5,bridges,register_all_bridges,"register_all_bridges(dispatcher: 'IntegrationDispatcher', db_session_factory, redis_client, config) -> None",?:__init__,create_bridges | register,__future__ | audit_schemas | bridges_driver | dispatcher | loop_events | sqlalchemy,pure,no,10,Register all bridges with the dispatcher.,Unclassified,low,no classification rules matched
integrations,L5,channel_engine,NotificationSender.send,"async send(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any]) -> NotifyDeliveryResult",,,,pure,yes,8,Send notification via this channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelConfig.is_configured,is_configured() -> bool,,bool | len,,pure,no,15,Check if channel has required configuration.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelConfig.is_event_enabled,is_event_enabled(event_type: NotifyEventType) -> bool,,,,pure,no,3,Check if an event type is enabled for this channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelConfig.record_failure,record_failure() -> None,,now,,pure,no,5,Record a failed delivery.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelConfig.record_success,record_success() -> None,,now,,pure,no,4,Record a successful delivery.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelConfig.to_dict,"to_dict() -> Dict[str, Any]",,is_configured | isoformat,,pure,no,20,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
integrations,L5,channel_engine,NotifyChannelConfigResponse.to_dict,"to_dict() -> Dict[str, Any]",,,,pure,no,9,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
integrations,L5,channel_engine,NotifyChannelError.__init__,"__init__(message: str, channel: NotifyChannel, event_type: Optional[NotifyEventType], details: Optional[Dict[str, Any]])",,__init__ | super,,pure,no,11,,Internal Helper,high,dunder method
integrations,L5,channel_engine,NotifyChannelError.to_dict,"to_dict() -> Dict[str, Any]",,str,,pure,no,9,Convert to dictionary for logging/API responses.,Internal Helper,medium,name matches 'to_'
integrations,L5,channel_engine,NotifyChannelService.__init__,__init__(default_channels: Optional[Set[NotifyChannel]]),,,,pure,no,13,Initialize the notification channel service.,Internal Helper,high,dunder method
integrations,L5,channel_engine,NotifyChannelService._send_email_notification,"async _send_email_notification(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | join | now | sha256 | total_seconds,,pure,yes,44,Send email notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_pagerduty_notification,"async _send_pagerduty_notification(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | now | sha256 | total_seconds,,pure,yes,42,Send PagerDuty notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_slack_notification,"async _send_slack_notification(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | now | sha256 | total_seconds,,pure,yes,43,Send Slack notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_teams_notification,"async _send_teams_notification(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | now | sha256 | total_seconds,,pure,yes,42,Send Microsoft Teams notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_ui_notification,"async _send_ui_notification(tenant_id: str, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | now | sha256 | total_seconds,,pure,yes,34,Send UI notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_via_channel,"async _send_via_channel(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | _send_email_notification | _send_pagerduty_notification | _send_slack_notification | _send_teams_notification | _send_ui_notification | _send_webhook_notification | now,,pure,yes,42,Send notification via a specific channel.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService._send_webhook_notification,"async _send_webhook_notification(config: NotifyChannelConfig, event_type: NotifyEventType, payload: Dict[str, Any], start_time: datetime) -> NotifyDeliveryResult",,NotifyDeliveryResult | encode | hexdigest | info | int | isoformat | now | sha256 | total_seconds,,pure,yes,45,Send webhook notification.,Internal Helper,medium,private function
integrations,L5,channel_engine,NotifyChannelService.check_health,"async check_health(tenant_id: str) -> Dict[NotifyChannel, Dict[str, Any]]",,get_channel_config | is_configured | isoformat,,pure,yes,41,Check health of all configured channels for a tenant.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,channel_engine,NotifyChannelService.configure_channel,"configure_channel(tenant_id: str, channel: NotifyChannel, status: NotifyChannelStatus, webhook_url: Optional[str], webhook_secret: Optional[str], email_recipients: Optional[List[str]], slack_webhook_url: Optional[str], slack_channel: Optional[str], pagerduty_routing_key: Optional[str], teams_webhook_url: Optional[str], enabled_events: Optional[Set[NotifyEventType]], retry_count: int, timeout_seconds: int) -> NotifyChannelConfig",,NotifyChannelConfig | info | is_configured | set,,pure,no,73,Configure a notification channel for a tenant.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.disable_channel,"disable_channel(tenant_id: str, channel: NotifyChannel) -> NotifyChannelConfigResponse",,NotifyChannelConfigResponse | get_channel_config | info | is_configured | list | now,,pure,no,41,Disable a notification channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.enable_channel,"enable_channel(tenant_id: str, channel: NotifyChannel) -> NotifyChannelConfigResponse",,NotifyChannelConfigResponse | get_channel_config | info | is_configured | list | now,,pure,no,50,Enable a notification channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.get_all_configs,"get_all_configs(tenant_id: str) -> Dict[NotifyChannel, NotifyChannelConfig]",,get,,pure,no,14,Get all channel configurations for a tenant.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.get_channel_config,"get_channel_config(tenant_id: str, channel: NotifyChannel) -> Optional[NotifyChannelConfig]",,get,,pure,no,18,Get configuration for a specific channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.get_delivery_history,"get_delivery_history(tenant_id: str, limit: int) -> List[NotifyDeliveryResult]",,,,pure,no,18,Get recent delivery history for a tenant.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.get_enabled_channels,"get_enabled_channels(tenant_id: str, event_type: Optional[NotifyEventType]) -> List[NotifyChannel]",,append | is_configured | is_event_enabled | items | list,,pure,no,29,Get list of enabled channels for a tenant.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.send,"async send(tenant_id: str, event_type: NotifyEventType, payload: Dict[str, Any], channels: Optional[List[NotifyChannel]]) -> List[NotifyDeliveryResult]",,NotifyDeliveryResult | _send_ui_notification | _send_via_channel | append | extend | get_channel_config | get_enabled_channels | is_event_enabled | len | now | record_failure | record_success | str,,pure,yes,80,Send notification via all enabled channels.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyChannelService.set_event_filter,"set_event_filter(tenant_id: str, channel: NotifyChannel, enabled_events: Set[NotifyEventType]) -> NotifyChannelConfigResponse",,NotifyChannelConfigResponse | get_channel_config | info | is_configured | list | now,,pure,no,47,Set which events trigger notifications for a channel.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,NotifyDeliveryResult.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,,pure,no,13,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
integrations,L5,channel_engine,_reset_notify_service,_reset_notify_service() -> None,,,,pure,no,4,Reset the notification service (for testing).,Internal Helper,medium,private function
integrations,L5,channel_engine,check_channel_health,"async check_channel_health(tenant_id: str) -> Dict[NotifyChannel, Dict[str, Any]]",,check_health | get_notify_service,,pure,yes,14,Quick helper to check channel health.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,channel_engine,get_channel_config,"get_channel_config(tenant_id: str, channel: NotifyChannel) -> Optional[NotifyChannelConfig]",,get_channel_config | get_notify_service,,pure,no,16,Quick helper to get channel configuration.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,get_notify_service,get_notify_service() -> NotifyChannelService,,NotifyChannelService,,pure,no,6,Get or create the notification service singleton.,Internal Helper,low,pure function with no callers
integrations,L5,channel_engine,send_notification,"async send_notification(tenant_id: str, event_type: NotifyEventType, payload: Dict[str, Any], channels: Optional[List[NotifyChannel]]) -> List[NotifyDeliveryResult]",,get_notify_service | send,,pure,yes,20,Quick helper to send notification.,Internal Helper,low,pure function with no callers
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.__init__,"__init__(project_id: Optional[str], region: Optional[str], credentials_path: Optional[str], **kwargs)",L3:__init__,getenv,base | cloud | httpx,pure,no,12,,Internal Helper,high,dunder method
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.connect,async connect() -> bool,L3:__init__,AsyncClient | error | get_event_loop | info | run_in_executor,base | cloud | httpx,external_api,yes,22,Connect to Google Cloud Functions.,Unclassified,low,no classification rules matched
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.disconnect,async disconnect() -> None,L3:__init__,aclose | info,base | cloud | httpx,pure,yes,7,Disconnect from Cloud Functions.,Unclassified,low,no classification rules matched
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.function_exists,async function_exists(function_name: str) -> bool,L3:__init__,get_function_info,base | cloud | httpx,pure,yes,7,Check if a Cloud Function exists.,Unclassified,low,no classification rules matched
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.get_function_info,async get_function_info(function_name: str) -> Optional[FunctionInfo],L3:__init__,FunctionInfo | RuntimeError | dict | error | get_event_loop | get_function | run_in_executor,base | cloud | httpx,pure,yes,37,Get information about a Cloud Function.,Unclassified,low,no classification rules matched
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.invoke,async invoke(request: InvocationRequest) -> InvocationResult,L3:__init__,InvocationResult | RuntimeError | create_task | error | get | get_function_info | int | isinstance | json | now | post | str | total_seconds | uuid4,base | cloud | httpx,external_api,yes,93,Invoke a Cloud Function.,Unclassified,low,no classification rules matched
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.invoke_batch,"async invoke_batch(requests: List[InvocationRequest], max_concurrent: int) -> List[InvocationResult]",L3:__init__,InvocationResult | RuntimeError | Semaphore | append | gather | invoke | invoke_with_semaphore | isinstance | str | uuid4,base | cloud | httpx,pure,yes,34,Invoke multiple Cloud Functions concurrently.,Coordinator/Aggregator,medium,name matches 'batch'
integrations,L5,cloud_functions_adapter,CloudFunctionsAdapter.list_functions,"async list_functions(prefix: Optional[str], max_results: int) -> List[FunctionInfo]",L3:__init__,FunctionInfo | RuntimeError | append | dict | error | get_event_loop | list | list_functions | run_in_executor | split | startswith,base | cloud | httpx,pure,yes,49,List Cloud Functions.,Unclassified,low,no classification rules matched
integrations,L5,connectors_facade,ConnectorInfo.to_dict,"to_dict() -> Dict[str, Any]",L4:integrations_handler,isoformat,connector_registry,pure,no,16,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L5,connectors_facade,ConnectorsFacade.__init__,__init__(),L4:integrations_handler,,connector_registry,pure,no,9,Initialize facade with lazy-loaded services.,Internal Helper,high,dunder method
integrations,L5,connectors_facade,ConnectorsFacade._get_capabilities_for_type,_get_capabilities_for_type(connector_type: str) -> List[str],L4:integrations_handler,get,connector_registry,pure,no,12,Get default capabilities for connector type.,Internal Helper,medium,private function
integrations,L5,connectors_facade,ConnectorsFacade.delete_connector,"async delete_connector(connector_id: str, tenant_id: str) -> bool",L4:integrations_handler,get | info,connector_registry,pure,yes,25,Delete a connector.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.get_connector,"async get_connector(connector_id: str, tenant_id: str) -> Optional[ConnectorInfo]",L4:integrations_handler,get,connector_registry,pure,yes,19,Get a specific connector.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.list_connectors,"async list_connectors(tenant_id: str, connector_type: Optional[str], status: Optional[str], limit: int, offset: int) -> List[ConnectorInfo]",L4:integrations_handler,append | debug | values,connector_registry,pure,yes,39,List connectors for a tenant.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.register_connector,"async register_connector(tenant_id: str, name: str, connector_type: str, endpoint: Optional[str], config: Optional[Dict[str, Any]], metadata: Optional[Dict[str, Any]]) -> ConnectorInfo",L4:integrations_handler,ConnectorInfo | _get_capabilities_for_type | info | now | str | uuid4,connector_registry,pure,yes,53,Register a new connector.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.registry,registry(),L4:integrations_handler,ConnectorRegistry | warning,connector_registry,pure,no,9,Lazy-load ConnectorRegistry.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.test_connector,"async test_connector(connector_id: str, tenant_id: str) -> TestResult",L4:integrations_handler,TestResult | get | int | now | str | time,connector_registry,pure,yes,63,Test a connector connection.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,ConnectorsFacade.update_connector,"async update_connector(connector_id: str, tenant_id: str, name: Optional[str], endpoint: Optional[str], config: Optional[Dict[str, Any]], metadata: Optional[Dict[str, Any]]) -> Optional[ConnectorInfo]",L4:integrations_handler,get | now,connector_registry,pure,yes,38,Update a connector.,Operation,high,called by L4 orchestrator
integrations,L5,connectors_facade,TestResult.to_dict,"to_dict() -> Dict[str, Any]",L4:integrations_handler,,connector_registry,pure,no,9,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L5,connectors_facade,get_connectors_facade,get_connectors_facade() -> ConnectorsFacade,L4:integrations_handler,ConnectorsFacade,connector_registry,pure,no,14,Get the connectors facade instance.,Operation,high,called by L4 orchestrator
integrations,L5,cost_bridges_engine,CostAnomaly.create,"create(tenant_id: str, anomaly_type: AnomalyType, entity_type: str, entity_id: str, current_value_cents: int, expected_value_cents: int, metadata: dict[str, Any] | None) -> 'CostAnomaly'",L5:__init__,cls | get | now | uuid4,__future__ | loop_events | orchestrator,pure,no,51,Factory method for creating cost anomalies.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostAnomaly.to_dict,"to_dict() -> dict[str, Any]",L5:__init__,isoformat,__future__ | loop_events | orchestrator,pure,no,16,Serialize for JSON.,Internal Helper,medium,name matches 'to_'
integrations,L5,cost_bridges_engine,CostEstimationProbe.__init__,__init__(db_session),L5:__init__,,__future__ | loop_events | orchestrator,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostEstimationProbe._calculate_cost,"_calculate_cost(model: str, prompt_tokens: int, output_tokens: int) -> int",L5:__init__,get | int,__future__ | loop_events | orchestrator,pure,no,9,Calculate cost in cents.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostEstimationProbe._find_cheaper_model,"_find_cheaper_model(current_model: str, prompt_tokens: int, output_tokens: int) -> Optional[dict[str, Any]]",L5:__init__,_calculate_cost,__future__ | loop_events | orchestrator,pure,no,25,Find a cheaper model that can handle the request.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostEstimationProbe.probe,"async probe(model: str, prompt_tokens: int, expected_output_tokens: int, tenant_id: str, cost_threshold_cents: int) -> dict[str, Any]",L5:__init__,_calculate_cost | _find_cheaper_model,__future__ | loop_events | orchestrator,pure,yes,48,Estimate cost and return routing decision.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostLoopBridge.__init__,__init__(db_session),L5:__init__,ValueError,__future__ | loop_events | orchestrator,pure,no,10,Initialize with database session.,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostLoopBridge._map_severity_to_incident_severity,_map_severity_to_incident_severity(severity: AnomalySeverity) -> str,L5:__init__,get,__future__ | loop_events | orchestrator,pure,no,9,Map cost anomaly severity to incident severity.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostLoopBridge.on_anomaly_detected,on_anomaly_detected(anomaly: CostAnomaly) -> Optional[str],L5:__init__,create_incident_from_cost_anomaly_sync | info,__future__ | loop_events | orchestrator,pure,no,34,Create incident from cost anomaly if severity warrants.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostLoopOrchestrator.__init__,__init__(db_session),L5:__init__,CostLoopBridge | CostPatternMatcher | CostPolicyGenerator | CostRecoveryGenerator | CostRoutingAdjuster | ValueError,__future__ | loop_events | orchestrator,pure,no,17,Initialize orchestrator with database session.,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostLoopOrchestrator.process_anomaly,"async process_anomaly(anomaly: CostAnomaly) -> dict[str, Any]",L5:__init__,append | generate_policy | generate_recovery | len | match_cost_pattern | max | on_anomaly_detected | on_cost_policy_created | to_dict,__future__ | loop_events | orchestrator,pure,yes,52,Process a cost anomaly through the full loop.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostPatternMatcher.__init__,__init__(db_session),L5:__init__,,__future__ | loop_events | orchestrator,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostPatternMatcher._build_signature,"_build_signature(anomaly: CostAnomaly) -> dict[str, Any]",L5:__init__,_deviation_bucket,__future__ | loop_events | orchestrator,pure,no,8,Build pattern signature from anomaly.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostPatternMatcher._calculate_confidence,"_calculate_confidence(anomaly: CostAnomaly, pattern_name: str) -> float",L5:__init__,get,__future__ | loop_events | orchestrator,pure,no,15,Calculate match confidence based on pattern fit.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostPatternMatcher._deviation_bucket,_deviation_bucket(pct: float) -> str,L5:__init__,,__future__ | loop_events | orchestrator,pure,no,10,Bucket deviation percentages for pattern matching.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostPatternMatcher._find_predefined_match,_find_predefined_match(anomaly: CostAnomaly) -> Optional[str],L5:__init__,items,__future__ | loop_events | orchestrator,pure,no,10,Find matching pre-defined pattern.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostPatternMatcher._hash_signature,"_hash_signature(signature: dict[str, Any]) -> str",L5:__init__,dumps | encode | hexdigest | sha256,__future__ | loop_events | orchestrator,pure,no,7,Create hash of signature for matching.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostPatternMatcher.match_cost_pattern,"async match_cost_pattern(anomaly: CostAnomaly, incident_id: str) -> PatternMatchResult",L5:__init__,_build_signature | _calculate_confidence | _find_predefined_match | _hash_signature | from_match | uuid4,__future__ | loop_events | orchestrator,pure,yes,47,Match anomaly to existing or new cost pattern.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostPolicyGenerator.__init__,__init__(db_session),L5:__init__,,__future__ | loop_events | orchestrator,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostPolicyGenerator.generate_policy,"async generate_policy(recovery: RecoverySuggestion, anomaly: CostAnomaly, pattern_result: PatternMatchResult) -> Optional[PolicyRule]",L5:__init__,create | format | get | info | isoformat | now | timedelta | warning,__future__ | loop_events | orchestrator,pure,yes,61,Generate policy from applied recovery.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostRecoveryGenerator.__init__,__init__(db_session),L5:__init__,,__future__ | loop_events | orchestrator,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostRecoveryGenerator.generate_recovery,"async generate_recovery(anomaly: CostAnomaly, pattern_result: PatternMatchResult, incident_id: str) -> list[RecoverySuggestion]",L5:__init__,append | create | get | info,__future__ | loop_events | orchestrator,pure,yes,46,Generate recovery suggestions for cost incident.,Unclassified,low,no classification rules matched
integrations,L5,cost_bridges_engine,CostRoutingAdjuster.__init__,__init__(db_session),L5:__init__,,__future__ | loop_events | orchestrator,pure,no,2,,Internal Helper,high,dunder method
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_budget_block_adjustment,_create_budget_block_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create budget blocking adjustment (highest priority).,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_escalation_adjustment,_create_escalation_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create escalation adjustment (pause + notify admin).,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_model_routing_adjustment,_create_model_routing_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,12,Create cost-based model routing adjustment.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_notify_adjustment,_create_notify_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create notification adjustment (minimal routing impact).,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_rate_limit_adjustment,_create_rate_limit_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create rate limiting adjustment.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_review_adjustment,_create_review_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create review flag adjustment (minimal routing impact).,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_throttle_adjustment,_create_throttle_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create throttling adjustment.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster._create_token_limit_adjustment,_create_token_limit_adjustment(policy: PolicyRule) -> RoutingAdjustment,L5:__init__,create,__future__ | loop_events | orchestrator,pure,no,11,Create token limiting adjustment.,Internal Helper,medium,private function
integrations,L5,cost_bridges_engine,CostRoutingAdjuster.on_cost_policy_created,async on_cost_policy_created(policy: PolicyRule) -> list[RoutingAdjustment],L5:__init__,_create_budget_block_adjustment | _create_escalation_adjustment | _create_model_routing_adjustment | _create_notify_adjustment | _create_rate_limit_adjustment | _create_review_adjustment | _create_throttle_adjustment | _create_token_limit_adjustment | append | info,__future__ | loop_events | orchestrator,pure,yes,47,Adjust CARE routing based on new cost policy.,Unclassified,low,no classification rules matched
integrations,L5,cus_health_engine,CusHealthService.__init__,__init__(credential_service: Optional[CusCredentialService]),?:cus_health_service,CusCredentialService,cus_credential_service | cus_models | db | httpx | sqlmodel,pure,no,8,Initialize health service.,Internal Helper,high,dunder method
integrations,L5,cus_health_engine,CusHealthService._calculate_overall_health,"_calculate_overall_health(counts: Dict[str, int]) -> str",?:cus_health_service,,cus_credential_service | cus_models | db | httpx | sqlmodel,pure,no,22,Calculate overall health status from counts.,Internal Helper,medium,private function
integrations,L5,cus_health_engine,CusHealthService._perform_health_check,"async _perform_health_check(integration: CusIntegration, tenant_id: str) -> Dict[str, Any]",?:cus_health_service,AsyncClient | Timeout | exception | get | int | lower | now | post | resolve_credential | str | total_seconds | update | warning,cus_credential_service | cus_models | db | httpx | sqlmodel,external_api,yes,183,Perform the actual health check call.,Internal Helper,medium,private function
integrations,L5,cus_health_engine,CusHealthService.check_all_integrations,"async check_all_integrations(tenant_id: str, stale_threshold_minutes: int) -> List[Dict[str, Any]]",?:cus_health_service,Session | UUID | all | append | check_health | exec | get_engine | info | is_ | len | list | now | select | sleep | str,cus_credential_service | cus_models | db | httpx | sqlmodel,pure,yes,61,Check health of all integrations that need checking.,Policy/Decision,medium,name matches 'check'
integrations,L5,cus_health_engine,CusHealthService.check_health,"async check_health(tenant_id: str, integration_id: str, force: bool) -> Dict[str, Any]",?:cus_health_service,Session | UUID | _perform_health_check | add | exec | first | get_engine | info | now | select | total_seconds | where,cus_credential_service | cus_models | db | httpx | sqlmodel,db_write,yes,72,Check health of a single integration.,Policy/Decision,medium,name matches 'check'
integrations,L5,cus_health_engine,CusHealthService.get_health_summary,"async get_health_summary(tenant_id: str) -> Dict[str, Any]",?:cus_health_service,Session | UUID | _calculate_overall_health | all | exec | get_engine | len | list | lower | now | select | timedelta | where,cus_credential_service | cus_models | db | httpx | sqlmodel,pure,yes,51,Get health summary for all integrations.,Unclassified,low,no classification rules matched
integrations,L5,cus_integration_service,get_cus_integration_service,get_cus_integration_service() -> CusIntegrationService,?:cus_integration_service | L5:integrations_facade | ?:shim_guard,get_cus_integration_engine,cus_integration_engine,pure,no,7,Get the CusIntegrationService instance.,Unclassified,low,no classification rules matched
integrations,L5,cus_schemas,CusIntegrationCreate.validate_not_raw_key,validate_not_raw_key(v: str) -> str,?:cus_telemetry | ?:aos_cus_integrations | ?:cus_telemetry_engine | ?:cus_integration_engine | L2:aos_cus_integrations | L2:cus_telemetry,ValueError | field_validator | startswith,cus_models | pydantic,pure,no,14,Ensure credential_ref is not a raw API key.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
integrations,L5,cus_schemas,CusIntegrationUpdate.validate_not_raw_key,validate_not_raw_key(v: Optional[str]) -> Optional[str],?:cus_telemetry | ?:aos_cus_integrations | ?:cus_telemetry_engine | ?:cus_integration_engine | L2:aos_cus_integrations | L2:cus_telemetry,ValueError | field_validator | startswith,cus_models | pydantic,pure,no,12,Ensure credential_ref is not a raw API key.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
integrations,L5,customer_activity_adapter,CustomerActivityAdapter.__init__,__init__(),?:test_l2_l3_contracts,,activity_facade | asyncio | pydantic,pure,no,3,Initialize adapter with lazy L5 facade loading.,Internal Helper,high,dunder method
integrations,L5,customer_activity_adapter,CustomerActivityAdapter._get_facade,_get_facade() -> ActivityFacade,?:test_l2_l3_contracts,get_activity_facade,activity_facade | asyncio | pydantic,pure,no,5,Get the L5 ActivityFacade (lazy loaded).,Internal Helper,medium,private function
integrations,L5,customer_activity_adapter,CustomerActivityAdapter._to_customer_detail,_to_customer_detail(detail: RunDetailResult) -> CustomerActivityDetail,?:test_l2_l3_contracts,CustomerActivityDetail | int | isoformat | upper,activity_facade | asyncio | pydantic,pure,no,35,Transform L5 RunDetailResult to L3 CustomerActivityDetail.,Internal Helper,medium,private function
integrations,L5,customer_activity_adapter,CustomerActivityAdapter._to_customer_summary,_to_customer_summary(summary: RunSummaryResult) -> CustomerActivitySummary,?:test_l2_l3_contracts,CustomerActivitySummary | int | isoformat | upper,activity_facade | asyncio | pydantic,pure,no,29,Transform L5 RunSummaryResult to L3 CustomerActivitySummary.,Internal Helper,medium,private function
integrations,L5,customer_activity_adapter,CustomerActivityAdapter.get_activity,"async get_activity(session: 'AsyncSession', tenant_id: str, run_id: str) -> Optional[CustomerActivityDetail]",?:test_l2_l3_contracts,ValueError | _get_facade | _to_customer_detail | get_run_detail,activity_facade | asyncio | pydantic,pure,yes,39,Get activity detail for a specific run.,Unclassified,low,no classification rules matched
integrations,L5,customer_activity_adapter,CustomerActivityAdapter.list_activities,"async list_activities(session: 'AsyncSession', tenant_id: str, limit: int, offset: int, status: Optional[str], worker_id: Optional[str]) -> CustomerActivityListResponse",?:test_l2_l3_contracts,CustomerActivityListResponse | ValueError | _get_facade | _to_customer_summary | get_runs,activity_facade | asyncio | pydantic,pure,yes,57,List activities for the customer's tenant.,Unclassified,low,no classification rules matched
integrations,L5,customer_activity_adapter,get_customer_activity_adapter,get_customer_activity_adapter() -> CustomerActivityAdapter,?:test_l2_l3_contracts,CustomerActivityAdapter,activity_facade | asyncio | pydantic,pure,no,16,Get the singleton CustomerActivityAdapter instance.,Unclassified,low,no classification rules matched
integrations,L5,customer_incidents_adapter,CustomerIncidentsAdapter.__init__,__init__(session: Session),?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,get_incident_read_service | get_incident_write_service,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,5,Initialize adapter with database session.,Internal Helper,high,dunder method
integrations,L5,customer_incidents_adapter,CustomerIncidentsAdapter.acknowledge_incident,"acknowledge_incident(incident_id: str, tenant_id: str, acknowledged_by: str) -> Optional[CustomerIncidentSummary]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerIncidentSummary | _translate_severity | acknowledge_incident | get_incident | hasattr | int | isoformat | str,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,42,Acknowledge an incident.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_incidents_adapter,CustomerIncidentsAdapter.get_incident,"get_incident(incident_id: str, tenant_id: str) -> Optional[CustomerIncidentDetail]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerIncidentDetail | CustomerIncidentEvent | CustomerIncidentSummary | _translate_severity | _translate_status | append | get_incident | get_incident_events | hasattr | int | isoformat | str,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,60,Get incident detail with timeline.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_incidents_adapter,CustomerIncidentsAdapter.list_incidents,"list_incidents(tenant_id: str, status: Optional[str], severity: Optional[str], from_date: Optional[str], to_date: Optional[str], limit: int, offset: int) -> CustomerIncidentListResponse",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerIncidentListResponse | CustomerIncidentSummary | _translate_severity | _translate_status | append | fromisoformat | hasattr | int | isoformat | list_incidents | str,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,72,List incidents for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_incidents_adapter,CustomerIncidentsAdapter.resolve_incident,"resolve_incident(incident_id: str, tenant_id: str, resolved_by: str, resolution_notes: Optional[str]) -> Optional[CustomerIncidentSummary]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerIncidentSummary | _translate_severity | get_incident | hasattr | int | isoformat | resolve_incident | str,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,44,Resolve an incident.,Operation,ambiguous,multi-match: Coordinator/Aggregator(name matches 'resolve'); Operation(called by L2 (gap  should route via L4))
integrations,L5,customer_incidents_adapter,_translate_severity,_translate_severity(internal_severity: str) -> str,?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,get | lower,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,10,Translate internal severity to calm customer vocabulary.,Internal Helper,medium,private function
integrations,L5,customer_incidents_adapter,_translate_status,_translate_status(internal_status: str) -> str,?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,get | lower,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,10,Translate internal status to customer vocabulary.,Internal Helper,medium,private function
integrations,L5,customer_incidents_adapter,get_customer_incidents_adapter,get_customer_incidents_adapter(session: Session) -> CustomerIncidentsAdapter,?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerIncidentsAdapter,incident_read_engine | incident_write_engine | pydantic | sqlmodel,pure,no,11,Get a CustomerIncidentsAdapter instance.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_keys_adapter,CustomerKeysAdapter.__init__,__init__(session: Session),?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,get_keys_read_service | get_keys_write_service,keys_engine | pydantic | sqlmodel,pure,no,5,Initialize adapter with database session.,Internal Helper,high,dunder method
integrations,L5,customer_keys_adapter,CustomerKeysAdapter.freeze_key,"freeze_key(key_id: str, tenant_id: str) -> Optional[CustomerKeyAction]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerKeyAction | freeze_key | get_key | getattr,keys_engine | pydantic | sqlmodel,pure,no,39,Freeze an API key.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_keys_adapter,CustomerKeysAdapter.get_key,"get_key(key_id: str, tenant_id: str) -> Optional[CustomerKeyInfo]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerKeyInfo | get_key | get_key_usage_today | getattr | hasattr | int | isoformat | now | replace,keys_engine | pydantic | sqlmodel,pure,no,39,Get API key detail.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_keys_adapter,CustomerKeysAdapter.list_keys,"list_keys(tenant_id: str, limit: int, offset: int) -> CustomerKeyListResponse",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerKeyInfo | CustomerKeyListResponse | append | get_key_usage_today | getattr | hasattr | int | isoformat | list_keys | now | replace,keys_engine | pydantic | sqlmodel,pure,no,50,List API keys for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_keys_adapter,CustomerKeysAdapter.unfreeze_key,"unfreeze_key(key_id: str, tenant_id: str) -> Optional[CustomerKeyAction]",?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerKeyAction | get_key | getattr | unfreeze_key,keys_engine | pydantic | sqlmodel,pure,no,39,Unfreeze an API key.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_keys_adapter,get_customer_keys_adapter,get_customer_keys_adapter(session: Session) -> CustomerKeysAdapter,?:guard | L3:__init__ | L2:guard | ?:test_l2_l3_contracts,CustomerKeysAdapter,keys_engine | pydantic | sqlmodel,pure,no,11,Get a CustomerKeysAdapter instance.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_logs_adapter,CustomerLogsAdapter.__init__,__init__(),?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,,logs_read_engine | pydantic,pure,no,3,Initialize adapter with lazy L4 service loading.,Internal Helper,high,dunder method
integrations,L5,customer_logs_adapter,CustomerLogsAdapter._get_service,async _get_service(),?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,get_logs_read_service,logs_read_engine | pydantic,pure,yes,8,Get the L4 LogsReadService (lazy loaded).,Internal Helper,medium,private function
integrations,L5,customer_logs_adapter,CustomerLogsAdapter.export_logs,"async export_logs(tenant_id: str, format: str, from_date: Optional[str], to_date: Optional[str], limit: int) -> Dict[str, Any]",?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,isoformat | list_logs | min | model_dump | str | utcnow,logs_read_engine | pydantic,pure,yes,80,Export logs for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_logs_adapter,CustomerLogsAdapter.get_log,"async get_log(log_id: str, tenant_id: str) -> Optional[CustomerLogDetail]",?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,CustomerLogDetail | CustomerLogStep | _get_service | get_trace | hasattr | isinstance | isoformat | len | replace | startswith | str | sum,logs_read_engine | pydantic,pure,yes,78,Get log detail for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_logs_adapter,CustomerLogsAdapter.list_logs,"async list_logs(tenant_id: str, agent_id: Optional[str], status: Optional[str], from_date: Optional[str], to_date: Optional[str], limit: int, offset: int) -> CustomerLogListResponse",?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,CustomerLogListResponse | CustomerLogSummary | _get_service | get_trace_count | isinstance | isoformat | min | replace | search_traces | startswith | str,logs_read_engine | pydantic,pure,yes,73,List logs for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_logs_adapter,get_customer_logs_adapter,get_customer_logs_adapter() -> CustomerLogsAdapter,?:guard_logs | L3:__init__ | L2:guard_logs | ?:test_l2_l3_contracts,CustomerLogsAdapter,logs_read_engine | pydantic,pure,no,16,Get the singleton CustomerLogsAdapter instance.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter.__init__,__init__(),?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,,customer_policy_read_engine | pydantic,pure,no,3,Initialize adapter with lazy L4 service loading.,Internal Helper,high,dunder method
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter._get_service,_get_service() -> CustomerPolicyReadService,?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,get_customer_policy_read_service,customer_policy_read_engine | pydantic,pure,no,5,Get the L4 CustomerPolicyReadService (lazy loaded).,Internal Helper,medium,private function
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter._to_customer_guardrail,_to_customer_guardrail(guardrail: GuardrailSummary) -> CustomerGuardrail,?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,CustomerGuardrail,customer_policy_read_engine | pydantic,pure,no,10,Transform L4 GuardrailSummary to L3 CustomerGuardrail.,Internal Helper,medium,private function
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter._to_customer_policy_constraints,_to_customer_policy_constraints(constraints: PolicyConstraints) -> CustomerPolicyConstraints,?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,CustomerBudgetConstraint | CustomerPolicyConstraints | CustomerRateLimit | _to_customer_guardrail,customer_policy_read_engine | pydantic,pure,no,32,Transform L4 PolicyConstraints to L3 CustomerPolicyConstraints.,Internal Helper,medium,private function
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter.get_guardrail_detail,"get_guardrail_detail(tenant_id: str, guardrail_id: str) -> Optional[CustomerGuardrail]",?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,ValueError | _get_service | _to_customer_guardrail | get_guardrail_detail,customer_policy_read_engine | pydantic,pure,no,35,Get guardrail detail for a customer.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'guard'); Operation(called by L2 (gap  should route via L4))
integrations,L5,customer_policies_adapter,CustomerPoliciesAdapter.get_policy_constraints,get_policy_constraints(tenant_id: str) -> CustomerPolicyConstraints,?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,ValueError | _get_service | _to_customer_policy_constraints | get_policy_constraints,customer_policy_read_engine | pydantic,pure,no,30,Get policy constraints for a customer.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,customer_policies_adapter,get_customer_policies_adapter,get_customer_policies_adapter() -> CustomerPoliciesAdapter,?:guard_policies | L3:__init__ | L2:guard_policies | ?:test_l2_l3_contracts,CustomerPoliciesAdapter,customer_policy_read_engine | pydantic,pure,no,20,Get the singleton CustomerPoliciesAdapter instance.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,datasource_model,CustomerDataSource.activate,activate(now: Optional[datetime]) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,6,Activate the data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.add_tag,add_tag(tag: str) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,append | now,,pure,no,5,Add a tag to the data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.deactivate,deactivate(now: Optional[datetime]) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,5,Deactivate the data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.deprecate,deprecate(now: Optional[datetime]) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,5,Mark data source as deprecated.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.grant_access,grant_access(role: str) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,append | now,,pure,no,5,Grant access to a role.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.has_access,has_access(role: str) -> bool,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,len,,pure,no,3,Check if a role has access.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.record_connection,record_connection(now: Optional[datetime]) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,6,Record a successful connection.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.record_error,"record_error(error: str, now: Optional[datetime]) -> None",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,7,Record a connection error.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.remove_tag,remove_tag(tag: str) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now | remove,,pure,no,5,Remove a tag from the data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.revoke_access,revoke_access(role: str) -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now | remove,,pure,no,5,Revoke access from a role.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,CustomerDataSource.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,isoformat | to_dict,,pure,no,23,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,datasource_model,CustomerDataSource.update_config,"update_config(config: DataSourceConfig, now: Optional[datetime]) -> None",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,now,,pure,no,10,Update the data source configuration.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceConfig.get_connection_url,get_connection_url() -> Optional[str],?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,,,pure,no,20,Build connection URL from components.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceConfig.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,,,pure,no,27,"Convert to dictionary, optionally masking secrets.",Internal Helper,medium,name matches 'to_'
integrations,L5,datasource_model,DataSourceError.__init__,"__init__(message: str, source_id: Optional[str], source_type: Optional[DataSourceType])",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,__init__ | super,,pure,no,10,,Internal Helper,high,dunder method
integrations,L5,datasource_model,DataSourceError.to_dict,"to_dict() -> dict[str, Any]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,,,pure,no,7,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,datasource_model,DataSourceRegistry.__init__,__init__(),?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,,,pure,no,4,Initialize the registry.,Internal Helper,high,dunder method
integrations,L5,datasource_model,DataSourceRegistry.activate,activate(source_id: str) -> Optional[CustomerDataSource],?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,activate | get,,pure,no,6,Activate a data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.clear_tenant,clear_tenant(tenant_id: str) -> int,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,delete | get | len | list | set,,db_write,no,6,Clear all sources for a tenant.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.deactivate,deactivate(source_id: str) -> Optional[CustomerDataSource],?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,deactivate | get,,pure,no,6,Deactivate a data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.delete,delete(source_id: str) -> bool,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,discard | get,,pure,no,13,Delete a data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.get,get(source_id: str) -> Optional[CustomerDataSource],?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,get,,pure,no,3,Get a data source by ID.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.get_by_name,"get_by_name(tenant_id: str, name: str) -> Optional[CustomerDataSource]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,values,,pure,no,10,Get a data source by name within a tenant.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.get_statistics,get_statistics(tenant_id: Optional[str]) -> DataSourceStats,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,DataSourceStats | get | values,,pure,no,32,Get registry statistics.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.list,"list(tenant_id: Optional[str], source_type: Optional[DataSourceType], status: Optional[DataSourceStatus], tag: Optional[str], limit: int, offset: int) -> list[CustomerDataSource]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,list | sort | values,,pure,no,41,List data sources with optional filters.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.register,"register(tenant_id: str, name: str, source_type: DataSourceType, config: Optional[DataSourceConfig], description: Optional[str], tags: Optional[list[str]], owner_id: Optional[str], source_id: Optional[str]) -> CustomerDataSource",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,CustomerDataSource | DataSourceConfig | add | set | str | uuid4,,db_write,no,49,Register a new data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.reset,reset() -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,clear,,pure,no,4,Reset all state (for testing).,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceRegistry.update,"update(source_id: str, name: Optional[str], description: Optional[str], config: Optional[DataSourceConfig], metadata: Optional[dict[str, Any]]) -> Optional[CustomerDataSource]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,get | now | update_config,,pure,no,24,Update a data source.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,DataSourceStats.to_dict,"to_dict() -> dict[str, Any]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,,,pure,no,12,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,datasource_model,_reset_registry,_reset_registry() -> None,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,reset,,pure,no,6,Reset the singleton (for testing).,Internal Helper,medium,private function
integrations,L5,datasource_model,create_datasource,"create_datasource(tenant_id: str, name: str, source_type: DataSourceType, config: Optional[DataSourceConfig]) -> CustomerDataSource",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,get_datasource_registry | register,,pure,no,14,Create a new data source using the singleton registry.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,get_datasource,get_datasource(source_id: str) -> Optional[CustomerDataSource],?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,get | get_datasource_registry,,pure,no,4,Get a data source by ID using the singleton registry.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,get_datasource_registry,get_datasource_registry() -> DataSourceRegistry,?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,DataSourceRegistry,,pure,no,6,Get the singleton registry instance.,Unclassified,low,no classification rules matched
integrations,L5,datasource_model,list_datasources,"list_datasources(tenant_id: Optional[str], source_type: Optional[DataSourceType]) -> list[CustomerDataSource]",?:facade | ?:__init__ | L5:datasources_facade | ?:test_customer_datasource,get_datasource_registry | list,,pure,no,7,List data sources using the singleton registry.,Unclassified,low,no classification rules matched
integrations,L5,datasources_facade,DataSourcesFacade.__init__,__init__(),L4:integrations_handler,,datasource_model,pure,no,3,Initialize facade.,Internal Helper,high,dunder method
integrations,L5,datasources_facade,DataSourcesFacade.activate_source,"async activate_source(source_id: str, tenant_id: str) -> Optional[CustomerDataSource]",L4:integrations_handler,activate | get | info,datasource_model,pure,yes,21,Activate a data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.deactivate_source,"async deactivate_source(source_id: str, tenant_id: str) -> Optional[CustomerDataSource]",L4:integrations_handler,deactivate | get | info,datasource_model,pure,yes,21,Deactivate a data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.delete_source,"async delete_source(source_id: str, tenant_id: str) -> bool",L4:integrations_handler,delete | get | info,datasource_model,db_write,yes,21,Delete a data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.get_source,"async get_source(source_id: str, tenant_id: str) -> Optional[CustomerDataSource]",L4:integrations_handler,get,datasource_model,pure,yes,19,Get a specific data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.get_statistics,async get_statistics(tenant_id: str) -> DataSourceStats,L4:integrations_handler,get_statistics,datasource_model,pure,yes,14,Get data source statistics for a tenant.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.list_sources,"async list_sources(tenant_id: str, source_type: Optional[str], status: Optional[str], tag: Optional[str], limit: int, offset: int) -> List[CustomerDataSource]",L4:integrations_handler,DataSourceStatus | DataSourceType | list,datasource_model,pure,yes,46,List data sources.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.register_source,"async register_source(tenant_id: str, name: str, source_type: str, config: Optional[Dict[str, Any]], description: Optional[str], tags: Optional[List[str]], owner_id: Optional[str], metadata: Optional[Dict[str, Any]]) -> CustomerDataSource",L4:integrations_handler,DataSourceConfig | DataSourceType | get | info | register,datasource_model,pure,yes,68,Register a new data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.registry,registry() -> DataSourceRegistry,L4:integrations_handler,get_datasource_registry,datasource_model,pure,no,5,Lazy load the registry.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.test_connection,"async test_connection(source_id: str, tenant_id: str) -> Optional[TestConnectionResult]",L4:integrations_handler,TestConnectionResult | get | info | record_connection,datasource_model,pure,yes,34,Test a data source connection.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,DataSourcesFacade.update_source,"async update_source(source_id: str, tenant_id: str, name: Optional[str], description: Optional[str], config: Optional[Dict[str, Any]], metadata: Optional[Dict[str, Any]]) -> Optional[CustomerDataSource]",L4:integrations_handler,DataSourceConfig | get | update,datasource_model,pure,yes,51,Update a data source.,Operation,high,called by L4 orchestrator
integrations,L5,datasources_facade,TestConnectionResult.to_dict,"to_dict() -> Dict[str, Any]",L4:integrations_handler,,datasource_model,pure,no,8,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L5,datasources_facade,get_datasources_facade,get_datasources_facade() -> DataSourcesFacade,L4:integrations_handler,DataSourcesFacade,datasource_model,pure,no,14,Get the data sources facade instance.,Operation,high,called by L4 orchestrator
integrations,L5,dispatcher,DispatcherConfig.from_env,from_env() -> 'DispatcherConfig',?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,cls | float | getenv | int | lower,__future__ | loop_events | sqlalchemy,pure,no,14,Load config from environment variables.,Internal Helper,medium,name matches 'from_'
integrations,L5,dispatcher,IntegrationDispatcher.__init__,"__init__(redis_client: Any, db_session_factory: Callable, config: DispatcherConfig | None)",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,from_env | info | set,__future__ | loop_events | sqlalchemy,pure,no,26,,Internal Helper,high,dunder method
integrations,L5,dispatcher,IntegrationDispatcher._check_db_idempotency,"async _check_db_idempotency(incident_id: str, stage: LoopStage) -> bool",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,db_factory | error | execute | fetchone | text,__future__ | loop_events | sqlalchemy,db_write,yes,25,HYGIENE #4: Check if this incident+stage was already processed.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._check_human_checkpoint_needed,async _check_human_checkpoint_needed(event: LoopEvent) -> Optional[HumanCheckpoint],?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,create | get,__future__ | loop_events | sqlalchemy,pure,yes,39,Check if a human checkpoint is needed for this event.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._execute_handlers,async _execute_handlers(event: LoopEvent) -> LoopEvent,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,error | exception | get | handler | str | wait_for | warning,__future__ | loop_events | sqlalchemy,pure,yes,28,Execute all handlers for an event stage.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._get_or_create_loop_status,async _get_or_create_loop_status(event: LoopEvent) -> LoopStatus,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,LoopStatus | _load_loop_status | _persist_loop_status | uuid4,__future__ | loop_events | sqlalchemy,pure,yes,24,Get existing loop status or create new one.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._load_checkpoint,async _load_checkpoint(checkpoint_id: str) -> Optional[HumanCheckpoint],?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,HumanCheckpoint | HumanCheckpointType | LoopStage | db_factory | error | execute | fetchone | isinstance | loads | text,__future__ | loop_events | sqlalchemy,db_write,yes,33,Load checkpoint from database.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._load_loop_status,async _load_loop_status(incident_id: str) -> Optional[LoopStatus],?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,LoopStatus | db_factory | error | execute | fetchone | get | isinstance | loads | text,__future__ | loop_events | sqlalchemy,db_write,yes,35,Load loop status from database.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._persist_checkpoint,async _persist_checkpoint(checkpoint: HumanCheckpoint) -> None,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,db_factory | dumps | error | execute | text,__future__ | loop_events | sqlalchemy,db_write,yes,38,Persist human checkpoint to database.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._persist_event,async _persist_event(event: LoopEvent) -> None,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,db_factory | dumps | ensure_json_serializable | error | execute | text | to_dict,__future__ | loop_events | sqlalchemy,db_write,yes,38,Persist event to database for durability.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._persist_loop_status,async _persist_loop_status(status: LoopStatus) -> None,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,db_factory | dumps | error | execute | text,__future__ | loop_events | sqlalchemy,db_write,yes,35,Persist loop status to database.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._publish_checkpoint_needed,async _publish_checkpoint_needed(checkpoint: HumanCheckpoint) -> None,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,dumps | error | publish,__future__ | loop_events | sqlalchemy,pure,yes,18,Publish checkpoint needed event for console notification.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._publish_event,async _publish_event(event: LoopEvent) -> None,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,dumps | error | publish | to_dict,__future__ | loop_events | sqlalchemy,pure,yes,7,Publish event to Redis for real-time updates.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._trigger_next_stage,"async _trigger_next_stage(event: LoopEvent, loop_status: LoopStatus) -> Optional[LoopEvent]",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,create | error | index | len,__future__ | loop_events | sqlalchemy,pure,yes,30,Determine and create the next stage event if needed.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher._update_loop_status,"async _update_loop_status(loop_status: LoopStatus, event: LoopEvent) -> None",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,_persist_loop_status | append | get | now | set,__future__ | loop_events | sqlalchemy,pure,yes,35,Update loop status after event processing.,Internal Helper,medium,private function
integrations,L5,dispatcher,IntegrationDispatcher.dispatch,async dispatch(event: LoopEvent) -> LoopEvent,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,_check_db_idempotency | _check_human_checkpoint_needed | _execute_handlers | _get_or_create_loop_status | _load_loop_status | _persist_checkpoint | _persist_event | _publish_checkpoint_needed | _publish_event | _trigger_next_stage | _update_loop_status | add | append | debug | dispatch,__future__ | loop_events | sqlalchemy,db_write,yes,98,Dispatch an event through the integration loop.,Coordinator/Aggregator,medium,name matches 'dispatch'
integrations,L5,dispatcher,IntegrationDispatcher.get_loop_status,async get_loop_status(incident_id: str) -> Optional[LoopStatus],?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,_load_loop_status,__future__ | loop_events | sqlalchemy,pure,yes,5,Get current loop status for an incident.,Unclassified,low,no classification rules matched
integrations,L5,dispatcher,IntegrationDispatcher.get_pending_checkpoints,async get_pending_checkpoints(tenant_id: str) -> list[HumanCheckpoint],?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,values,__future__ | loop_events | sqlalchemy,pure,yes,3,Get all pending human checkpoints for a tenant.,Policy/Decision,medium,name matches 'check'
integrations,L5,dispatcher,IntegrationDispatcher.is_bridge_enabled,is_bridge_enabled(stage: LoopStage) -> bool,?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,get,__future__ | loop_events | sqlalchemy,pure,no,10,Check if a bridge is enabled by its stage.,Unclassified,low,no classification rules matched
integrations,L5,dispatcher,IntegrationDispatcher.register_handler,"register_handler(stage: LoopStage, handler: Handler) -> None",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,append | debug,__future__ | loop_events | sqlalchemy,pure,no,4,Register a handler for a specific loop stage.,Unclassified,low,no classification rules matched
integrations,L5,dispatcher,IntegrationDispatcher.resolve_checkpoint,"async resolve_checkpoint(checkpoint_id: str, user_id: str, resolution: str) -> Optional[LoopEvent]",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,ValueError | _load_checkpoint | _persist_checkpoint | create | dispatch | get | len | pop | remove | resolve,__future__ | loop_events | sqlalchemy,pure,yes,46,Resolve a pending human checkpoint.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Coordinator/Aggregator(name matches 'resolve')
integrations,L5,dispatcher,IntegrationDispatcher.retry_failed_stage,"async retry_failed_stage(incident_id: str, stage: LoopStage, tenant_id: str) -> Optional[LoopEvent]",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,ValueError | create | dispatch | get_loop_status | remove,__future__ | loop_events | sqlalchemy,pure,yes,22,Retry a failed stage in the loop.,Unclassified,low,no classification rules matched
integrations,L5,dispatcher,IntegrationDispatcher.revert_loop,"async revert_loop(incident_id: str, user_id: str, reason: str) -> None",?:bridges | ?:__init__ | L5:bridges | ?:test_m25_integration_loop,ValueError | _persist_loop_status | clear | get_loop_status | rollback | warning,__future__ | loop_events | sqlalchemy,pure,yes,25,Revert all changes made by a loop.,Unclassified,low,no classification rules matched
integrations,L5,file_storage_base,DownloadResult.success,success() -> bool,,len,,pure,no,2,,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileMetadata.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,,pure,no,10,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,file_storage_base,FileStorageAdapter.connect,async connect() -> bool,,,,pure,yes,8,Connect to the file storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.copy,"async copy(source_key: str, dest_key: str) -> bool",,,,pure,yes,16,Copy a file within storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.delete,async delete(key: str) -> bool,,,,pure,yes,14,Delete a file from storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.delete_many,async delete_many(keys: List[str]) -> int,,,,pure,yes,14,Delete multiple files from storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.disconnect,async disconnect() -> None,,,,pure,yes,3,Disconnect from the file storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.download,async download(key: str) -> DownloadResult,,,,pure,yes,14,Download a file from storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.download_stream,"async download_stream(key: str, chunk_size: int) -> AsyncIterator[bytes]",,,,pure,yes,16,Stream download a file from storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.exists,async exists(key: str) -> bool,,,,pure,yes,14,Check if a file exists in storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.generate_presigned_url,"async generate_presigned_url(key: str, operation: str, expires_in: int) -> str",,,,pure,yes,18,Generate a presigned URL for direct access.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.get_metadata,async get_metadata(key: str) -> Optional[FileMetadata],,,,pure,yes,14,Get file metadata without downloading content.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.health_check,async health_check() -> bool,,list_files | warning,,pure,yes,13,Check if the file storage is healthy.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,file_storage_base,FileStorageAdapter.list_files,"async list_files(prefix: Optional[str], max_keys: int, continuation_token: Optional[str]) -> ListResult",,,,pure,yes,18,List files in storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,FileStorageAdapter.upload,"async upload(key: str, data: bytes | BinaryIO, content_type: Optional[str], metadata: Optional[Dict[str, str]]) -> UploadResult",,,,pure,yes,20,Upload a file to storage.,Internal Helper,low,pure function with no callers
integrations,L5,file_storage_base,UploadResult.success,success() -> bool,,,,pure,no,2,,Internal Helper,low,pure function with no callers
integrations,L5,founder_ops_adapter,FounderOpsAdapter.to_summary_response,"to_summary_response(incidents: List[OpsIncident], summary_counts: dict, window_start: datetime, window_end: datetime, max_recent: int) -> FounderIncidentsSummaryResponse",?:ops,FounderIncidentsSummaryResponse | isoformat | len | to_summary_view,ops_domain_models,pure,no,31,Convert incident list and summary to Founder-facing response.,Internal Helper,medium,name matches 'to_'
integrations,L5,founder_ops_adapter,FounderOpsAdapter.to_summary_view,to_summary_view(incident: OpsIncident) -> FounderIncidentSummaryView,?:ops,FounderIncidentSummaryView | isoformat,ops_domain_models,pure,no,18,Convert a single OpsIncident to Founder-facing view.,Internal Helper,medium,name matches 'to_'
integrations,L5,gcs_adapter,GCSAdapter.__init__,"__init__(bucket_name: Optional[str], project_id: Optional[str], credentials_path: Optional[str], **kwargs)",L3:__init__,getenv,base | cloud,pure,no,12,,Internal Helper,high,dunder method
integrations,L5,gcs_adapter,GCSAdapter.connect,async connect() -> bool,L3:__init__,Client | create_bucket | error | get_bucket | get_event_loop | info | run_in_executor,base | cloud,pure,yes,32,Connect to GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.copy,"async copy(source_key: str, dest_key: str) -> bool",L3:__init__,RuntimeError | blob | copy_blob | error | get_event_loop | info | reload | run_in_executor,base | cloud,pure,yes,32,Copy a file within GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.delete,async delete(key: str) -> bool,L3:__init__,RuntimeError | blob | error | get_event_loop | info | run_in_executor,base | cloud,pure,yes,22,Delete a file from GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.delete_many,async delete_many(keys: List[str]) -> int,L3:__init__,RuntimeError | blob | error | get_event_loop | info | run_in_executor,base | cloud,pure,yes,32,Delete multiple files from GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.disconnect,async disconnect() -> None,L3:__init__,info,base | cloud,pure,yes,5,Disconnect from GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.download,async download(key: str) -> DownloadResult,L3:__init__,DownloadResult | FileMetadata | RuntimeError | blob | debug | error | get_event_loop | len | run_in_executor,base | cloud,pure,yes,37,Download a file from GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.download_stream,"async download_stream(key: str, chunk_size: int) -> AsyncIterator[bytes]",L3:__init__,BytesIO | RuntimeError | blob | download_to_file | get_event_loop | read | run_in_executor | seek,base | cloud,file_io,yes,28,Stream download a file from GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.exists,async exists(key: str) -> bool,L3:__init__,RuntimeError | blob | get_event_loop | run_in_executor,base | cloud,pure,yes,18,Check if a file exists in GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.generate_presigned_url,"async generate_presigned_url(key: str, operation: str, expires_in: int) -> str",L3:__init__,RuntimeError | blob | error | generate_signed_url | get_event_loop | run_in_executor | timedelta,base | cloud,pure,yes,33,Generate a signed URL for GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.get_metadata,async get_metadata(key: str) -> Optional[FileMetadata],L3:__init__,FileMetadata | RuntimeError | blob | get_event_loop | run_in_executor,base | cloud,pure,yes,31,Get file metadata without downloading content.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.list_files,"async list_files(prefix: Optional[str], max_keys: int, continuation_token: Optional[str]) -> ListResult",L3:__init__,FileMetadata | ListResult | RuntimeError | append | error | get_event_loop | len | list | list_blobs | run_in_executor,base | cloud,pure,yes,53,List files in GCS.,Unclassified,low,no classification rules matched
integrations,L5,gcs_adapter,GCSAdapter.upload,"async upload(key: str, data: bytes | BinaryIO, content_type: Optional[str], metadata: Optional[Dict[str, str]]) -> UploadResult",L3:__init__,RuntimeError | UploadResult | blob | error | get_event_loop | info | isinstance | len | run_in_executor | seek | str | tell | upload_from_file | upload_from_string,base | cloud,pure,yes,51,Upload a file to GCS.,Unclassified,low,no classification rules matched
integrations,L5,graduation_engine,CapabilityGates.can_auto_activate_policy,can_auto_activate_policy(status: ComputedGraduationStatus) -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,get,__future__,pure,no,9,Gate 2 required: Auto-activate policies only after self-correction proven.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
integrations,L5,graduation_engine,CapabilityGates.can_auto_apply_recovery,can_auto_apply_recovery(status: ComputedGraduationStatus) -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,get,__future__,pure,no,9,Gate 1 required: Auto-apply recovery only after prevention proven.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
integrations,L5,graduation_engine,CapabilityGates.can_full_auto_routing,can_full_auto_routing(status: ComputedGraduationStatus) -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,,__future__,pure,no,7,All gates required: Full autonomous routing only after proven.,Operation,ambiguous,multi-match: Policy/Decision(name matches 'can_'); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
integrations,L5,graduation_engine,CapabilityGates.get_blocked_capabilities,get_blocked_capabilities(status: ComputedGraduationStatus) -> list[str],?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,append | can_auto_activate_policy | can_auto_apply_recovery | can_full_auto_routing,__future__,pure,no,14,Get list of currently blocked capabilities.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,CapabilityGates.get_unlocked_capabilities,get_unlocked_capabilities(status: ComputedGraduationStatus) -> list[str],?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,append | can_auto_activate_policy | can_auto_apply_recovery | can_full_auto_routing,__future__,pure,no,14,Get list of currently unlocked capabilities.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,ComputedGraduationStatus.is_degraded,is_degraded() -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,,__future__,pure,no,2,,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,ComputedGraduationStatus.is_graduated,is_graduated() -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,,__future__,pure,no,2,,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,ComputedGraduationStatus.status_label,status_label() -> str,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,sum | upper | values,__future__,pure,no,8,,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,ComputedGraduationStatus.to_api_response,to_api_response() -> dict,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,isoformat | items,__future__,pure,no,26,Format for API response.,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
integrations,L5,graduation_engine,GraduationEngine.__init__,__init__(thresholds: Optional[GraduationThresholds]),?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,GraduationThresholds,__future__,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,graduation_engine,GraduationEngine._check_degradation,"_check_degradation(previous_level: GraduationLevel, current_level: GraduationLevel, gates: dict[str, GateEvidence], evidence: GraduationEvidence) -> Optional[dict]",?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,items | now,__future__,pure,no,52,Check if graduation should be degraded.,Internal Helper,medium,private function
integrations,L5,graduation_engine,GraduationEngine._evaluate_gate1,_evaluate_gate1(evidence: GraduationEvidence) -> GateEvidence,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,GateEvidence | get | isoformat | min | now,__future__,pure,no,43,Gate 1: Prevention Proof,Internal Helper,medium,private function
integrations,L5,graduation_engine,GraduationEngine._evaluate_gate2,_evaluate_gate2(evidence: GraduationEvidence) -> GateEvidence,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,GateEvidence | get | min | now,__future__,pure,no,35,Gate 2: Regret Rollback,Internal Helper,medium,private function
integrations,L5,graduation_engine,GraduationEngine._evaluate_gate3,_evaluate_gate3(evidence: GraduationEvidence) -> GateEvidence,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,GateEvidence | get | isoformat | min | now,__future__,pure,no,30,Gate 3: Console Timeline,Internal Helper,medium,private function
integrations,L5,graduation_engine,GraduationEngine.compute,"compute(evidence: GraduationEvidence, previous_status: Optional[ComputedGraduationStatus]) -> ComputedGraduationStatus",?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,ComputedGraduationStatus | _check_degradation | _evaluate_gate1 | _evaluate_gate2 | _evaluate_gate3 | now | sum | values,__future__,pure,no,66,Compute graduation status from evidence.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,SimulationState.is_demo_mode,is_demo_mode() -> bool,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,,__future__,pure,no,3,True if any simulation is active.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,graduation_engine,SimulationState.to_display,to_display() -> dict,?:M25_integrations | ?:graduation_evaluator | L2:M25_integrations | ?:test_m25_graduation_downgrade,,__future__,pure,no,11,Display format - clearly marked as simulation.,Operation,ambiguous,multi-match: Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
integrations,L5,http_connector,HttpConnectorError.__init__,"__init__(message: str, status_code: Optional[int])",?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,http_connector,HttpConnectorService.__init__,"__init__(config: HttpConnectorConfig, credential_service: Optional[CredentialService])",?:__init__ | ?:test_connectors,,credentials | httpx,pure,no,8,,Internal Helper,high,dunder method
integrations,L5,http_connector,HttpConnectorService._build_url,"_build_url(path: str, payload: Dict[str, Any]) -> str",?:__init__ | ?:test_connectors,items | replace | rstrip | str,credentials | httpx,pure,no,10,Build URL from base URL and path.,Internal Helper,medium,private function
integrations,L5,http_connector,HttpConnectorService._check_rate_limit,_check_rate_limit(tenant_id: str),?:__init__ | ?:test_connectors,RateLimitExceededError | len | now | timestamp | warning,credentials | httpx,pure,no,22,Check if rate limit exceeded (AC-059-09).,Internal Helper,medium,private function
integrations,L5,http_connector,HttpConnectorService._get_auth_headers,"async _get_auth_headers() -> Dict[str, str]",?:__init__ | ?:test_connectors,b64encode | decode | encode | get | warning,credentials | httpx,pure,yes,22,Get auth headers from vault (machine-controlled).,Internal Helper,medium,private function
integrations,L5,http_connector,HttpConnectorService._record_request,_record_request(tenant_id: str),?:__init__ | ?:test_connectors,append | now,credentials | httpx,pure,no,5,Record a request for rate limiting.,Internal Helper,medium,private function
integrations,L5,http_connector,HttpConnectorService._resolve_endpoint,_resolve_endpoint(action: str) -> EndpointConfig,?:__init__ | ?:test_connectors,ValueError | keys | list,credentials | httpx,pure,no,8,Map action to endpoint (machine-controlled).,Internal Helper,medium,private function
integrations,L5,http_connector,HttpConnectorService.execute,"async execute(action: str, payload: Dict[str, Any], tenant_id: Optional[str]) -> Dict[str, Any]",?:__init__ | ?:test_connectors,AsyncClient | HttpConnectorError | ValueError | _build_url | _check_rate_limit | _get_auth_headers | _record_request | _resolve_endpoint | decode | delete | error | get | json | len | patch,credentials | httpx,"db_write,external_api",yes,130,Execute a governed HTTP request.,Unclassified,low,no classification rules matched
integrations,L5,http_connector,HttpConnectorService.id,id() -> str,?:__init__ | ?:test_connectors,,credentials | httpx,pure,no,3,Connector ID for protocol compliance.,Unclassified,low,no classification rules matched
integrations,L5,http_connector,RateLimitExceededError.__init__,__init__(retry_after_seconds: int),?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,iam_engine,AccessDecision.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,jwt,pure,no,12,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,iam_engine,IAMService.__init__,__init__(),,_setup_default_roles,jwt,pure,no,5,,Internal Helper,high,dunder method
integrations,L5,iam_engine,IAMService._create_system_identity,"_create_system_identity(system_id: str, tenant_id: Optional[str]) -> Identity",,Identity | _expand_role_permissions,jwt,pure,no,16,Create a system identity for internal services.,Internal Helper,medium,private function
integrations,L5,iam_engine,IAMService._expand_role_permissions,_expand_role_permissions(roles: Set[str]) -> Set[str],,set | update,jwt,pure,no,7,Expand roles into their constituent permissions.,Internal Helper,medium,private function
integrations,L5,iam_engine,IAMService._resolve_api_key_identity,"async _resolve_api_key_identity(api_key: str, tenant_id: Optional[str]) -> Optional[Identity]",,Identity | _expand_role_permissions,jwt,pure,yes,19,Resolve identity from API key.,Internal Helper,medium,private function
integrations,L5,iam_engine,IAMService._resolve_clerk_identity,"async _resolve_clerk_identity(token: str, tenant_id: Optional[str]) -> Optional[Identity]",,Identity | _expand_role_permissions | decode | get | set | warning,jwt,pure,yes,33,Resolve identity from Clerk JWT.,Internal Helper,medium,private function
integrations,L5,iam_engine,IAMService._setup_default_roles,_setup_default_roles() -> None,,,jwt,pure,no,44,Set up default role-permission mappings.,Internal Helper,medium,private function
integrations,L5,iam_engine,IAMService.check_access,"async check_access(identity: Identity, resource: str, action: str) -> AccessDecision",,AccessDecision | append | len | warning,jwt,pure,yes,47,Check if an identity can perform an action on a resource.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,iam_engine,IAMService.define_resource_permissions,"define_resource_permissions(resource: str, permissions: Set[str]) -> None",,,jwt,pure,no,7,Define permissions for a resource.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.define_role,"define_role(role_name: str, permissions: Set[str]) -> None",,info | len,jwt,pure,no,8,Define or update a role's permissions.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.get_access_log,"get_access_log(identity_id: Optional[str], resource: Optional[str], limit: int) -> List[AccessDecision]",,,jwt,pure,no,15,Get access decision log for auditing.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.grant_role,"async grant_role(identity_id: str, role: str, granted_by: str) -> bool",,info,jwt,pure,yes,13,Grant a role to an identity.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.list_resources,"list_resources() -> Dict[str, Set[str]]",,dict,jwt,pure,no,3,List all resources and their required permissions.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.list_roles,"list_roles() -> Dict[str, Set[str]]",,dict,jwt,pure,no,3,List all defined roles and their permissions.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,IAMService.resolve_identity,"async resolve_identity(provider: IdentityProvider, token_or_key: str, tenant_id: Optional[str]) -> Optional[Identity]",,_create_system_identity | _resolve_api_key_identity | _resolve_clerk_identity | error | warning,jwt,pure,yes,31,Resolve an identity from a token or API key.,Coordinator/Aggregator,ambiguous,multi-match: Coordinator/Aggregator(name matches 'resolve'); Internal Helper(pure function with no callers)
integrations,L5,iam_engine,IAMService.revoke_role,"async revoke_role(identity_id: str, role: str, revoked_by: str) -> bool",,info,jwt,pure,yes,13,Revoke a role from an identity.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,Identity.has_all_roles,has_all_roles(roles: List[str]) -> bool,,issubset | set,jwt,pure,no,3,Check if identity has all specified roles.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,Identity.has_any_role,has_any_role(roles: List[str]) -> bool,,bool | set,jwt,pure,no,3,Check if identity has any of the specified roles.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,Identity.has_permission,has_permission(permission: str) -> bool,,,jwt,pure,no,3,Check if identity has a specific permission.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,Identity.has_role,has_role(role: str) -> bool,,,jwt,pure,no,3,Check if identity has a specific role.,Internal Helper,low,pure function with no callers
integrations,L5,iam_engine,Identity.to_dict,"to_dict() -> Dict[str, Any]",,isoformat | list,jwt,pure,no,16,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,integrations_facade,IntegrationsFacade.__init__,__init__() -> None,?:aos_cus_integrations | L4:integrations_handler,CusIntegrationService,cus_integration_service,pure,no,3,Initialize with CusIntegrationService.,Internal Helper,high,dunder method
integrations,L5,integrations_facade,IntegrationsFacade.create_integration,async create_integration(tenant_id: UUID) -> IntegrationDetailResult,?:aos_cus_integrations | L4:integrations_handler,IntegrationDetailResult | create_integration | str,cus_integration_service,pure,yes,45,Create a new LLM integration.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.delete_integration,"async delete_integration(tenant_id: UUID, integration_id: str) -> IntegrationDeleteResult",?:aos_cus_integrations | L4:integrations_handler,IntegrationDeleteResult | delete_integration,cus_integration_service,pure,yes,15,Delete an integration (soft delete).,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.disable_integration,"async disable_integration(tenant_id: UUID, integration_id: str) -> Optional[IntegrationLifecycleResult]",?:aos_cus_integrations | L4:integrations_handler,IntegrationLifecycleResult | disable_integration | str,cus_integration_service,pure,yes,19,Disable an integration.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.enable_integration,"async enable_integration(tenant_id: UUID, integration_id: str) -> Optional[IntegrationLifecycleResult]",?:aos_cus_integrations | L4:integrations_handler,IntegrationLifecycleResult | enable_integration | str,cus_integration_service,pure,yes,19,Enable an integration.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.get_health_status,"async get_health_status(tenant_id: UUID, integration_id: str) -> Optional[HealthStatusResult]",?:aos_cus_integrations | L4:integrations_handler,HealthStatusResult | get_integration | str,cus_integration_service,pure,yes,20,Get cached health status without running a new check.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.get_integration,"async get_integration(tenant_id: UUID, integration_id: str) -> Optional[IntegrationDetailResult]",?:aos_cus_integrations | L4:integrations_handler,IntegrationDetailResult | get_integration | str,cus_integration_service,pure,yes,31,Get full details for a specific integration.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.get_limits_status,"async get_limits_status(tenant_id: UUID, integration_id: str) -> Optional[LimitsStatusResult]",?:aos_cus_integrations | L4:integrations_handler,LimitsStatusResult | get_limits_status,cus_integration_service,pure,yes,28,Get current usage against configured limits.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.list_integrations,async list_integrations(tenant_id: UUID) -> IntegrationListResult,?:aos_cus_integrations | L4:integrations_handler,IntegrationListResult | IntegrationSummaryResult | list_integrations | str,cus_integration_service,pure,yes,32,List all integrations for the tenant.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.test_credentials,"async test_credentials(tenant_id: UUID, integration_id: str) -> Optional[HealthCheckResult]",?:aos_cus_integrations | L4:integrations_handler,HealthCheckResult | get | test_credentials,cus_integration_service,pure,yes,21,Test credentials and update health status.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,IntegrationsFacade.update_integration,"async update_integration(tenant_id: UUID, integration_id: str, **update_data) -> Optional[IntegrationDetailResult]",?:aos_cus_integrations | L4:integrations_handler,IntegrationDetailResult | str | update_integration,cus_integration_service,pure,yes,33,Update an existing integration.,Operation,high,called by L4 orchestrator
integrations,L5,integrations_facade,get_integrations_facade,get_integrations_facade() -> IntegrationsFacade,?:aos_cus_integrations | L4:integrations_handler,IntegrationsFacade,cus_integration_service,pure,no,6,Get the singleton IntegrationsFacade instance.,Operation,high,called by L4 orchestrator
integrations,L5,lambda_adapter,LambdaAdapter.__init__,"__init__(region: Optional[str], access_key_id: Optional[str], secret_access_key: Optional[str], **kwargs)",L3:__init__,getenv,aioboto3 | base,pure,no,11,,Internal Helper,high,dunder method
integrations,L5,lambda_adapter,LambdaAdapter.connect,async connect() -> bool,L3:__init__,Session | client | error | info | list_functions,aioboto3 | base,pure,yes,21,Connect to AWS Lambda.,Unclassified,low,no classification rules matched
integrations,L5,lambda_adapter,LambdaAdapter.disconnect,async disconnect() -> None,L3:__init__,info,aioboto3 | base,pure,yes,4,Disconnect from AWS Lambda.,Unclassified,low,no classification rules matched
integrations,L5,lambda_adapter,LambdaAdapter.function_exists,async function_exists(function_name: str) -> bool,L3:__init__,get_function_info,aioboto3 | base,pure,yes,7,Check if a Lambda function exists.,Unclassified,low,no classification rules matched
integrations,L5,lambda_adapter,LambdaAdapter.get_function_info,async get_function_info(function_name: str) -> Optional[FunctionInfo],L3:__init__,FunctionInfo | RuntimeError | client | error | get | get_function,aioboto3 | base,pure,yes,28,Get information about a Lambda function.,Unclassified,low,no classification rules matched
integrations,L5,lambda_adapter,LambdaAdapter.invoke,async invoke(request: InvocationRequest) -> InvocationResult,L3:__init__,InvocationResult | RuntimeError | b64decode | client | decode | dumps | encode | error | get | invoke | loads | read | str | uuid4,aioboto3 | base,file_io,yes,74,Invoke a Lambda function.,Unclassified,low,no classification rules matched
integrations,L5,lambda_adapter,LambdaAdapter.invoke_batch,"async invoke_batch(requests: List[InvocationRequest], max_concurrent: int) -> List[InvocationResult]",L3:__init__,InvocationResult | RuntimeError | Semaphore | append | enumerate | gather | invoke | invoke_with_semaphore | isinstance | str | uuid4,aioboto3 | base,pure,yes,34,Invoke multiple Lambda functions concurrently.,Coordinator/Aggregator,medium,name matches 'batch'
integrations,L5,lambda_adapter,LambdaAdapter.list_functions,"async list_functions(prefix: Optional[str], max_results: int) -> List[FunctionInfo]",L3:__init__,FunctionInfo | RuntimeError | append | client | error | get | len | list_functions | min | startswith,aioboto3 | base,pure,yes,47,List Lambda functions.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,ConfidenceBand.allows_auto_apply,allows_auto_apply() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,3,Only strong matches allow auto-apply.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'allow'); Internal Helper(name matches 'to_')
integrations,L5,loop_events,ConfidenceBand.from_confidence,from_confidence(confidence: float) -> 'ConfidenceBand',L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,8,Classify confidence score into band.,Internal Helper,medium,name matches 'from_'
integrations,L5,loop_events,ConfidenceBand.requires_human_review,requires_human_review() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,3,Weak and novel patterns require human review.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,ConfidenceCalculator.calculate_recovery_confidence,"calculate_recovery_confidence(base_confidence: float, occurrence_count: int, is_strong_match: bool) -> tuple[float, str, dict]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,min,__future__,pure,no,32,Calculate recovery confidence with occurrence boosting.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,ConfidenceCalculator.get_confirmation_level,get_confirmation_level(confidence: float) -> int,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,8,Get required confirmation level based on confidence.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,ConfidenceCalculator.should_auto_apply,"should_auto_apply(confidence: float, occurrence_count: int) -> bool",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,3,Determine if recovery should auto-apply.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'should_'); Internal Helper(name matches 'to_')
integrations,L5,loop_events,HumanCheckpoint.create,"create(checkpoint_type: HumanCheckpointType, incident_id: str, tenant_id: str, stage: LoopStage, target_id: str, description: str, options: list[str] | None) -> 'HumanCheckpoint'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | get | now | uuid4,__future__,pure,no,30,Factory for creating checkpoints.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,HumanCheckpoint.is_pending,is_pending() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,loop_events,HumanCheckpoint.resolve,"resolve(user_id: str, resolution: str) -> None",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,now,__future__,pure,no,5,Resolve checkpoint with user action.,Coordinator/Aggregator,medium,name matches 'resolve'
integrations,L5,loop_events,LoopEvent.create,"create(incident_id: str, tenant_id: str, stage: LoopStage, details: dict[str, Any] | None, failure_state: LoopFailureState | None, confidence_band: ConfidenceBand | None) -> 'LoopEvent'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | now | uuid4,__future__,pure,no,21,Factory method to create events with auto-generated ID and timestamp.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,LoopEvent.is_blocked,is_blocked() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,6,Check if loop is blocked at this stage.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,LoopEvent.is_success,is_success() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,3,Check if event represents successful stage completion.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,LoopEvent.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,isoformat,__future__,pure,no,14,Serialize for Redis/JSON.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,LoopStatus._generate_narrative,"_generate_narrative() -> dict[str, str]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,33,Generate narrative artifacts for storytelling.,Internal Helper,medium,private function
integrations,L5,loop_events,LoopStatus.completion_pct,completion_pct() -> float,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,len,__future__,pure,no,3,Calculate loop completion percentage.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,LoopStatus.to_console_display,"to_console_display() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,_generate_narrative | append,__future__,pure,no,46,Format for console display:,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,LoopStatus.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,isoformat | to_dict,__future__,pure,no,22,Serialize for JSON/Redis storage.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,PatternMatchResult.from_match,"from_match(incident_id: str, pattern_id: str, confidence: float, signature_hash: str, is_new: bool, details: dict[str, Any] | None) -> 'PatternMatchResult'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | from_confidence,__future__,pure,no,21,Create result from successful match.,Internal Helper,medium,name matches 'from_'
integrations,L5,loop_events,PatternMatchResult.no_match,"no_match(incident_id: str, signature_hash: str) -> 'PatternMatchResult'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls,__future__,pure,no,11,Create result for no match found.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PatternMatchResult.should_auto_proceed,should_auto_proceed() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,3,Only proceed automatically for strong matches.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'should_'); Internal Helper(name matches 'to_')
integrations,L5,loop_events,PatternMatchResult.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,13,Serialize for JSON/Redis.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,PolicyRule.add_confirmation,add_confirmation() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,now,__future__,pure,no,8,Add confirmation. Returns True if ready to activate.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PolicyRule.create,"create(name: str, description: str, category: str, condition: str, action: str, source_pattern_id: str, source_recovery_id: str, confidence: float, scope_type: str, scope_id: str | None, confirmations_required: int) -> 'PolicyRule'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | from_confidence | uuid4,__future__,pure,no,37,Factory method for creating policy rules.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PolicyRule.record_regret,record_regret() -> None,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,6,Record when this policy caused an incident (regret).,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PolicyRule.record_shadow_evaluation,record_shadow_evaluation(would_block: bool) -> None,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,5,Track shadow mode evaluations for confidence building.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PolicyRule.shadow_block_rate,shadow_block_rate() -> float,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,5,Percentage of shadow evaluations that would have blocked.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,PolicyRule.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,isoformat,__future__,pure,no,25,Serialize for JSON/Redis.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,RecoverySuggestion.add_confirmation,add_confirmation() -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,7,Add a confirmation. Returns True if threshold reached.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RecoverySuggestion.create,"create(incident_id: str, pattern_id: str, action_type: str, action_params: dict[str, Any], confidence: float, suggestion_type: Literal['template', 'generated'], requires_confirmation: int) -> 'RecoverySuggestion'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | from_confidence | uuid4,__future__,pure,no,25,Factory method for creating recovery suggestions.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RecoverySuggestion.none_available,"none_available(incident_id: str, pattern_id: str) -> 'RecoverySuggestion'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | uuid4,__future__,pure,no,16,Create placeholder when no recovery is available.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RecoverySuggestion.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,17,Serialize for JSON/Redis.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,RoutingAdjustment.check_kpi_regression,check_kpi_regression(current_kpi: float) -> bool,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,rollback,__future__,pure,no,16,Check if KPI has regressed past threshold.,Policy/Decision,medium,name matches 'check'
integrations,L5,loop_events,RoutingAdjustment.create,"create(agent_id: str, adjustment_type: str, magnitude: float, reason: str, source_policy_id: str, capability: str | None, max_delta: float, decay_days: int) -> 'RoutingAdjustment'",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,cls | max | min | now | replace | uuid4,__future__,pure,no,33,Factory with guardrail enforcement.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RoutingAdjustment.effective_magnitude,effective_magnitude() -> float,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,now | total_seconds,__future__,pure,no,15,Calculate current magnitude with decay applied.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RoutingAdjustment.rollback,rollback(reason: str) -> None,L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,,__future__,pure,no,5,Rollback this adjustment.,Unclassified,low,no classification rules matched
integrations,L5,loop_events,RoutingAdjustment.to_dict,"to_dict() -> dict[str, Any]",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,isoformat,__future__,pure,no,22,Serialize for JSON/Redis.,Internal Helper,medium,name matches 'to_'
integrations,L5,loop_events,ensure_json_serializable,"ensure_json_serializable(obj: Any, path: str) -> Any",L6:bridges_driver | L5s:__init__ | L5:bridges | L5:dispatcher | L5:cost_bridges_engine,TypeError | ensure_json_serializable | enumerate | hasattr | isinstance | isoformat | items | to_dict | type,__future__,pure,no,26,Guard function to ensure all objects stored in details are JSON-serializable.,Unclassified,low,no classification rules matched
integrations,L5,mcp_connector,McpApprovalRequiredError.__init__,__init__(tool_name: str),?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx | jsonschema,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,mcp_connector,McpConnectorError.__init__,"__init__(message: str, code: Optional[int])",?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx | jsonschema,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,mcp_connector,McpConnectorService.__init__,"__init__(config: McpConnectorConfig, tool_registry: Dict[str, McpToolDefinition], credential_service: Optional[CredentialService])",?:__init__ | ?:test_connectors,,credentials | httpx | jsonschema,pure,no,10,,Internal Helper,high,dunder method
integrations,L5,mcp_connector,McpConnectorService._build_mcp_request,"_build_mcp_request(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]",?:__init__ | ?:test_connectors,,credentials | httpx | jsonschema,pure,no,15,Build MCP JSON-RPC request.,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService._check_rate_limit,_check_rate_limit(tenant_id: str),?:__init__ | ?:test_connectors,McpRateLimitExceededError | len | now | timestamp | warning,credentials | httpx | jsonschema,pure,no,22,Check if rate limit exceeded.,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService._get_api_key,async _get_api_key() -> str,?:__init__ | ?:test_connectors,McpConnectorError | get,credentials | httpx | jsonschema,pure,yes,7,Get API key from vault (machine-controlled).,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService._record_request,_record_request(tenant_id: str),?:__init__ | ?:test_connectors,append | now,credentials | httpx | jsonschema,pure,no,5,Record a request for rate limiting.,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService._resolve_tool,_resolve_tool(tool_name: str) -> McpToolDefinition,?:__init__ | ?:test_connectors,ValueError | keys | list,credentials | httpx | jsonschema,pure,no,15,Resolve tool by name (machine-controlled allowlist).,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService._validate_against_schema,"_validate_against_schema(schema: Dict[str, Any], payload: Dict[str, Any])",?:__init__ | ?:test_connectors,Draft7Validator | McpSchemaValidationError | iter_errors | str | validate | warning,credentials | httpx | jsonschema,pure,no,25,Validate payload against JSON Schema.,Internal Helper,medium,private function
integrations,L5,mcp_connector,McpConnectorService.execute,"async execute(action: str, payload: Dict[str, Any], tenant_id: Optional[str]) -> Dict[str, Any]",?:__init__ | ?:test_connectors,AsyncClient | McpApprovalRequiredError | McpConnectorError | _build_mcp_request | _check_rate_limit | _get_api_key | _record_request | _resolve_tool | _validate_against_schema | error | get | json | len | min | post,credentials | httpx | jsonschema,external_api,yes,139,Execute an MCP tool call.,Unclassified,low,no classification rules matched
integrations,L5,mcp_connector,McpConnectorService.get_available_tools,"get_available_tools() -> List[Dict[str, Any]]",?:__init__ | ?:test_connectors,append,credentials | httpx | jsonschema,pure,no,13,Get list of available tools with their schemas.,Unclassified,low,no classification rules matched
integrations,L5,mcp_connector,McpConnectorService.id,id() -> str,?:__init__ | ?:test_connectors,,credentials | httpx | jsonschema,pure,no,3,Connector ID for protocol compliance.,Unclassified,low,no classification rules matched
integrations,L5,mcp_connector,McpRateLimitExceededError.__init__,__init__(retry_after_seconds: int),?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx | jsonschema,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,mcp_connector,McpSchemaValidationError.__init__,"__init__(message: str, errors: List[str])",?:__init__ | ?:test_connectors,__init__ | super,credentials | httpx | jsonschema,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,pgvector_adapter,PGVectorAdapter.__init__,"__init__(database_url: Optional[str], table_name: str, dimension: int, index_type: str, **kwargs)",L3:__init__,getenv,asyncpg | base,pure,no,13,,Internal Helper,high,dunder method
integrations,L5,pgvector_adapter,PGVectorAdapter.connect,async connect() -> bool,L3:__init__,acquire | create_pool | error | execute | info,asyncpg | base,pure,yes,57,Connect to PostgreSQL and ensure pgvector is set up.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.create_namespace,async create_namespace(namespace: str) -> bool,L3:__init__,info,asyncpg | base,pure,yes,8,Create a namespace in PGVector.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.delete,"async delete(ids: Optional[List[str]], namespace: Optional[str], filter: Optional[Dict[str, Any]], delete_all: bool) -> DeleteResult",L3:__init__,DeleteResult | RuntimeError | acquire | append | error | execute | info | int | isinstance | items | split,asyncpg | base,pure,yes,59,Delete vectors from PGVector.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.delete_namespace,async delete_namespace(namespace: str) -> bool,L3:__init__,delete,asyncpg | base,db_write,yes,4,Delete a namespace from PGVector.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.disconnect,async disconnect() -> None,L3:__init__,close | info,asyncpg | base,pure,yes,6,Disconnect from PostgreSQL.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.get_stats,async get_stats(namespace: Optional[str]) -> IndexStats,L3:__init__,IndexStats | RuntimeError | acquire | error | fetch | fetchval,asyncpg | base,pure,yes,34,Get PGVector statistics.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.list_namespaces,async list_namespaces() -> List[str],L3:__init__,RuntimeError | acquire | error | fetch,asyncpg | base,pure,yes,19,List all namespaces in PGVector.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.query,"async query(vector: List[float], top_k: int, namespace: Optional[str], filter: Optional[Dict[str, Any]], include_vectors: bool, include_metadata: bool) -> List[QueryResult]",L3:__init__,QueryResult | RuntimeError | acquire | append | debug | dict | error | fetch | float | get | isinstance | items | join | len | map,asyncpg | base,pure,yes,75,Query PGVector for similar vectors.,Unclassified,low,no classification rules matched
integrations,L5,pgvector_adapter,PGVectorAdapter.upsert,"async upsert(records: List[VectorRecord], namespace: Optional[str]) -> UpsertResult",L3:__init__,RuntimeError | UpsertResult | acquire | append | dumps | error | execute | info | join | len | map | str,asyncpg | base,pure,yes,50,Upsert vectors to PGVector.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.__init__,"__init__(api_key: Optional[str], environment: Optional[str], index_name: Optional[str], dimension: int, metric: str, **kwargs)",L3:__init__,getenv,base | pinecone,pure,no,16,,Internal Helper,high,dunder method
integrations,L5,pinecone_adapter,PineconeAdapter.connect,async connect() -> bool,L3:__init__,Index | Pinecone | create_index | error | info | list_indexes,base | pinecone,pure,yes,32,Connect to Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.create_namespace,async create_namespace(namespace: str) -> bool,L3:__init__,info,base | pinecone,pure,yes,9,Create a namespace in Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.delete,"async delete(ids: Optional[List[str]], namespace: Optional[str], filter: Optional[Dict[str, Any]], delete_all: bool) -> DeleteResult",L3:__init__,DeleteResult | RuntimeError | delete | error | info | len,base | pinecone,db_write,yes,32,Delete vectors from Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.delete_namespace,async delete_namespace(namespace: str) -> bool,L3:__init__,RuntimeError | delete | error | info,base | pinecone,db_write,yes,13,Delete a namespace from Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.disconnect,async disconnect() -> None,L3:__init__,info,base | pinecone,pure,yes,5,Disconnect from Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.get_stats,async get_stats(namespace: Optional[str]) -> IndexStats,L3:__init__,IndexStats | RuntimeError | describe_index_stats | error | items,base | pinecone,pure,yes,23,Get Pinecone index statistics.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.list_namespaces,async list_namespaces() -> List[str],L3:__init__,RuntimeError | describe_index_stats | error | keys | list,base | pinecone,pure,yes,13,List all namespaces in Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.query,"async query(vector: List[float], top_k: int, namespace: Optional[str], filter: Optional[Dict[str, Any]], include_vectors: bool, include_metadata: bool) -> List[QueryResult]",L3:__init__,QueryResult | RuntimeError | append | debug | error | len | query,base | pinecone,pure,yes,40,Query Pinecone for similar vectors.,Unclassified,low,no classification rules matched
integrations,L5,pinecone_adapter,PineconeAdapter.upsert,"async upsert(records: List[VectorRecord], namespace: Optional[str]) -> UpsertResult",L3:__init__,RuntimeError | UpsertResult | append | error | extend | info | len | range | str | upsert,base | pinecone,pure,yes,45,Upsert vectors to Pinecone.,Unclassified,low,no classification rules matched
integrations,L5,prevention_contract,PreventionContractViolation.__init__,"__init__(rule: str, details: str)",L5:__init__,__init__ | super,__future__,pure,no,4,,Internal Helper,high,dunder method
integrations,L5,prevention_contract,assert_no_deletion,assert_no_deletion(record_id: str) -> None,L5:__init__,PreventionContractViolation,__future__,pure,no,9,Assert that a prevention record cannot be deleted.,Policy/Decision,medium,name matches 'assert'
integrations,L5,prevention_contract,assert_prevention_immutable,"assert_prevention_immutable(record_id: str, existing_record: dict[str, Any]) -> None",L5:__init__,PreventionContractViolation,__future__,pure,no,10,Assert that a prevention record has not been modified.,Policy/Decision,medium,name matches 'assert'
integrations,L5,prevention_contract,validate_prevention_candidate,validate_prevention_candidate(candidate: PreventionCandidate) -> None,L5:__init__,PreventionContractViolation | info,__future__,pure,no,55,Validate that a prevention candidate satisfies the contract.,Policy/Decision,medium,name matches 'validate'
integrations,L5,prevention_contract,validate_prevention_for_graduation,"validate_prevention_for_graduation(prevention_record: dict[str, Any], policy_activated_at: datetime) -> bool",L5:__init__,debug | get | info | isinstance | replace,__future__,pure,no,32,Validate that a prevention record counts toward graduation.,Policy/Decision,medium,name matches 'validate'
integrations,L5,protocol,CredentialService.get,async get(credential_ref: str) -> Credential,L5:http_connector | L5:mcp_connector | L5:sql_gateway | L5:__init__ | ?:credential_service,,types,pure,yes,11,Get credential from vault.,Unclassified,low,no classification rules matched
integrations,L5,runtime_adapter,RuntimeAdapter.__init__,__init__(),?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,getLogger,runtime_command,pure,no,3,Initialize the adapter.,Internal Helper,high,dunder method
integrations,L5,runtime_adapter,RuntimeAdapter.describe_skill,describe_skill(skill_id: str) -> Optional[SkillInfo],?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,debug | get_skill_info,runtime_command,pure,no,18,Get skill description.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.get_capabilities,"get_capabilities(agent_id: Optional[str], tenant_id: Optional[str]) -> CapabilitiesInfo",?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,debug | get_capabilities,runtime_command,pure,no,23,Get capabilities for an agent/tenant.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.get_resource_contract,get_resource_contract(resource_id: str) -> ResourceContractInfo,?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,debug | get_resource_contract,runtime_command,pure,no,18,Get resource contract.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.get_skill_descriptors,"get_skill_descriptors() -> Dict[str, Dict[str, Any]]",?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,get_all_skill_descriptors,runtime_command,pure,no,8,Get descriptors for all skills.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.get_supported_queries,get_supported_queries() -> List[str],?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,get_supported_query_types,runtime_command,pure,no,8,Get list of supported query types.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.list_skills,list_skills() -> List[str],?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,list_skills,runtime_command,pure,no,8,List all available skills.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,RuntimeAdapter.query,"query(query_type: str, params: Optional[Dict[str, Any]]) -> QueryResult",?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,debug | execute_query,runtime_command,pure,no,26,Execute a runtime query.,Operation,high,called by L4 orchestrator
integrations,L5,runtime_adapter,get_runtime_adapter,get_runtime_adapter() -> RuntimeAdapter,?:runtime | L3:__init__ | L2:runtime | L4:runtime_adapter,RuntimeAdapter,runtime_command,pure,no,12,Factory function to get RuntimeAdapter instance.,Operation,high,called by L4 orchestrator
integrations,L5,s3_adapter,S3Adapter.__init__,"__init__(bucket_name: Optional[str], region: Optional[str], access_key_id: Optional[str], secret_access_key: Optional[str], endpoint_url: Optional[str], **kwargs)",L3:__init__,getenv,aioboto3 | base,pure,no,16,,Internal Helper,high,dunder method
integrations,L5,s3_adapter,S3Adapter.connect,async connect() -> bool,L3:__init__,Session | client | create_bucket | error | head_bucket | info,aioboto3 | base,pure,yes,30,Connect to S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.copy,"async copy(source_key: str, dest_key: str) -> bool",L3:__init__,RuntimeError | client | copy_object | error | info,aioboto3 | base,pure,yes,23,Copy a file within S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.delete,async delete(key: str) -> bool,L3:__init__,RuntimeError | client | delete_object | error | info,aioboto3 | base,pure,yes,21,Delete a file from S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.delete_many,async delete_many(keys: List[str]) -> int,L3:__init__,RuntimeError | client | delete_objects | error | get | info | len | range,aioboto3 | base,pure,yes,32,Delete multiple files from S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.disconnect,async disconnect() -> None,L3:__init__,info,aioboto3 | base,pure,yes,4,Disconnect from S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.download,async download(key: str) -> DownloadResult,L3:__init__,DownloadResult | FileMetadata | RuntimeError | client | debug | error | get | get_object | read | strip,aioboto3 | base,file_io,yes,32,Download a file from S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.download_stream,"async download_stream(key: str, chunk_size: int) -> AsyncIterator[bytes]",L3:__init__,RuntimeError | client | get_object | iter_chunks,aioboto3 | base,pure,yes,17,Stream download a file from S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.exists,async exists(key: str) -> bool,L3:__init__,RuntimeError | client | head_object,aioboto3 | base,pure,yes,18,Check if a file exists in S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.generate_presigned_url,"async generate_presigned_url(key: str, operation: str, expires_in: int) -> str",L3:__init__,RuntimeError | client | error | generate_presigned_url,aioboto3 | base,pure,yes,23,Generate a presigned URL for S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.get_metadata,async get_metadata(key: str) -> Optional[FileMetadata],L3:__init__,FileMetadata | RuntimeError | client | get | head_object | strip,aioboto3 | base,pure,yes,26,Get file metadata without downloading content.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.list_files,"async list_files(prefix: Optional[str], max_keys: int, continuation_token: Optional[str]) -> ListResult",L3:__init__,FileMetadata | ListResult | RuntimeError | append | client | error | get | list_objects_v2 | strip,aioboto3 | base,pure,yes,43,List files in S3.,Unclassified,low,no classification rules matched
integrations,L5,s3_adapter,S3Adapter.upload,"async upload(key: str, data: bytes | BinaryIO, content_type: Optional[str], metadata: Optional[Dict[str, str]]) -> UploadResult",L3:__init__,RuntimeError | UploadResult | client | error | get | info | isinstance | len | put_object | seek | strip | tell | upload_fileobj,aioboto3 | base,pure,yes,51,Upload a file to S3.,Unclassified,low,no classification rules matched
integrations,L5,serverless_base,FunctionInfo.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,,pure,no,12,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,serverless_base,InvocationRequest.to_dict,"to_dict() -> Dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,serverless_base,InvocationResult.success,success() -> bool,,,,pure,no,2,,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,InvocationResult.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,,pure,no,14,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,serverless_base,ServerlessAdapter.connect,async connect() -> bool,,,,pure,yes,8,Connect to the serverless platform.,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,ServerlessAdapter.disconnect,async disconnect() -> None,,,,pure,yes,3,Disconnect from the serverless platform.,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,ServerlessAdapter.function_exists,async function_exists(function_name: str) -> bool,,,,pure,yes,14,Check if a function exists.,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,ServerlessAdapter.get_function_info,async get_function_info(function_name: str) -> Optional[FunctionInfo],,,,pure,yes,14,Get information about a function.,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,ServerlessAdapter.health_check,async health_check() -> bool,,list_functions | warning,,pure,yes,13,Check if the serverless platform is healthy.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,serverless_base,ServerlessAdapter.invoke,async invoke(request: InvocationRequest) -> InvocationResult,,,,pure,yes,14,Invoke a serverless function.,Internal Helper,low,pure function with no callers
integrations,L5,serverless_base,ServerlessAdapter.invoke_batch,"async invoke_batch(requests: List[InvocationRequest], max_concurrent: int) -> List[InvocationResult]",,,,pure,yes,16,Invoke multiple functions concurrently.,Coordinator/Aggregator,ambiguous,multi-match: Coordinator/Aggregator(name matches 'batch'); Internal Helper(pure function with no callers)
integrations,L5,serverless_base,ServerlessAdapter.list_functions,"async list_functions(prefix: Optional[str], max_results: int) -> List[FunctionInfo]",,,,pure,yes,16,List available functions.,Internal Helper,low,pure function with no callers
integrations,L5,service,CredentialService.__init__,"__init__(vault: CredentialVault, audit_enabled: bool)",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,,vault,pure,no,8,,Internal Helper,high,dunder method
integrations,L5,service,CredentialService._audit,"_audit(credential_id: str, tenant_id: str, accessor_id: str, accessor_type: str, action: str, success: bool, error_message: Optional[str]) -> None",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,CredentialAccessRecord | append | len | now,vault,pure,no,29,Record an access for auditing.,Internal Helper,medium,private function
integrations,L5,service,CredentialService._validate_name,_validate_name(name: str) -> None,?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,ValueError | len | strip,vault,pure,no,6,Validate credential name.,Internal Helper,medium,private function
integrations,L5,service,CredentialService._validate_secret_data,"_validate_secret_data(credential_type: CredentialType, secret_data: Dict[str, str]) -> None",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,ValueError | issubset | keys,vault,pure,no,32,Validate secret data based on credential type.,Internal Helper,medium,private function
integrations,L5,service,CredentialService._validate_tenant_id,_validate_tenant_id(tenant_id: str) -> None,?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,ValueError | len | strip,vault,pure,no,6,Validate tenant ID.,Internal Helper,medium,private function
integrations,L5,service,CredentialService.delete_credential,"async delete_credential(tenant_id: str, credential_id: str, accessor_id: Optional[str], accessor_type: str) -> bool",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,_audit | delete_credential | str,vault,pure,yes,34,Delete a credential.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.get_access_log,"get_access_log(tenant_id: Optional[str], credential_id: Optional[str], limit: int) -> List[CredentialAccessRecord]",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,,vault,pure,no,15,Get credential access log (for auditing).,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.get_credential,"async get_credential(tenant_id: str, credential_id: str, accessor_id: Optional[str], accessor_type: str) -> Optional[CredentialData]",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,_audit | get_credential | now | str | warning,vault,pure,yes,70,Get a credential with expiration checking.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.get_expiring_credentials,"async get_expiring_credentials(tenant_id: str, days_until_expiry: int) -> List[CredentialMetadata]",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,list_credentials | now | timedelta,vault,pure,yes,20,Get credentials expiring within specified days.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.get_rotatable_credentials,async get_rotatable_credentials(tenant_id: str) -> List[CredentialMetadata],?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,append | list_credentials | now | timedelta,vault,pure,yes,21,Get credentials that need rotation based on their schedule.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.get_secret_value,"async get_secret_value(tenant_id: str, credential_id: str, key: str, accessor_id: Optional[str], accessor_type: str) -> Optional[str]",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,get | get_credential,vault,pure,yes,32,Get a specific secret value from a credential.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.list_credentials,"async list_credentials(tenant_id: str, credential_type: Optional[CredentialType], tags: Optional[List[str]], include_expired: bool) -> List[CredentialMetadata]",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,list_credentials | now,vault,pure,yes,30,List credentials for a tenant.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.rotate_credential,"async rotate_credential(tenant_id: str, credential_id: str, new_secret_data: Dict[str, str], accessor_id: Optional[str], accessor_type: str) -> bool",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,_audit | rotate_credential | str,vault,pure,yes,39,Rotate a credential's secrets.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.store_credential,"async store_credential(tenant_id: str, name: str, credential_type: CredentialType, secret_data: Dict[str, str], description: Optional[str], tags: Optional[List[str]], expires_at: Optional[datetime], is_rotatable: bool, rotation_interval_days: Optional[int], metadata: Optional[Dict[str, Any]], accessor_id: Optional[str], accessor_type: str) -> str",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,_audit | _validate_name | _validate_secret_data | _validate_tenant_id | info | store_credential | str,vault,pure,yes,80,Store a credential with validation.,Unclassified,low,no classification rules matched
integrations,L5,service,CredentialService.update_credential,"async update_credential(tenant_id: str, credential_id: str, secret_data: Optional[Dict[str, str]], description: Optional[str], tags: Optional[List[str]], expires_at: Optional[datetime], metadata: Optional[Dict[str, Any]], accessor_id: Optional[str], accessor_type: str) -> bool",?:rbac_engine | ?:role_mapping | ?:__init__ | ?:agent_spawn | ?:definitions | ?:failure_intelligence | ?:datasets | L5:datasets,_audit | str | update_credential,vault,pure,yes,47,Update a credential.,Unclassified,low,no classification rules matched
integrations,L5,slack_adapter,SlackAdapter.__init__,"__init__(bot_token: Optional[str], default_channel: Optional[str], app_name: Optional[str])",L3:__init__,getenv,async_client | base,pure,no,11,,Internal Helper,high,dunder method
integrations,L5,slack_adapter,SlackAdapter._build_blocks,"_build_blocks(message: NotificationMessage) -> List[Dict[str, Any]]",L3:__init__,_get_priority_emoji | append | len | upper,async_client | base,pure,no,59,Build Slack blocks for rich formatting.,Internal Helper,medium,private function
integrations,L5,slack_adapter,SlackAdapter._get_priority_emoji,_get_priority_emoji(priority: NotificationPriority) -> str,L3:__init__,get,async_client | base,pure,no,8,Get emoji for priority level.,Internal Helper,medium,private function
integrations,L5,slack_adapter,SlackAdapter.connect,async connect() -> bool,L3:__init__,AsyncWebClient | RuntimeError | auth_test | error | get | info,async_client | base,pure,yes,18,Connect to Slack API.,Unclassified,low,no classification rules matched
integrations,L5,slack_adapter,SlackAdapter.disconnect,async disconnect() -> None,L3:__init__,info,async_client | base,pure,yes,4,Disconnect from Slack API.,Unclassified,low,no classification rules matched
integrations,L5,slack_adapter,SlackAdapter.get_status,async get_status(message_id: str) -> Optional[NotificationResult],L3:__init__,get,async_client | base,pure,yes,6,Get the status of a sent Slack message.,Unclassified,low,no classification rules matched
integrations,L5,slack_adapter,SlackAdapter.send,async send(message: NotificationMessage) -> NotificationResult,L3:__init__,NotificationResult | RuntimeError | _build_blocks | append | chat_postMessage | error | get | info | len | str | uuid4,async_client | base,pure,yes,66,Send a Slack notification.,Unclassified,low,no classification rules matched
integrations,L5,slack_adapter,SlackAdapter.send_batch,"async send_batch(messages: List[NotificationMessage], max_concurrent: int) -> List[NotificationResult]",L3:__init__,NotificationResult | RuntimeError | Semaphore | append | enumerate | gather | isinstance | send | send_with_semaphore | str | uuid4,async_client | base,pure,yes,34,Send multiple Slack messages concurrently.,Coordinator/Aggregator,medium,name matches 'batch'
integrations,L5,slack_adapter,SlackAdapter.send_thread_reply,"async send_thread_reply(channel: str, thread_ts: str, text: str) -> NotificationResult",L3:__init__,NotificationResult | RuntimeError | chat_postMessage | get | str | uuid4,async_client | base,pure,yes,46,Send a reply to a thread.,Unclassified,low,no classification rules matched
integrations,L5,smtp_adapter,SMTPAdapter.__init__,"__init__(host: Optional[str], port: Optional[int], username: Optional[str], password: Optional[str], use_tls: bool, from_address: Optional[str], from_name: Optional[str], timeout: int)",L3:__init__,getenv | int,aiosmtplib | base | email | multipart | text,pure,no,21,,Internal Helper,high,dunder method
integrations,L5,smtp_adapter,SMTPAdapter._build_email,"_build_email(message: NotificationMessage, message_id: str) -> MIMEMultipart",L3:__init__,MIMEBase | MIMEMultipart | MIMEText | add_header | attach | encode_base64 | get | join | set_payload,aiosmtplib | base | email | multipart | text,pure,no,46,Build a MIME email message.,Internal Helper,medium,private function
integrations,L5,smtp_adapter,SMTPAdapter.connect,async connect() -> bool,L3:__init__,SMTP | connect | error | info | login | quit,aiosmtplib | base | email | multipart | text,pure,yes,27,Connect to SMTP server (test connection).,Unclassified,low,no classification rules matched
integrations,L5,smtp_adapter,SMTPAdapter.disconnect,async disconnect() -> None,L3:__init__,info,aiosmtplib | base | email | multipart | text,pure,yes,4,Disconnect from SMTP server.,Unclassified,low,no classification rules matched
integrations,L5,smtp_adapter,SMTPAdapter.get_status,async get_status(message_id: str) -> Optional[NotificationResult],L3:__init__,get,aiosmtplib | base | email | multipart | text,pure,yes,6,Get the status of a sent email.,Unclassified,low,no classification rules matched
integrations,L5,smtp_adapter,SMTPAdapter.send,async send(message: NotificationMessage) -> NotificationResult,L3:__init__,NotificationResult | SMTP | _build_email | as_string | connect | error | info | keys | len | list | login | quit | sendmail | str | uuid4,aiosmtplib | base | email | multipart | text,pure,yes,70,Send an email notification.,Unclassified,low,no classification rules matched
integrations,L5,smtp_adapter,SMTPAdapter.send_batch,"async send_batch(messages: List[NotificationMessage], max_concurrent: int) -> List[NotificationResult]",L3:__init__,NotificationResult | Semaphore | append | enumerate | gather | isinstance | send | send_with_semaphore | str | uuid4,aiosmtplib | base | email | multipart | text,pure,yes,31,Send multiple emails concurrently.,Coordinator/Aggregator,medium,name matches 'batch'
integrations,L5,sql_gateway,SqlGatewayService.__init__,"__init__(config: SqlGatewayConfig, template_registry: Dict[str, QueryTemplate], credential_service: Optional[CredentialService])",?:__init__ | ?:test_connectors,,asyncpg | credentials,pure,no,9,,Internal Helper,high,dunder method
integrations,L5,sql_gateway,SqlGatewayService._check_sql_injection,_check_sql_injection(value: str),?:__init__ | ?:test_connectors,SqlInjectionAttemptError | upper | warning,asyncpg | credentials,pure,no,19,Check for SQL injection patterns.,Internal Helper,medium,private function
integrations,L5,sql_gateway,SqlGatewayService._coerce_parameter,"_coerce_parameter(value: Any, spec: ParameterSpec) -> Any",?:__init__ | ?:test_connectors,UUID | ValueError | _check_sql_injection | bool | date | float | fromisoformat | int | isinstance | len | lower | str | strptime,asyncpg | credentials,pure,no,73,Coerce and validate a single parameter.,Internal Helper,medium,private function
integrations,L5,sql_gateway,SqlGatewayService._get_connection_string,async _get_connection_string() -> str,?:__init__ | ?:test_connectors,SqlGatewayError | get,asyncpg | credentials,pure,yes,9,Get connection string from vault (machine-controlled).,Internal Helper,medium,private function
integrations,L5,sql_gateway,SqlGatewayService._resolve_template,_resolve_template(template_id: str) -> QueryTemplate,?:__init__ | ?:test_connectors,ValueError | keys | list,asyncpg | credentials,pure,no,17,Resolve template by ID (machine-controlled).,Internal Helper,medium,private function
integrations,L5,sql_gateway,SqlGatewayService._validate_parameters,"_validate_parameters(template: QueryTemplate, payload: Dict[str, Any]) -> Dict[str, Any]",?:__init__ | ?:test_connectors,ValueError | _coerce_parameter | keys | list | set | warning,asyncpg | credentials,pure,no,43,Validate and type-coerce parameters.,Internal Helper,medium,private function
integrations,L5,sql_gateway,SqlGatewayService.execute,"async execute(action: str, payload: Dict[str, Any], tenant_id: Optional[str]) -> Dict[str, Any]",?:__init__ | ?:test_connectors,SqlGatewayError | _get_connection_string | _resolve_template | _validate_parameters | close | connect | dict | encode | error | fetch | get | len | min | pop | str,asyncpg | credentials,pure,yes,118,Execute a templated SQL query.,Unclassified,low,no classification rules matched
integrations,L5,sql_gateway,SqlGatewayService.id,id() -> str,?:__init__ | ?:test_connectors,,asyncpg | credentials,pure,no,3,Connector ID for protocol compliance.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialData.credential_id,credential_id() -> str,L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialData.tenant_id,tenant_id() -> str,L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,no,2,,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.delete_credential,"async delete_credential(tenant_id: str, credential_id: str) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,16,Delete a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.get_credential,"async get_credential(tenant_id: str, credential_id: str) -> Optional[CredentialData]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,16,Get a credential by ID.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.get_metadata,"async get_metadata(tenant_id: str, credential_id: str) -> Optional[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,16,Get credential metadata without secret values.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.list_credentials,"async list_credentials(tenant_id: str, credential_type: Optional[CredentialType], tags: Optional[list[str]]) -> list[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,18,List credentials for a tenant (metadata only).,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.rotate_credential,"async rotate_credential(tenant_id: str, credential_id: str, new_secret_data: Dict[str, str]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,18,Rotate a credential's secret values.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.store_credential,"async store_credential(tenant_id: str, name: str, credential_type: CredentialType, secret_data: Dict[str, str], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], is_rotatable: bool, rotation_interval_days: Optional[int], metadata: Optional[Dict[str, Any]]) -> str",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,32,Store a credential and return its ID.,Unclassified,low,no classification rules matched
integrations,L5,vault,CredentialVault.update_credential,"async update_credential(tenant_id: str, credential_id: str, secret_data: Optional[Dict[str, str]], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], metadata: Optional[Dict[str, Any]]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,yes,26,Update a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.__init__,__init__(),L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,no,3,,Internal Helper,high,dunder method
integrations,L5,vault,EnvCredentialVault.delete_credential,"async delete_credential(tenant_id: str, credential_id: str) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,pop,httpx,pure,yes,12,Delete a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.get_credential,"async get_credential(tenant_id: str, credential_id: str) -> Optional[CredentialData]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,CredentialData | CredentialMetadata | get | getenv | now | replace | upper,httpx,pure,yes,29,Get credential from memory or environment.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.get_metadata,"async get_metadata(tenant_id: str, credential_id: str) -> Optional[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,get,httpx,pure,yes,8,Get credential metadata.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.list_credentials,"async list_credentials(tenant_id: str, credential_type: Optional[CredentialType], tags: Optional[list[str]]) -> list[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,all | append | items | startswith,httpx,pure,yes,17,List credentials for tenant.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.rotate_credential,"async rotate_credential(tenant_id: str, credential_id: str, new_secret_data: Dict[str, str]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,update_credential,httpx,pure,yes,12,Rotate credential secrets.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.store_credential,"async store_credential(tenant_id: str, name: str, credential_type: CredentialType, secret_data: Dict[str, str], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], is_rotatable: bool, rotation_interval_days: Optional[int], metadata: Optional[Dict[str, Any]]) -> str",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,CredentialMetadata | info | now | str | uuid4,httpx,pure,yes,40,Store credential in memory.,Unclassified,low,no classification rules matched
integrations,L5,vault,EnvCredentialVault.update_credential,"async update_credential(tenant_id: str, credential_id: str, secret_data: Optional[Dict[str, str]], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], metadata: Optional[Dict[str, Any]]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,now,httpx,pure,yes,30,Update a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.__init__,"__init__(vault_url: str, token: str, mount_path: str)",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,,httpx,pure,no,10,,Internal Helper,high,dunder method
integrations,L5,vault,HashiCorpVault.delete_credential,"async delete_credential(tenant_id: str, credential_id: str) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,AsyncClient | delete | pop,httpx,"db_write,external_api",yes,25,Delete a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.get_credential,"async get_credential(tenant_id: str, credential_id: str) -> Optional[CredentialData]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,AsyncClient | CredentialData | CredentialMetadata | CredentialType | fromisoformat | get | json | now | pop | raise_for_status,httpx,external_api,yes,53,Get credential from Vault.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.get_metadata,"async get_metadata(tenant_id: str, credential_id: str) -> Optional[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,get_credential,httpx,pure,yes,15,Get credential metadata without secrets.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.list_credentials,"async list_credentials(tenant_id: str, credential_type: Optional[CredentialType], tags: Optional[list[str]]) -> list[CredentialMetadata]",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,AsyncClient | all | append | get | get_metadata | json | raise_for_status | request,httpx,external_api,yes,44,List credentials for tenant.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.rotate_credential,"async rotate_credential(tenant_id: str, credential_id: str, new_secret_data: Dict[str, str]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,update_credential,httpx,pure,yes,12,Rotate credential secrets.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.store_credential,"async store_credential(tenant_id: str, name: str, credential_type: CredentialType, secret_data: Dict[str, str], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], is_rotatable: bool, rotation_interval_days: Optional[int], metadata: Optional[Dict[str, Any]]) -> str",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,AsyncClient | CredentialMetadata | info | isoformat | now | post | raise_for_status | str | uuid4,httpx,external_api,yes,65,Store credential in Vault.,Unclassified,low,no classification rules matched
integrations,L5,vault,HashiCorpVault.update_credential,"async update_credential(tenant_id: str, credential_id: str, secret_data: Optional[Dict[str, str]], description: Optional[str], tags: Optional[list[str]], expires_at: Optional[datetime], metadata: Optional[Dict[str, Any]]) -> bool",L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,AsyncClient | get_credential | isoformat | now | post | raise_for_status,httpx,external_api,yes,60,Update a credential.,Unclassified,low,no classification rules matched
integrations,L5,vault,create_credential_vault,create_credential_vault() -> CredentialVault,L7:cus_models | ?:cus_schemas | ?:__init__ | ?:service | L5s:cus_schemas,EnvCredentialVault | HashiCorpVault | getenv | info | warning,httpx,pure,no,21,Factory function to create appropriate vault based on configuration.,Unclassified,low,no classification rules matched
integrations,L5,vector_stores_base,DeleteResult.success,success() -> bool,,,,pure,no,2,,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,IndexStats.to_dict,"to_dict() -> Dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,vector_stores_base,QueryResult.to_dict,"to_dict() -> Dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,vector_stores_base,UpsertResult.success,success() -> bool,,len,,pure,no,2,,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorRecord.to_dict,"to_dict() -> Dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,vector_stores_base,VectorStoreAdapter.connect,async connect() -> bool,,,,pure,yes,8,Connect to the vector store.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.create_namespace,async create_namespace(namespace: str) -> bool,,,,pure,yes,11,Create a new namespace/collection.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.delete,"async delete(ids: Optional[List[str]], namespace: Optional[str], filter: Optional[Dict[str, Any]], delete_all: bool) -> DeleteResult",,,,pure,yes,20,Delete vectors from the store.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.delete_namespace,async delete_namespace(namespace: str) -> bool,,,,pure,yes,11,Delete a namespace/collection.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.disconnect,async disconnect() -> None,,,,pure,yes,3,Disconnect from the vector store.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.get_stats,async get_stats(namespace: Optional[str]) -> IndexStats,,,,pure,yes,11,Get index statistics.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.health_check,async health_check() -> bool,,get_stats | warning,,pure,yes,13,Check if the vector store is healthy.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
integrations,L5,vector_stores_base,VectorStoreAdapter.list_namespaces,async list_namespaces() -> List[str],,,,pure,yes,8,List all namespaces/collections.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.query,"async query(vector: List[float], top_k: int, namespace: Optional[str], filter: Optional[Dict[str, Any]], include_vectors: bool, include_metadata: bool) -> List[QueryResult]",,,,pure,yes,24,Query for similar vectors.,Internal Helper,low,pure function with no callers
integrations,L5,vector_stores_base,VectorStoreAdapter.upsert,"async upsert(records: List[VectorRecord], namespace: Optional[str]) -> UpsertResult",,,,pure,yes,16,Upsert vectors into the store.,Internal Helper,low,pure function with no callers
integrations,L5,weaviate_adapter,WeaviateAdapter.__init__,"__init__(url: Optional[str], api_key: Optional[str], collection_name: str, dimension: int, **kwargs)",L3:__init__,getenv,auth | base | weaviate,pure,no,13,,Internal Helper,high,dunder method
integrations,L5,weaviate_adapter,WeaviateAdapter._build_filter,"_build_filter(filter: Dict[str, Any]) -> Dict[str, Any]",L3:__init__,append | isinstance | items | len,auth | base | weaviate,pure,no,27,Build Weaviate where filter from dict.,Internal Helper,medium,private function
integrations,L5,weaviate_adapter,WeaviateAdapter._create_collection,_create_collection() -> None,L3:__init__,create_class,auth | base | weaviate,pure,no,25,Create the vector collection schema.,Internal Helper,medium,private function
integrations,L5,weaviate_adapter,WeaviateAdapter.connect,async connect() -> bool,L3:__init__,AuthApiKey | Client | _create_collection | error | exists | info,auth | base | weaviate,pure,yes,24,Connect to Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.create_namespace,async create_namespace(namespace: str) -> bool,L3:__init__,info,auth | base | weaviate,pure,yes,8,Create a namespace in Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.delete,"async delete(ids: Optional[List[str]], namespace: Optional[str], filter: Optional[Dict[str, Any]], delete_all: bool) -> DeleteResult",L3:__init__,DeleteResult | RuntimeError | _build_filter | _create_collection | delete | delete_class | delete_objects | error | get | info | warning,auth | base | weaviate,db_write,yes,65,Delete vectors from Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.delete_namespace,async delete_namespace(namespace: str) -> bool,L3:__init__,delete,auth | base | weaviate,db_write,yes,4,Delete a namespace from Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.disconnect,async disconnect() -> None,L3:__init__,info,auth | base | weaviate,pure,yes,4,Disconnect from Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.get_stats,async get_stats(namespace: Optional[str]) -> IndexStats,L3:__init__,IndexStats | RuntimeError | aggregate | do | error | get | with_meta_count | with_where,auth | base | weaviate,pure,yes,35,Get Weaviate collection statistics.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.list_namespaces,async list_namespaces() -> List[str],L3:__init__,RuntimeError | aggregate | append | do | error | get | with_fields | with_group_by_filter,auth | base | weaviate,pure,yes,28,List all namespaces in Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.query,"async query(vector: List[float], top_k: int, namespace: Optional[str], filter: Optional[Dict[str, Any]], include_vectors: bool, include_metadata: bool) -> List[QueryResult]",L3:__init__,QueryResult | RuntimeError | _build_filter | append | debug | do | error | get | len | with_additional | with_limit | with_near_vector | with_where,auth | base | weaviate,pure,yes,64,Query Weaviate for similar vectors.,Unclassified,low,no classification rules matched
integrations,L5,weaviate_adapter,WeaviateAdapter.upsert,"async upsert(records: List[VectorRecord], namespace: Optional[str]) -> UpsertResult",L3:__init__,RuntimeError | UpsertResult | add_data_object | append | error | info | len | str,auth | base | weaviate,pure,yes,47,Upsert vectors to Weaviate.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,CircuitBreaker.can_execute,can_execute() -> bool,L3:__init__,time,base | httpx,pure,no,21,Check if requests can be executed.,Policy/Decision,medium,name matches 'can_'
integrations,L5,webhook_adapter,CircuitBreaker.record_failure,record_failure() -> None,L3:__init__,time,base | httpx,pure,no,11,Record a failed call.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,CircuitBreaker.record_success,record_success() -> None,L3:__init__,,base | httpx,pure,no,10,Record a successful call.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.__init__,"__init__(retry_config: Optional[RetryConfig], circuit_breaker_config: Optional[CircuitBreakerConfig], signing_secret: Optional[str], default_timeout: int, dead_letter_callback: Optional[Callable[[WebhookDelivery], None]])",L3:__init__,CircuitBreakerConfig | RetryConfig | getenv,base | httpx,pure,no,17,,Internal Helper,high,dunder method
integrations,L5,webhook_adapter,WebhookAdapter._attempt_delivery,"async _attempt_delivery(delivery: WebhookDelivery, attempt_number: int) -> WebhookDeliveryAttempt",L3:__init__,WebhookDeliveryAttempt | _sign_payload | dumps | encode | int | now | post | str | time,base | httpx,external_api,yes,57,Make a single delivery attempt.,Internal Helper,medium,private function
integrations,L5,webhook_adapter,WebhookAdapter._deliver_with_retry,async _deliver_with_retry(delivery: WebhookDelivery) -> bool,L3:__init__,_attempt_delivery | _get_circuit_breaker | append | can_execute | debug | get_delay | range | record_failure | record_success | sleep | warning,base | httpx,pure,yes,33,Attempt delivery with exponential backoff retry.,Internal Helper,medium,private function
integrations,L5,webhook_adapter,WebhookAdapter._get_circuit_breaker,_get_circuit_breaker(url: str) -> CircuitBreaker,L3:__init__,CircuitBreaker | urlparse,base | httpx,pure,no,10,Get or create circuit breaker for URL.,Internal Helper,medium,private function
integrations,L5,webhook_adapter,WebhookAdapter._sign_payload,"_sign_payload(payload: bytes, timestamp: str) -> str",L3:__init__,decode | encode | hexdigest | new,base | httpx,pure,no,13,Generate HMAC signature for payload.,Internal Helper,medium,private function
integrations,L5,webhook_adapter,WebhookAdapter.connect,async connect() -> bool,L3:__init__,AsyncClient | error | info,base | httpx,external_api,yes,16,Initialize HTTP client.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.disconnect,async disconnect() -> None,L3:__init__,aclose | info,base | httpx,pure,yes,6,Close HTTP client.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.get_circuit_breaker_status,"get_circuit_breaker_status(url: str) -> Optional[Dict[str, Any]]",L3:__init__,get | urlparse,base | httpx,pure,no,19,Get circuit breaker status for a URL.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.get_delivery_details,get_delivery_details(message_id: str) -> Optional[WebhookDelivery],L3:__init__,get,base | httpx,pure,no,6,Get full delivery details including all attempts.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.get_status,async get_status(message_id: str) -> Optional[NotificationResult],L3:__init__,NotificationResult | get | len,base | httpx,pure,yes,16,Get the status of a webhook delivery.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.send,async send(message: NotificationMessage) -> NotificationResult,L3:__init__,NotificationResult | RuntimeError | WebhookDelivery | _dead_letter_callback | _deliver_with_retry | append | error | isoformat | now | str | uuid4,base | httpx,pure,yes,59,Send a webhook notification with retry logic.,Unclassified,low,no classification rules matched
integrations,L5,webhook_adapter,WebhookAdapter.send_batch,"async send_batch(messages: List[NotificationMessage], max_concurrent: int) -> List[NotificationResult]",L3:__init__,NotificationResult | RuntimeError | Semaphore | append | enumerate | gather | isinstance | send | send_with_semaphore | str | uuid4,base | httpx,pure,yes,34,Send multiple webhook notifications concurrently.,Coordinator/Aggregator,medium,name matches 'batch'
integrations,L5,webhook_adapter,WebhookDelivery.to_dict,"to_dict() -> Dict[str, Any]",L3:__init__,isoformat,base | httpx,pure,no,20,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
integrations,L5,workers_adapter,WorkersAdapter.calculate_cost_cents,"calculate_cost_cents(model: str, input_tokens: int, output_tokens: int) -> int",?:workers | L3:__init__ | L2:workers,calculate_cost_cents,worker_execution_command,pure,no,23,Calculate LLM cost in cents.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,workers_adapter,WorkersAdapter.convert_brand_request,convert_brand_request(brand_req: Any) -> Any,?:workers | L3:__init__ | L2:workers,convert_brand_request,worker_execution_command,pure,no,16,Convert API brand request to BrandSchema.,Operation,ambiguous,multi-match: Internal Helper(name matches 'convert'); Operation(called by L2 (gap  should route via L4))
integrations,L5,workers_adapter,WorkersAdapter.execute_worker,"async execute_worker(task: str, brand: Optional[Any], budget: Optional[int], strict_mode: bool, depth: int, run_id: Optional[str], event_bus: Optional[Any]) -> WorkerExecutionResult",?:workers | L3:__init__ | L2:workers,execute_worker,worker_execution_command,pure,yes,40,Execute Business Builder Worker.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,workers_adapter,WorkersAdapter.replay_execution,"async replay_execution(replay_token: str, run_id: str) -> ReplayResult",?:workers | L3:__init__ | L2:workers,replay_execution,worker_execution_command,pure,yes,22,Replay a previous execution.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L5,workers_adapter,get_workers_adapter,get_workers_adapter() -> WorkersAdapter,?:workers | L3:__init__ | L2:workers,WorkersAdapter,worker_execution_command,pure,no,16,Get the singleton WorkersAdapter instance.,Operation,medium,called by L2 (gap  should route via L4)
integrations,L6,connector_registry,BaseConnector.__init__,"__init__(connector_id: str, tenant_id: str, name: str, connector_type: ConnectorType, config: Optional[ConnectorConfig])",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorConfig | now,,pure,no,25,,Internal Helper,high,dunder method
integrations,L6,connector_registry,BaseConnector.connect,connect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Establish connection to the service.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,BaseConnector.disconnect,disconnect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Disconnect from the service.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,BaseConnector.health_check,health_check() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Check if connector is healthy.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
integrations,L6,connector_registry,BaseConnector.record_connection,record_connection(now: Optional[datetime]) -> None,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,now,,pure,no,7,Record a successful connection.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,BaseConnector.record_error,"record_error(error: str, now: Optional[datetime]) -> None",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,now,,pure,no,7,Record a connection error.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,BaseConnector.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,isoformat | to_dict,,pure,no,20,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,ConnectorConfig.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,18,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,ConnectorError.__init__,"__init__(message: str, connector_id: Optional[str], connector_type: Optional[ConnectorType])",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,__init__ | super,,pure,no,10,,Internal Helper,high,dunder method
integrations,L6,connector_registry,ConnectorError.to_dict,"to_dict() -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,9,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,ConnectorRegistry.__init__,__init__(),?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,4,Initialize the registry.,Internal Helper,high,dunder method
integrations,L6,connector_registry,ConnectorRegistry.clear_tenant,clear_tenant(tenant_id: str) -> int,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,delete | get | len | list | set,,db_write,no,6,Clear all connectors for a tenant.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.create_file_connector,"create_file_connector(tenant_id: str, name: str, config: Optional[ConnectorConfig], storage_type: str, base_path: str, connector_id: Optional[str]) -> FileConnector",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,FileConnector | register | str | uuid4,,pure,no,19,Create and register a file connector.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.create_serverless_connector,"create_serverless_connector(tenant_id: str, name: str, config: Optional[ConnectorConfig], platform: str, region: str, connector_id: Optional[str]) -> ServerlessConnector",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ServerlessConnector | register | str | uuid4,,pure,no,19,Create and register a serverless connector.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.create_vector_connector,"create_vector_connector(tenant_id: str, name: str, config: Optional[ConnectorConfig], vector_dimension: int, connector_id: Optional[str]) -> VectorConnector",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,VectorConnector | register | str | uuid4,,pure,no,17,Create and register a vector connector.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.delete,delete(connector_id: str) -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,discard | get,,pure,no,13,Delete a connector.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.get,get(connector_id: str) -> Optional[BaseConnector],?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,get,,pure,no,3,Get a connector by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.get_by_name,"get_by_name(tenant_id: str, name: str) -> Optional[BaseConnector]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,values,,pure,no,10,Get a connector by name within a tenant.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.get_statistics,get_statistics(tenant_id: Optional[str]) -> ConnectorStats,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorStats | get | values,,pure,no,28,Get registry statistics.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.list,"list(tenant_id: Optional[str], connector_type: Optional[ConnectorType], status: Optional[ConnectorStatus], limit: int, offset: int) -> list[BaseConnector]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,list | sort | values,,pure,no,23,List connectors with optional filters.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.register,register(connector: BaseConnector) -> BaseConnector,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,add | set,,db_write,no,14,Register a connector.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorRegistry.reset,reset() -> None,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,clear,,pure,no,4,Reset all state (for testing).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ConnectorStats.to_dict,"to_dict() -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,11,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,FileConnector.__init__,"__init__(connector_id: str, tenant_id: str, name: str, config: Optional[ConnectorConfig], storage_type: str, base_path: str)",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,__init__ | super,,pure,no,24,,Internal Helper,high,dunder method
integrations,L6,connector_registry,FileConnector.connect,connect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,record_connection | record_error | str,,pure,no,9,Connect to file storage.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,FileConnector.delete_file,"delete_file(path: str) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError,,pure,no,13,Delete a file.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,FileConnector.disconnect,disconnect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,now,,pure,no,6,Disconnect from file storage.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,FileConnector.health_check,health_check() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Check file storage health.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
integrations,L6,connector_registry,FileConnector.list_files,"list_files(path: str, recursive: bool) -> list[dict[str, Any]]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | range,,pure,no,18,List files in a directory.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,FileConnector.read_file,read_file(path: str) -> bytes,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError,,pure,no,11,Read a file.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,FileConnector.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,super | to_dict,,pure,no,6,Convert to dictionary with file-specific fields.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,FileConnector.write_file,"write_file(path: str, content: bytes) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | len,,pure,no,14,Write a file.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.__init__,"__init__(connector_id: str, tenant_id: str, name: str, config: Optional[ConnectorConfig], platform: str, region: str)",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,__init__ | super,,pure,no,23,,Internal Helper,high,dunder method
integrations,L6,connector_registry,ServerlessConnector.connect,connect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,record_connection | record_error | str,,pure,no,9,Connect to serverless platform.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.disconnect,disconnect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,now,,pure,no,6,Disconnect from serverless platform.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.get_result,"get_result(request_id: str) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError,,pure,no,15,Get async invocation result.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.health_check,health_check() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Check serverless platform health.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
integrations,L6,connector_registry,ServerlessConnector.invoke,"invoke(function_name: str, payload: dict[str, Any], async_invoke: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | str | uuid4,,pure,no,21,Invoke a serverless function.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.list_functions,"list_functions() -> list[dict[str, Any]]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | range,,pure,no,14,List available functions.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,ServerlessConnector.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,super | to_dict,,pure,no,6,Convert to dictionary with serverless-specific fields.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,VectorConnector.__init__,"__init__(connector_id: str, tenant_id: str, name: str, config: Optional[ConnectorConfig], vector_dimension: int, distance_metric: str)",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,__init__ | super,,pure,no,25,,Internal Helper,high,dunder method
integrations,L6,connector_registry,VectorConnector.connect,connect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,record_connection | record_error | str,,pure,no,10,Connect to vector database.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,VectorConnector.delete_vectors,"delete_vectors(ids: list[str]) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | len,,pure,no,13,Delete vectors by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,VectorConnector.disconnect,disconnect() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,now,,pure,no,6,Disconnect from vector database.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,VectorConnector.health_check,health_check() -> bool,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,,,pure,no,3,Check vector database health.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
integrations,L6,connector_registry,VectorConnector.search,"search(query_vector: list[float], top_k: int, filter_metadata: Optional[dict[str, Any]]) -> list[dict[str, Any]]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | min | range,,pure,no,19,Search for similar vectors.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,VectorConnector.to_dict,"to_dict(include_secrets: bool) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,super | to_dict,,pure,no,6,Convert to dictionary with vector-specific fields.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
integrations,L6,connector_registry,VectorConnector.upsert_vectors,"upsert_vectors(vectors: list[dict[str, Any]]) -> dict[str, Any]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorError | len,,pure,no,17,Upsert vectors to the database.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,_reset_registry,_reset_registry() -> None,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,reset,,pure,no,6,Reset the singleton (for testing).,Internal Helper,medium,private function
integrations,L6,connector_registry,get_connector,get_connector(connector_id: str) -> Optional[BaseConnector],?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,get | get_connector_registry,,pure,no,4,Get a connector by ID using the singleton registry.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,get_connector_registry,get_connector_registry() -> ConnectorRegistry,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,ConnectorRegistry,,pure,no,6,Get the singleton registry instance.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,list_connectors,"list_connectors(tenant_id: Optional[str], connector_type: Optional[ConnectorType]) -> list[BaseConnector]",?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,get_connector_registry | list,,pure,no,7,List connectors using the singleton registry.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,connector_registry,register_connector,register_connector(connector: BaseConnector) -> BaseConnector,?:retrieval_mediator | ?:facade | ?:__init__ | L5:connectors_facade | L4:retrieval_mediator | L4:execution | ?:test_connector_registry | ?:test_retrieval_mediator,get_connector_registry | register,,pure,no,4,Register a connector using the singleton registry.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator)
integrations,L6,external_response_driver,ExternalResponseService.__init__,__init__(session: Session),,,external_response | orm | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
integrations,L6,external_response_driver,ExternalResponseService.get_interpreted,get_interpreted(response_id: UUID) -> Optional[InterpretedResponse],,InterpretedResponse | and_ | execute | is_not | scalar_one_or_none | select | where,external_response | orm | sqlalchemy,db_write,no,35,Get interpreted response for consumers (L5/L2  L6 read).,Persistence/Driver,high,L6 layer = persistence
integrations,L6,external_response_driver,ExternalResponseService.get_pending_interpretations,"get_pending_interpretations(interpretation_owner: str, limit: int) -> list[ExternalResponse]",,all | and_ | execute | is_ | limit | list | order_by | scalars | select | where,external_response | orm | sqlalchemy,db_write,no,29,Get responses pending interpretation by owner.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,external_response_driver,ExternalResponseService.get_raw_for_interpretation,"get_raw_for_interpretation(response_id: UUID, expected_owner: str) -> Optional[ExternalResponse]",,and_ | execute | scalar_one_or_none | select | where,external_response | orm | sqlalchemy,db_write,no,25,Get raw response for L4 interpretation.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,external_response_driver,ExternalResponseService.interpret,"interpret(response_id: UUID, interpreted_value: dict, interpreted_by: str) -> ExternalResponse",,execute | flush | now | returning | scalar_one | update | values | where,external_response | orm | sqlalchemy,db_write,no,36,Record L4 engine interpretation (L4  L6 write).,Persistence/Driver,high,L6 layer = persistence
integrations,L6,external_response_driver,ExternalResponseService.record_raw_response,"record_raw_response(source: str, raw_response: dict, interpretation_owner: str, interpretation_contract: Optional[str], request_id: Optional[str], run_id: Optional[str]) -> ExternalResponse",,ExternalResponse | add | flush | now,external_response | orm | sqlalchemy,db_write,no,42,Record a raw external response (L3  L6 write).,Persistence/Driver,high,L6 layer = persistence
integrations,L6,external_response_driver,get_interpreted_response,"get_interpreted_response(session: Session, response_id: UUID) -> Optional[InterpretedResponse]",,ExternalResponseService | get_interpreted,external_response | orm | sqlalchemy,pure,no,7,Get interpreted response for consumers (L5/L2  L6).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
integrations,L6,external_response_driver,interpret_response,"interpret_response(session: Session, response_id: UUID, interpreted_value: dict, interpreted_by: str) -> ExternalResponse",,ExternalResponseService | interpret,external_response | orm | sqlalchemy,pure,no,13,Record L4 engine interpretation (L4  L6).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
integrations,L6,external_response_driver,record_external_response,"record_external_response(session: Session, source: str, raw_response: dict, interpretation_owner: str, interpretation_contract: Optional[str], request_id: Optional[str], run_id: Optional[str]) -> ExternalResponse",,ExternalResponseService | record_raw_response,external_response | orm | sqlalchemy,pure,no,19,Record a raw external response (L3  L6).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
integrations,L6,worker_registry_driver,WorkerRegistryService.__init__,__init__(session: Session),L6:__init__,,sqlmodel | tenant,pure,no,2,,Internal Helper,high,dunder method
integrations,L6,worker_registry_driver,WorkerRegistryService.deprecate_worker,deprecate_worker(worker_id: str) -> WorkerRegistry,L6:__init__,update_worker_status,sqlmodel | tenant,pure,no,3,Mark a worker as deprecated.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_effective_worker_config,"get_effective_worker_config(tenant_id: str, worker_id: str) -> Dict[str, Any]",L6:__init__,get_tenant_worker_config | get_worker_or_raise | loads | update,sqlmodel | tenant,pure,no,44,"Get effective worker configuration, merging tenant overrides with defaults.",Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_tenant_worker_config,"get_tenant_worker_config(tenant_id: str, worker_id: str) -> Optional[WorkerConfig]",L6:__init__,exec | first | select | where,sqlmodel | tenant,pure,no,11,Get tenant-specific worker configuration.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_worker,get_worker(worker_id: str) -> Optional[WorkerRegistry],L6:__init__,get,sqlmodel | tenant,pure,no,3,Get a worker by ID.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_worker_details,"get_worker_details(worker_id: str) -> Dict[str, Any]",L6:__init__,get_worker_or_raise | isoformat | loads,sqlmodel | tenant,pure,no,49,Get detailed worker information including schemas.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_worker_or_raise,get_worker_or_raise(worker_id: str) -> WorkerRegistry,L6:__init__,WorkerNotFoundError | get_worker,sqlmodel | tenant,pure,no,6,"Get a worker by ID, raising if not found.",Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_worker_summary,"get_worker_summary(worker_id: str) -> Dict[str, Any]",L6:__init__,get_worker_or_raise | loads,sqlmodel | tenant,pure,no,21,Get summary worker information (for listings).,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.get_workers_for_tenant,"get_workers_for_tenant(tenant_id: str, include_disabled: bool) -> List[Dict[str, Any]]",L6:__init__,append | bool | get_effective_worker_config | list_available_workers | loads,sqlmodel | tenant,pure,no,41,Get all workers available to a tenant with their effective configs.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.is_worker_available,is_worker_available(worker_id: str) -> bool,L6:__init__,get_worker,sqlmodel | tenant,pure,no,6,Check if a worker is available for execution.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.is_worker_enabled_for_tenant,"is_worker_enabled_for_tenant(tenant_id: str, worker_id: str) -> bool",L6:__init__,get_tenant_worker_config,sqlmodel | tenant,pure,no,7,Check if a worker is enabled for a tenant.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.list_available_workers,list_available_workers() -> List[WorkerRegistry],L6:__init__,list_workers,sqlmodel | tenant,pure,no,3,List only available (runnable) workers.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.list_tenant_worker_configs,list_tenant_worker_configs(tenant_id: str) -> List[WorkerConfig],L6:__init__,exec | list | select | where,sqlmodel | tenant,pure,no,4,List all worker configurations for a tenant.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.list_worker_summaries,"list_worker_summaries(status: Optional[str], public_only: bool) -> List[Dict[str, Any]]",L6:__init__,get_worker_summary | list_workers,sqlmodel | tenant,pure,no,8,List worker summaries.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.list_workers,"list_workers(status: Optional[str], public_only: bool) -> List[WorkerRegistry]",L6:__init__,exec | list | order_by | select | where,sqlmodel | tenant,pure,no,13,"List all workers, optionally filtered.",Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.register_worker,"register_worker(worker_id: str, name: str, description: Optional[str], version: str, status: str, is_public: bool, moats: Optional[List[str]], default_config: Optional[Dict], input_schema: Optional[Dict], output_schema: Optional[Dict], tokens_per_run_estimate: Optional[int], cost_per_run_cents: Optional[int]) -> WorkerRegistry",L6:__init__,WorkerRegistry | WorkerRegistryError | add | dumps | flush | get_worker | info | refresh,sqlmodel | tenant,db_write,no,41,Register a new worker.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.set_tenant_worker_config,"set_tenant_worker_config(tenant_id: str, worker_id: str, enabled: bool, config: Optional[Dict], brand: Optional[Dict], max_runs_per_day: Optional[int], max_tokens_per_run: Optional[int]) -> WorkerConfig",L6:__init__,WorkerConfig | add | dumps | flush | get_tenant_worker_config | get_worker_or_raise | refresh,sqlmodel | tenant,db_write,no,42,Set or update tenant-specific worker configuration.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,WorkerRegistryService.update_worker_status,"update_worker_status(worker_id: str, status: str) -> WorkerRegistry",L6:__init__,add | flush | get_worker_or_raise | info | refresh,sqlmodel | tenant,db_write,no,9,Update worker status.,Persistence/Driver,high,L6 layer = persistence
integrations,L6,worker_registry_driver,get_worker_registry_service,get_worker_registry_service(session: Session) -> WorkerRegistryService,L6:__init__,WorkerRegistryService,sqlmodel | tenant,pure,no,3,Get a WorkerRegistryService instance.,Persistence/Driver,high,L6 layer = persistence
logs,L5,audit_engine,AuditChecks._is_health_degraded,"_is_health_degraded(before: Any, after: Any) -> bool",L4:__init__,get | str,contract,pure,no,9,Check if health status degraded.,Internal Helper,medium,private function
logs,L5,audit_engine,AuditChecks.check_execution_fidelity,check_execution_fidelity(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | add | get | isinstance | list | set,contract,db_write,no,60,A-003: Execution Fidelity,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_health_preservation,check_health_preservation(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | _is_health_degraded | append | get | items,contract,pure,no,63,A-002: Health Preservation,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_no_unauthorized_mutations,check_no_unauthorized_mutations(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | append | get | keys | list | set,contract,pure,no,51,A-007: No Unauthorized Mutations,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_rollback_availability,check_rollback_availability(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | append | enumerate | get,contract,pure,no,63,A-005: Rollback Availability,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_scope_compliance,check_scope_compliance(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | add | get | list | set,contract,db_write,no,46,A-001: Scope Compliance,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_signal_consistency,check_signal_consistency(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck,contract,pure,no,33,A-006: Signal Consistency,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditChecks.check_timing_compliance,check_timing_compliance(audit_input: AuditInput) -> AuditCheck,L4:__init__,AuditCheck | isoformat,contract,pure,no,62,A-004: Timing Compliance,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
logs,L5,audit_engine,AuditService.__init__,__init__(auditor_version: str),L4:__init__,,contract,pure,no,11,Initialize Audit Service.,Internal Helper,high,dunder method
logs,L5,audit_engine,AuditService._determine_verdict,"_determine_verdict(checks: list[AuditCheck]) -> tuple[AuditVerdict, str]",L4:__init__,join,contract,pure,no,36,Determine final verdict from check results.,Internal Helper,medium,private function
logs,L5,audit_engine,AuditService._run_all_checks,_run_all_checks(audit_input: AuditInput) -> list[AuditCheck],L4:__init__,check_execution_fidelity | check_health_preservation | check_no_unauthorized_mutations | check_rollback_availability | check_scope_compliance | check_signal_consistency | check_timing_compliance,contract,pure,no,11,Run all audit checks and return results.,Internal Helper,medium,private function
logs,L5,audit_engine,AuditService.audit,audit(audit_input: AuditInput) -> AuditResult,L4:__init__,AuditResult | _determine_verdict | _run_all_checks | int | len | now | str | sum | total_seconds | tuple | uuid4,contract,pure,no,59,Perform audit on completed job.,Operation,high,called by L4 orchestrator
logs,L5,audit_engine,AuditService.version,version() -> str,L4:__init__,,contract,pure,no,3,Return auditor version.,Operation,high,called by L4 orchestrator
logs,L5,audit_engine,RolloutGate.get_rollout_status,"get_rollout_status(verdict: AuditVerdict) -> dict[str, Any]",L4:__init__,,contract,pure,no,35,Get rollout status details.,Operation,high,called by L4 orchestrator
logs,L5,audit_engine,RolloutGate.is_rollout_authorized,is_rollout_authorized(verdict: AuditVerdict) -> bool,L4:__init__,,contract,pure,no,13,Check if rollout is authorized based on verdict.,Operation,high,called by L4 orchestrator
logs,L5,audit_engine,audit_result_to_record,"audit_result_to_record(result: AuditResult) -> dict[str, Any]",L4:__init__,isoformat | str,contract,pure,no,33,Convert AuditResult to database record format.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,audit_engine,create_audit_input_from_evidence,"create_audit_input_from_evidence(job_id: UUID, contract_id: UUID, job_status: str, contract_scope: list[str], proposed_changes: dict[str, Any], execution_result: dict[str, Any], activation_window_start: Optional[datetime], activation_window_end: Optional[datetime]) -> AuditInput",L4:__init__,AuditInput | fromisoformat | get | now | replace,contract,pure,no,51,Create AuditInput from job execution evidence.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
logs,L5,audit_evidence,MCPAuditEmitter.__init__,__init__(publisher: Optional[Any]),?:__init__,,events,pure,no,10,Initialize audit emitter.,Internal Helper,high,dunder method
logs,L5,audit_evidence,MCPAuditEmitter._emit,async _emit(event: MCPAuditEvent) -> None,?:__init__,_get_publisher | debug | error | info | publish | str | to_dict,events,pure,yes,48,Emit event to event bus and update chain.,Internal Helper,medium,private function
logs,L5,audit_evidence,MCPAuditEmitter._generate_event_id,_generate_event_id() -> str,?:__init__,uuid4,events,pure,no,5,Generate unique event ID.,Internal Helper,medium,private function
logs,L5,audit_evidence,MCPAuditEmitter._get_publisher,_get_publisher() -> Optional[Any],?:__init__,debug | get_publisher,events,pure,no,11,Get event publisher (lazy initialization).,Internal Helper,medium,private function
logs,L5,audit_evidence,MCPAuditEmitter.emit_server_registered,"async emit_server_registered(tenant_id: str, server_id: str, server_name: str, url: str, tool_count: int) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,39,Emit audit event when MCP server is registered.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_server_unregistered,"async emit_server_unregistered(tenant_id: str, server_id: str) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,28,Emit audit event when MCP server is unregistered.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_allowed,"async emit_tool_allowed(tenant_id: str, server_id: str, tool_name: str, run_id: str, policy_id: Optional[str], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,39,Emit audit event when tool invocation is allowed.,Policy/Decision,medium,name matches 'allow'
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_completed,"async emit_tool_completed(tenant_id: str, server_id: str, tool_name: str, run_id: str, output: Optional[Any], duration_ms: Optional[float], span_id: Optional[str], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | _hash_value | isoformat | now,events,pure,yes,44,Emit audit event when tool execution completes successfully.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_denied,"async emit_tool_denied(tenant_id: str, server_id: str, tool_name: str, run_id: str, deny_reason: str, policy_id: Optional[str], message: Optional[str], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,45,Emit audit event when tool invocation is denied.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_failed,"async emit_tool_failed(tenant_id: str, server_id: str, tool_name: str, run_id: str, error_message: str, duration_ms: Optional[float], span_id: Optional[str], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,44,Emit audit event when tool execution fails.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_requested,"async emit_tool_requested(tenant_id: str, server_id: str, tool_name: str, run_id: str, input_params: Optional[Dict[str, Any]], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | _hash_value | _redact_sensitive | isoformat | now,events,pure,yes,39,Emit audit event when tool invocation is requested.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEmitter.emit_tool_started,"async emit_tool_started(tenant_id: str, server_id: str, tool_name: str, run_id: str, span_id: Optional[str], trace_id: Optional[str]) -> MCPAuditEvent",?:__init__,MCPAuditEvent | _emit | _generate_event_id | isoformat | now,events,pure,yes,38,Emit audit event when tool execution starts.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,MCPAuditEvent.__post_init__,__post_init__(),?:__init__,_compute_integrity_hash,events,pure,no,4,Compute integrity hash after initialization.,Internal Helper,high,dunder method
logs,L5,audit_evidence,MCPAuditEvent._compute_integrity_hash,_compute_integrity_hash() -> str,?:__init__,encode | hexdigest | sha256,events,pure,no,9,Compute tamper-evident integrity hash.,Internal Helper,medium,private function
logs,L5,audit_evidence,MCPAuditEvent.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,,events,pure,no,24,Convert to dictionary for serialization.,Internal Helper,medium,name matches 'to_'
logs,L5,audit_evidence,MCPAuditEvent.verify_integrity,verify_integrity() -> bool,?:__init__,_compute_integrity_hash,events,pure,no,4,Verify the integrity hash is valid.,Policy/Decision,medium,name matches 'verify'
logs,L5,audit_evidence,_contains_sensitive,_contains_sensitive(key: str) -> bool,?:__init__,any | lower,events,pure,no,4,Check if key name suggests sensitive data.,Internal Helper,medium,private function
logs,L5,audit_evidence,_hash_value,_hash_value(value: Any) -> str,?:__init__,encode | hexdigest | sha256 | str,events,pure,no,6,Hash a value for audit purposes.,Internal Helper,medium,private function
logs,L5,audit_evidence,_redact_sensitive,"_redact_sensitive(data: Dict[str, Any]) -> Dict[str, Any]",?:__init__,_contains_sensitive | _redact_sensitive | isinstance | items,events,pure,no,19,Redact sensitive fields from data for logging.,Internal Helper,medium,private function
logs,L5,audit_evidence,configure_mcp_audit_emitter,configure_mcp_audit_emitter(publisher: Optional[Any]) -> MCPAuditEmitter,?:__init__,MCPAuditEmitter | info,events,pure,no,22,Configure the singleton MCPAuditEmitter.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,get_mcp_audit_emitter,get_mcp_audit_emitter() -> MCPAuditEmitter,?:__init__,MCPAuditEmitter | info,events,pure,no,14,Get or create the singleton MCPAuditEmitter.,Unclassified,low,no classification rules matched
logs,L5,audit_evidence,reset_mcp_audit_emitter,reset_mcp_audit_emitter() -> None,?:__init__,,events,pure,no,4,Reset the singleton (for testing).,Unclassified,low,no classification rules matched
logs,L5,audit_ledger_service,AuditLedgerService.__init__,__init__(session: 'Session'),?:incident_write_engine | L5:incident_write_engine,,audit_ledger | sqlmodel,pure,no,3,Initialize with sync database session.,Internal Helper,high,dunder method
logs,L5,audit_ledger_service,AuditLedgerService._emit,"_emit(tenant_id: str, event_type: AuditEventType, entity_type: AuditEntityType, entity_id: str, actor_type: ActorType, actor_id: Optional[str], reason: Optional[str], before_state: Optional[Dict[str, Any]], after_state: Optional[Dict[str, Any]]) -> AuditLedger",?:incident_write_engine | L5:incident_write_engine,AuditLedger | add | flush | info,audit_ledger | sqlmodel,db_write,no,56,Emit an audit event to the ledger.,Internal Helper,medium,private function
logs,L5,audit_ledger_service,AuditLedgerService.incident_acknowledged,"incident_acknowledged(tenant_id: str, incident_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], incident_state: Optional[Dict[str, Any]]) -> AuditLedger",?:incident_write_engine | L5:incident_write_engine,_emit,audit_ledger | sqlmodel,pure,no,20,Record an incident acknowledgment event.,Unclassified,low,no classification rules matched
logs,L5,audit_ledger_service,AuditLedgerService.incident_manually_closed,"incident_manually_closed(tenant_id: str, incident_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], incident_state: Optional[Dict[str, Any]]) -> AuditLedger",?:incident_write_engine | L5:incident_write_engine,_emit,audit_ledger | sqlmodel,pure,no,20,Record an incident manual closure event.,Unclassified,low,no classification rules matched
logs,L5,audit_ledger_service,AuditLedgerService.incident_resolved,"incident_resolved(tenant_id: str, incident_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], before_state: Optional[Dict[str, Any]], after_state: Optional[Dict[str, Any]]) -> AuditLedger",?:incident_write_engine | L5:incident_write_engine,_emit,audit_ledger | sqlmodel,pure,no,22,Record an incident resolution event.,Coordinator/Aggregator,medium,name matches 'resolve'
logs,L5,audit_ledger_service,get_audit_ledger_service,get_audit_ledger_service(session: 'Session') -> AuditLedgerService,?:incident_write_engine | L5:incident_write_engine,AuditLedgerService,audit_ledger | sqlmodel,pure,no,11,Get an AuditLedgerService instance.,Unclassified,low,no classification rules matched
logs,L5,audit_reconciler,AuditReconciler.__init__,__init__(store: Optional[AuditStore]),?:run_orchestration_kernel,get_audit_store,audit_store | prometheus_client | rac_models,pure,no,8,Initialize the reconciler.,Internal Helper,high,dunder method
logs,L5,audit_reconciler,AuditReconciler._record_metrics,_record_metrics(result: ReconciliationResult) -> None,?:run_orchestration_kernel,inc | labels,audit_store | prometheus_client | rac_models,pure,no,16,Record Prometheus metrics for reconciliation.,Internal Helper,medium,private function
logs,L5,audit_reconciler,AuditReconciler.check_deadline_violations,check_deadline_violations(run_id: UUID) -> List[AuditExpectation],?:run_orchestration_kernel,append | get_expectations | len | now | str | timestamp | warning,audit_store | prometheus_client | rac_models,pure,no,33,Check for expectations that have exceeded their deadlines.,Policy/Decision,medium,name matches 'check'
logs,L5,audit_reconciler,AuditReconciler.get_run_audit_summary,get_run_audit_summary(run_id: UUID) -> dict,?:run_orchestration_kernel,get_acks | get_expectations | len | str,audit_store | prometheus_client | rac_models,pure,no,38,Get a summary of the audit state for a run.,Unclassified,low,no classification rules matched
logs,L5,audit_reconciler,AuditReconciler.reconcile,reconcile(run_id: UUID) -> ReconciliationResult,?:run_orchestration_kernel,ReconciliationResult | _record_metrics | any | get_acks | get_expectations | info | key | len | list | now | str | total_seconds,audit_store | prometheus_client | rac_models,pure,no,91,Reconcile expectations against acknowledgments for a run.,Coordinator/Aggregator,medium,name matches 'reconcile'
logs,L5,audit_reconciler,get_audit_reconciler,get_audit_reconciler(store: Optional[AuditStore]) -> AuditReconciler,?:run_orchestration_kernel,AuditReconciler,audit_store | prometheus_client | rac_models,pure,no,14,Get the audit reconciler singleton.,Coordinator/Aggregator,medium,name matches 'reconcile'
logs,L5,certificate,Certificate.from_dict,"from_dict(data: Dict[str, Any]) -> 'Certificate'",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,CertificatePayload | CertificateType | cls | get,replay_determinism,pure,no,27,Create certificate from dict.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
logs,L5,certificate,Certificate.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,to_dict,replay_determinism,pure,no,7,Convert to full certificate dict.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,certificate,Certificate.to_json,to_json() -> str,?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,dumps | to_dict,replay_determinism,pure,no,3,Convert to JSON string.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,certificate,CertificatePayload.canonical_json,canonical_json() -> str,?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,dumps | to_dict,replay_determinism,pure,no,3,Canonical JSON for deterministic signing.,Operation,high,called by L4 orchestrator
logs,L5,certificate,CertificatePayload.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,,replay_determinism,pure,no,21,Convert to dictionary for signing.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,certificate,CertificateService.__init__,__init__(secret: Optional[str]),?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,getenv | token_hex,replay_determinism,pure,no,14,Initialize certificate service.,Internal Helper,high,dunder method
logs,L5,certificate,CertificateService._sign,_sign(content: str) -> str,?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,encode | hexdigest | new,replay_determinism,pure,no,4,Sign content with HMAC-SHA256.,Internal Helper,medium,private function
logs,L5,certificate,CertificateService._verify_signature,"_verify_signature(content: str, signature: str) -> bool",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,_sign | compare_digest,replay_determinism,pure,no,4,Verify HMAC signature.,Internal Helper,medium,private function
logs,L5,certificate,CertificateService.create_policy_audit_certificate,"create_policy_audit_certificate(incident_id: str, policy_decisions: List[Dict[str, Any]], tenant_id: Optional[str]) -> Certificate",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,Certificate | CertificatePayload | _sign | canonical_json | get | len | str | sum | uuid4,replay_determinism,pure,no,40,Create a certificate proving policy evaluation at a point in time.,Operation,high,called by L4 orchestrator
logs,L5,certificate,CertificateService.create_replay_certificate,"create_replay_certificate(call_id: str, validation_result: ReplayResult, level: DeterminismLevel, tenant_id: Optional[str], user_id: Optional[str], request_hash: Optional[str], response_hash: Optional[str]) -> Certificate",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,Certificate | CertificatePayload | _sign | canonical_json | len | str | sum | uuid4,replay_determinism,pure,no,56,Create a certificate proving deterministic replay.,Operation,high,called by L4 orchestrator
logs,L5,certificate,CertificateService.export_certificate,"export_certificate(certificate: Certificate, format: str) -> str",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,ValueError | dumps | join | to_dict | to_json,replay_determinism,pure,no,39,Export certificate in various formats.,Operation,high,called by L4 orchestrator
logs,L5,certificate,CertificateService.verify_certificate,"verify_certificate(certificate: Certificate) -> Dict[str, Any]",?:guard | ?:certificate | L4:logs_handler | ?:apply | ?:mypy_zones,_verify_signature | canonical_json | fromisoformat | now | replace,replay_determinism,pure,no,28,Verify a certificate's signature and validity.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'verify')
logs,L5,completeness_checker,CompletenessCheckResponse.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,sorted,,pure,no,12,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
logs,L5,completeness_checker,EvidenceCompletenessChecker.__init__,"__init__(validation_enabled: bool, strict_mode: bool)",?:__init__,,,pure,no,14,Initialize the completeness checker.,Internal Helper,high,dunder method
logs,L5,completeness_checker,EvidenceCompletenessChecker.check,"check(bundle: Any, export_type: str) -> CompletenessCheckResponse",?:__init__,CompletenessCheckResponse | add | get_required_fields | is_field_present | len | set | sorted,,db_write,no,89,Check if a bundle is complete for PDF generation.,Policy/Decision,medium,name matches 'check'
logs,L5,completeness_checker,EvidenceCompletenessChecker.ensure_complete,"ensure_complete(bundle: Any, export_type: str) -> None",?:__init__,EvidenceCompletenessError | check | len | sorted,,pure,no,31,Ensure bundle is complete or raise error.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.from_governance_config,from_governance_config(config: Any) -> 'EvidenceCompletenessChecker',?:__init__,cls | getattr,,pure,no,13,Create checker from GovernanceConfig.,Internal Helper,medium,name matches 'from_'
logs,L5,completeness_checker,EvidenceCompletenessChecker.get_completeness_summary,"get_completeness_summary(bundle: Any, export_type: str) -> Dict[str, Any]",?:__init__,get_required_fields | is_field_present | len | sum | values,,pure,no,40,Get a summary of bundle completeness for reporting.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.get_field_value,"get_field_value(bundle: Any, field_name: str) -> Any",?:__init__,get | getattr | isinstance,,pure,no,14,Get field value from bundle (dict or object).,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.get_required_fields,get_required_fields(export_type: str) -> FrozenSet[str],?:__init__,frozenset,,pure,no,29,Get required fields for an export type.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.is_field_present,"is_field_present(bundle: Any, field_name: str) -> bool",?:__init__,get_field_value | isinstance | len | strip,,pure,no,26,Check if a field is present and non-empty.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.should_allow_export,"should_allow_export(bundle: Any, export_type: str) -> tuple[bool, str]",?:__init__,check,,pure,no,26,Check if an export should be allowed.,Policy/Decision,medium,name matches 'allow'
logs,L5,completeness_checker,EvidenceCompletenessChecker.strict_mode,strict_mode() -> bool,?:__init__,,,pure,no,3,Check if strict mode is enabled.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessChecker.validation_enabled,validation_enabled() -> bool,?:__init__,,,pure,no,3,Check if validation is enabled.,Unclassified,low,no classification rules matched
logs,L5,completeness_checker,EvidenceCompletenessError.__init__,"__init__(message: str, missing_fields: Set[str], export_type: str, validation_enabled: bool)",?:__init__,__init__ | super,,pure,no,11,,Internal Helper,high,dunder method
logs,L5,completeness_checker,EvidenceCompletenessError.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,sorted | str,,pure,no,9,Convert to dictionary for logging/API responses.,Internal Helper,medium,name matches 'to_'
logs,L5,completeness_checker,check_evidence_completeness,"check_evidence_completeness(bundle: Any, export_type: str, validation_enabled: bool, strict_mode: bool) -> CompletenessCheckResponse",?:__init__,EvidenceCompletenessChecker | check,,pure,no,23,Quick helper to check evidence completeness.,Policy/Decision,medium,name matches 'check'
logs,L5,completeness_checker,ensure_evidence_completeness,"ensure_evidence_completeness(bundle: Any, export_type: str, validation_enabled: bool, strict_mode: bool) -> None",?:__init__,EvidenceCompletenessChecker | ensure_complete,,pure,no,23,Quick helper to ensure evidence completeness or raise error.,Unclassified,low,no classification rules matched
logs,L5,evidence_facade,EvidenceChain.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:logs_handler,to_dict,,pure,no,12,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,evidence_facade,EvidenceExport.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:logs_handler,,,pure,no,13,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,evidence_facade,EvidenceFacade.__init__,__init__(),L5:__init__ | L4:logs_handler,,,pure,no,5,Initialize facade.,Internal Helper,high,dunder method
logs,L5,evidence_facade,EvidenceFacade._create_link,"_create_link(evidence_type: str, data: Dict[str, Any], previous_hash: Optional[str]) -> EvidenceLink",L5:__init__ | L4:logs_handler,EvidenceLink | _hash_data | isoformat | now | str | uuid4,,pure,no,26,Create a new evidence link.,Internal Helper,medium,private function
logs,L5,evidence_facade,EvidenceFacade._hash_data,"_hash_data(data: Dict[str, Any]) -> str",L5:__init__ | L4:logs_handler,dumps | encode | hexdigest | sha256,,pure,no,4,Create deterministic hash of data.,Internal Helper,medium,private function
logs,L5,evidence_facade,EvidenceFacade.add_evidence,"async add_evidence(chain_id: str, tenant_id: str, evidence_type: str, data: Dict[str, Any]) -> Optional[EvidenceChain]",L5:__init__ | L4:logs_handler,_create_link | append | get | info | len,,pure,yes,42,Add evidence to a chain.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.create_chain,"async create_chain(tenant_id: str, run_id: Optional[str], initial_evidence: Optional[Dict[str, Any]]) -> EvidenceChain",L5:__init__ | L4:logs_handler,EvidenceChain | _create_link | _hash_data | append | get | info | isoformat | len | now | str | uuid4,,pure,yes,49,Create a new evidence chain.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.create_export,"async create_export(tenant_id: str, chain_id: str, format: str) -> EvidenceExport",L5:__init__ | L4:logs_handler,EvidenceExport | get | info | isoformat | now | str | uuid4,,pure,yes,54,Create evidence export request.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.get_chain,"async get_chain(chain_id: str, tenant_id: str) -> Optional[EvidenceChain]",L5:__init__ | L4:logs_handler,get,,pure,yes,19,Get a specific evidence chain.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.get_export,"async get_export(export_id: str, tenant_id: str) -> Optional[EvidenceExport]",L5:__init__ | L4:logs_handler,get,,pure,yes,19,Get export status.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.list_chains,"async list_chains(tenant_id: str, run_id: Optional[str], limit: int, offset: int) -> List[EvidenceChain]",L5:__init__ | L4:logs_handler,append | sort | values,,pure,yes,31,List evidence chains.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.list_exports,"async list_exports(tenant_id: str, chain_id: Optional[str], limit: int, offset: int) -> List[EvidenceExport]",L5:__init__ | L4:logs_handler,append | sort | values,,pure,yes,31,List exports.,Operation,high,called by L4 orchestrator
logs,L5,evidence_facade,EvidenceFacade.verify_chain,"async verify_chain(chain_id: str, tenant_id: str) -> VerificationResult",L5:__init__ | L4:logs_handler,VerificationResult | _hash_data | append | enumerate | get | len,,pure,yes,55,Verify chain integrity.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'verify')
logs,L5,evidence_facade,EvidenceLink.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:logs_handler,,,pure,no,10,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,evidence_facade,VerificationResult.to_dict,"to_dict() -> Dict[str, Any]",L5:__init__ | L4:logs_handler,,,pure,no,8,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,evidence_facade,get_evidence_facade,get_evidence_facade() -> EvidenceFacade,L5:__init__ | L4:logs_handler,EvidenceFacade,,pure,no,14,Get the evidence facade instance.,Operation,high,called by L4 orchestrator
logs,L5,evidence_report,EvidenceReportGenerator.__init__,__init__(is_demo: bool),?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,_setup_custom_styles | getSampleStyleSheet,enums | lib | pagesizes | platypus | styles | units,pure,no,4,,Internal Helper,high,dunder method
logs,L5,evidence_report,EvidenceReportGenerator._add_footer,"_add_footer(canvas, doc)",?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,Color | HexColor | drawCentredString | drawRightString | getPageNumber | restoreState | rotate | saveState | setFillColor | setFont,enums | lib | pagesizes | platypus | styles | units,pure,no,22,Add footer to every page.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_certificate_section,_build_certificate_section(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | append | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,99,M23: Build cryptographic certificate section - HMAC-signed proof.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_cover_page,_build_cover_page(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HexColor | Paragraph | Spacer | Table | TableStyle | append | setStyle | strftime | utcnow,enums | lib | pagesizes | platypus | styles | units,pure,no,51,Build cover page with metadata.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_decision_timeline,_build_decision_timeline(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | append | get | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,43,Build decision timeline section - deterministic trace.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_executive_summary,_build_executive_summary(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | append | get | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,86,Build executive summary section.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_factual_reconstruction,_build_factual_reconstruction(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | append | items | join | setStyle | str,enums | lib | pagesizes | platypus | styles | units,pure,no,58,"Build factual reconstruction section - pure facts, no opinions.",Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_incident_snapshot,_build_incident_snapshot(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HexColor | Paragraph | Spacer | Table | TableStyle | append | get | getattr | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,120,Build 1-page Incident Snapshot - scannable summary for executives.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_legal_attestation,_build_legal_attestation(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | _compute_report_hash | append | setStyle | strftime | utcnow,enums | lib | pagesizes | platypus | styles | units,pure,no,43,Build legal attestation section.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_policy_evaluation,_build_policy_evaluation(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | append | enumerate | get | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,94,Build policy evaluation record.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_prevention_proof,_build_prevention_proof(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | append | get | lower | str,enums | lib | pagesizes | platypus | styles | units,pure,no,44,Build counterfactual prevention proof.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_remediation,_build_remediation(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | append,enums | lib | pagesizes | platypus | styles | units,pure,no,34,Build remediation & controls section.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._build_replay_verification,_build_replay_verification(evidence: IncidentEvidence) -> List,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HRFlowable | HexColor | Paragraph | Spacer | Table | TableStyle | _compute_hash | append | get | setStyle,enums | lib | pagesizes | platypus | styles | units,pure,no,63,Build replay verification section - the hard moat.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._compute_hash,_compute_hash(content: str) -> str,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,encode | hexdigest | sha256,enums | lib | pagesizes | platypus | styles | units,pure,no,3,Compute SHA-256 hash of content.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._compute_report_hash,_compute_report_hash(evidence: IncidentEvidence) -> str,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,_compute_hash,enums | lib | pagesizes | platypus | styles | units,pure,no,4,Compute verification hash for the entire report.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator._setup_custom_styles,_setup_custom_styles(),?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,HexColor | ParagraphStyle | add,enums | lib | pagesizes | platypus | styles | units,db_write,no,125,Create custom paragraph styles.,Internal Helper,medium,private function
logs,L5,evidence_report,EvidenceReportGenerator.generate,generate(evidence: IncidentEvidence) -> bytes,?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,BytesIO | PageBreak | SimpleDocTemplate | _build_certificate_section | _build_cover_page | _build_decision_timeline | _build_executive_summary | _build_factual_reconstruction | _build_incident_snapshot | _build_legal_attestation | _build_policy_evaluation | _build_prevention_proof | _build_remediation | _build_replay_verification | append,enums | lib | pagesizes | platypus | styles | units,file_io,no,64,Generate the complete PDF evidence report.,Operation,high,called by L4 orchestrator
logs,L5,evidence_report,generate_evidence_report,"generate_evidence_report(incident_id: str, tenant_id: str, tenant_name: str, user_id: str, product_name: str, model_id: str, timestamp: str, user_input: str, context_data: Dict[str, Any], ai_output: str, policy_results: List[Dict[str, Any]], timeline_events: List[Dict[str, Any]], replay_result: Optional[Dict[str, Any]], prevention_result: Optional[Dict[str, Any]], root_cause: str, impact_assessment: Optional[List[str]], certificate: Optional[Dict[str, Any]], severity: str, status: str, is_demo: bool) -> bytes",?:guard | L4:logs_handler | ?:apply | ?:mypy_zones,CertificateEvidence | EvidenceReportGenerator | IncidentEvidence | generate | get,enums | lib | pagesizes | platypus | styles | units,pure,no,76,Convenience function to generate an evidence report.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.__init__,__init__(store: Optional[LogsDomainStore]),?:logs | L5:__init__ | L4:logs_handler,get_logs_domain_store,logs_domain_store,pure,no,3,Initialize with optional store (for testing).,Internal Helper,high,dunder method
logs,L5,logs_facade,LogsFacade._snapshot_to_record_result,_snapshot_to_record_result(s: LLMRunSnapshot) -> LLMRunRecordResult,?:logs | L5:__init__ | L4:logs_handler,LLMRunRecordResult,logs_domain_store,pure,no,18,Convert snapshot to result type.,Internal Helper,medium,private function
logs,L5,logs_facade,LogsFacade.get_audit_access,"async get_audit_access(session: Any, tenant_id: str) -> AuditAccessResult",?:logs | L5:__init__ | L4:logs_handler,AccessEventResult | AuditAccessResult | EvidenceMetadataResult | len | list_audit_entries | now,logs_domain_store,pure,yes,38,O3: Get log access audit.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_audit_authorization,"async get_audit_authorization(session: Any, tenant_id: str) -> AuditAuthorizationResult",?:logs | L5:__init__ | L4:logs_handler,AuditAuthorizationResult | AuthorizationDecisionResult | EvidenceMetadataResult | len | list_audit_entries | now,logs_domain_store,pure,yes,38,O2: Get authorization decisions.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_audit_entry,"async get_audit_entry(session: Any, tenant_id: str, entry_id: str) -> Optional[AuditLedgerDetailResult]",?:logs | L5:__init__ | L4:logs_handler,AuditLedgerDetailResult | get_audit_entry,logs_domain_store,pure,yes,25,Get audit entry detail with state snapshots.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_audit_exports,"async get_audit_exports(session: Any, tenant_id: str) -> AuditExportsResult",?:logs | L5:__init__ | L4:logs_handler,AuditExportsResult | EvidenceMetadataResult | ExportRecordResult | list_log_exports | now,logs_domain_store,pure,yes,42,O5: Get compliance exports.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_audit_identity,"async get_audit_identity(session: Any, tenant_id: str) -> AuditIdentityResult",?:logs | L5:__init__ | L4:logs_handler,AuditIdentityResult | EvidenceMetadataResult | IdentityEventResult | len | list_audit_entries | now,logs_domain_store,pure,yes,36,O1: Get identity lifecycle events.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_audit_integrity,get_audit_integrity(tenant_id: str) -> AuditIntegrityResult,?:logs | L5:__init__ | L4:logs_handler,AuditIntegrityResult | EvidenceMetadataResult | IntegrityCheckResult | now,logs_domain_store,pure,no,21,O4: Get tamper detection status.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_llm_run_envelope,"async get_llm_run_envelope(session: Any, tenant_id: str, run_id: str) -> Optional[LLMRunEnvelopeResult]",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | LLMRunEnvelopeResult | get_llm_run,logs_domain_store,pure,yes,40,O1: Get canonical immutable run record.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_llm_run_export,"async get_llm_run_export(session: Any, tenant_id: str, run_id: str) -> Optional[LLMRunExportResult]",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | LLMRunExportResult | get_llm_run | now,logs_domain_store,pure,yes,31,O5: Get export information.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_llm_run_governance,"async get_llm_run_governance(session: Any, tenant_id: str, run_id: str) -> LLMRunGovernanceResult",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | GovernanceEventResult | LLMRunGovernanceResult | get_governance_events | len | now,logs_domain_store,pure,yes,39,O3: Get policy interaction trace.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_llm_run_replay,"async get_llm_run_replay(session: Any, tenant_id: str, run_id: str) -> Optional[LLMRunReplayResult]",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | LLMRunReplayResult | ReplayEventResult | get_llm_run | get_replay_window_events | now | timedelta,logs_domain_store,pure,yes,51,O4: Get 60-second replay window.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_llm_run_trace,"async get_llm_run_trace(session: Any, tenant_id: str, run_id: str) -> Optional[LLMRunTraceResult]",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | LLMRunTraceResult | TraceStepResult | get_trace_id_for_run | get_trace_steps | len | now,logs_domain_store,pure,yes,46,O2: Get step-by-step execution trace.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_system_audit,"async get_system_audit(session: Any, tenant_id: str) -> SystemAuditResult",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | SystemAuditResult | SystemEventResult | list_system_records | now,logs_domain_store,pure,yes,42,O5: Get infra attribution.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_system_events,"async get_system_events(session: Any, tenant_id: str, run_id: str) -> SystemEventsResult",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | SystemEventResult | SystemEventsResult | len | list_system_records | now,logs_domain_store,pure,yes,42,O3: Get infra events affecting run.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_system_replay,"async get_system_replay(session: Any, tenant_id: str, run_id: str) -> Optional[SystemReplayResult]",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | ReplayEventResult | SystemReplayResult | get_llm_run | get_system_records_in_window | now | timedelta,logs_domain_store,pure,yes,48,O4: Get infra replay window.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_system_snapshot,"async get_system_snapshot(session: Any, tenant_id: str, run_id: str) -> SystemSnapshotResult",?:logs | L5:__init__ | L4:logs_handler,EvidenceMetadataResult | SystemSnapshotResult | get_system_record_by_correlation | now,logs_domain_store,pure,yes,55,O1: Get environment baseline snapshot.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.get_system_telemetry,get_system_telemetry(run_id: str) -> TelemetryStubResult,?:logs | L5:__init__ | L4:logs_handler,TelemetryStubResult,logs_domain_store,pure,no,3,O2: Telemetry stub - producer not implemented.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.list_audit_entries,"async list_audit_entries(session: Any, tenant_id: str) -> AuditLedgerListResult",?:logs | L5:__init__ | L4:logs_handler,AuditLedgerItemResult | AuditLedgerListResult | isoformat | list_audit_entries,logs_domain_store,pure,yes,59,List audit entries with optional filters.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.list_llm_run_records,"async list_llm_run_records(session: Any, tenant_id: str) -> LLMRunRecordsResult",?:logs | L5:__init__ | L4:logs_handler,LLMRunRecordsResult | _snapshot_to_record_result | isoformat | list_llm_runs,logs_domain_store,pure,yes,56,List LLM run records with optional filters.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,LogsFacade.list_system_records,"async list_system_records(session: Any, tenant_id: str) -> SystemRecordsResult",?:logs | L5:__init__ | L4:logs_handler,SystemRecordResult | SystemRecordsResult | isoformat | list_system_records,logs_domain_store,pure,yes,60,List system records with optional filters.,Operation,high,called by L4 orchestrator
logs,L5,logs_facade,get_logs_facade,get_logs_facade() -> LogsFacade,?:logs | L5:__init__ | L4:logs_handler,LogsFacade,logs_domain_store,pure,no,6,Get the singleton LogsFacade instance.,Operation,high,called by L4 orchestrator
logs,L5,logs_read_engine,LogsReadService.__init__,__init__(store: Optional[PostgresTraceStore]),L3:customer_logs_adapter | L5:customer_logs_adapter,,models | pg_store,pure,no,4,Initialize with trace store (lazy loaded if not provided).,Internal Helper,high,dunder method
logs,L5,logs_read_engine,LogsReadService._get_store,async _get_store() -> PostgresTraceStore,L3:customer_logs_adapter | L5:customer_logs_adapter,get_postgres_trace_store,models | pg_store,pure,yes,6,Get the L6 PostgresTraceStore (lazy loaded).,Internal Helper,medium,private function
logs,L5,logs_read_engine,LogsReadService.get_trace,"async get_trace(trace_id: str, tenant_id: str) -> Optional[TraceRecord]",L3:customer_logs_adapter | L5:customer_logs_adapter,_get_store | get_trace,models | pg_store,pure,yes,20,Get a single trace by ID with tenant isolation.,Unclassified,low,no classification rules matched
logs,L5,logs_read_engine,LogsReadService.get_trace_by_root_hash,"async get_trace_by_root_hash(root_hash: str, tenant_id: str) -> Optional[TraceRecord]",L3:customer_logs_adapter | L5:customer_logs_adapter,_get_store | get_trace_by_root_hash,models | pg_store,pure,yes,20,Get trace by deterministic root hash with tenant isolation.,Unclassified,low,no classification rules matched
logs,L5,logs_read_engine,LogsReadService.get_trace_count,async get_trace_count(tenant_id: str) -> int,L3:customer_logs_adapter | L5:customer_logs_adapter,_get_store | get_trace_count,models | pg_store,pure,yes,15,Get total trace count for a tenant.,Unclassified,low,no classification rules matched
logs,L5,logs_read_engine,LogsReadService.list_traces,"async list_traces(tenant_id: str, limit: int, offset: int) -> List[TraceSummary]",L3:customer_logs_adapter | L5:customer_logs_adapter,_get_store | list_traces | min,models | pg_store,pure,yes,26,List traces for a tenant.,Unclassified,low,no classification rules matched
logs,L5,logs_read_engine,LogsReadService.search_traces,"async search_traces(tenant_id: str, agent_id: Optional[str], status: Optional[str], from_date: Optional[str], to_date: Optional[str], limit: int, offset: int) -> List[TraceSummary]",L3:customer_logs_adapter | L5:customer_logs_adapter,_get_store | min | search_traces,models | pg_store,pure,yes,38,Search traces for a tenant with optional filters.,Unclassified,low,no classification rules matched
logs,L5,logs_read_engine,get_logs_read_service,get_logs_read_service() -> LogsReadService,L3:customer_logs_adapter | L5:customer_logs_adapter,LogsReadService,models | pg_store,pure,no,10,Factory function to get LogsReadService instance.,Unclassified,low,no classification rules matched
logs,L5,mapper,SOC2ControlMapper.__init__,__init__(registry: Optional[SOC2ControlRegistry]),?:__init__ | ?:control_registry | L4:control_registry,get_control_registry,control_registry | time,pure,no,3,Initialize mapper with control registry.,Internal Helper,high,dunder method
logs,L5,mapper,SOC2ControlMapper._create_mapping,"_create_mapping(control: SOC2Control, incident_data: dict[str, Any]) -> SOC2ControlMapping",?:__init__ | ?:control_registry | L4:control_registry,SOC2ControlMapping | _determine_compliance_status | append | format | get | utc_now,control_registry | time,pure,no,54,Create a mapping with evidence for a control.,Internal Helper,medium,private function
logs,L5,mapper,SOC2ControlMapper._determine_compliance_status,"_determine_compliance_status(control: SOC2Control, incident_data: dict[str, Any]) -> SOC2ComplianceStatus",?:__init__ | ?:control_registry | L4:control_registry,bool | get | startswith,control_registry | time,pure,no,38,Determine compliance status based on control and evidence.,Internal Helper,medium,private function
logs,L5,mapper,SOC2ControlMapper.get_all_applicable_controls,get_all_applicable_controls(incident_category: str) -> list[SOC2Control],?:__init__ | ?:control_registry | L4:control_registry,append | get | get_control,control_registry | time,pure,no,17,Get all controls applicable to an incident category.,Operation,high,called by L4 orchestrator
logs,L5,mapper,SOC2ControlMapper.map_incident_to_controls,"map_incident_to_controls(incident_category: str, incident_data: dict[str, Any]) -> list[SOC2ControlMapping]",?:__init__ | ?:control_registry | L4:control_registry,_create_mapping | append | get | get_control,control_registry | time,pure,no,39,Map an incident to relevant SOC2 controls.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
logs,L5,mapper,get_control_mappings_for_incident,"get_control_mappings_for_incident(incident_category: str, incident_data: dict[str, Any]) -> list[dict[str, Any]]",?:__init__ | ?:control_registry | L4:control_registry,SOC2ControlMapper | map_incident_to_controls | to_dict,control_registry | time,pure,no,20,Get SOC2 control mappings for an incident (GAP-025 main entry point).,Operation,high,called by L4 orchestrator
logs,L5,panel_response_assembler,PanelResponseAssembler.__init__,"__init__(adapter_version: str, schema_version: str)",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,,panel_consistency_checker | panel_types,pure,no,7,,Internal Helper,high,dunder method
logs,L5,panel_response_assembler,PanelResponseAssembler._aggregate_verification,"_aggregate_verification(slot_results: List[PanelSlotResult]) -> Dict[str, int]",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,,panel_consistency_checker | panel_types,pure,no,15,Aggregate verification signals across all slots.,Internal Helper,medium,private function
logs,L5,panel_response_assembler,PanelResponseAssembler._determine_panel_authority,"_determine_panel_authority(slot_results: List[PanelSlotResult], consistency: ConsistencyCheckResult) -> str",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,all | any,panel_consistency_checker | panel_types,pure,no,22,Determine overall panel authority.,Internal Helper,medium,private function
logs,L5,panel_response_assembler,PanelResponseAssembler._determine_panel_state,_determine_panel_state(slot_results: List[PanelSlotResult]) -> str,?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,any,panel_consistency_checker | panel_types,pure,no,12,Determine overall panel state from slots.,Internal Helper,medium,private function
logs,L5,panel_response_assembler,PanelResponseAssembler._slot_to_dict,"_slot_to_dict(slot: PanelSlotResult) -> Dict[str, Any]",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,isoformat,panel_consistency_checker | panel_types,pure,no,38,Convert PanelSlotResult to dict.,Internal Helper,medium,private function
logs,L5,panel_response_assembler,PanelResponseAssembler.assemble,"assemble(panel_id: str, panel_contract_id: str, slot_results: List[PanelSlotResult], consistency: ConsistencyCheckResult, evaluation_time_ms: float, request_params: Optional[Dict[str, Any]]) -> Dict[str, Any]",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,_aggregate_verification | _determine_panel_authority | _determine_panel_state | _slot_to_dict | isoformat | len | now | round,panel_consistency_checker | panel_types,pure,no,63,Assemble complete panel response.,Unclassified,low,no classification rules matched
logs,L5,panel_response_assembler,PanelResponseAssembler.assemble_error,"assemble_error(panel_id: str, error: str, request_params: Optional[Dict[str, Any]]) -> Dict[str, Any]",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,isoformat | now,panel_consistency_checker | panel_types,pure,no,41,Assemble error response envelope.,Unclassified,low,no classification rules matched
logs,L5,panel_response_assembler,create_response_assembler,"create_response_assembler(adapter_version: Optional[str], schema_version: Optional[str]) -> PanelResponseAssembler",?:__init__ | ?:ai_console_panel_engine | L5:ai_console_panel_engine,PanelResponseAssembler,panel_consistency_checker | panel_types,pure,no,9,Create response assembler.,Unclassified,low,no classification rules matched
logs,L5,pdf_renderer,PDFRenderer.__init__,__init__(),?:incidents | L7:export_bundles | L4:logs_handler,_setup_styles | getSampleStyleSheet,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,4,Initialize PDF renderer with styles.,Internal Helper,high,dunder method
logs,L5,pdf_renderer,PDFRenderer._build_attestation,_build_attestation(bundle: SOC2Bundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | append,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,14,Build attestation statement section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_control_mappings,_build_control_mappings(bundle: SOC2Bundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | append,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,30,Build SOC2 control mappings section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_evidence_cover,_build_evidence_cover(bundle: EvidenceBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,Paragraph | Spacer | append | strftime,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,20,Build evidence cover page.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_evidence_summary,_build_evidence_summary(bundle: EvidenceBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | Table | TableStyle | append | setStyle | str,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,38,Build evidence summary section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_exec_cover,_build_exec_cover(bundle: ExecutiveDebriefBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,Paragraph | Spacer | append | hexval | strftime | upper,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,30,Build executive debrief cover page.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_exec_metrics,_build_exec_metrics(bundle: ExecutiveDebriefBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | Table | TableStyle | append | setStyle,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,35,Build executive metrics section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_exec_summary,_build_exec_summary(bundle: ExecutiveDebriefBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | Table | TableStyle | append | setStyle | strftime | upper,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,44,Build executive summary section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_integrity_section,_build_integrity_section(bundle: EvidenceBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | append,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,21,Build integrity verification section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_policy_section,_build_policy_section(bundle: EvidenceBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | Table | TableStyle | append | setStyle,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,33,Build policy context section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_recommendations,_build_recommendations(bundle: ExecutiveDebriefBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | append | enumerate,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,12,Build recommendations section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_soc2_cover,_build_soc2_cover(bundle: SOC2Bundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,Paragraph | Spacer | append | strftime,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,29,Build SOC2 cover page.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._build_trace_timeline,_build_trace_timeline(bundle: EvidenceBundle) -> list,?:incidents | L7:export_bundles | L4:logs_handler,HRFlowable | Paragraph | Spacer | Table | TableStyle | append | len | setStyle | str | strftime | upper,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,52,Build trace timeline section.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer._setup_styles,_setup_styles() -> None,?:incidents | L7:export_bundles | L4:logs_handler,ParagraphStyle | add,enums | export_bundles | lib | pagesizes | platypus | styles | units,db_write,no,59,Configure custom paragraph styles.,Internal Helper,medium,private function
logs,L5,pdf_renderer,PDFRenderer.render_evidence_pdf,render_evidence_pdf(bundle: EvidenceBundle) -> bytes,?:incidents | L7:export_bundles | L4:logs_handler,BytesIO | PageBreak | SimpleDocTemplate | _build_evidence_cover | _build_evidence_summary | _build_integrity_section | _build_policy_section | _build_trace_timeline | append | build | extend | getvalue | info | len | seek,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,53,Render evidence bundle to PDF bytes.,Operation,high,called by L4 orchestrator
logs,L5,pdf_renderer,PDFRenderer.render_executive_debrief_pdf,render_executive_debrief_pdf(bundle: ExecutiveDebriefBundle) -> bytes,?:incidents | L7:export_bundles | L4:logs_handler,BytesIO | PageBreak | SimpleDocTemplate | _build_exec_cover | _build_exec_metrics | _build_exec_summary | _build_recommendations | append | build | extend | getvalue | info | seek,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,47,Render executive debrief to PDF.,Operation,high,called by L4 orchestrator
logs,L5,pdf_renderer,PDFRenderer.render_soc2_pdf,render_soc2_pdf(bundle: SOC2Bundle) -> bytes,?:incidents | L7:export_bundles | L4:logs_handler,BytesIO | PageBreak | SimpleDocTemplate | _build_attestation | _build_control_mappings | _build_evidence_summary | _build_soc2_cover | _build_trace_timeline | append | build | extend | getvalue | info | len | seek,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,54,Render SOC2 bundle to PDF with attestation.,Operation,high,called by L4 orchestrator
logs,L5,pdf_renderer,get_pdf_renderer,get_pdf_renderer() -> PDFRenderer,?:incidents | L7:export_bundles | L4:logs_handler,PDFRenderer,enums | export_bundles | lib | pagesizes | platypus | styles | units,pure,no,6,Get or create PDFRenderer singleton.,Operation,high,called by L4 orchestrator
logs,L5,redact,add_redaction_pattern,"add_redaction_pattern(pattern: str, replacement: str) -> None",?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,append | compile,,pure,no,3,Add a custom redaction pattern.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,add_sensitive_field,add_sensitive_field(field_name: str) -> None,?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,add | lower,,db_write,no,3,Add a custom field name to the sensitive fields set.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,is_sensitive_field,is_sensitive_field(field_name: str) -> bool,?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,lower,,pure,no,3,Check if a field name indicates sensitive data.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,redact_dict,"redact_dict(data: dict[str, Any], depth: int, max_depth: int) -> dict[str, Any]",?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,isinstance | items | lower | redact_dict | redact_list | redact_string_value,,pure,no,31,Recursively redact sensitive fields in a dictionary.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,redact_json_string,redact_json_string(json_str: str) -> str,?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,sub,,pure,no,14,Apply PII redaction patterns to a JSON string.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,redact_list,"redact_list(data: list[Any], depth: int, max_depth: int) -> list[Any]",?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,append | isinstance | redact_dict | redact_list | redact_string_value,,pure,no,17,Recursively redact sensitive fields in a list.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,redact_string_value,redact_string_value(value: str) -> str,?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,lower | search | sub,,pure,no,22,Redact sensitive patterns in a string value.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,redact,redact_trace_data,"redact_trace_data(trace: dict[str, Any]) -> dict[str, Any]",?:traces | ?:pg_store | ?:__init__ | L6:pg_store | L2:traces | ?:mypy_zones,deepcopy | isinstance | redact_dict | redact_list,,pure,no,53,Redact PII from a complete trace object.,Operation,medium,called by L2 (gap  should route via L4)
logs,L5,replay_determinism,CallRecord.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,isoformat | to_dict,,pure,no,11,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,ModelVersion.from_dict,"from_dict(data: Dict[str, Any]) -> 'ModelVersion'",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,cls | fromisoformat | get | now,,pure,no,9,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,ModelVersion.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,isoformat,,pure,no,9,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,PolicyDecision.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,,,pure,no,9,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,ReplayContextBuilder.__init__,__init__(),?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,ReplayValidator,,pure,no,2,,Internal Helper,high,dunder method
logs,L5,replay_determinism,ReplayContextBuilder.build_call_record,"build_call_record(call_id: str, request: Dict[str, Any], response: Dict[str, Any], model_info: Dict[str, Any], policy_decisions: List[Dict[str, Any]], duration_ms: Optional[int]) -> CallRecord",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,CallRecord | ModelVersion | PolicyDecision | dumps | get | hash_content,,pure,no,58,Build a CallRecord from raw API data.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'build_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,ReplayResult.to_dict,"to_dict() -> Dict[str, Any]",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,to_dict,,pure,no,12,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
logs,L5,replay_determinism,ReplayValidator.__init__,__init__(),?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,,,pure,no,2,,Internal Helper,high,dunder method
logs,L5,replay_determinism,ReplayValidator._compare_policies,"_compare_policies(original: List[PolicyDecision], replay: List[PolicyDecision]) -> bool",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,items | keys | len | set,,pure,no,25,Compare policy decisions for logical equivalence.,Internal Helper,medium,private function
logs,L5,replay_determinism,ReplayValidator._detect_model_drift,"_detect_model_drift(original: ModelVersion, replay: ModelVersion) -> bool",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,abs,,pure,no,23,Detect if the model has drifted between original and replay.,Internal Helper,medium,private function
logs,L5,replay_determinism,ReplayValidator._level_meets_requirement,"_level_meets_requirement(achieved: ReplayMatch, required: DeterminismLevel) -> bool",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,,,pure,no,17,Check if achieved match level meets the required determinism level.,Internal Helper,medium,private function
logs,L5,replay_determinism,ReplayValidator._semantic_equivalent,"_semantic_equivalent(original: CallRecord, replay: CallRecord) -> bool",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,isinstance | keys | len | loads | max | set,,pure,no,31,Check if two responses are semantically equivalent.,Internal Helper,medium,private function
logs,L5,replay_determinism,ReplayValidator.hash_content,hash_content(content: str) -> str,?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,encode | hexdigest | sha256,,pure,no,3,Create a deterministic hash of content.,Operation,high,called by L4 orchestrator
logs,L5,replay_determinism,ReplayValidator.validate_replay,"validate_replay(original: CallRecord, replay: CallRecord, level: DeterminismLevel) -> ReplayResult",?:guard | ?:certificate | ?:replay_determinism | L5:certificate | L2:guard | L4:logs_handler,ReplayResult | _compare_policies | _detect_model_drift | _level_meets_requirement | _semantic_equivalent,,pure,no,67,Validate a replay against the original call.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
logs,L5,trace_facade,TraceFacade.__init__,__init__(trace_store),?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,,audit_store | models | trace_store,pure,no,9,Initialize facade with optional trace store.,Internal Helper,high,dunder method
logs,L5,trace_facade,TraceFacade._emit_ack,"_emit_ack(run_id: str, action: str, result_id: Optional[str], error: Optional[str]) -> None",?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,DomainAck | UUID | add_ack | debug | get | get_audit_store | warning,audit_store | models | trace_store,pure,no,49,Emit RAC acknowledgment for trace operations.,Internal Helper,medium,private function
logs,L5,trace_facade,TraceFacade._store,_store(),?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,PostgresTraceStore,audit_store | models | trace_store,pure,no,6,Lazy-load trace store.,Internal Helper,medium,private function
logs,L5,trace_facade,TraceFacade.add_step,"async add_step(trace_id: str, step_type: str, data: dict) -> bool",?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,add_step | warning,audit_store | models | trace_store,pure,yes,33,Add a step to a trace.,Operation,high,called by L4 orchestrator
logs,L5,trace_facade,TraceFacade.complete_trace,"async complete_trace(trace_id: str, run_id: str, status: str) -> bool",?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,_emit_ack | complete_trace | debug | error | str,audit_store | models | trace_store,pure,yes,50,Complete a trace.,Operation,high,called by L4 orchestrator
logs,L5,trace_facade,TraceFacade.start_trace,"async start_trace(run_id: str, tenant_id: str, agent_id: Optional[str]) -> Optional[str]",?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,_emit_ack | debug | error | start_trace | str,audit_store | models | trace_store,pure,yes,50,Start a trace for a run.,Operation,high,called by L4 orchestrator
logs,L5,trace_facade,get_trace_facade,get_trace_facade(trace_store) -> TraceFacade,?:transaction_coordinator | ?:__init__ | ?:trace_facade | L5:__init__ | L4:transaction_coordinator,TraceFacade,audit_store | models | trace_store,pure,no,14,Get the trace facade singleton.,Operation,high,called by L4 orchestrator
logs,L5,traces_metrics,TracesMetrics.__init__,__init__(),?:__init__,,prometheus_client,pure,no,2,,Internal Helper,high,dunder method
logs,L5,traces_metrics,TracesMetrics.measure_request,"measure_request(operation: str, tenant_id: str)",?:__init__,inc | labels | observe | perf_counter,prometheus_client,pure,no,13,Context manager to measure request duration.,Unclassified,low,no classification rules matched
logs,L5,traces_metrics,TracesMetrics.measure_storage,"measure_storage(operation: str, backend: str)",?:__init__,labels | observe | perf_counter,prometheus_client,pure,no,8,Context manager to measure storage operation duration.,Unclassified,low,no classification rules matched
logs,L5,traces_metrics,TracesMetrics.record_idempotency_check,"record_idempotency_check(result: str, tenant_id: str)",?:__init__,inc | labels,prometheus_client,pure,no,3,Record idempotency check result.,Policy/Decision,medium,name matches 'check'
logs,L5,traces_metrics,TracesMetrics.record_parity_check,"record_parity_check(trace_id: str, check_type: str, passed: bool)",?:__init__,inc | labels | set,prometheus_client,pure,no,9,Record parity check result.,Policy/Decision,medium,name matches 'check'
logs,L5,traces_metrics,TracesMetrics.record_replay_enforcement,"record_replay_enforcement(behavior: str, outcome: str, tenant_id: str)",?:__init__,inc | labels,prometheus_client,pure,no,3,Record replay enforcement outcome.,Policy/Decision,medium,name matches 'enforce'
logs,L5,traces_metrics,TracesMetrics.record_trace_stored,"record_trace_stored(trace_id: str, step_count: int, size_bytes: int, tenant_id: str)",?:__init__,labels | observe,prometheus_client,pure,no,4,Record trace storage metrics.,Unclassified,low,no classification rules matched
logs,L5,traces_metrics,get_traces_metrics,get_traces_metrics() -> TracesMetrics,?:__init__,TracesMetrics,prometheus_client,pure,no,6,Get or create global traces metrics instance.,Unclassified,low,no classification rules matched
logs,L5,traces_metrics,instrument_parity_check,instrument_parity_check(func: Callable) -> Callable,?:__init__,func | get | get_traces_metrics | getattr | record_parity_check | wraps,prometheus_client,pure,no,17,Decorator to instrument parity checks.,Policy/Decision,medium,name matches 'check'
logs,L5,traces_metrics,instrument_replay_check,instrument_replay_check(func: Callable) -> Callable,?:__init__,func | get | get_traces_metrics | getattr | record_replay_enforcement | str | wraps,prometheus_client,pure,no,18,Decorator to instrument replay enforcement.,Policy/Decision,medium,name matches 'check'
logs,L5,traces_metrics,instrument_trace_request,instrument_trace_request(operation: str),?:__init__,func | get | get_traces_metrics | measure_request | wraps,prometheus_client,pure,no,16,Decorator to instrument trace API endpoints.,Unclassified,low,no classification rules matched
logs,L5,traces_models,ParityResult.to_dict,"to_dict() -> dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
logs,L5,traces_models,TraceRecord.determinism_signature,determinism_signature() -> str,,determinism_hash | encode | hexdigest | join | sha256,,pure,no,9,Compute signature of all determinism-relevant fields.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceRecord.failure_count,failure_count() -> int,,sum,,pure,no,3,Count of failed steps.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceRecord.from_dict,"from_dict(data: dict[str, Any]) -> 'TraceRecord'",,cls | from_dict | fromisoformat | get,,pure,no,18,Create from dictionary.,Internal Helper,medium,name matches 'from_'
logs,L5,traces_models,TraceRecord.success_count,success_count() -> int,,sum,,pure,no,3,Count of successful steps.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceRecord.to_dict,"to_dict() -> dict[str, Any]",,determinism_signature | isoformat | to_dict,,pure,no,22,Convert to dictionary for storage.,Internal Helper,medium,name matches 'to_'
logs,L5,traces_models,TraceRecord.to_summary,to_summary() -> TraceSummary,,TraceSummary | len,,pure,no,16,Create a summary from this record.,Internal Helper,medium,name matches 'to_'
logs,L5,traces_models,TraceRecord.total_cost_cents,total_cost_cents() -> float,,sum,,pure,no,3,Sum of all step costs.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceRecord.total_duration_ms,total_duration_ms() -> float,,sum,,pure,no,3,Sum of all step durations.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceStep.determinism_hash,determinism_hash() -> str,,_normalize_for_determinism | dumps | encode | getattr | hexdigest | sha256,,pure,no,15,Compute hash of determinism-relevant fields only.,Internal Helper,low,pure function with no callers
logs,L5,traces_models,TraceStep.from_dict,"from_dict(data: dict[str, Any]) -> 'TraceStep'",,TraceStatus | cls | fromisoformat | get,,pure,no,15,Create from dictionary.,Internal Helper,medium,name matches 'from_'
logs,L5,traces_models,TraceStep.to_dict,"to_dict() -> dict[str, Any]",,isoformat,,pure,no,15,Convert to dictionary for storage.,Internal Helper,medium,name matches 'to_'
logs,L5,traces_models,TraceSummary.to_dict,"to_dict() -> dict[str, Any]",,isoformat,,pure,no,21,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
logs,L5,traces_models,_normalize_for_determinism,_normalize_for_determinism(value: Any) -> Any,,_normalize_for_determinism | isinstance | items | round,,pure,no,17,Normalize a value for deterministic hashing.,Internal Helper,medium,private function
logs,L5,traces_models,compare_traces,"compare_traces(original: TraceRecord, replay: TraceRecord) -> ParityResult",,ParityResult | append | determinism_hash | determinism_signature | dumps | enumerate | join | len | min | zip,,pure,no,68,Compare two traces to verify replay parity.,Internal Helper,low,pure function with no callers
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.__init__,__init__(session: AsyncSession),?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,,asyncio | audit_ledger,pure,no,3,Initialize with async database session.,Internal Helper,high,dunder method
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync._emit,"async _emit(tenant_id: str, event_type: AuditEventType, entity_type: AuditEntityType, entity_id: str, actor_type: ActorType, actor_id: Optional[str], reason: Optional[str], before_state: Optional[Dict[str, Any]], after_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,AuditLedger | add | flush | info,asyncio | audit_ledger,db_write,yes,56,Emit an audit event to the ledger.,Internal Helper,medium,private function
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.limit_breached,"async limit_breached(tenant_id: str, limit_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], breach_details: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a limit breach event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.limit_created,"async limit_created(tenant_id: str, limit_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], limit_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a limit creation event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.limit_updated,"async limit_updated(tenant_id: str, limit_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], before_state: Optional[Dict[str, Any]], after_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,22,Record a limit update event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.policy_proposal_approved,"async policy_proposal_approved(tenant_id: str, proposal_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], proposal_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a policy proposal approval event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.policy_proposal_rejected,"async policy_proposal_rejected(tenant_id: str, proposal_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], proposal_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a policy proposal rejection event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.policy_rule_created,"async policy_rule_created(tenant_id: str, rule_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], rule_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a policy rule creation event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.policy_rule_modified,"async policy_rule_modified(tenant_id: str, rule_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], before_state: Optional[Dict[str, Any]], after_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,22,Record a policy rule modification event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,AuditLedgerServiceAsync.policy_rule_retired,"async policy_rule_retired(tenant_id: str, rule_id: str, actor_id: Optional[str], actor_type: ActorType, reason: Optional[str], rule_state: Optional[Dict[str, Any]]) -> AuditLedger",?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,_emit,asyncio | audit_ledger,pure,yes,20,Record a policy rule retirement event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,audit_ledger_service_async,get_audit_ledger_service_async,get_audit_ledger_service_async(session: AsyncSession) -> AuditLedgerServiceAsync,?:policy_proposal | ?:policy_rules_service | ?:policy_limits_service | L5:policy_limits_engine | L5:policy_rules_engine | L5:policy_proposal_engine,AuditLedgerServiceAsync,asyncio | audit_ledger,pure,no,11,Get an AuditLedgerServiceAsync instance.,Persistence/Driver,high,L6 layer = persistence
logs,L6,bridges_driver,record_policy_activation,"async record_policy_activation(db_factory, policy_id: str, source_pattern_id: str, source_recovery_id: str, confidence: float, approval_path: str, loop_trace_id: str, tenant_id: str) -> PolicyActivationAudit",L6:__init__ | L5:bridges,PolicyActivationAudit | db_factory | execute | info | now | text,__future__ | audit_schemas | loop_events | sqlalchemy,db_write,yes,63,Record policy activation for audit trail.,Persistence/Driver,high,L6 layer = persistence
logs,L6,capture,EvidenceContextError.__init__,"__init__(evidence_type: str, message: str)",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,__init__ | super,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,pure,no,4,,Internal Helper,high,dunder method
logs,L6,capture,_assert_context_exists,"_assert_context_exists(ctx: ExecutionContext, evidence_type: str) -> None",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,EvidenceContextError | error,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,pure,no,25,Hard guard: Fail fast if context is None.,Internal Helper,medium,private function
logs,L6,capture,_hash_content,_hash_content(content: str) -> str,?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,encode | hexdigest | sha256,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,pure,no,3,Generate SHA256 fingerprint of content.,Internal Helper,medium,private function
logs,L6,capture,_record_capture_failure,"_record_capture_failure(session: Session, run_id: str, evidence_type: str, failure_reason: str, error_message: Optional[str], resolution: Optional[str]) -> None",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,debug | execute | get | now | text | uuid4,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,61,Record an evidence capture failure for later integrity reporting.,Internal Helper,medium,private function
logs,L6,capture,capture_activity_evidence,"capture_activity_evidence(session: Session, ctx: ExecutionContext) -> Optional[str]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,_assert_context_exists | _record_capture_failure | assert_valid_for_evidence | debug | execute | now | str | text | warning,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,118,Capture activity evidence (Class B) before/after LLM calls.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,capture_environment_evidence,"capture_environment_evidence(session: Session, ctx: ExecutionContext) -> Optional[str]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,_assert_context_exists | _record_capture_failure | assert_valid_for_evidence | execute | info | now | str | text | warning,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,93,Capture environment evidence (Class H) at run creation.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,capture_integrity_evidence,"capture_integrity_evidence(session: Session, run_id: str) -> Optional[str]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,compute_integrity | copy | dumps | execute | get | info | now | str | text | warning,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,86,Capture integrity evidence (Class J) at terminal state.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,capture_policy_decision_evidence,"capture_policy_decision_evidence(session: Session, ctx: ExecutionContext) -> Optional[str]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,_assert_context_exists | _record_capture_failure | assert_valid_for_evidence | debug | execute | now | str | text | uuid4 | warning,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,110,Capture policy decision evidence (Class D) during policy evaluation.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,capture_provider_evidence,"capture_provider_evidence(session: Session, ctx: ExecutionContext) -> Optional[str]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,_assert_context_exists | _record_capture_failure | assert_valid_for_evidence | debug | execute | now | str | text | warning,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,db_write,no,120,Capture provider evidence (Class G) after LLM provider response.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,compute_integrity,"compute_integrity(run_id: str) -> Dict[str, Any]",?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,compute_integrity_v2 | debug,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,pure,no,22,Compute integrity payload by examining evidence tables.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,capture,hash_prompt,hash_prompt(prompt: str) -> str,?:workers | ?:runner | ?:__init__ | ?:executor | L2:workers | ?:inject_synthetic,_hash_content,__future__ | exc | execution_context | integrity | sqlalchemy | sqlmodel,pure,no,3,Generate SHA256 fingerprint of prompt content.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,export_bundle_store,ExportBundleStore.__init__,__init__(trace_store: Optional[TraceStore]),L6:__init__ | L3:export_bundle_adapter,,db | sqlmodel | store,pure,no,3,Initialize with optional trace store for testing.,Internal Helper,high,dunder method
logs,L6,export_bundle_store,ExportBundleStore.get_incident,get_incident(incident_id: str) -> Optional[IncidentSnapshot],L6:__init__ | L3:export_bundle_adapter,IncidentSnapshot | Session | get | getattr,db | sqlmodel | store,pure,no,17,Get incident by ID.,Persistence/Driver,high,L6 layer = persistence
logs,L6,export_bundle_store,ExportBundleStore.get_run_by_run_id,get_run_by_run_id(run_id: str) -> Optional[RunSnapshot],L6:__init__ | L3:export_bundle_adapter,RunSnapshot | Session | exec | first | getattr | select | where,db | sqlmodel | store,pure,no,21,Get run by run_id.,Persistence/Driver,high,L6 layer = persistence
logs,L6,export_bundle_store,ExportBundleStore.get_trace_steps,"async get_trace_steps(trace_id: str, tenant_id: str) -> list[TraceStepSnapshot]",L6:__init__ | L3:export_bundle_adapter,TraceStepSnapshot | enumerate | get_trace_steps,db | sqlmodel | store,pure,yes,24,Get trace steps for a trace.,Persistence/Driver,high,L6 layer = persistence
logs,L6,export_bundle_store,ExportBundleStore.get_trace_summary,"async get_trace_summary(run_id: str, tenant_id: str) -> Optional[TraceSummarySnapshot]",L6:__init__ | L3:export_bundle_adapter,TraceSummarySnapshot | get_trace_summary,db | sqlmodel | store,pure,yes,21,Get trace summary for a run.,Persistence/Driver,high,L6 layer = persistence
logs,L6,export_bundle_store,ExportBundleStore.trace_store,trace_store() -> TraceStore,L6:__init__ | L3:export_bundle_adapter,TraceStore,db | sqlmodel | store,pure,no,5,Get or create TraceStore instance.,Persistence/Driver,high,L6 layer = persistence
logs,L6,export_bundle_store,get_export_bundle_store,get_export_bundle_store() -> ExportBundleStore,L6:__init__ | L3:export_bundle_adapter,ExportBundleStore,db | sqlmodel | store,pure,no,6,Get the singleton ExportBundleStore instance.,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,IdempotencyResponse.is_conflict,is_conflict() -> bool,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,2,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,IdempotencyResponse.is_duplicate,is_duplicate() -> bool,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,2,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,IdempotencyResponse.is_new,is_new() -> bool,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,2,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,InMemoryIdempotencyStore.__init__,__init__(default_ttl: int),?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,3,,Internal Helper,high,dunder method
logs,L6,idempotency,InMemoryIdempotencyStore._make_key,"_make_key(idempotency_key: str, tenant_id: str) -> str",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,2,,Internal Helper,medium,private function
logs,L6,idempotency,InMemoryIdempotencyStore.check,"async check(idempotency_key: str, request_data: Dict[str, Any], tenant_id: str, trace_id: str, ttl: Optional[int]) -> IdempotencyResponse",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,IdempotencyResponse | _make_key | get | hash_request,asyncio,pure,yes,26,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
logs,L6,idempotency,InMemoryIdempotencyStore.delete,"async delete(idempotency_key: str, tenant_id: str) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | pop,asyncio,pure,yes,4,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,InMemoryIdempotencyStore.get_status,"async get_status(idempotency_key: str, tenant_id: str) -> Optional[Dict[str, str]]",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | get,asyncio,pure,yes,3,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,InMemoryIdempotencyStore.mark_completed,"async mark_completed(idempotency_key: str, trace_id: str, tenant_id: str, response_data: Optional[Dict[str, Any]]) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key,asyncio,pure,yes,12,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,InMemoryIdempotencyStore.mark_failed,"async mark_failed(idempotency_key: str, tenant_id: str, error: str) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key,asyncio,pure,yes,6,,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,RedisIdempotencyStore.__init__,"__init__(redis_client: Any, key_prefix: str, default_ttl: int)",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,10,,Internal Helper,high,dunder method
logs,L6,idempotency,RedisIdempotencyStore._ensure_script_loaded,async _ensure_script_loaded() -> str,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_load_lua_script | script_load,asyncio,pure,yes,6,Ensure Lua script is loaded in Redis.,Internal Helper,medium,private function
logs,L6,idempotency,RedisIdempotencyStore._make_key,"_make_key(idempotency_key: str, tenant_id: str) -> str",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,,asyncio,pure,no,3,Construct Redis key.,Internal Helper,medium,private function
logs,L6,idempotency,RedisIdempotencyStore.check,"async check(idempotency_key: str, request_data: Dict[str, Any], tenant_id: str, trace_id: str, ttl: Optional[int]) -> IdempotencyResponse",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,IdempotencyResponse | IdempotencyResult | _ensure_script_loaded | _make_key | decode | error | evalsha | hash_request | isinstance | str,asyncio,pure,yes,47,Check idempotency key atomically.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
logs,L6,idempotency,RedisIdempotencyStore.delete,"async delete(idempotency_key: str, tenant_id: str) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | delete | error,asyncio,db_write,yes,9,Delete idempotency key (admin operation).,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,RedisIdempotencyStore.get_status,"async get_status(idempotency_key: str, tenant_id: str) -> Optional[Dict[str, str]]",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | decode | error | hgetall | isinstance | items,asyncio,pure,yes,14,Get current status of idempotency key.,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,RedisIdempotencyStore.mark_completed,"async mark_completed(idempotency_key: str, trace_id: str, tenant_id: str, response_data: Optional[Dict[str, Any]]) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | error | hash_request | hset,asyncio,pure,yes,23,Mark idempotency key as completed with trace result.,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,RedisIdempotencyStore.mark_failed,"async mark_failed(idempotency_key: str, tenant_id: str, error: str) -> bool",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,_make_key | error | expire | hset,asyncio,pure,yes,18,Mark idempotency key as failed (allows retry).,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,_load_lua_script,_load_lua_script() -> str,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,exists | read_text,asyncio,pure,no,49,Load Lua script from file.,Internal Helper,medium,private function
logs,L6,idempotency,canonical_json,canonical_json(obj: Any) -> str,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,dumps,asyncio,pure,no,3,"Produce canonical JSON (sorted keys, compact format).",Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,get_idempotency_store,async get_idempotency_store() -> Any,?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,InMemoryIdempotencyStore | RedisIdempotencyStore | from_url | getenv | info | ping | warning,asyncio,pure,yes,25,Get or create idempotency store based on environment.,Persistence/Driver,high,L6 layer = persistence
logs,L6,idempotency,hash_request,"hash_request(data: Dict[str, Any]) -> str",?:__init__ | ?:job_queue_worker | ?:main | ?:base | ?:skills_base,canonical_json | encode | hexdigest | sha256,asyncio,pure,no,4,Hash request data for idempotency comparison.,Persistence/Driver,high,L6 layer = persistence
logs,L6,integrity,CaptureFailure.to_dict,"to_dict() -> Dict[str, Any]",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,7,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityAssembler.__init__,__init__(database_url: Optional[str]),?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
logs,L6,integrity,IntegrityAssembler._count_evidence,"_count_evidence(conn, run_id: str, table: str) -> int",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,execute | scalar | text,__future__ | exc | sqlalchemy,pure,no,25,Count evidence records for a table.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityAssembler._gather_failures,"_gather_failures(conn, run_id: str) -> List[CaptureFailure]",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,CaptureFailure | _string_to_class | append | execute | text,__future__ | exc | sqlalchemy,pure,no,22,Gather capture failures from the failures table.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityAssembler._resolve_superseded,_resolve_superseded(facts: IntegrityFacts) -> None,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,5,Mark failures as superseded if evidence was later captured.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityAssembler._string_to_class,_string_to_class(value: str) -> EvidenceClass,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,6,Convert string to EvidenceClass.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityAssembler._table_to_class,_table_to_class(table: str) -> EvidenceClass,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,get,__future__ | exc | sqlalchemy,pure,no,11,Map table name to EvidenceClass.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityAssembler.gather,gather(run_id: str) -> IntegrityFacts,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,IntegrityFacts | _count_evidence | _gather_failures | _resolve_superseded | _table_to_class | append | connect | create_engine | dispose | warning,__future__ | exc | sqlalchemy,pure,no,43,Gather integrity facts for a run.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityEvaluation.integrity_status,integrity_status() -> str,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,8,Legacy status for backward compatibility.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityEvaluator._build_explanation,"_build_explanation(facts: IntegrityFacts, grade: IntegrityGrade) -> str",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,append | join | len,__future__ | exc | sqlalchemy,pure,no,19,Build human-readable explanation.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityEvaluator._compute_grade,"_compute_grade(facts: IntegrityFacts, score: float) -> IntegrityGrade",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,34,Compute integrity grade based on policy.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityEvaluator._find_failure,"_find_failure(facts: IntegrityFacts, evidence_class: EvidenceClass) -> Optional[CaptureFailure]",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,7,Find a capture failure for an evidence class.,Internal Helper,medium,private function
logs,L6,integrity,IntegrityEvaluator.evaluate,evaluate(facts: IntegrityFacts) -> IntegrityEvaluation,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,IntegrityEvaluation | _build_explanation | _compute_grade | _find_failure | len | to_dict,__future__ | exc | sqlalchemy,pure,no,47,Evaluate integrity facts and produce a grade.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'evaluate'); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityFacts.has_capture_failures,has_capture_failures() -> bool,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,len,__future__ | exc | sqlalchemy,pure,no,3,Check if any capture failures were recorded.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityFacts.has_required_evidence,has_required_evidence() -> bool,?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,all,__future__ | exc | sqlalchemy,pure,no,3,Check if all required evidence is present.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,IntegrityFacts.unresolved_failures,unresolved_failures() -> List[CaptureFailure],?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,,__future__ | exc | sqlalchemy,pure,no,4,Get failures that are not superseded.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve'); Operation(called by L2 (gap  should route via L4))
logs,L6,integrity,compute_integrity_v2,"compute_integrity_v2(run_id: str) -> Dict[str, Any]",?:logs | ?:__init__ | ?:capture | L6:capture | L2:logs | ?:SDSR_output_emit_AURORA_L2,IntegrityAssembler | IntegrityEvaluator | evaluate | gather | to_dict,__future__ | exc | sqlalchemy,pure,no,24,Compute integrity using the new split architecture.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,job_execution,JobAuditEmitter.__init__,__init__(publisher: Optional[Any]),?:__init__,,events | random,pure,no,10,Initialize the audit emitter.,Internal Helper,high,dunder method
logs,L6,job_execution,JobAuditEmitter._emit,async _emit(event: JobAuditEvent) -> None,?:__init__,_get_publisher | debug | error | publish | str | to_dict,events | random,pure,yes,26,Emit event and update chain.,Internal Helper,medium,private function
logs,L6,job_execution,JobAuditEmitter._generate_event_id,_generate_event_id() -> str,?:__init__,uuid4,events | random,pure,no,5,Generate unique event ID.,Internal Helper,medium,private function
logs,L6,job_execution,JobAuditEmitter._get_publisher,_get_publisher() -> Optional[Any],?:__init__,get_publisher,events | random,pure,no,10,Get event publisher.,Internal Helper,medium,private function
logs,L6,job_execution,JobAuditEmitter.emit_completed,"async emit_completed(job_id: str, tenant_id: str, duration_ms: int, result: Optional[Dict[str, Any]]) -> JobAuditEvent",?:__init__,JobAuditEvent | _emit | _generate_event_id | _hash_value | isoformat | now,events | random,pure,yes,21,Emit job completed event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobAuditEmitter.emit_created,"async emit_created(job_id: str, tenant_id: str, handler: str, payload: Optional[Dict[str, Any]]) -> JobAuditEvent",?:__init__,JobAuditEvent | _emit | _generate_event_id | _hash_value | isoformat | now,events | random,pure,yes,21,Emit job created event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobAuditEmitter.emit_failed,"async emit_failed(job_id: str, tenant_id: str, error: str, duration_ms: Optional[int], attempt_number: int) -> JobAuditEvent",?:__init__,JobAuditEvent | _emit | _generate_event_id | isoformat | now,events | random,pure,yes,23,Emit job failed event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobAuditEmitter.emit_retried,"async emit_retried(job_id: str, tenant_id: str, attempt_number: int, delay_seconds: int, error: str) -> JobAuditEvent",?:__init__,JobAuditEvent | _emit | _generate_event_id | isoformat | now,events | random,pure,yes,23,Emit job retried event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobAuditEmitter.emit_started,"async emit_started(job_id: str, tenant_id: str, handler: str, attempt_number: int) -> JobAuditEvent",?:__init__,JobAuditEvent | _emit | _generate_event_id | isoformat | now,events | random,pure,yes,21,Emit job started event.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobAuditEvent.__post_init__,__post_init__(),?:__init__,_compute_integrity_hash,events | random,pure,no,4,Compute integrity hash.,Internal Helper,high,dunder method
logs,L6,job_execution,JobAuditEvent._compute_integrity_hash,_compute_integrity_hash() -> str,?:__init__,encode | hexdigest | sha256,events | random,pure,no,7,Compute tamper-evident integrity hash.,Internal Helper,medium,private function
logs,L6,job_execution,JobAuditEvent.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,,events | random,pure,no,18,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
logs,L6,job_execution,JobAuditEvent.verify_integrity,verify_integrity() -> bool,?:__init__,_compute_integrity_hash,events | random,pure,no,4,Verify integrity hash is valid.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'verify')
logs,L6,job_execution,JobProgressTracker.__init__,__init__(publisher: Optional[Any]),?:__init__,,events | random,pure,no,10,Initialize the progress tracker.,Internal Helper,high,dunder method
logs,L6,job_execution,JobProgressTracker._calculate_eta,_calculate_eta(update: ProgressUpdate) -> Optional[int],?:__init__,fromisoformat | int | now | total_seconds,events | random,pure,no,22,Calculate estimated time to completion.,Internal Helper,medium,private function
logs,L6,job_execution,JobProgressTracker._emit_progress,async _emit_progress(update: ProgressUpdate) -> None,?:__init__,_get_publisher | callback | get | publish | str | to_dict | warning,events | random,pure,yes,26,Emit progress event.,Internal Helper,medium,private function
logs,L6,job_execution,JobProgressTracker._get_publisher,_get_publisher() -> Optional[Any],?:__init__,get_publisher,events | random,pure,no,10,Get event publisher.,Internal Helper,medium,private function
logs,L6,job_execution,JobProgressTracker.complete,"async complete(job_id: str, message: Optional[str]) -> Optional[ProgressUpdate]",?:__init__,_emit_progress | debug | get | isoformat | now,events | random,pure,yes,29,Mark a job as complete.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobProgressTracker.fail,"async fail(job_id: str, message: Optional[str]) -> Optional[ProgressUpdate]",?:__init__,_emit_progress | debug | get | isoformat | now,events | random,pure,yes,28,Mark a job as failed.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobProgressTracker.get_progress,get_progress(job_id: str) -> Optional[ProgressUpdate],?:__init__,get,events | random,pure,no,3,Get current progress for a job.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobProgressTracker.register_callback,"register_callback(job_id: str, callback: Callable[[ProgressUpdate], None]) -> None",?:__init__,append,events | random,pure,no,9,Register a callback for progress updates.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobProgressTracker.start,"async start(job_id: str, total_steps: Optional[int], metadata: Optional[Dict[str, Any]]) -> ProgressUpdate",?:__init__,ProgressUpdate | _emit_progress | debug | isoformat | now,events | random,pure,yes,35,Start tracking progress for a job.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobProgressTracker.update,"async update(job_id: str, percentage: Optional[float], stage: Optional[ProgressStage], message: Optional[str], current_step: Optional[int], metadata: Optional[Dict[str, Any]]) -> Optional[ProgressUpdate]",?:__init__,_calculate_eta | _emit_progress | get | isoformat | max | min | now | update,events | random,pure,yes,60,Update progress for a job.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobRetryManager.__init__,__init__(config: Optional[RetryConfig]),?:__init__,RetryConfig,events | random,pure,no,9,Initialize the retry manager.,Internal Helper,high,dunder method
logs,L6,job_execution,JobRetryManager.calculate_delay,calculate_delay(attempt_number: int) -> int,?:__init__,int | len | min | random,events | random,pure,no,37,Calculate retry delay based on strategy.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobRetryManager.clear_history,clear_history(job_id: str) -> None,?:__init__,pop,events | random,pure,no,3,Clear retry history for a job.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobRetryManager.get_retry_history,get_retry_history(job_id: str) -> List[RetryAttempt],?:__init__,get,events | random,pure,no,3,Get retry history for a job.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobRetryManager.record_retry,"record_retry(job_id: str, attempt_number: int, error: str, will_retry: bool) -> RetryAttempt",?:__init__,RetryAttempt | append | calculate_delay | info | isoformat | now | timedelta,events | random,pure,no,51,Record a retry attempt.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,JobRetryManager.should_retry,"should_retry(job_id: str, error: str, attempt_number: int) -> bool",?:__init__,any | info,events | random,pure,no,38,Determine if a job should be retried.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'should_')
logs,L6,job_execution,ProgressUpdate.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,,events | random,pure,no,14,Convert to dictionary.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
logs,L6,job_execution,_hash_value,_hash_value(value: Any) -> str,?:__init__,encode | hexdigest | sha256 | str,events | random,pure,no,6,Hash a value for audit purposes.,Internal Helper,medium,private function
logs,L6,job_execution,get_job_audit_emitter,get_job_audit_emitter() -> JobAuditEmitter,?:__init__,JobAuditEmitter,events | random,pure,no,6,Get the singleton JobAuditEmitter.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,get_job_progress_tracker,get_job_progress_tracker() -> JobProgressTracker,?:__init__,JobProgressTracker,events | random,pure,no,6,Get the singleton JobProgressTracker.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,get_job_retry_manager,get_job_retry_manager() -> JobRetryManager,?:__init__,JobRetryManager,events | random,pure,no,6,Get the singleton JobRetryManager.,Persistence/Driver,high,L6 layer = persistence
logs,L6,job_execution,reset_job_execution_services,reset_job_execution_services() -> None,?:__init__,,events | random,pure,no,6,Reset all singletons (for testing).,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore._to_audit_snapshot,_to_audit_snapshot(entry: AuditLedger) -> AuditLedgerSnapshot,L6:__init__ | L5:logs_facade,AuditLedgerSnapshot | getattr,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,pure,no,16,Transform ORM model to immutable snapshot.,Internal Helper,medium,private function
logs,L6,logs_domain_store,LogsDomainStore._to_export_snapshot,_to_export_snapshot(entry: LogExport) -> LogExportSnapshot,L6:__init__ | L5:logs_facade,LogExportSnapshot,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,pure,no,13,Transform ORM model to immutable snapshot.,Internal Helper,medium,private function
logs,L6,logs_domain_store,LogsDomainStore._to_llm_run_snapshot,_to_llm_run_snapshot(entry: LLMRunRecord) -> LLMRunSnapshot,L6:__init__ | L5:logs_facade,LLMRunSnapshot,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,pure,no,19,Transform ORM model to immutable snapshot.,Internal Helper,medium,private function
logs,L6,logs_domain_store,LogsDomainStore._to_system_record_snapshot,_to_system_record_snapshot(entry: SystemRecord) -> SystemRecordSnapshot,L6:__init__ | L5:logs_facade,SystemRecordSnapshot,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,pure,no,14,Transform ORM model to immutable snapshot.,Internal Helper,medium,private function
logs,L6,logs_domain_store,LogsDomainStore.get_audit_entry,"async get_audit_entry(session: AsyncSession, tenant_id: str, entry_id: str) -> Optional[AuditLedgerSnapshot]",L6:__init__ | L5:logs_facade,_to_audit_snapshot | execute | scalar_one_or_none | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,18,Get single audit ledger entry.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_governance_events,"async get_governance_events(session: AsyncSession, tenant_id: str, limit: int) -> list[AuditLedgerSnapshot]",L6:__init__ | L5:logs_facade,_to_audit_snapshot | all | desc | execute | in_ | limit | order_by | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,20,Get governance (policy) related audit events.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_llm_run,"async get_llm_run(session: AsyncSession, tenant_id: str, run_id: str) -> Optional[LLMRunSnapshot]",L6:__init__ | L5:logs_facade,_to_llm_run_snapshot | execute | scalar_one_or_none | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,18,Get single LLM run record by run_id.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_replay_window_events,"async get_replay_window_events(session: AsyncSession, tenant_id: str, trace_id: str, window_start: datetime, window_end: datetime) -> list[dict]",L6:__init__ | L5:logs_facade,execute | fetchall | text,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,56,Get replay window events from multiple sources.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_system_record_by_correlation,"async get_system_record_by_correlation(session: AsyncSession, tenant_id: str, correlation_id: str) -> Optional[SystemRecordSnapshot]",L6:__init__ | L5:logs_facade,_to_system_record_snapshot | asc | execute | is_ | limit | order_by | scalar_one_or_none | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,23,Get first system record for a correlation_id.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_system_records_in_window,"async get_system_records_in_window(session: AsyncSession, tenant_id: str, window_start: datetime, window_end: datetime) -> list[SystemRecordSnapshot]",L6:__init__ | L5:logs_facade,_to_system_record_snapshot | all | between | execute | is_ | order_by | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,20,Get system records in a time window.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_trace_id_for_run,"async get_trace_id_for_run(session: AsyncSession, tenant_id: str, run_id: str) -> Optional[str]",L6:__init__ | L5:logs_facade,execute | fetchone | text,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,14,Get trace_id from aos_traces for a run.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.get_trace_steps,"async get_trace_steps(session: AsyncSession, trace_id: str) -> list[TraceStepSnapshot]",L6:__init__ | L5:logs_facade,TraceStepSnapshot | execute | fetchall | int | text,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,28,Get trace steps for a trace_id.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.list_audit_entries,"async list_audit_entries(session: AsyncSession, tenant_id: str) -> QueryResult",L6:__init__ | L5:logs_facade,QueryResult | _to_audit_snapshot | all | count | desc | execute | len | limit | offset | order_by | scalar | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,48,Query audit ledger entries with filters.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.list_llm_runs,"async list_llm_runs(session: AsyncSession, tenant_id: str) -> QueryResult",L6:__init__ | L5:logs_facade,QueryResult | _to_llm_run_snapshot | all | count | desc | execute | len | limit | offset | order_by | scalar | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,56,Query LLM run records with filters.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.list_log_exports,"async list_log_exports(session: AsyncSession, tenant_id: str) -> QueryResult",L6:__init__ | L5:logs_facade,QueryResult | _to_export_snapshot | all | count | desc | execute | len | limit | offset | order_by | scalar | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,32,Query log export records.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,LogsDomainStore.list_system_records,"async list_system_records(session: AsyncSession, tenant_id: str) -> QueryResult",L6:__init__ | L5:logs_facade,QueryResult | _to_system_record_snapshot | all | count | desc | execute | is_ | len | limit | offset | order_by | scalar | scalars | select | where,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,db_write,yes,54,Query system records with filters.,Persistence/Driver,high,L6 layer = persistence
logs,L6,logs_domain_store,get_logs_domain_store,get_logs_domain_store() -> LogsDomainStore,L6:__init__ | L5:logs_facade,LogsDomainStore,asyncio | audit_ledger | log_exports | logs_records | sqlalchemy,pure,no,6,Get the singleton LogsDomainStore instance.,Persistence/Driver,high,L6 layer = persistence
logs,L6,panel_consistency_checker,PanelConsistencyChecker.__init__,"__init__(rules: Optional[List[Dict[str, Any]]])",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,_default_rules,panel_types,pure,no,2,,Internal Helper,high,dunder method
logs,L6,panel_consistency_checker,PanelConsistencyChecker._check_rule,"_check_rule(rule: Dict[str, Any], signals: Dict[str, Any], sources: Dict[str, str]) -> Optional[ConsistencyViolation]",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,ConsistencyViolation | _evaluate_condition | append | get | warning,panel_types,pure,no,40,Check a single consistency rule.,Internal Helper,medium,private function
logs,L6,panel_consistency_checker,PanelConsistencyChecker._default_rules,"_default_rules() -> List[Dict[str, Any]]",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,,panel_types,pure,no,36,Default consistency rules from spec.,Internal Helper,medium,private function
logs,L6,panel_consistency_checker,PanelConsistencyChecker._eval_expr,"_eval_expr(expr: str, signal_a: Any, signal_b: Any) -> bool",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,bool | isinstance | strip,panel_types,pure,no,22,Evaluate a simple expression.,Internal Helper,medium,private function
logs,L6,panel_consistency_checker,PanelConsistencyChecker._evaluate_condition,"_evaluate_condition(condition: str, signal_a: Any, signal_b: Any) -> bool",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,_eval_expr | len | split | strip | warning,panel_types,pure,no,28,Evaluate a condition expression.,Internal Helper,medium,private function
logs,L6,panel_consistency_checker,PanelConsistencyChecker.check,"check(panel_id: str, slot_results: List[PanelSlotResult]) -> ConsistencyCheckResult",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,ConsistencyCheckResult | ConsistencyViolation | _check_rule | append | items | len,panel_types,pure,no,45,Check consistency across all slots in a panel.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
logs,L6,panel_consistency_checker,create_consistency_checker,"create_consistency_checker(rules: Optional[List[Dict[str, Any]]]) -> PanelConsistencyChecker",?:__init__ | ?:panel_metrics_emitter | ?:panel_response_assembler | ?:ai_console_panel_engine | L5:ai_console_panel_engine | L5:panel_response_assembler,PanelConsistencyChecker,panel_types,pure,no,5,Create consistency checker with optional custom rules.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
logs,L6,pg_store,PostgresTraceStore.__init__,__init__(database_url: str | None),?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,getenv,asyncpg | models | redact,pure,no,5,,Internal Helper,high,dunder method
logs,L6,pg_store,PostgresTraceStore._get_pool,async _get_pool(),?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,create_pool,asyncpg | models | redact,pure,yes,13,Get or create connection pool.,Internal Helper,medium,private function
logs,L6,pg_store,PostgresTraceStore.check_idempotency_key,"async check_idempotency_key(idempotency_key: str, tenant_id: str) -> dict | None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | fetchrow | loads,asyncpg | models | redact,pure,yes,35,Check if an idempotency key has been executed.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check'); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.cleanup_old_traces,async cleanup_old_traces(days: int) -> int,?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | execute | int | split,asyncpg | models | redact,pure,yes,28,Archive and delete traces older than specified days.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.close,async close(),?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,close,asyncpg | models | redact,pure,yes,5,Close connection pool.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.complete_trace,"async complete_trace(run_id: str, status: str, metadata: dict[str, Any] | None) -> None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | dumps | execute | now,asyncpg | models | redact,pure,yes,22,Mark a trace as completed (for replay compatibility).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.delete_trace,"async delete_trace(trace_id: str, tenant_id: str | None) -> bool",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | bool | execute,asyncpg | models | redact,pure,yes,23,Delete trace by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.get_trace,"async get_trace(trace_id: str, tenant_id: str | None) -> TraceRecord | None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,TraceRecord | TraceStatus | TraceStep | _get_pool | acquire | fetch | fetchrow | loads | now,asyncpg | models | redact,pure,yes,68,Get trace by ID with optional tenant check.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.get_trace_by_root_hash,"async get_trace_by_root_hash(root_hash: str, tenant_id: str | None) -> TraceRecord | None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | fetchrow | get_trace,asyncpg | models | redact,pure,yes,21,Get trace by deterministic root hash.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.get_trace_count,async get_trace_count(tenant_id: str | None) -> int,?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | fetchrow,asyncpg | models | redact,pure,yes,10,Get total trace count.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.list_traces,"async list_traces(tenant_id: str | None, limit: int, offset: int) -> list[TraceSummary]",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,search_traces,asyncpg | models | redact,pure,yes,8,"List traces, optionally filtered by tenant (TraceStore interface).",Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.mark_trace_aborted,"async mark_trace_aborted(run_id: str, reason: str) -> None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | dumps | execute | now,asyncpg | models | redact,pure,yes,40,Mark a trace as ABORTED due to finalization failure.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.record_step,"async record_step(trace_id: str, run_id: str, step_index: int, skill_name: str, params: dict[str, Any], status: str, outcome_category: str, outcome_code: str | None, outcome_data: dict[str, Any] | None, cost_cents: float, duration_ms: float, retry_count: int) -> None",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,ValueError | _get_pool | _status_to_level | acquire | dumps | execute | fetchval | hasattr | now,asyncpg | models | redact,pure,yes,90,Record a step in the trace (for replay compatibility).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.search_traces,"async search_traces(tenant_id: str | None, agent_id: str | None, root_hash: str | None, plan_hash: str | None, seed: int | None, status: str | None, from_date: str | None, to_date: str | None, limit: int, offset: int) -> list[TraceSummary]",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,TraceSummary | _get_pool | acquire | append | fetch | fromisoformat | join | now,asyncpg | models | redact,pure,yes,100,Search traces with multiple filters.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.start_trace,"async start_trace(run_id: str, correlation_id: str, tenant_id: str, agent_id: str | None, plan: list[dict[str, Any]]) -> str",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | acquire | dumps | execute | now,asyncpg | models | redact,pure,yes,61,Start a new trace record (for replay compatibility).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,PostgresTraceStore.store_trace,"async store_trace(trace: dict[str, Any], tenant_id: str, stored_by: str | None, redact_pii: bool) -> str",?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,_get_pool | _status_to_level | acquire | dumps | execute | fromisoformat | get | now | redact_trace_data | uuid4,asyncpg | models | redact,pure,yes,124,Store a trace from SDK or simulation.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,pg_store,_status_to_level,_status_to_level(status: str) -> str,?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,isinstance | lower | str,asyncpg | models | redact,pure,no,17,Derive log level from step status.,Internal Helper,medium,private function
logs,L6,pg_store,get_postgres_trace_store,get_postgres_trace_store() -> PostgresTraceStore,?:traces | ?:runner | ?:__init__ | ?:logs_read_service | ?:replay | L5:logs_read_engine | L2:traces | ?:apply | ?:mypy_zones | ?:test_trace_fail_closed,PostgresTraceStore,asyncpg | models | redact,pure,no,6,Get singleton PostgreSQL trace store.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,IdempotencyStore.delete,"async delete(key: str, tenant_id: str) -> bool",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,yes,2,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,IdempotencyStore.get,"async get(key: str, tenant_id: str) -> Optional[dict]",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,yes,2,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,IdempotencyStore.set,"async set(key: str, tenant_id: str, value: dict) -> None",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,yes,2,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,IdempotencyViolationError.__init__,"__init__(idempotency_key: str, message: str)",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,__init__ | super,asyncio,pure,no,7,,Internal Helper,high,dunder method
logs,L6,replay,InMemoryIdempotencyStore.__init__,__init__(),?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,no,2,,Internal Helper,high,dunder method
logs,L6,replay,InMemoryIdempotencyStore._make_key,"_make_key(key: str, tenant_id: str) -> str",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,no,2,,Internal Helper,medium,private function
logs,L6,replay,InMemoryIdempotencyStore.clear,clear() -> None,?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,clear,asyncio,pure,no,3,Clear all stored keys.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,InMemoryIdempotencyStore.delete,"async delete(key: str, tenant_id: str) -> bool",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_make_key,asyncio,pure,yes,6,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,InMemoryIdempotencyStore.get,"async get(key: str, tenant_id: str) -> Optional[dict]",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_make_key | get,asyncio,pure,yes,3,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,InMemoryIdempotencyStore.set,"async set(key: str, tenant_id: str, value: dict) -> None",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_make_key,asyncio,pure,yes,3,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,RedisIdempotencyStore.__init__,"__init__(redis_url: str | None, ttl_seconds: int)",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,getenv,asyncio,pure,no,6,,Internal Helper,high,dunder method
logs,L6,replay,RedisIdempotencyStore._get_client,async _get_client(),?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,from_url,asyncio,pure,yes,6,,Internal Helper,medium,private function
logs,L6,replay,RedisIdempotencyStore._make_key,"_make_key(key: str, tenant_id: str) -> str",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,,asyncio,pure,no,2,,Internal Helper,medium,private function
logs,L6,replay,RedisIdempotencyStore.delete,"async delete(key: str, tenant_id: str) -> bool",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_get_client | _make_key | bool | delete,asyncio,"db_write,external_api",yes,5,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,RedisIdempotencyStore.get,"async get(key: str, tenant_id: str) -> Optional[dict]",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_get_client | _make_key | get | loads,asyncio,external_api,yes,7,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,RedisIdempotencyStore.set,"async set(key: str, tenant_id: str, value: dict) -> None",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,_get_client | _make_key | dumps | setex,asyncio,pure,yes,4,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,ReplayEnforcer.__init__,__init__(idempotency_store: Optional['IdempotencyStore']),?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,InMemoryIdempotencyStore,asyncio,pure,no,2,,Internal Helper,high,dunder method
logs,L6,replay,ReplayEnforcer.enforce_step,"async enforce_step(step: dict, execute_fn: Callable[[], Awaitable[Any]], tenant_id: str) -> ReplayResult",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,ReplayBehavior | ReplayMismatchError | ReplayResult | execute_fn | get | hash_output | set,asyncio,pure,yes,90,Enforce replay behavior for a single step.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'enforce'); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,ReplayEnforcer.enforce_trace,"async enforce_trace(trace: dict, step_executor: Callable[[dict], Awaitable[Any]], tenant_id: str) -> list[ReplayResult]",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,append | enforce_step | get | step_executor,asyncio,pure,yes,34,Enforce replay behavior for an entire trace.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'enforce'); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,ReplayMismatchError.__init__,"__init__(step_index: int, expected_hash: str, actual_hash: str, message: str)",?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,__init__ | super,asyncio,pure,no,11,,Internal Helper,high,dunder method
logs,L6,replay,get_replay_enforcer,get_replay_enforcer(use_redis: bool) -> ReplayEnforcer,?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,InMemoryIdempotencyStore | RedisIdempotencyStore | ReplayEnforcer,asyncio,pure,no,10,Get singleton replay enforcer.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Policy/Decision(name matches 'enforce'); Operation(called by L2 (gap  should route via L4))
logs,L6,replay,hash_output,hash_output(data: Any) -> str,?:logs | ?:runtime | ?:workers | ?:execution_plan | ?:__init__ | ?:main | L2:logs | L2:runtime | L2:workers | L4:logs_handler,dumps | encode | hexdigest | sha256,asyncio,pure,no,6,Compute hash of output data for comparison.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L4 orchestrator); Operation(called by L2 (gap  should route via L4))
logs,L6,traces_store,InMemoryTraceStore.__init__,__init__(),,,models | sqlite3,pure,no,3,,Internal Helper,high,dunder method
logs,L6,traces_store,InMemoryTraceStore.complete_trace,"async complete_trace(run_id: str, status: str, metadata: dict[str, Any] | None) -> None",,TraceRecord | get | now,models | sqlite3,pure,yes,20,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,InMemoryTraceStore.delete_trace,async delete_trace(run_id: str) -> bool,,pop,models | sqlite3,pure,yes,6,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,InMemoryTraceStore.get_trace,async get_trace(run_id: str) -> TraceRecord | None,,TraceRecord | get,models | sqlite3,pure,yes,17,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,InMemoryTraceStore.list_traces,"async list_traces(tenant_id: str | None, limit: int, offset: int) -> list[TraceSummary]",,TraceSummary | append | get | len | list | sort | sum | values,models | sqlite3,pure,yes,33,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,InMemoryTraceStore.record_step,"async record_step(run_id: str, step_index: int, skill_name: str, params: dict[str, Any], status: TraceStatus, outcome_category: str, outcome_code: str | None, outcome_data: dict[str, Any] | None, cost_cents: float, duration_ms: float, retry_count: int) -> None",,TraceStep | append | sort,models | sqlite3,pure,yes,33,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,InMemoryTraceStore.start_trace,"async start_trace(run_id: str, correlation_id: str, tenant_id: str, agent_id: str | None, plan: list[dict[str, Any]]) -> None",,TraceRecord | now,models | sqlite3,pure,yes,20,,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.__init__,__init__(db_path: str | Path),,Path | _init_db | mkdir,models | sqlite3,pure,no,4,,Internal Helper,high,dunder method
logs,L6,traces_store,SQLiteTraceStore._get_conn,_get_conn() -> sqlite3.Connection,,connect,models | sqlite3,pure,no,5,Get a database connection.,Internal Helper,medium,private function
logs,L6,traces_store,SQLiteTraceStore._init_db,_init_db() -> None,,commit | connect | executescript,models | sqlite3,db_write,no,63,Initialize database schema.,Internal Helper,medium,private function
logs,L6,traces_store,SQLiteTraceStore.cleanup_old_traces,async cleanup_old_traces(days: int) -> int,,_get_conn | commit | execute | to_thread,models | sqlite3,db_write,yes,16,Delete traces older than specified days.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,SQLiteTraceStore.complete_trace,"async complete_trace(run_id: str, status: str, metadata: dict[str, Any] | None) -> None",,_get_conn | commit | dumps | execute | isoformat | now | to_thread,models | sqlite3,db_write,yes,21,Mark a trace as completed.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,SQLiteTraceStore.delete_trace,async delete_trace(run_id: str) -> bool,,_get_conn | commit | execute | to_thread,models | sqlite3,db_write,yes,10,Delete a trace by run_id.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,SQLiteTraceStore.find_matching_traces,"async find_matching_traces(plan_hash: str, seed: int) -> list[TraceSummary]",,search_traces,models | sqlite3,pure,yes,11,Find traces with matching plan and seed (for replay verification).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.get_trace,async get_trace(run_id: str) -> TraceRecord | None,,TraceRecord | TraceStatus | TraceStep | _get_conn | execute | fetchall | fetchone | fromisoformat | loads | to_thread,models | sqlite3,pure,yes,47,Get a complete trace by run_id.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.get_trace_by_root_hash,async get_trace_by_root_hash(root_hash: str) -> TraceRecord | None,,_get_conn | execute | fetchone | get_trace | to_thread,models | sqlite3,pure,yes,12,Get a trace by its deterministic root hash.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.get_trace_count,async get_trace_count(tenant_id: str | None) -> int,,_get_conn | execute | fetchone | to_thread,models | sqlite3,pure,yes,12,Get total trace count.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.list_traces,"async list_traces(tenant_id: str | None, limit: int, offset: int) -> list[TraceSummary]",,TraceSummary | _get_conn | execute | fetchall | fromisoformat | to_thread,models | sqlite3,pure,yes,65,"List traces, optionally filtered by tenant.",Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.record_step,"async record_step(run_id: str, step_index: int, skill_name: str, params: dict[str, Any], status: TraceStatus, outcome_category: str, outcome_code: str | None, outcome_data: dict[str, Any] | None, cost_cents: float, duration_ms: float, retry_count: int) -> None",,_get_conn | commit | dumps | execute | isoformat | now | to_thread,models | sqlite3,db_write,yes,43,Record a step in the trace.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,SQLiteTraceStore.search_traces,"async search_traces(tenant_id: str | None, agent_id: str | None, root_hash: str | None, plan_hash: str | None, seed: int | None, status: str | None, from_date: str | None, to_date: str | None, limit: int, offset: int) -> list[TraceSummary]",,TraceSummary | _get_conn | append | execute | fetchall | fromisoformat | join | to_thread,models | sqlite3,pure,yes,108,Search traces with multiple filter criteria.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,SQLiteTraceStore.start_trace,"async start_trace(run_id: str, correlation_id: str, tenant_id: str, agent_id: str | None, plan: list[dict[str, Any]]) -> None",,_get_conn | commit | dumps | execute | isoformat | now | to_thread,models | sqlite3,db_write,yes,29,Start a new trace record.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,SQLiteTraceStore.update_trace_determinism,"async update_trace_determinism(run_id: str, seed: int, frozen_timestamp: str | None, root_hash: str, plan_hash: str) -> None",,_get_conn | commit | execute | to_thread,models | sqlite3,db_write,yes,23,Update determinism fields after trace finalization.,Persistence/Driver,high,L6 layer = persistence
logs,L6,traces_store,TraceStore.complete_trace,"async complete_trace(run_id: str, status: str, metadata: dict[str, Any] | None) -> None",,,models | sqlite3,pure,yes,8,Mark a trace as completed.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,TraceStore.delete_trace,async delete_trace(run_id: str) -> bool,,,models | sqlite3,pure,yes,3,Delete a trace by run_id.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,TraceStore.get_trace,async get_trace(run_id: str) -> TraceRecord | None,,,models | sqlite3,pure,yes,3,Get a complete trace by run_id.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,TraceStore.list_traces,"async list_traces(tenant_id: str | None, limit: int, offset: int) -> list[TraceSummary]",,,models | sqlite3,pure,yes,8,"List traces, optionally filtered by tenant.",Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,TraceStore.record_step,"async record_step(run_id: str, step_index: int, skill_name: str, params: dict[str, Any], status: TraceStatus, outcome_category: str, outcome_code: str | None, outcome_data: dict[str, Any] | None, cost_cents: float, duration_ms: float, retry_count: int) -> None",,,models | sqlite3,pure,yes,16,Record a step in the trace.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,TraceStore.start_trace,"async start_trace(run_id: str, correlation_id: str, tenant_id: str, agent_id: str | None, plan: list[dict[str, Any]]) -> None",,,models | sqlite3,pure,yes,10,Start a new trace record.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,generate_correlation_id,generate_correlation_id() -> str,,str | uuid4,models | sqlite3,pure,no,3,Generate a unique correlation ID for tracing.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
logs,L6,traces_store,generate_run_id,generate_run_id() -> str,,uuid4,models | sqlite3,pure,no,3,Generate a unique run ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(pure function with no callers)
overview,L5,overview_facade,CostPeriod.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,isoformat,__future__ | asyncio | overview_facade_driver | time,pure,no,5,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,CostsResult.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,to_dict,__future__ | asyncio | overview_facade_driver | time,pure,no,11,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,DecisionItem.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,isoformat,__future__ | asyncio | overview_facade_driver | time,pure,no,10,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,DecisionsCountResult.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,,__future__ | asyncio | overview_facade_driver | time,pure,no,6,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,DecisionsResult.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,to_dict,__future__ | asyncio | overview_facade_driver | time,pure,no,7,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,DomainCount.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,,__future__ | asyncio | overview_facade_driver | time,pure,no,7,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,HighlightsResult.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,isoformat | to_dict,__future__ | asyncio | overview_facade_driver | time,pure,no,6,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,LimitCostItem.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,,__future__ | asyncio | overview_facade_driver | time,pure,no,10,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,OverviewFacade.__init__,__init__() -> None,?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,OverviewFacadeDriver,__future__ | asyncio | overview_facade_driver | time,pure,no,3,Initialize the facade with its driver.,Internal Helper,high,dunder method
overview,L5,overview_facade,OverviewFacade.get_costs,"async get_costs(session: AsyncSession, tenant_id: str, period_days: int) -> CostsResult",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,CostPeriod | CostsResult | LimitCostItem | append | fetch_breach_stats | fetch_budget_limits | fetch_run_cost | float | max | timedelta | utc_now,__future__ | asyncio | overview_facade_driver | time,pure,yes,56,Get cost intelligence (O2).,Operation,high,called by L4 orchestrator
overview,L5,overview_facade,OverviewFacade.get_decisions,"async get_decisions(session: AsyncSession, tenant_id: str, source_domain: Optional[str], priority: Optional[str], limit: int, offset: int) -> DecisionsResult",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,DecisionItem | DecisionsResult | append | fetch_pending_incidents | fetch_pending_proposals | len | replace | sort,__future__ | asyncio | overview_facade_driver | time,pure,yes,91,Get pending decisions (O2).,Operation,high,called by L4 orchestrator
overview,L5,overview_facade,OverviewFacade.get_decisions_count,"async get_decisions_count(session: AsyncSession, tenant_id: str) -> DecisionsCountResult",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,DecisionsCountResult | fetch_incident_decision_counts | fetch_proposal_count,__future__ | asyncio | overview_facade_driver | time,pure,yes,36,Get decisions count summary (O2).,Operation,high,called by L4 orchestrator
overview,L5,overview_facade,OverviewFacade.get_highlights,"async get_highlights(session: AsyncSession, tenant_id: str) -> HighlightsResult",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,DomainCount | HighlightsResult | SystemPulse | fetch_breach_counts | fetch_incident_counts | fetch_last_activity | fetch_proposal_counts | fetch_run_counts | timedelta | utc_now,__future__ | asyncio | overview_facade_driver | time,pure,yes,67,Get system highlights (O1).,Operation,high,called by L4 orchestrator
overview,L5,overview_facade,OverviewFacade.get_recovery_stats,"async get_recovery_stats(session: AsyncSession, tenant_id: str, period_days: int) -> RecoveryStatsResult",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,CostPeriod | RecoveryStatsResult | fetch_recovery_stats | round | timedelta | utc_now,__future__ | asyncio | overview_facade_driver | time,pure,yes,28,Get recovery statistics (O3).,Operation,high,called by L4 orchestrator
overview,L5,overview_facade,RecoveryStatsResult.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,to_dict,__future__ | asyncio | overview_facade_driver | time,pure,no,9,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,SystemPulse.to_dict,"to_dict() -> Dict[str, Any]",?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,,__future__ | asyncio | overview_facade_driver | time,pure,no,9,,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
overview,L5,overview_facade,get_overview_facade,get_overview_facade() -> OverviewFacade,?:overview | ?:overview_facade | L5:__init__ | L4:operation_registry | L4:overview_handler,OverviewFacade,__future__ | asyncio | overview_facade_driver | time,pure,no,6,Get the singleton OverviewFacade instance.,Operation,high,called by L4 orchestrator
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_breach_counts,"async fetch_breach_counts(session: AsyncSession, tenant_id: str, since: datetime) -> BreachCountSnapshot",L6:__init__ | L5:overview_facade,BreachCountSnapshot | count | execute | label | one | select | warning | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,20,Fetch limit breach counts from DB (defensive query).,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_breach_stats,"async fetch_breach_stats(session: AsyncSession, tenant_id: str, since: datetime) -> BreachStatsSnapshot",L6:__init__ | L5:overview_facade,BreachStatsSnapshot | coalesce | count | execute | float | label | max | one | select | sum | warning | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,26,Fetch breach statistics (defensive query).,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_budget_limits,"async fetch_budget_limits(session: AsyncSession, tenant_id: str) -> List[LimitSnapshot]",L6:__init__ | L5:overview_facade,LimitSnapshot | all | execute | float | order_by | scalars | select | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,28,Fetch active budget limits.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_incident_counts,"async fetch_incident_counts(session: AsyncSession, tenant_id: str) -> IncidentCountSnapshot",L6:__init__ | L5:overview_facade,IncidentCountSnapshot | and_ | case | count | execute | in_ | label | one | select | sum | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,33,Fetch incident counts from DB.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_incident_decision_counts,"async fetch_incident_decision_counts(session: AsyncSession, tenant_id: str) -> IncidentDecisionCountSnapshot",L6:__init__ | L5:overview_facade,IncidentDecisionCountSnapshot | case | count | execute | in_ | label | one | select | sum | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,26,Fetch incident counts by severity for decisions count.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_last_activity,"async fetch_last_activity(session: AsyncSession, tenant_id: str) -> AuditCountSnapshot",L6:__init__ | L5:overview_facade,AuditCountSnapshot | execute | max | scalar | select | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,11,Fetch last activity timestamp from audit ledger.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_pending_incidents,"async fetch_pending_incidents(session: AsyncSession, tenant_id: str) -> List[IncidentSnapshot]",L6:__init__ | L5:overview_facade,IncidentSnapshot | all | desc | execute | order_by | scalars | select | str | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,27,Fetch pending incidents for decisions projection.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_pending_proposals,"async fetch_pending_proposals(session: AsyncSession, tenant_id: str) -> List[ProposalSnapshot]",L6:__init__ | L5:overview_facade,ProposalSnapshot | all | desc | execute | order_by | scalars | select | str | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,26,Fetch pending policy proposals for decisions projection.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_proposal_count,"async fetch_proposal_count(session: AsyncSession, tenant_id: str) -> int",L6:__init__ | L5:overview_facade,count | execute | label | scalar | select | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,12,Fetch count of pending policy proposals.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_proposal_counts,"async fetch_proposal_counts(session: AsyncSession, tenant_id: str) -> ProposalCountSnapshot",L6:__init__ | L5:overview_facade,ProposalCountSnapshot | case | count | execute | label | one | select | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,18,Fetch policy proposal counts from DB.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_recovery_stats,"async fetch_recovery_stats(session: AsyncSession, tenant_id: str, since: datetime) -> RecoverySnapshot",L6:__init__ | L5:overview_facade,RecoverySnapshot | case | count | execute | in_ | label | one | select | sum | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,37,Fetch incident recovery statistics.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_run_cost,"async fetch_run_cost(session: AsyncSession, tenant_id: str, since: datetime) -> RunCostSnapshot",L6:__init__ | L5:overview_facade,RunCostSnapshot | coalesce | execute | int | label | scalar | select | sum | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,17,Fetch total LLM run cost from worker runs.,Persistence/Driver,high,L6 layer = persistence
overview,L6,overview_facade_driver,OverviewFacadeDriver.fetch_run_counts,"async fetch_run_counts(session: AsyncSession, tenant_id: str) -> RunCountSnapshot",L6:__init__ | L5:overview_facade,RunCountSnapshot | case | count | execute | label | one | select | sum | where,asyncio | audit_ledger | killswitch | policy | policy_control_plane | sqlalchemy | tenant | time,db_write,yes,20,Fetch worker run counts from DB.,Persistence/Driver,high,L6 layer = persistence
policies,L5,ast,BlockAction.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,2,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,Clause.__post_init__,__post_init__() -> None,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,ValueError,__future__,pure,no,4,,Internal Helper,high,dunder method
policies,L5,ast,Clause.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,to_dict,__future__,pure,no,5,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,ExistsPredicate.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,5,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,LogicalCondition.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,to_dict,__future__,pure,no,7,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,PolicyAST.__post_init__,__post_init__() -> None,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,ValueError,__future__,pure,no,4,,Internal Helper,high,dunder method
policies,L5,ast,PolicyAST.compute_hash,compute_hash() -> str,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,encode | hexdigest | sha256 | to_json,__future__,pure,no,12,Compute deterministic SHA256 hash of the AST.,Unclassified,low,no classification rules matched
policies,L5,ast,PolicyAST.mode,mode() -> Mode,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,3,Convenience accessor for policy mode.,Unclassified,low,no classification rules matched
policies,L5,ast,PolicyAST.name,name() -> str,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,3,Convenience accessor for policy name.,Unclassified,low,no classification rules matched
policies,L5,ast,PolicyAST.scope,scope() -> Scope,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,3,Convenience accessor for policy scope.,Unclassified,low,no classification rules matched
policies,L5,ast,PolicyAST.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,to_dict,__future__,pure,no,6,Convert AST to dictionary (serializable).,Internal Helper,medium,name matches 'to_'
policies,L5,ast,PolicyAST.to_json,to_json(indent: int | None) -> str,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,dumps | to_dict,__future__,pure,no,3,Convert AST to JSON string.,Internal Helper,medium,name matches 'to_'
policies,L5,ast,PolicyAST.version,version() -> int,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,3,Convenience accessor for policy version.,Unclassified,low,no classification rules matched
policies,L5,ast,PolicyMetadata.__post_init__,__post_init__() -> None,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,ValueError | strip,__future__,pure,no,7,,Internal Helper,high,dunder method
policies,L5,ast,PolicyMetadata.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,7,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,Predicate.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,7,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,RequireApprovalAction.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,2,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,WarnAction.to_dict,"to_dict() -> dict[str, Any]",?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,,__future__,pure,no,2,,Internal Helper,medium,name matches 'to_'
policies,L5,ast,is_block_action,is_block_action(action: Action) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if action is a BLOCK action.,Unclassified,low,no classification rules matched
policies,L5,ast,is_exists_predicate,is_exists_predicate(condition: Condition) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if condition is an exists predicate.,Unclassified,low,no classification rules matched
policies,L5,ast,is_logical_condition,is_logical_condition(condition: Condition) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if condition is a compound logical condition.,Unclassified,low,no classification rules matched
policies,L5,ast,is_predicate,is_predicate(condition: Condition) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if condition is a simple predicate.,Unclassified,low,no classification rules matched
policies,L5,ast,is_require_approval_action,is_require_approval_action(action: Action) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if action is a REQUIRE_APPROVAL action.,Unclassified,low,no classification rules matched
policies,L5,ast,is_warn_action,is_warn_action(action: Action) -> bool,?:parser | ?:ir_builder | ?:visitors | ?:__init__ | L5:ir_compiler | L5:visitors | L5:compiler_parser | L5:ir_builder | L5:validator | L5:dsl_parser,isinstance,__future__,pure,no,3,Check if action is a WARN action.,Unclassified,low,no classification rules matched
policies,L5,authority_checker,OverrideAuthorityChecker._is_override_active,_is_override_active(override_authority: Any) -> bool,?:__init__,getattr | hasattr | is_override_active | now,,pure,no,17,Check if override is currently active.,Internal Helper,medium,private function
policies,L5,authority_checker,OverrideAuthorityChecker.check,check(override_authority: Any) -> OverrideCheckResult,?:__init__,OverrideCheckResult | _is_override_active | getattr | int | max | now | total_seconds,,pure,no,69,Check override authority status.,Policy/Decision,medium,name matches 'check'
policies,L5,authority_checker,OverrideAuthorityChecker.check_from_dict,"check_from_dict(policy_id: str, currently_overridden: bool, override_allowed: bool, override_by: Optional[str], override_reason: Optional[str], override_started_at: Optional[datetime], override_expires_at: Optional[datetime]) -> OverrideCheckResult",?:__init__,OverrideCheckResult | int | max | now | total_seconds,,pure,no,72,Check override status from individual fields.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(name matches 'from_')
policies,L5,authority_checker,OverrideCheckResult.to_dict,"to_dict() -> dict[str, Any]",?:__init__,isoformat,,pure,no,16,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
policies,L5,authority_checker,should_skip_enforcement,should_skip_enforcement(override_authority: Any) -> bool,?:__init__,OverrideAuthorityChecker | check,,pure,no,13,Quick helper to check if enforcement should be skipped.,Policy/Decision,medium,name matches 'enforce'
policies,L5,binding_moment_enforcer,_check_fields_changed,"_check_fields_changed(policy: Any, context: Dict[str, Any]) -> bool",?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,get | getattr,,pure,no,17,Check if monitored fields changed (for ON_CHANGE binding).,Internal Helper,medium,private function
policies,L5,binding_moment_enforcer,_mark_evaluated,"_mark_evaluated(run_id: str, policy_id: str) -> None",?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,add | set,,db_write,no,5,Mark a policy as evaluated for a run.,Internal Helper,medium,private function
policies,L5,binding_moment_enforcer,_was_evaluated,"_was_evaluated(run_id: str, policy_id: str) -> bool",?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,,,pure,no,3,Check if a policy was already evaluated for a run.,Internal Helper,medium,private function
policies,L5,binding_moment_enforcer,clear_run_cache,clear_run_cache(run_id: str) -> None,?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,,,pure,no,4,Clear the evaluation cache for a run (call on run completion).,Unclassified,low,no classification rules matched
policies,L5,binding_moment_enforcer,get_binding_moment,get_binding_moment(policy: Any) -> BindingMoment,?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,BindingMoment | getattr | isinstance | lower | warning,,pure,no,39,Get the binding moment for a policy.,Unclassified,low,no classification rules matched
policies,L5,binding_moment_enforcer,should_evaluate_policy,"should_evaluate_policy(policy: Any, context: Dict[str, Any], evaluation_point: EvaluationPoint) -> BindingDecision",?:prevention_engine | L5:prevention_engine | ?:test_binding_moment_enforcer,BindingDecision | _check_fields_changed | _mark_evaluated | _was_evaluated | debug | get | get_binding_moment | getattr | str,,pure,no,110,Determine if a policy should be evaluated at this point.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,claim_decision_engine,determine_claim_status,"determine_claim_status(evaluation_result: Dict[str, Any]) -> str",,get,,pure,no,20,Determine the execution status from an evaluation result.,Internal Helper,low,pure function with no callers
policies,L5,claim_decision_engine,get_result_confidence,"get_result_confidence(evaluation_result: Dict[str, Any]) -> float",,get,,pure,no,15,Extract confidence from evaluation result with default fallback.,Internal Helper,low,pure function with no callers
policies,L5,claim_decision_engine,is_candidate_claimable,is_candidate_claimable(confidence: Optional[float]) -> bool,,,,pure,no,21,Determine if a candidate is eligible for claiming based on confidence.,Internal Helper,low,pure function with no callers
policies,L5,compiler_parser,ParseError.__init__,"__init__(message: str, token: Token)",,__init__ | super,grammar | nodes | tokenizer,pure,no,4,,Internal Helper,high,dunder method
policies,L5,compiler_parser,Parser.__init__,__init__(tokens: List[Token]),,,grammar | nodes | tokenizer,pure,no,3,,Internal Helper,high,dunder method
policies,L5,compiler_parser,Parser.advance,advance() -> Token,,,grammar | nodes | tokenizer,pure,no,5,Advance to next token and return current.,Internal Helper,low,pure function with no callers
policies,L5,compiler_parser,Parser.current,current() -> Token,,len,grammar | nodes | tokenizer,pure,no,5,Get current token.,Internal Helper,low,pure function with no callers
policies,L5,compiler_parser,Parser.expect,expect(token_type: TokenType) -> Token,,ParseError | advance,grammar | nodes | tokenizer,pure,no,5,Expect current token to be of given type.,Internal Helper,low,pure function with no callers
policies,L5,compiler_parser,Parser.from_source,from_source(source: str) -> 'Parser',,Tokenizer | cls | tokenize,grammar | nodes | tokenizer,pure,no,5,Create parser from source code.,Internal Helper,medium,name matches 'from_'
policies,L5,compiler_parser,Parser.match,match(*token_types) -> bool,,,grammar | nodes | tokenizer,pure,no,3,Check if current token matches any of the given types.,Internal Helper,low,pure function with no callers
policies,L5,compiler_parser,Parser.parse,parse() -> ProgramNode,,ParseError | ProgramNode | append | match | parse_import | parse_policy_decl | parse_rule_decl,grammar | nodes | tokenizer,pure,no,20,Parse the token stream into an AST.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_action_block,parse_action_block() -> ActionBlockNode,,ActionBlockNode | ParseError | advance | parse_route_target,grammar | nodes | tokenizer,pure,no,26,Parse an action block.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_and_expr,parse_and_expr() -> ExprNode,,BinaryOpNode | advance | match | parse_not_expr,grammar | nodes | tokenizer,pure,no,16,Parse AND expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_category,parse_category() -> PolicyCategory,,ParseError | advance | items | match,grammar | nodes | tokenizer,pure,no,16,Parse a policy category.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_comparison,parse_comparison() -> ExprNode,,BinaryOpNode | advance | parse_value,grammar | nodes | tokenizer,pure,no,25,Parse comparison expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_condition_block,parse_condition_block() -> ConditionBlockNode,,ConditionBlockNode | expect | parse_action_block | parse_expr,grammar | nodes | tokenizer,pure,no,13,Parse a when/then condition block.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_expr,parse_expr() -> ExprNode,,parse_or_expr,grammar | nodes | tokenizer,pure,no,3,Parse an expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_func_call,parse_func_call(callee: ExprNode) -> FuncCallNode,,FuncCallNode | advance | append | expect | match | parse_expr,grammar | nodes | tokenizer,pure,no,19,Parse a function call.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_import,parse_import() -> ImportNode,,ImportNode | expect,grammar | nodes | tokenizer,pure,no,9,Parse an import statement.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_not_expr,parse_not_expr() -> ExprNode,,UnaryOpNode | advance | match | parse_comparison | parse_not_expr,grammar | nodes | tokenizer,pure,no,12,Parse NOT expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_or_expr,parse_or_expr() -> ExprNode,,BinaryOpNode | advance | match | parse_and_expr,grammar | nodes | tokenizer,pure,no,16,Parse OR expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_policy_body,parse_policy_body() -> List[ASTNode],,ParseError | append | match | parse_action_block | parse_condition_block | parse_priority | parse_rule_decl | parse_rule_ref | peek,grammar | nodes | tokenizer,pure,no,21,Parse policy body contents.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_policy_decl,parse_policy_decl() -> PolicyDeclNode,,PolicyDeclNode | expect | parse_category | parse_policy_body,grammar | nodes | tokenizer,pure,no,17,Parse a policy declaration.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_priority,parse_priority() -> PriorityNode,,PriorityNode | expect | int,grammar | nodes | tokenizer,pure,no,9,Parse a priority declaration.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_route_target,parse_route_target() -> RouteTargetNode,,RouteTargetNode | expect,grammar | nodes | tokenizer,pure,no,9,Parse a route target.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_rule_body,parse_rule_body() -> List[ASTNode],,ParseError | append | match | parse_action_block | parse_condition_block | parse_priority,grammar | nodes | tokenizer,pure,no,15,Parse rule body contents.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_rule_decl,parse_rule_decl() -> RuleDeclNode,,RuleDeclNode | expect | parse_category | parse_rule_body,grammar | nodes | tokenizer,pure,no,17,Parse a rule declaration.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_rule_ref,parse_rule_ref() -> RuleRefNode,,RuleRefNode | expect,grammar | nodes | tokenizer,pure,no,9,Parse a rule reference.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.parse_value,parse_value() -> ExprNode,,AttrAccessNode | IdentNode | LiteralNode | ParseError | advance | expect | float | int | match | parse_expr | parse_func_call,grammar | nodes | tokenizer,pure,no,55,Parse a value expression.,Internal Helper,medium,name matches 'parse'
policies,L5,compiler_parser,Parser.peek,peek(offset: int) -> Token,,len,grammar | nodes | tokenizer,pure,no,6,Peek ahead by offset tokens.,Internal Helper,low,pure function with no callers
policies,L5,content_accuracy,ContentAccuracyResult.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:prevention_hook | L5:prevention_hook,len | str,,pure,no,21,,Internal Helper,medium,name matches 'to_'
policies,L5,content_accuracy,ContentAccuracyValidator.__init__,"__init__(strict_mode: bool, required_fields: Optional[List[str]], domain_terms: Optional[Dict[str, List[str]]])",?:__init__ | ?:prevention_hook | L5:prevention_hook,compile,,pure,no,14,,Internal Helper,high,dunder method
policies,L5,content_accuracy,ContentAccuracyValidator._claims_affirmative,_claims_affirmative(claim: str) -> bool,?:__init__ | ?:prevention_hook | L5:prevention_hook,search,,pure,no,17,Check if the claim makes an affirmative statement.,Internal Helper,medium,private function
policies,L5,content_accuracy,ContentAccuracyValidator._detect_assertion_type,_detect_assertion_type(text: str) -> AssertionType,?:__init__ | ?:prevention_hook | L5:prevention_hook,lower | search,,pure,no,20,Detect the type of assertion in the text.,Internal Helper,medium,private function
policies,L5,content_accuracy,ContentAccuracyValidator._extract_claim,"_extract_claim(text: str, terms: List[str]) -> str",?:__init__ | ?:prevention_hook | L5:prevention_hook,escape | search | split | strip,,pure,no,10,Extract the sentence containing the claim about these terms.,Internal Helper,medium,private function
policies,L5,content_accuracy,ContentAccuracyValidator._get_nested_value,"_get_nested_value(data: Dict[str, Any], key: str) -> Any",?:__init__ | ?:prevention_hook | L5:prevention_hook,get | isinstance | split,,pure,no,15,Get a value from nested dict using dot notation.,Internal Helper,medium,private function
policies,L5,content_accuracy,ContentAccuracyValidator.validate,"validate(output: str, context: Dict[str, Any], user_query: Optional[str]) -> ContentAccuracyResult",?:__init__ | ?:prevention_hook | L5:prevention_hook,AssertionCheck | ContentAccuracyResult | _claims_affirmative | _detect_assertion_type | _extract_claim | _get_nested_value | any | append | escape | items | join | len | search,,pure,no,93,Validate that output content is accurate given the context.,Policy/Decision,medium,name matches 'validate'
policies,L5,content_accuracy,validate_content_accuracy,"validate_content_accuracy(output: str, context: Dict[str, Any], user_query: Optional[str], strict_mode: bool) -> ContentAccuracyResult",?:__init__ | ?:prevention_hook | L5:prevention_hook,ContentAccuracyValidator | validate,,pure,no,22,Convenience function to validate content accuracy.,Policy/Decision,medium,name matches 'validate'
policies,L5,cus_enforcement_service,get_cus_enforcement_service,get_cus_enforcement_service() -> CusEnforcementService,?:cus_enforcement | L4:policies_handler | ?:shim_guard,get_cus_enforcement_engine,cus_enforcement_engine,pure,no,11,Get the CusEnforcementService instance.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'enforce')
policies,L5,customer_policy_read_engine,CustomerPolicyReadService.__init__,__init__(session: 'Session'),L3:customer_policies_adapter | L5:customer_policies_adapter,get_policy_read_driver,policy_read_driver | sqlmodel,pure,no,8,Initialize with database session (passed to driver).,Internal Helper,high,dunder method
policies,L5,customer_policy_read_engine,CustomerPolicyReadService._calculate_period_bounds,"_calculate_period_bounds(now: datetime, period: str) -> tuple[datetime, datetime]",L3:customer_policies_adapter | L5:customer_policies_adapter,replace | timedelta | weekday,policy_read_driver | sqlmodel,pure,no,32,Calculate period start and reset time.,Internal Helper,medium,private function
policies,L5,customer_policy_read_engine,CustomerPolicyReadService._get_budget_constraint,_get_budget_constraint(tenant_id: str) -> Optional[BudgetConstraint],L3:customer_policies_adapter | L5:customer_policies_adapter,BudgetConstraint | _calculate_period_bounds | get_tenant_budget_settings | get_usage_sum_since | isoformat | max | now | round,policy_read_driver | sqlmodel,pure,no,35,Get budget constraint for tenant.,Internal Helper,medium,private function
policies,L5,customer_policy_read_engine,CustomerPolicyReadService._get_guardrails,_get_guardrails() -> List[GuardrailSummary],L3:customer_policies_adapter | L5:customer_policies_adapter,GuardrailSummary | list_all_guardrails,policy_read_driver | sqlmodel,pure,no,21,Get all guardrails.,Internal Helper,medium,private function
policies,L5,customer_policy_read_engine,CustomerPolicyReadService._get_rate_limits,_get_rate_limits(tenant_id: str) -> List[RateLimit],L3:customer_policies_adapter | L5:customer_policies_adapter,RateLimit,policy_read_driver | sqlmodel,pure,no,16,Get rate limits for tenant.,Internal Helper,medium,private function
policies,L5,customer_policy_read_engine,CustomerPolicyReadService.get_guardrail_detail,"get_guardrail_detail(tenant_id: str, guardrail_id: str) -> Optional[GuardrailSummary]",L3:customer_policies_adapter | L5:customer_policies_adapter,GuardrailSummary | ValueError | get_guardrail_by_id,policy_read_driver | sqlmodel,pure,no,35,Get guardrail detail.,Policy/Decision,medium,name matches 'guard'
policies,L5,customer_policy_read_engine,CustomerPolicyReadService.get_policy_constraints,get_policy_constraints(tenant_id: str) -> PolicyConstraints,L3:customer_policies_adapter | L5:customer_policies_adapter,PolicyConstraints | ValueError | _get_budget_constraint | _get_guardrails | _get_rate_limits | isoformat | now,policy_read_driver | sqlmodel,pure,no,34,Get policy constraints for a tenant.,Unclassified,low,no classification rules matched
policies,L5,customer_policy_read_engine,get_customer_policy_read_service,get_customer_policy_read_service(session: 'Session') -> CustomerPolicyReadService,L3:customer_policies_adapter | L5:customer_policies_adapter,CustomerPolicyReadService,policy_read_driver | sqlmodel,pure,no,15,Factory function for CustomerPolicyReadService.,Unclassified,low,no classification rules matched
policies,L5,decorator,_extract_subject,"_extract_subject(args: tuple, kwargs: dict, extractor: Optional[Callable[..., str]]) -> str",?:__init__,extractor | hasattr | str,__future__ | kernel,pure,no,25,Extract subject from function arguments.,Internal Helper,medium,private function
policies,L5,decorator,_extract_tenant_id,"_extract_tenant_id(args: tuple, kwargs: dict, extractor: Optional[Callable[..., str]]) -> str",?:__init__,extractor | hasattr | str | values,__future__ | kernel,pure,no,27,Extract tenant_id from function arguments.,Internal Helper,medium,private function
policies,L5,decorator,governed,"governed(capability: str, execution_vector: str, extract_tenant: Optional[Callable[..., str]], extract_subject: Optional[Callable[..., str]], reason: Optional[str]) -> Callable[[F], F]",?:__init__,InvocationContext | _extract_subject | _extract_tenant_id | func | invoke | invoke_async | iscoroutinefunction | wraps,__future__ | kernel,pure,no,88,Decorator that routes execution through the ExecutionKernel.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,DegradedModeStatus.get_inactive,get_inactive() -> 'DegradedModeStatus',?:test_degraded_mode,cls,,pure,no,3,Get inactive status.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,enter_degraded_mode,"enter_degraded_mode(reason: str, entered_by: str, existing_runs_action: str) -> DegradedModeTransition",?:test_degraded_mode,DegradedModeStatus | DegradedModeTransition | isoformat | now | warning,,pure,no,47,Enter degraded mode.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,exit_degraded_mode,exit_degraded_mode(exited_by: str) -> DegradedModeTransition,?:test_degraded_mode,DegradedModeTransition | get_inactive | info | isoformat | now,,pure,no,37,Exit degraded mode.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,get_degraded_mode_status,get_degraded_mode_status() -> DegradedModeStatus,?:test_degraded_mode,get_inactive,,pure,no,13,Get current degraded mode status.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,get_existing_run_action,get_existing_run_action() -> str,?:test_degraded_mode,,,pure,no,11,Get action for existing/in-flight runs in degraded mode.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,is_degraded_mode_active,is_degraded_mode_active() -> bool,?:test_degraded_mode,,,pure,no,9,Check if degraded mode is currently active.,Unclassified,low,no classification rules matched
policies,L5,degraded_mode,should_allow_new_run,should_allow_new_run(run_id: str) -> bool,?:test_degraded_mode,is_degraded_mode_active | warning,,pure,no,20,Check if a new run should be allowed.,Policy/Decision,medium,name matches 'allow'
policies,L5,deterministic_engine,DeterministicEngine.__init__,__init__(),?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,IntentEmitter | _register_builtins,grammar | intent | ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,deterministic_engine,DeterministicEngine._action_to_intent_type,_action_to_intent_type(action: ActionType) -> IntentType,?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,get,grammar | intent | ir_nodes,pure,no,9,Convert action to intent type.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._call_function,"async _call_function(name: str, args: List[Any], context: ExecutionContext, module: IRModule) -> Any",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,_execute_function | get_function,grammar | intent | ir_nodes,pure,yes,22,Call a function (builtin or user-defined).,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._eval_binary_op,"_eval_binary_op(op: str, left: Any, right: Any) -> Any",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,bool,grammar | intent | ir_nodes,pure,no,7,Evaluate binary operation.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._eval_compare,"_eval_compare(op: str, left: Any, right: Any) -> bool",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,bool | get,grammar | intent | ir_nodes,pure,no,14,Evaluate comparison.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._eval_unary_op,"_eval_unary_op(op: str, operand: Any) -> Any",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,bool,grammar | intent | ir_nodes,pure,no,5,Evaluate unary operation.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._execute_function,"async _execute_function(module: IRModule, func: IRFunction, context: ExecutionContext) -> Optional[ActionType]",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,RuntimeError | _execute_instruction | add_trace | get | isinstance | pop_call | push_call,grammar | intent | ir_nodes,pure,yes,56,Execute a single function.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._execute_instruction,"async _execute_instruction(instr: IRInstruction, registers: Dict[int, Any], context: ExecutionContext, module: IRModule) -> Any",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,IntentPayload | _action_to_intent_type | _call_function | _eval_binary_op | _eval_compare | _eval_unary_op | add_trace | create_intent | get | get_variable | isinstance | set_variable | upper,grammar | intent | ir_nodes,pure,yes,108,Execute a single instruction.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine._register_builtins,"_register_builtins() -> Dict[str, Callable[..., Any]]",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,endswith | get | getattr | isinstance | len | lower | startswith | upper,grammar | intent | ir_nodes,pure,no,14,Register built-in functions.,Internal Helper,medium,private function
policies,L5,deterministic_engine,DeterministicEngine.execute,"async execute(module: IRModule, context: ExecutionContext, entry_function: Optional[str]) -> ExecutionResult",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,ExecutionResult | _execute_function | clear | emit_all | get_function | get_functions_by_category | list | str | values,grammar | intent | ir_nodes,pure,yes,69,Execute a compiled policy module.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionContext.__post_init__,__post_init__(),?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,_generate_id,grammar | intent | ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,deterministic_engine,ExecutionContext._generate_id,_generate_id() -> str,?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,encode | hexdigest | sha256,grammar | intent | ir_nodes,pure,no,4,Generate deterministic execution ID from context.,Internal Helper,medium,private function
policies,L5,deterministic_engine,ExecutionContext.add_trace,"add_trace(event: str, data: Dict[str, Any]) -> None",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,append,grammar | intent | ir_nodes,pure,no,9,Add event to execution trace.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionContext.get_variable,get_variable(name: str) -> Any,?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,get,grammar | intent | ir_nodes,pure,no,12,Get a variable value.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionContext.pop_call,pop_call() -> Optional[str],?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,pop,grammar | intent | ir_nodes,pure,no,5,Pop function from call stack.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionContext.push_call,push_call(function_name: str) -> None,?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,append,grammar | intent | ir_nodes,pure,no,3,Push function onto call stack.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionContext.set_variable,"set_variable(name: str, value: Any) -> None",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,,grammar | intent | ir_nodes,pure,no,3,Set a variable value.,Operation,high,called by L4 orchestrator
policies,L5,deterministic_engine,ExecutionResult.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:dag_executor | ?:worker | L4:dag_executor | ?:apply | ?:mypy_zones | ?:test_m20_runtime,len | to_dict,grammar | intent | ir_nodes,pure,no,13,Convert to dictionary for API response.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,dsl_parser,Lexer.__init__,__init__(source: str) -> None,,compile,__future__ | ast,pure,no,6,,Internal Helper,high,dunder method
policies,L5,dsl_parser,Lexer._advance,_advance(text: str) -> None,,,__future__ | ast,pure,no,9,"Advance position, tracking line/column.",Internal Helper,medium,private function
policies,L5,dsl_parser,Lexer._convert_value,"_convert_value(token_type: str, text: str) -> Any",,float | int,__future__ | ast,pure,no,12,Convert token text to appropriate Python value.,Internal Helper,medium,private function
policies,L5,dsl_parser,Lexer.tokenize,tokenize() -> list[Token],,ParseError | ParseLocation | Token | _advance | _convert_value | append | group | len | match,__future__ | ast,pure,no,35,Convert source text to list of tokens.,Internal Helper,low,pure function with no callers
policies,L5,dsl_parser,ParseError.__init__,"__init__(message: str, location: ParseLocation | None) -> None",,__init__ | super,__future__ | ast,pure,no,7,,Internal Helper,high,dunder method
policies,L5,dsl_parser,ParseLocation.__str__,__str__() -> str,,,__future__ | ast,pure,no,2,,Internal Helper,high,dunder method
policies,L5,dsl_parser,Parser.__init__,__init__(tokens: list[Token]) -> None,,,__future__ | ast,pure,no,3,,Internal Helper,high,dunder method
policies,L5,dsl_parser,Parser._parse_actions,_parse_actions() -> list[Action],,_try_parse_action | append | error,__future__ | ast,pure,no,14,Parse one or more actions.,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_and_expr,_parse_and_expr() -> Condition,,LogicalCondition | _parse_atom | accept,__future__ | ast,pure,no,13,Parse AND expression: atom (AND atom)*,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_atom,_parse_atom() -> Condition,,ExistsPredicate | _parse_or_expr | _parse_predicate | accept | expect,__future__ | ast,pure,no,17,Parse atomic condition: predicate | exists | ( or_expr ),Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_clause,_parse_clause() -> Clause,,Clause | _parse_actions | _parse_condition | expect | tuple,__future__ | ast,pure,no,11,Parse a single when-then clause.,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_clauses,_parse_clauses() -> list[Clause],,_parse_clause | append | error,__future__ | ast,pure,no,11,Parse one or more when-then clauses.,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_condition,_parse_condition() -> Condition,,_parse_or_expr,__future__ | ast,pure,no,3,Parse a condition (or_expr).,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_header,_parse_header() -> PolicyMetadata,,PolicyMetadata | accept | error | expect,__future__ | ast,pure,no,30,Parse policy header.,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_or_expr,_parse_or_expr() -> Condition,,LogicalCondition | _parse_and_expr | accept,__future__ | ast,pure,no,13,Parse OR expression: and_expr (OR and_expr)*,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_predicate,_parse_predicate() -> Predicate,,Predicate | _parse_value | accept | error | expect,__future__ | ast,pure,no,18,Parse simple predicate: metric comparator value,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._parse_value,_parse_value() -> int | float | str | bool,,accept | error,__future__ | ast,pure,no,6,Parse a literal value.,Internal Helper,medium,private function
policies,L5,dsl_parser,Parser._try_parse_action,_try_parse_action() -> Action | None,,BlockAction | RequireApprovalAction | WarnAction | accept | expect,__future__ | ast,pure,no,13,"Try to parse an action, return None if not an action.",Internal Helper,medium,private function
policies,L5,dsl_parser,Parser.accept,accept(*token_types) -> Token | None,,,__future__ | ast,pure,no,7,Consume token if it matches any of the types.,Internal Helper,low,pure function with no callers
policies,L5,dsl_parser,Parser.current,current() -> Token,,len,__future__ | ast,pure,no,5,Current token.,Internal Helper,low,pure function with no callers
policies,L5,dsl_parser,Parser.error,error(message: str) -> ParseError,,ParseError | ParseLocation,__future__ | ast,pure,no,6,Create a parse error at current position.,Internal Helper,low,pure function with no callers
policies,L5,dsl_parser,Parser.expect,expect(token_type: str) -> Token,,error,__future__ | ast,pure,no,7,Consume and return token of expected type.,Internal Helper,low,pure function with no callers
policies,L5,dsl_parser,Parser.parse,parse() -> PolicyAST,,PolicyAST | _parse_clauses | _parse_header | expect | tuple,__future__ | ast,pure,no,6,Parse complete policy.,Internal Helper,medium,name matches 'parse'
policies,L5,dsl_parser,parse,parse(source: str) -> PolicyAST,,Lexer | Parser | parse | tokenize,__future__ | ast,pure,no,30,Parse Policy DSL text into AST.,Internal Helper,medium,name matches 'parse'
policies,L5,dsl_parser,parse_condition,parse_condition(source: str) -> Condition,,Lexer | Parser | _parse_condition | error | tokenize,__future__ | ast,pure,no,25,Parse a standalone condition expression.,Internal Helper,medium,name matches 'parse'
policies,L5,eligibility_engine,CapabilityLookup.exists,exists(capability_name: str) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,3,Check if capability exists in registry.,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,CapabilityLookup.is_frozen,is_frozen(capability_name: str) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,3,Check if capability is frozen.,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,ContractLookup.has_similar_pending,"has_similar_pending(capabilities: tuple[str, ...], window_hours: int) -> tuple[bool, Optional[UUID]]",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,13,Check for similar pending contracts.,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultCapabilityLookup.__init__,"__init__(registry: Optional[frozenset[str]], frozen: Optional[frozenset[str]])",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,frozenset,orchestrator,pure,no,7,,Internal Helper,high,dunder method
policies,L5,eligibility_engine,DefaultCapabilityLookup.exists,exists(capability_name: str) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultCapabilityLookup.is_frozen,is_frozen(capability_name: str) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultContractLookup.__init__,"__init__(pending_contracts: Optional[dict[frozenset[str], UUID]])",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,5,,Internal Helper,high,dunder method
policies,L5,eligibility_engine,DefaultContractLookup.has_similar_pending,"has_similar_pending(capabilities: tuple[str, ...], window_hours: int) -> tuple[bool, Optional[UUID]]",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,frozenset | items,orchestrator,pure,no,10,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultGovernanceSignalLookup.__init__,"__init__(blocking_scopes: Optional[dict[str, str]])",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Internal Helper,high,dunder method
policies,L5,eligibility_engine,DefaultGovernanceSignalLookup.has_blocking_signal,"has_blocking_signal(scope: str) -> tuple[bool, Optional[str]]",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,4,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultPreApprovalLookup.__init__,__init__(approved_ids: Optional[set[UUID]]),?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,set,orchestrator,pure,no,2,,Internal Helper,high,dunder method
policies,L5,eligibility_engine,DefaultPreApprovalLookup.has_system_pre_approval,has_system_pre_approval(proposal_id: UUID) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,DefaultSystemHealthLookup.__init__,__init__(status: SystemHealthStatus),?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Internal Helper,high,dunder method
policies,L5,eligibility_engine,DefaultSystemHealthLookup.get_status,get_status() -> SystemHealthStatus,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,2,,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,EligibilityEngine.__init__,"__init__(config: Optional[EligibilityConfig], capability_lookup: Optional[CapabilityLookup], governance_lookup: Optional[GovernanceSignalLookup], health_lookup: Optional[SystemHealthLookup], contract_lookup: Optional[ContractLookup], pre_approval_lookup: Optional[PreApprovalLookup])",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,DefaultCapabilityLookup | DefaultContractLookup | DefaultGovernanceSignalLookup | DefaultPreApprovalLookup | DefaultSystemHealthLookup,orchestrator,pure,no,26,Initialize eligibility engine with lookups.,Internal Helper,high,dunder method
policies,L5,eligibility_engine,EligibilityEngine._create_verdict,"_create_verdict(decision: EligibilityDecision, reason: str, results: list[RuleResult], first_failing: Optional[str], blocking_signals: list[str], missing_prerequisites: list[str]) -> EligibilityVerdict",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,EligibilityVerdict | len | now | tuple,orchestrator,pure,no,21,Create eligibility verdict from evaluation results.,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e001_confidence_threshold,_evaluate_e001_confidence_threshold(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | float,orchestrator,pure,no,20,E-001: Validator Confidence Threshold,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e002_known_capability,_evaluate_e002_known_capability(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | append | exists | join | len | list,orchestrator,pure,no,26,E-002: Known Capability Reference,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e003_no_blocking_signal,_evaluate_e003_no_blocking_signal(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | append | has_blocking_signal | join | len,orchestrator,pure,no,31,E-003: No Blocking Governance Signal,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e004_actionable_type,_evaluate_e004_actionable_type(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult,orchestrator,pure,no,36,E-004: Actionable Issue Type,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e005_source_allowlist,_evaluate_e005_source_allowlist(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | list,orchestrator,pure,no,19,E-005: Source Allowlist,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e006_not_duplicate,_evaluate_e006_not_duplicate(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | has_similar_pending | str,orchestrator,pure,no,24,E-006: Not Duplicate,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e100_below_minimum_confidence,_evaluate_e100_below_minimum_confidence(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | float,orchestrator,pure,no,22,E-100: Below Minimum Confidence,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e101_critical_without_escalation,_evaluate_e101_critical_without_escalation(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult,orchestrator,pure,no,25,E-101: Critical Without Escalation,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e102_frozen_capability,_evaluate_e102_frozen_capability(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | append | is_frozen | join | len | list,orchestrator,pure,no,25,E-102: Frozen Capability Target,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e103_system_scope_without_preapproval,_evaluate_e103_system_scope_without_preapproval(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | has_system_pre_approval,orchestrator,pure,no,23,E-103: System Scope Without Founder Pre-Approval,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine._evaluate_e104_health_degraded,_evaluate_e104_health_degraded(input: EligibilityInput) -> RuleResult,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,RuleResult | get_status,orchestrator,pure,no,21,E-104: Health Degraded,Internal Helper,medium,private function
policies,L5,eligibility_engine,EligibilityEngine.evaluate,evaluate(input: EligibilityInput) -> EligibilityVerdict,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,_create_verdict | append | rule_fn,orchestrator,pure,no,89,Evaluate eligibility for a proposal.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
policies,L5,eligibility_engine,GovernanceSignalLookup.has_blocking_signal,"has_blocking_signal(scope: str) -> tuple[bool, Optional[str]]",?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,9,Check if scope has a blocking governance signal.,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,PreApprovalLookup.has_system_pre_approval,has_system_pre_approval(proposal_id: UUID) -> bool,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,3,Check if proposal has system-wide pre-approval.,Operation,high,called by L4 orchestrator
policies,L5,eligibility_engine,SystemHealthLookup.get_status,get_status() -> SystemHealthStatus,?:__init__ | ?:contract_service | L4:contract_engine | L4:__init__ | ?:test_founder_review_invariants | ?:test_contract_invariants | ?:test_eligibility_invariants,,orchestrator,pure,no,3,Get current system health status.,Operation,high,called by L4 orchestrator
policies,L5,engine,PolicyEngine.__init__,"__init__(database_url: Optional[str], governor)",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,get | get_policy_engine_driver,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,33,,Internal Helper,high,dunder method
policies,L5,engine,PolicyEngine._add_windowed_value,"_add_windowed_value(key: str, value: float) -> None",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,append | now,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,6,Add value to windowed tracking.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_business_rules,"async _check_business_rules(request: PolicyEvaluationRequest) -> Tuple[List[PolicyViolation], List[PolicyModification]]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_evaluate_business_rule | append | get,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,27,Check request against business rules.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_compliance,async _check_compliance(request: PolicyEvaluationRequest) -> List[PolicyViolation],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_evaluate_compliance_rule | append,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,20,Check request against compliance policies.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_cooldown,_check_cooldown(request: PolicyEvaluationRequest) -> Optional[PolicyViolation],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | isoformat | items | list | now | total_seconds,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,27,Check if agent is in cooldown.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_ethical_constraints,async _check_ethical_constraints(request: PolicyEvaluationRequest) -> List[PolicyViolation],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_evaluate_ethical_constraint | append,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,13,Check request against ethical constraints.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_risk_ceilings,"async _check_risk_ceilings(request: PolicyEvaluationRequest) -> Tuple[List[PolicyViolation], List[PolicyModification]]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_evaluate_risk_ceiling | append | now,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,24,Check request against risk ceilings.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._check_safety_rules,async _check_safety_rules(request: PolicyEvaluationRequest) -> List[PolicyViolation],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_evaluate_safety_rule | append | get | now | sorted,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,29,Check request against safety rules.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._classify_recoverability,_classify_recoverability(violation) -> 'RecoverabilityType',?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,13,Classify violation recoverability (GAP 5).,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._classify_severity,_classify_severity(violation) -> 'ViolationSeverity',?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,20,Classify violation severity (GAP 5).,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._evaluate_business_rule,"_evaluate_business_rule(rule: BusinessRule, request: PolicyEvaluationRequest) -> Tuple[Optional[PolicyViolation], Optional[PolicyModification]]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | get,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,63,Evaluate a business rule.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._evaluate_compliance_rule,"_evaluate_compliance_rule(policy: Policy, rule: PolicyRule, request: PolicyEvaluationRequest) -> Optional[PolicyViolation]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | get | list | match | set,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,58,Evaluate a compliance rule.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._evaluate_ethical_constraint,"_evaluate_ethical_constraint(constraint: EthicalConstraint, request: PolicyEvaluationRequest) -> Optional[PolicyViolation]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | _extract_text_content | get | lower,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,45,Evaluate a single ethical constraint.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._evaluate_risk_ceiling,"_evaluate_risk_ceiling(ceiling: RiskCeiling, request: PolicyEvaluationRequest) -> Tuple[Optional[PolicyViolation], Optional[PolicyModification]]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyModification | PolicyViolation | _add_windowed_value | _get_windowed_value | get | warning,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,69,Evaluate a single risk ceiling.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._evaluate_safety_rule,"_evaluate_safety_rule(rule: SafetyRule, request: PolicyEvaluationRequest) -> Optional[PolicyViolation]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | _extract_text_content | get | lower | now | search | timedelta,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,86,Evaluate a single safety rule.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._extract_text_content,_extract_text_content(request: PolicyEvaluationRequest) -> str,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,append | dumps | join | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,17,Extract text content from request for analysis.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._get_windowed_value,"_get_windowed_value(key: str, window_seconds: int) -> float",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,now | sum | timedelta,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,13,Get accumulated value within time window.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._is_cache_stale,_is_cache_stale() -> bool,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,now | total_seconds,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,7,Check if policy cache is stale.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._load_default_policies,_load_default_policies() -> None,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,EthicalConstraint | RiskCeiling | SafetyRule | now,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,51,Load default policies when database is unavailable.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._load_policies,async _load_policies() -> PolicyLoadResult,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,BusinessRule | BusinessRuleType | EthicalConstraint | EthicalConstraintType | PolicyLoadResult | RiskCeiling | SafetyRule | SafetyRuleType | _get_engine | _load_default_policies | append | connect | error | fetch_business_rules | fetch_ethical_constraints,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,126,Load policies from database.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._persist_evaluation,"async _persist_evaluation(request: PolicyEvaluationRequest, result: PolicyEvaluationResult) -> None",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | dispose | dumps | insert_evaluation | insert_violation | model_dump,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,54,Persist evaluation to audit log.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine._route_to_governor,async _route_to_governor(violations: List[PolicyViolation]) -> None,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,error | force_freeze | warning,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,32,Route violations to M18 Governor.,Internal Helper,medium,private function
policies,L5,engine,PolicyEngine.acknowledge_violation,"async acknowledge_violation(db, violation_id: str, notes: Optional[str]) -> bool",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | update_violation_acknowledged,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,22,Mark a violation as acknowledged.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.activate_policy_version,"async activate_policy_version(db, version_id: str, activated_by: str, dry_run: bool) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyEvaluationRequest | _get_engine | activate_version | add | append | commit | connect | deactivate_all_versions | dispose | error | evaluate | extend | fetch_active_policies_for_integrity | fetch_conflicts | fetch_dependency_edges,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,228,Activate a policy version with comprehensive pre-activation integrity checks.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.add_dependency_with_dag_check,"async add_dependency_with_dag_check(db, source_policy: str, target_policy: str, dependency_type: str, resolution_strategy: str, priority: int, description: Optional[str]) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | add | append | can_reach | commit | connect | dispose | error | extend | fetch_dependency_edges | get | insert_dependency | pop | set | str,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,90,Add a policy dependency with DAG validation.,Policy/Decision,medium,name matches 'check'
policies,L5,engine,PolicyEngine.clear_cooldowns,"async clear_cooldowns(db, agent_id: str, rule_name: Optional[str]) -> int",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,keys | list,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,9,Clear cooldowns for an agent.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.create_policy_version,"async create_policy_version(db, description: str, created_by: str)",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyVersion | _get_engine | commit | connect | deactivate_all_versions | debug | dispose | dumps | encode | get_current_version | hexdigest | insert_policy_version | int | model_dump | sha256,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,65,Create a new policy version snapshot.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.create_temporal_policy,"async create_temporal_policy(db, data: Dict)",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,TemporalPolicy | _get_engine | commit | connect | debug | dispose | get | insert_temporal_policy,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,30,Create a temporal policy.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.evaluate,"async evaluate(request: PolicyEvaluationRequest, db, dry_run: bool) -> PolicyEvaluationResult",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyEvaluationResult | _check_business_rules | _check_compliance | _check_cooldown | _check_ethical_constraints | _check_risk_ceilings | _check_safety_rules | _is_cache_stale | _load_policies | _persist_evaluation | _route_to_governor | append | emit_policy_decision | extend | info,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,162,Evaluate a request against all applicable policies.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,engine,PolicyEngine.evaluate_with_context,"async evaluate_with_context(db, action_type, policy_context, proposed_action: Optional[str], target_resource: Optional[str], estimated_cost: Optional[float], data_categories: Optional[List[str]], context: Optional[Dict])",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,EnhancedPolicyEvaluationResult | EnhancedPolicyViolation | PolicyEvaluationRequest | _classify_recoverability | _classify_severity | _load_policies | append | evaluate | get | get_temporal_policies | get_temporal_utilization | join | len | model_copy | now,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,156,Enhanced evaluation with full policy context.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,engine,PolicyEngine.get_active_cooldowns,"async get_active_cooldowns(db, agent_id: Optional[str]) -> List[Dict[str, Any]]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,append | items | len | list | now | split | timedelta | total_seconds,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,28,Get all active cooldowns.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_current_version,async get_current_version(db) -> Optional[Dict],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | connect | debug | fetch_current_active_version | get | isoformat | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,26,Get the currently active policy version.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_dependency_graph,async get_dependency_graph(db),?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,DependencyGraph | PolicyConflict | PolicyDependency | _get_engine | append | connect | debug | dispose | fetch_conflicts | fetch_dependencies | get | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,64,Get the policy dependency graph.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_ethical_constraints,"async get_ethical_constraints(db, include_inactive: bool) -> List[EthicalConstraint]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_load_policies,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,12,Get all ethical constraints.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_metrics,"async get_metrics(db, hours: int) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,max,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,12,Get policy engine metrics.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_policy_conflicts,"async get_policy_conflicts(db, include_resolved: bool) -> List",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyConflict | _get_engine | append | connect | debug | dispose | fetch_conflicts | get | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,29,Get policy conflicts.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_policy_versions,"async get_policy_versions(db, limit: int, include_inactive: bool) -> List[Dict]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | connect | debug | fetch_policy_versions | get | isoformat | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,35,Get policy version history.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_risk_ceiling,"async get_risk_ceiling(db, ceiling_id: str) -> Optional[RiskCeiling]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_load_policies,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,7,Get a specific risk ceiling.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_risk_ceilings,"async get_risk_ceilings(db, tenant_id: Optional[str], include_inactive: bool) -> List[RiskCeiling]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_load_policies,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,15,Get all risk ceilings.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_safety_rules,"async get_safety_rules(db, tenant_id: Optional[str], include_inactive: bool) -> List[SafetyRule]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_load_policies,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,15,Get all safety rules.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_state,async get_state(db) -> PolicyState,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyState | len | max,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,17,Get current policy layer state.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_temporal_policies,"async get_temporal_policies(db, metric: Optional[str], include_inactive: bool) -> List",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,TemporalPolicy | _get_engine | append | connect | debug | dispose | fetch_temporal_policies | get | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,37,Get temporal (sliding window) policies.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_temporal_storage_stats,"async get_temporal_storage_stats(db) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | connect | dispose | error | fetch_temporal_storage_stats | isoformat | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,29,Get storage statistics for temporal metrics.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_temporal_utilization,"async get_temporal_utilization(db, policy_id: str, agent_id: Optional[str]) -> Dict",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | connect | debug | dispose | fetch_temporal_metric_sum | fetch_temporal_policy_for_utilization,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,39,Get current utilization for a temporal policy.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_topological_evaluation_order,get_topological_evaluation_order(dependencies: List) -> List[str],?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,add | append | error | get | hasattr | len | pop | set,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,no,47,Get topological order for policy evaluation based on dependencies.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_version_provenance,"async get_version_provenance(db, version_id: str) -> List[Dict]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | connect | debug | fetch_provenance | get | isoformat,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,26,Get provenance (change history) for a version.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_violation,"async get_violation(db, violation_id: str) -> Optional[PolicyViolation]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | ViolationType | _get_engine | connect | debug | dispose | fetch_violation_by_id | get | isinstance | loads | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,37,Get a specific violation by ID.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.get_violations,"async get_violations(db, violation_type: Optional[ViolationType], agent_id: Optional[str], tenant_id: Optional[str], severity_min: Optional[float], since: Optional[datetime], limit: int) -> List[PolicyViolation]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyViolation | ViolationType | _get_engine | append | connect | debug | dispose | fetch_violations | get | isinstance | loads | str,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,58,Get violations from database with filtering.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.pre_check,"async pre_check(request_id: str, agent_id: str, goal: str, tenant_id: str) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyEvaluationRequest | _is_cache_stale | _load_policies | error | evaluate | warning,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,82,Pre-check policy constraints before run creation.,Policy/Decision,medium,name matches 'check'
policies,L5,engine,PolicyEngine.prune_temporal_metrics,"async prune_temporal_metrics(db, retention_hours: int, compact_older_than_hours: int, max_events_per_policy: int) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | cap_temporal_events | commit | compact_temporal_events | connect | delete_old_temporal_events | dispose | error | fetch_temporal_stats | get | str,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,61,Prune and compact temporal metric events to prevent storage explosion.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.reload_policies,async reload_policies(db) -> PolicyLoadResult,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_load_policies,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,yes,4,Force reload policies from database.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.reset_risk_ceiling,"async reset_risk_ceiling(db, ceiling_id: str) -> bool",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | reset_risk_ceiling,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,21,Reset a risk ceiling's current value.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.resolve_conflict,"async resolve_conflict(db, conflict_id: str, resolution: str, resolved_by: str) -> bool",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | resolve_conflict,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,23,Resolve a policy conflict.,Coordinator/Aggregator,medium,name matches 'resolve'
policies,L5,engine,PolicyEngine.rollback_to_version,"async rollback_to_version(db, target_version: str, reason: str, rolled_back_by: str)",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | activate_version | commit | connect | error | fetch_version_for_rollback | insert_provenance | mark_version_rolled_back | reload_policies | str | uuid4,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,44,Rollback to a previous policy version.,Internal Helper,medium,name matches 'to_'
policies,L5,engine,PolicyEngine.set_governor,set_governor(governor) -> None,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,3,Set the M18 Governor for violation routing.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.update_risk_ceiling,"async update_risk_ceiling(db, ceiling_id: str, updates: Dict[str, Any]) -> Optional[RiskCeiling]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | dispose | get_risk_ceiling | reload_policies | update_risk_ceiling,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,26,Update a risk ceiling.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.update_safety_rule,"async update_safety_rule(db, rule_id: str, updates: Dict[str, Any]) -> Optional[SafetyRule]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | commit | connect | debug | dispose | dumps | items | reload_policies | update_safety_rule,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,37,Update a safety rule.,Unclassified,low,no classification rules matched
policies,L5,engine,PolicyEngine.validate_dependency_dag,"async validate_dependency_dag(db) -> Dict[str, Any]",?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,_get_engine | add | append | connect | dfs | dispose | error | fetch_dependency_edges_with_type | get | index | len | reverse | set | str | sum,__future__ | decisions | exc | models | policy_engine_driver | routing,db_write,yes,84,Validate that policy dependencies form a valid DAG (Directed Acyclic Graph).,Policy/Decision,medium,name matches 'validate'
policies,L5,engine,get_policy_engine,get_policy_engine() -> PolicyEngine,?:identity_chain | ?:policy | ?:workers | ?:__init__ | ?:dag_executor | ?:checkpoint | ?:policies | ?:golden | ?:service | ?:invoke_audit_driver,PolicyEngine | get_governor | info | set_governor | warning,__future__ | decisions | exc | models | policy_engine_driver | routing,pure,no,19,Get singleton policy engine with M18 Governor integration.,Unclassified,low,no classification rules matched
policies,L5,failure_mode_handler,get_failure_mode,get_failure_mode() -> FailureMode,?:prevention_engine | L5:prevention_engine | ?:test_failure_mode_handler,FailureMode | get_governance_config | hasattr | lower | str | warning,profile_policy_mode,pure,no,32,Get configured failure mode.,Unclassified,low,no classification rules matched
policies,L5,failure_mode_handler,handle_evaluation_error,"handle_evaluation_error(error: Exception, context: Dict[str, Any]) -> FailureDecision",?:prevention_engine | L5:prevention_engine | ?:test_failure_mode_handler,handle_policy_failure,profile_policy_mode,pure,no,16,Handle policy evaluation error.,Unclassified,low,no classification rules matched
policies,L5,failure_mode_handler,handle_missing_policy,"handle_missing_policy(context: Dict[str, Any]) -> FailureDecision",?:prevention_engine | L5:prevention_engine | ?:test_failure_mode_handler,handle_policy_failure,profile_policy_mode,pure,no,17,Handle case where no policy exists for the action.,Unclassified,low,no classification rules matched
policies,L5,failure_mode_handler,handle_policy_failure,"handle_policy_failure(error: Optional[Exception], context: Dict[str, Any], failure_type: FailureType) -> FailureDecision",?:prevention_engine | L5:prevention_engine | ?:test_failure_mode_handler,FailureDecision | error | get | get_failure_mode | info | isoformat | now | str | warning,profile_policy_mode,pure,no,97,Handle a policy evaluation failure.,Unclassified,low,no classification rules matched
policies,L5,failure_mode_handler,handle_timeout,"handle_timeout(context: Dict[str, Any], timeout_seconds: float) -> FailureDecision",?:prevention_engine | L5:prevention_engine | ?:test_failure_mode_handler,Exception | handle_policy_failure,profile_policy_mode,pure,no,16,Handle policy evaluation timeout.,Unclassified,low,no classification rules matched
policies,L5,folds,ConstantFolder.__init__,__init__(),?:__init__ | ?:test_m20_optimizer,,ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,folds,ConstantFolder._fold_binary_op,_fold_binary_op(instr: IRBinaryOp) -> FoldResult,?:__init__ | ?:test_m20_optimizer,FoldResult | get,ir_nodes,pure,no,19,Fold binary operation if both operands are constant.,Internal Helper,medium,private function
policies,L5,folds,ConstantFolder._fold_compare,_fold_compare(instr: IRCompare) -> FoldResult,?:__init__ | ?:test_m20_optimizer,FoldResult | get,ir_nodes,pure,no,25,Fold comparison if both operands are constant.,Internal Helper,medium,private function
policies,L5,folds,ConstantFolder._fold_unary_op,_fold_unary_op(instr: IRUnaryOp) -> FoldResult,?:__init__ | ?:test_m20_optimizer,FoldResult | get,ir_nodes,pure,no,16,Fold unary operation if operand is constant.,Internal Helper,medium,private function
policies,L5,folds,ConstantFolder.fold_block,fold_block(block: IRBlock) -> None,?:__init__ | ?:test_m20_optimizer,IRLoadConst | append | try_fold,ir_nodes,pure,no,21,Fold constants in a basic block.,Unclassified,low,no classification rules matched
policies,L5,folds,ConstantFolder.fold_function,fold_function(func: IRFunction) -> None,?:__init__ | ?:test_m20_optimizer,fold_block | values,ir_nodes,pure,no,6,Fold constants in a function.,Unclassified,low,no classification rules matched
policies,L5,folds,ConstantFolder.fold_module,fold_module(module: IRModule) -> IRModule,?:__init__ | ?:test_m20_optimizer,fold_function | values,ir_nodes,pure,no,10,Fold constants in all functions.,Unclassified,low,no classification rules matched
policies,L5,folds,ConstantFolder.try_fold,try_fold(instr: IRInstruction) -> FoldResult,?:__init__ | ?:test_m20_optimizer,FoldResult | _fold_binary_op | _fold_compare | _fold_unary_op | isinstance,ir_nodes,pure,no,21,Try to fold an instruction.,Unclassified,low,no classification rules matched
policies,L5,folds,DeadCodeEliminator.__init__,__init__(),?:__init__ | ?:test_m20_optimizer,set,ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,folds,DeadCodeEliminator._eliminate_function,_eliminate_function(func: IRFunction) -> None,?:__init__ | ?:test_m20_optimizer,_find_reachable_blocks | _find_used_instructions | isinstance | keys | len | set | values,ir_nodes,pure,no,26,Eliminate dead code in a function.,Internal Helper,medium,private function
policies,L5,folds,DeadCodeEliminator._find_reachable_blocks,_find_reachable_blocks(func: IRFunction) -> Set[str],?:__init__ | ?:test_m20_optimizer,add | append | get | isinstance | pop | set,ir_nodes,db_write,no,24,Find all reachable blocks from entry.,Internal Helper,medium,private function
policies,L5,folds,DeadCodeEliminator._find_used_instructions,_find_used_instructions(func: IRFunction) -> Set[int],?:__init__ | ?:test_m20_optimizer,add | isinstance | set | values,ir_nodes,db_write,no,38,Find all instructions whose results are used.,Internal Helper,medium,private function
policies,L5,folds,DeadCodeEliminator._mark_governance_critical,_mark_governance_critical(func: IRFunction) -> None,?:__init__ | ?:test_m20_optimizer,add | isinstance | set | values,ir_nodes,db_write,no,12,Mark instructions that are governance-critical (cannot be eliminated).,Internal Helper,medium,private function
policies,L5,folds,DeadCodeEliminator.eliminate,eliminate(module: IRModule) -> IRModule,?:__init__ | ?:test_m20_optimizer,_eliminate_function | _mark_governance_critical | values,ir_nodes,pure,no,11,Eliminate dead code in module.,Unclassified,low,no classification rules matched
policies,L5,folds,PolicySimplifier.__init__,__init__(),?:__init__ | ?:test_m20_optimizer,,ir_nodes,pure,no,2,,Internal Helper,high,dunder method
policies,L5,folds,PolicySimplifier._find_mergeable_policies,_find_mergeable_policies(module: IRModule) -> List[List[str]],?:__init__ | ?:test_m20_optimizer,append | items | list | values,ir_nodes,pure,no,26,Find groups of policies that can be safely merged.,Internal Helper,medium,private function
policies,L5,folds,PolicySimplifier._merge_policies,"_merge_policies(module: IRModule, policy_names: List[str]) -> None",?:__init__ | ?:test_m20_optimizer,len | sort,ir_nodes,pure,no,24,Merge a group of compatible policies.,Internal Helper,medium,private function
policies,L5,folds,PolicySimplifier.simplify,simplify(module: IRModule) -> IRModule,?:__init__ | ?:test_m20_optimizer,_find_mergeable_policies | _merge_policies | len,ir_nodes,pure,no,16,Simplify policies in module.,Unclassified,low,no classification rules matched
policies,L5,governance_facade,BootStatusResult.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,isoformat,policy_driver | runtime_switch,pure,no,8,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,governance_facade,ConflictResolutionResult.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,isoformat,policy_driver | runtime_switch,pure,no,11,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,governance_facade,GovernanceFacade.__init__,__init__(),L4:policies_handler,now,policy_driver | runtime_switch,pure,no,4,Initialize facade with lazy-loaded services.,Internal Helper,high,dunder method
policies,L5,governance_facade,GovernanceFacade.disable_kill_switch,disable_kill_switch(actor: str) -> KillSwitchResult,L4:policies_handler,KillSwitchResult | enable_governance_runtime | error | info | is_governance_active | now | str,policy_driver | runtime_switch,pure,no,51,Disable kill switch - re-enable governance enforcement.,Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceFacade.enable_kill_switch,"enable_kill_switch(reason: str, actor: str) -> KillSwitchResult",L4:policies_handler,KillSwitchResult | disable_governance_runtime | error | is_degraded_mode | is_governance_active | now | str | warning,policy_driver | runtime_switch,pure,no,67,Enable kill switch - disable all governance enforcement.,Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceFacade.get_boot_status,get_boot_status() -> BootStatusResult,L4:policies_handler,BootStatusResult | all | error | get | get_policy_facade | int | is_governance_active | now | str | total_seconds | values,policy_driver | runtime_switch,pure,no,70,Get SPINE component health status.,Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceFacade.get_governance_state,get_governance_state() -> GovernanceStateResult,L4:policies_handler,GovernanceStateResult | error | fromisoformat | get | get_runtime_state | is_degraded_mode | is_governance_active | str,policy_driver | runtime_switch,pure,no,56,Get current governance state.,Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceFacade.list_conflicts,"list_conflicts(tenant_id: Optional[str], status: Optional[str]) -> List[Dict[str, Any]]",L4:policies_handler,error | str,policy_driver | runtime_switch,pure,no,25,List policy conflicts.,Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceFacade.resolve_conflict,"resolve_conflict(conflict_id: str, resolution: str, actor: str, notes: Optional[str]) -> ConflictResolutionResult",L4:policies_handler,ConflictResolutionResult | error | info | now | str,policy_driver | runtime_switch,pure,no,55,Manually resolve a policy conflict.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
policies,L5,governance_facade,GovernanceFacade.set_mode,"set_mode(mode: GovernanceMode, reason: str, actor: str) -> KillSwitchResult",L4:policies_handler,KillSwitchResult | disable_governance_runtime | enable_governance_runtime | enter_degraded_mode | error | exit_degraded_mode | info | is_degraded_mode | is_governance_active | now | str,policy_driver | runtime_switch,pure,no,77,"Set governance mode (NORMAL, DEGRADED, KILL).",Operation,high,called by L4 orchestrator
policies,L5,governance_facade,GovernanceStateResult.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,isoformat,policy_driver | runtime_switch,pure,no,10,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,governance_facade,KillSwitchResult.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,isoformat,policy_driver | runtime_switch,pure,no,11,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,governance_facade,get_governance_facade,get_governance_facade() -> GovernanceFacade,L4:policies_handler,GovernanceFacade,policy_driver | runtime_switch,pure,no,14,Get the governance facade instance.,Operation,high,called by L4 orchestrator
policies,L5,grammar,PLangGrammar.get_action_precedence,get_action_precedence(action: str) -> int,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,get,,pure,no,3,Get precedence for an action type.,Unclassified,low,no classification rules matched
policies,L5,grammar,PLangGrammar.get_category_priority,get_category_priority(category: str) -> int,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,get,,pure,no,3,Get priority for a policy category.,Unclassified,low,no classification rules matched
policies,L5,grammar,PLangGrammar.is_action,is_action(word: str) -> bool,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,,,pure,no,3,Check if word is a valid action.,Unclassified,low,no classification rules matched
policies,L5,grammar,PLangGrammar.is_category,is_category(word: str) -> bool,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,,,pure,no,3,Check if word is a valid M19 category.,Unclassified,low,no classification rules matched
policies,L5,grammar,PLangGrammar.is_keyword,is_keyword(word: str) -> bool,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,,,pure,no,3,Check if word is a PLang keyword.,Unclassified,low,no classification rules matched
policies,L5,grammar,PLangGrammar.is_operator,is_operator(char: str) -> bool,?:__init__ | ?:parser | ?:conflict_resolver | ?:dag_sorter | ?:ir_builder | ?:ir_nodes | ?:symbol_table | ?:visitors | ?:nodes | ?:dag_executor,,,pure,no,3,Check if character is part of an operator.,Unclassified,low,no classification rules matched
policies,L5,intent,Intent.__post_init__,__post_init__(),?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,_generate_id,,pure,no,3,,Internal Helper,high,dunder method
policies,L5,intent,Intent._generate_id,_generate_id() -> str,?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,dumps | encode | hexdigest | sha256 | to_dict,,pure,no,12,Generate deterministic intent ID.,Internal Helper,medium,private function
policies,L5,intent,Intent.from_dict,"from_dict(data: Dict[str, Any]) -> 'Intent'",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,cls | from_dict | get,,pure,no,16,Create from dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_'); Operation(called by L2 (gap  should route via L4))
policies,L5,intent,Intent.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,to_dict,,pure,no,18,Convert to dictionary for M18 consumption.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
policies,L5,intent,IntentEmitter.__init__,__init__(),?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,,,pure,no,4,,Internal Helper,high,dunder method
policies,L5,intent,IntentEmitter.clear,clear() -> None,?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,clear,,pure,no,4,Clear all intents.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.create_intent,"create_intent(intent_type: IntentType, payload: Optional[IntentPayload], priority: int, source_policy: Optional[str], source_rule: Optional[str], category: Optional[str], requires_confirmation: bool) -> Intent",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,Intent | IntentPayload | append,,pure,no,38,Create a new intent.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.emit,async emit(intent: Intent) -> bool,?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,append | get | handler | remove | validate_intent,,pure,yes,35,Emit a validated intent to M18.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.emit_all,async emit_all() -> List[Intent],?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,append | emit | list,,pure,yes,12,Emit all pending intents.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.get_emitted,get_emitted() -> List[Intent],?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,list,,pure,no,3,Get all emitted intents.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.get_pending,get_pending() -> List[Intent],?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,list,,pure,no,3,Get all pending intents.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.register_handler,"register_handler(intent_type: IntentType, handler: Callable[..., Any]) -> None",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,append,,pure,no,9,Register a handler for an intent type.,Operation,high,called by L4 orchestrator
policies,L5,intent,IntentEmitter.validate_intent,async validate_intent(intent: Intent) -> bool,?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,append | len,,pure,yes,40,Validate intent against M19 policy engine.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate'); Operation(called by L2 (gap  should route via L4))
policies,L5,intent,IntentPayload.from_dict,"from_dict(data: Dict[str, Any]) -> 'IntentPayload'",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,cls | get,,pure,no,14,Create from dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_'); Operation(called by L2 (gap  should route via L4))
policies,L5,intent,IntentPayload.to_dict,"to_dict() -> Dict[str, Any]",?:recovery | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L5:deterministic_engine | L2:recovery | L4:dag_executor | ?:test_m20_runtime,,,pure,no,14,Convert to dictionary for serialization.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_'); Operation(called by L2 (gap  should route via L4))
policies,L5,interpreter,ActionResult.to_dict,"to_dict() -> dict[str, Any]",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,,__future__ | ir_compiler,pure,no,5,,Internal Helper,medium,name matches 'to_'
policies,L5,interpreter,ClauseResult.to_dict,"to_dict() -> dict[str, Any]",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,to_dict,__future__ | ir_compiler,pure,no,5,,Internal Helper,medium,name matches 'to_'
policies,L5,interpreter,EvaluationError.__init__,"__init__(message: str, instruction: Instruction | None) -> None",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,__init__ | super,__future__ | ir_compiler,pure,no,7,,Internal Helper,high,dunder method
policies,L5,interpreter,EvaluationResult.has_block,has_block() -> bool,?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,any,__future__ | ir_compiler,pure,no,3,Check if any action is BLOCK.,Unclassified,low,no classification rules matched
policies,L5,interpreter,EvaluationResult.has_require_approval,has_require_approval() -> bool,?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,any,__future__ | ir_compiler,pure,no,3,Check if any action is REQUIRE_APPROVAL.,Unclassified,low,no classification rules matched
policies,L5,interpreter,EvaluationResult.to_dict,"to_dict() -> dict[str, Any]",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,to_dict,__future__ | ir_compiler,pure,no,6,,Internal Helper,medium,name matches 'to_'
policies,L5,interpreter,EvaluationResult.warnings,warnings() -> list[str],?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,,__future__ | ir_compiler,pure,no,3,Get all warning messages.,Unclassified,low,no classification rules matched
policies,L5,interpreter,Interpreter.__init__,__init__() -> None,?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,,__future__ | ir_compiler,pure,no,3,Initialize interpreter (stateless).,Internal Helper,high,dunder method
policies,L5,interpreter,Interpreter._collect_actions,"_collect_actions(instructions: tuple[Instruction, ...]) -> list[ActionResult]",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,ActionResult | EvaluationError | append,__future__ | ir_compiler,pure,no,28,Collect action results from action IR.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter._compare,"_compare(left: Any, comparator: str, right: Any, inst: Instruction) -> bool",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,EvaluationError | TypeMismatchError | _types_compatible | type,__future__ | ir_compiler,pure,no,33,Perform comparison.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter._evaluate_clause,"_evaluate_clause(clause: CompiledClause, facts: dict[str, Any]) -> ClauseResult",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,ClauseResult | _collect_actions | _evaluate_condition | tuple,__future__ | ir_compiler,pure,no,16,Evaluate a single clause.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter._evaluate_condition,"_evaluate_condition(instructions: tuple[Instruction, ...], facts: dict[str, Any]) -> bool",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,EvaluationError | _execute_instruction | isinstance | len | type,__future__ | ir_compiler,pure,no,29,Evaluate condition instructions using a stack.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter._execute_instruction,"_execute_instruction(inst: Instruction, facts: dict[str, Any], stack: list[Any]) -> None",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,EvaluationError | MissingMetricError | TypeMismatchError | _compare | append | isinstance | len | pop | type,__future__ | ir_compiler,pure,no,77,Execute a single instruction.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter._types_compatible,"_types_compatible(left: Any, right: Any) -> bool",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,isinstance | type,__future__ | ir_compiler,pure,no,19,Check if types are compatible for comparison.,Internal Helper,medium,private function
policies,L5,interpreter,Interpreter.evaluate,"evaluate(ir: PolicyIR, facts: dict[str, Any]) -> EvaluationResult",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,EvaluationResult | _evaluate_clause | any | append | extend | tuple,__future__ | ir_compiler,pure,no,37,Evaluate policy IR against facts.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,interpreter,_LenientInterpreter._compare,"_compare(left: Any, comparator: str, right: Any, inst: Instruction) -> bool",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,_compare | super,__future__ | ir_compiler,pure,no,11,Compare with sentinel handling.,Internal Helper,medium,private function
policies,L5,interpreter,_LenientInterpreter._execute_instruction,"_execute_instruction(inst: Instruction, facts: dict[str, Any], stack: list[Any]) -> None",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,_execute_instruction | append | super,__future__ | ir_compiler,pure,no,15,Execute instruction with lenient missing metric handling.,Internal Helper,medium,private function
policies,L5,interpreter,evaluate,"evaluate(ir: PolicyIR, facts: dict[str, Any]) -> EvaluationResult",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,Interpreter | evaluate,__future__ | ir_compiler,pure,no,41,Evaluate policy IR against facts.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,interpreter,evaluate_policy,"evaluate_policy(ir: PolicyIR, facts: dict[str, Any], strict: bool) -> EvaluationResult",?:__init__ | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,_LenientInterpreter | evaluate,__future__ | ir_compiler,pure,no,27,Evaluate policy with optional strict mode.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,ir_builder,IRBuilder.__init__,__init__(),?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,SymbolTable,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,7,,Internal Helper,high,dunder method
policies,L5,ir_builder,IRBuilder._emit,_emit(instr: IRInstruction) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,_next_id | add_instruction,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,6,Emit an instruction to current block.,Internal Helper,medium,private function
policies,L5,ir_builder,IRBuilder._new_block,_new_block(name: str) -> IRBlock,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRBlock | add_block,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,6,Create a new basic block.,Internal Helper,medium,private function
policies,L5,ir_builder,IRBuilder._next_block_name,_next_block_name(prefix: str) -> str,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,4,Get next block name.,Internal Helper,medium,private function
policies,L5,ir_builder,IRBuilder._next_id,_next_id() -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,4,Get next instruction ID.,Internal Helper,medium,private function
policies,L5,ir_builder,IRBuilder.build,"build(ast: ProgramNode, module_name: str) -> IRModule",?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRModule | accept | append | isinstance,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,24,Build IR module from AST.,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_action_block,visit_action_block(node: ActionBlockNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRAction | IREmitIntent | IRLoadConst | _emit | append,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,28,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_attr_access,visit_attr_access(node: AttrAccessNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRCall | IRLoadConst | _emit | accept,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,9,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_binary_op,visit_binary_op(node: BinaryOpNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRBinaryOp | IRCompare | _emit | accept,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,23,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_condition_block,visit_condition_block(node: ConditionBlockNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRJump | IRJumpIf | _emit | _new_block | _next_block_name | accept,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,31,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_func_call,visit_func_call(node: FuncCallNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRCall | _emit | accept | isinstance,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,17,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_ident,visit_ident(node: IdentNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRLoadVar | _emit | add_reference,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,4,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_import,visit_import(node: ImportNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_literal,visit_literal(node: LiteralNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRLoadConst | _emit,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_policy_decl,visit_policy_decl(node: PolicyDeclNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRAction | IRFunction | Symbol | _emit | _new_block | accept | add_function | define | enter_scope | exit_scope | from_ast,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,48,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_priority,visit_priority(node: PriorityNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,4,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_program,visit_program(node: ProgramNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,accept,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_route_target,visit_route_target(node: RouteTargetNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_rule_decl,visit_rule_decl(node: RuleDeclNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRFunction | IRReturn | Symbol | _emit | _new_block | accept | add_function | define | enter_scope | exit_scope | from_ast,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,53,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_rule_ref,visit_rule_ref(node: RuleRefNode) -> Any,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRCall | IRLoadVar | _emit | lookup_rule,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,8,,Unclassified,low,no classification rules matched
policies,L5,ir_builder,IRBuilder.visit_unary_op,visit_unary_op(node: UnaryOpNode) -> int,?:__init__ | ?:test_m20_optimizer | ?:test_m20_runtime | ?:test_m20_ir,IRUnaryOp | _emit | accept,grammar | ir_nodes | nodes | symbol_table | visitors,pure,no,9,,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,CompiledClause.to_dict,"to_dict() -> dict[str, Any]",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,to_dict,__future__ | ast,pure,no,6,Serialize to dict.,Internal Helper,medium,name matches 'to_'
policies,L5,ir_compiler,IRCompiler.__init__,__init__(optimize: bool) -> None,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,,__future__ | ast,pure,no,8,Initialize compiler.,Internal Helper,high,dunder method
policies,L5,ir_compiler,IRCompiler._compile_actions,"_compile_actions(actions: tuple[Action, ...]) -> list[Instruction]",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,Instruction | append | is_block_action | is_require_approval_action | is_warn_action,__future__ | ast,pure,no,29,Compile actions to IR.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._compile_clause,_compile_clause(clause: Clause) -> CompiledClause,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,CompiledClause | _compile_actions | _compile_condition | tuple,__future__ | ast,pure,no,12,Compile a single when-then clause.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._compile_condition,_compile_condition(condition: Condition) -> list[Instruction],L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,_emit_condition,__future__ | ast,pure,no,14,Compile a condition to IR.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._emit_condition,"_emit_condition(condition: Condition, out: list[Instruction]) -> None",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,_emit_exists | _emit_logical | _emit_predicate | is_exists_predicate | is_logical_condition | is_predicate,__future__ | ast,pure,no,8,Recursively emit condition instructions.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._emit_exists,"_emit_exists(pred: ExistsPredicate, out: list[Instruction]) -> None",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,Instruction | append,__future__ | ast,pure,no,12,Emit exists check.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._emit_logical,"_emit_logical(cond: LogicalCondition, out: list[Instruction]) -> None",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,Instruction | _emit_condition | append,__future__ | ast,pure,no,20,Emit logical condition.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler._emit_predicate,"_emit_predicate(pred: Predicate, out: list[Instruction]) -> None",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,Instruction | append,__future__ | ast,pure,no,29,Emit predicate comparison.,Internal Helper,medium,private function
policies,L5,ir_compiler,IRCompiler.compile,compile(ast: PolicyAST) -> PolicyIR,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,PolicyIR | _compile_clause | append | tuple,__future__ | ast,pure,no,25,Compile AST to IR.,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,Instruction.to_dict,"to_dict() -> dict[str, Any]",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,list,__future__ | ast,pure,no,6,Serialize to dict for hashing/storage.,Internal Helper,medium,name matches 'to_'
policies,L5,ir_compiler,OptimizingIRCompiler.__init__,__init__() -> None,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,__init__ | super,__future__ | ast,pure,no,3,,Internal Helper,high,dunder method
policies,L5,ir_compiler,OptimizingIRCompiler.compile,compile(ast: PolicyAST) -> PolicyIR,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,compile | super,__future__ | ast,pure,no,5,Compile with optimizations.,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,PolicyIR.compute_hash,compute_hash() -> str,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,encode | hexdigest | sha256 | to_json,__future__ | ast,pure,no,9,Compute deterministic SHA256 hash of IR.,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,PolicyIR.instruction_count,instruction_count() -> int,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,len,__future__ | ast,pure,no,7,Total number of instructions in IR.,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,PolicyIR.to_dict,"to_dict() -> dict[str, Any]",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,to_dict,__future__ | ast,pure,no,10,Serialize to dict for storage/hashing.,Internal Helper,medium,name matches 'to_'
policies,L5,ir_compiler,PolicyIR.to_json,to_json(indent: int | None) -> str,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,dumps | to_dict,__future__ | ast,pure,no,3,Serialize to JSON.,Internal Helper,medium,name matches 'to_'
policies,L5,ir_compiler,compile_policy,"compile_policy(ast: PolicyAST, optimize: bool) -> PolicyIR",L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,IRCompiler | OptimizingIRCompiler | compile,__future__ | ast,pure,no,33,Compile PolicyAST to PolicyIR.,Unclassified,low,no classification rules matched
policies,L5,ir_compiler,ir_hash,ir_hash(ast: PolicyAST) -> str,L5:interpreter | ?:__init__ | ?:interpreter | ?:test_ir_compiler | ?:test_roundtrip | ?:test_interpreter | ?:test_replay,compile_policy | compute_hash,__future__ | ast,pure,no,8,Convenience function to get IR hash from AST.,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRAction.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append | join,grammar,pure,no,7,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRBinaryOp.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRBlock.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append | join,grammar,pure,no,5,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRBlock.add_instruction,add_instruction(instr: IRInstruction) -> None,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRBlock.is_terminated,is_terminated() -> bool,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,isinstance,grammar,pure,no,6,Check if block ends with terminator instruction.,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRCall.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,join,grammar,pure,no,3,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRCheckPolicy.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,3,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRCompare.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IREmitIntent.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append | join,grammar,pure,no,8,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRFunction.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append | join | str | values,grammar,pure,no,9,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRFunction.add_block,add_block(block: IRBlock) -> None,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRFunction.get_block,get_block(name: str) -> Optional[IRBlock],?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,get,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRGovernance.from_ast,from_ast(governance: Any) -> 'IRGovernance',?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,cls,grammar,pure,no,10,Create from AST governance metadata.,Internal Helper,medium,name matches 'from_'
policies,L5,ir_nodes,IRGovernance.to_dict,"to_dict() -> Dict[str, Any]",?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,10,Convert to dictionary for serialization.,Internal Helper,medium,name matches 'to_'
policies,L5,ir_nodes,IRJump.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRJumpIf.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRLoadConst.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRLoadVar.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRModule.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append | join | str | values,grammar,pure,no,9,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRModule.add_function,add_function(func: IRFunction) -> None,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,append,grammar,pure,no,8,,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRModule.get_function,get_function(name: str) -> Optional[IRFunction],?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,get,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRModule.get_functions_by_category,get_functions_by_category(category: PolicyCategory) -> List[IRFunction],?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,get | sorted,grammar,pure,no,5,"Get all functions in a category, sorted by priority.",Unclassified,low,no classification rules matched
policies,L5,ir_nodes,IRNode.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRReturn.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,4,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRStoreVar.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,ir_nodes,IRUnaryOp.__str__,__str__() -> str,?:conflict_resolver | ?:folds | ?:dag_sorter | ?:ir_builder | ?:__init__ | ?:dag_executor | ?:deterministic_engine | L6:optimizer_conflict_resolver | L5:ir_builder | L5:folds,,grammar,pure,no,2,,Internal Helper,high,dunder method
policies,L5,kernel,ExecutionKernel._emit_envelope,"_emit_envelope(capability_id: str, execution_vector: str, context: InvocationContext, reason: Optional[str]) -> str",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,create_admin_envelope | emit_envelope | error | info | startswith | str | uuid4,__future__ | execution_envelope,pure,no,82,Emit execution envelope for attribution.,Internal Helper,medium,private function
policies,L5,kernel,ExecutionKernel._record_invocation_complete,"_record_invocation_complete(capability_id: str, context: InvocationContext, success: bool, duration_ms: float, error: Optional[str]) -> None",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,info,__future__ | execution_envelope,pure,no,19,Record invocation completion for metrics and audit.,Internal Helper,medium,private function
policies,L5,kernel,ExecutionKernel._record_invocation_start,"_record_invocation_start(capability_id: str, execution_vector: str, context: InvocationContext, enforcement_mode: EnforcementMode) -> None",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,info,__future__ | execution_envelope,pure,no,19,Record invocation start for metrics and audit.,Internal Helper,medium,private function
policies,L5,kernel,ExecutionKernel.get_known_capabilities,get_known_capabilities() -> set[str],?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,copy,__future__ | execution_envelope,pure,no,3,Get the set of known capability IDs.,Unclassified,low,no classification rules matched
policies,L5,kernel,ExecutionKernel.invoke,"invoke(capability_id: str, execution_vector: str, context: InvocationContext, work: Callable[[], T], reason: Optional[str]) -> ExecutionResult",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,ExecutionResult | _emit_envelope | _record_invocation_complete | _record_invocation_start | get_enforcement_mode | isoformat | now | str | total_seconds | warning | work,__future__ | execution_envelope,pure,no,124,Execute work through the governance kernel.,Unclassified,low,no classification rules matched
policies,L5,kernel,ExecutionKernel.invoke_async,"async invoke_async(capability_id: str, execution_vector: str, context: InvocationContext, work: Callable[[], T], reason: Optional[str]) -> ExecutionResult",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,ExecutionResult | _emit_envelope | _record_invocation_complete | _record_invocation_start | get_enforcement_mode | hasattr | isoformat | now | str | total_seconds | warning | work,__future__ | execution_envelope,pure,yes,108,Async version of invoke for async execution paths.,Unclassified,low,no classification rules matched
policies,L5,kernel,ExecutionKernel.is_known_capability,is_known_capability(capability_id: str) -> bool,?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,,__future__ | execution_envelope,pure,no,3,Check if a capability ID is known to the kernel.,Unclassified,low,no classification rules matched
policies,L5,kernel,get_enforcement_mode,get_enforcement_mode(capability_id: str) -> EnforcementMode,?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,get,__future__ | execution_envelope,pure,no,11,Get enforcement mode for a capability.,Policy/Decision,medium,name matches 'enforce'
policies,L5,kernel,set_enforcement_mode,"set_enforcement_mode(capability_id: str, mode: EnforcementMode) -> None",?:__init__ | ?:decorator | ?:recovery_claim_worker | ?:main | L5:decorator | ?:aos,info,__future__ | execution_envelope,pure,no,19,Set enforcement mode for a capability.,Policy/Decision,medium,name matches 'enforce'
policies,L5,keys_shim,KeysReadService.__init__,__init__(session: 'Session'),,get_keys_driver,keys_driver | sqlmodel | tenant,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
policies,L5,keys_shim,KeysReadService.get_key,"get_key(key_id: str, tenant_id: str) -> Optional[APIKey]",,fetch_key_by_id,keys_driver | sqlmodel | tenant,pure,no,11,Get a single API key by ID with tenant isolation.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,KeysReadService.get_key_usage_today,"get_key_usage_today(key_id: str, today_start: datetime) -> Tuple[int, int]",,fetch_key_usage_today,keys_driver | sqlmodel | tenant,pure,no,11,Get today's usage for an API key.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,KeysReadService.list_keys,"list_keys(tenant_id: str, limit: int, offset: int) -> Tuple[List[APIKey], int]",,fetch_keys_paginated,keys_driver | sqlmodel | tenant,pure,no,12,List API keys for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,KeysWriteService.__init__,__init__(session: 'Session'),,get_keys_driver,keys_driver | sqlmodel | tenant,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
policies,L5,keys_shim,KeysWriteService.freeze_key,freeze_key(key: APIKey) -> APIKey,,update_key_frozen,keys_driver | sqlmodel | tenant,pure,no,10,Freeze an API key.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,KeysWriteService.unfreeze_key,unfreeze_key(key: APIKey) -> APIKey,,update_key_frozen,keys_driver | sqlmodel | tenant,pure,no,10,Unfreeze an API key.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,get_keys_read_service,get_keys_read_service(session: 'Session') -> KeysReadService,,KeysReadService,keys_driver | sqlmodel | tenant,pure,no,3,Factory function to get KeysReadService instance.,Internal Helper,low,pure function with no callers
policies,L5,keys_shim,get_keys_write_service,get_keys_write_service(session: 'Session') -> KeysWriteService,,KeysWriteService,keys_driver | sqlmodel | tenant,pure,no,3,Factory function to get KeysWriteService instance.,Internal Helper,low,pure function with no callers
policies,L5,kill_switch,KillSwitchStatus.get_current,get_current() -> 'KillSwitchStatus',?:test_kill_switch,cls,,pure,no,7,Get current kill switch status.,Unclassified,low,no classification rules matched
policies,L5,kill_switch,activate_kill_switch,"activate_kill_switch(reason: str, activated_by: str, auto_expire_minutes: int) -> KillSwitchActivation",?:test_kill_switch,KillSwitchActivation | KillSwitchStatus | isoformat | now | timedelta | warning,,pure,no,55,Activate the runtime kill switch.,Unclassified,low,no classification rules matched
policies,L5,kill_switch,deactivate_kill_switch,deactivate_kill_switch(deactivated_by: str) -> KillSwitchDeactivation,?:test_kill_switch,KillSwitchDeactivation | KillSwitchStatus | info | isoformat | now,,pure,no,37,Deactivate the runtime kill switch.,Unclassified,low,no classification rules matched
policies,L5,kill_switch,is_kill_switch_active,is_kill_switch_active() -> bool,?:test_kill_switch,KillSwitchStatus | fromisoformat | info | now,,pure,no,26,Check if kill switch is currently active.,Unclassified,low,no classification rules matched
policies,L5,kill_switch,should_bypass_governance,should_bypass_governance() -> bool,?:test_kill_switch,is_kill_switch_active,,pure,no,10,Check if governance should be bypassed.,Policy/Decision,medium,name matches 'should_'
policies,L5,learning_proof_engine,AdaptiveConfidenceSystem.get_confidence_report,get_confidence_report() -> dict,L5:__init__,abs | len | values,__future__,pure,no,18,Report on confidence calibration health.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,AdaptiveConfidenceSystem.get_or_create_calibration,get_or_create_calibration(pattern_id: str) -> PatternCalibration,L5:__init__,PatternCalibration,__future__,pure,no,4,,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,AdaptiveConfidenceSystem.get_threshold_for_pattern,"get_threshold_for_pattern(pattern_id: str) -> tuple[float, float]",L5:__init__,,__future__,pure,no,8,Get calibrated strong/weak thresholds for a pattern.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,AdaptiveConfidenceSystem.record_outcome,"record_outcome(pattern_id: str, confidence: float, was_correct: bool) -> None",L5:__init__,get_or_create_calibration | record_outcome,__future__,pure,no,10,Record prediction outcome for calibration.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,CheckpointConfig.get_priority,"get_priority(checkpoint_type: str, confidence: float) -> CheckpointPriority",L5:__init__,get,__future__,pure,no,19,"Get priority for a checkpoint, considering confidence.",Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,CheckpointConfig.is_blocking,is_blocking(checkpoint_type: str) -> bool,L5:__init__,,__future__,pure,no,3,Check if checkpoint type blocks loop progress.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,CheckpointConfig.should_auto_dismiss,"should_auto_dismiss(checkpoint_type: str, age_hours: float) -> bool",L5:__init__,get_priority,__future__,pure,no,8,Check if checkpoint should be auto-dismissed.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'should_'); Internal Helper(name matches 'to_')
policies,L5,learning_proof_engine,GlobalRegretTracker.get_or_create_tracker,get_or_create_tracker(policy_id: str) -> PolicyRegretTracker,L5:__init__,PolicyRegretTracker,__future__,pure,no,4,,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,GlobalRegretTracker.has_proven_rollback,has_proven_rollback() -> bool,L5:__init__,,__future__,pure,no,3,Gate 2 check: Has at least one policy been auto-demoted?,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,GlobalRegretTracker.record_regret,"record_regret(policy_id: str, event: RegretEvent) -> bool",L5:__init__,add_regret | get_or_create_tracker,__future__,pure,no,8,Record regret. Returns True if demotion triggered.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,GlobalRegretTracker.system_regret_rate,system_regret_rate() -> float,L5:__init__,len | sum | values,__future__,pure,no,6,Overall regret rate across all policies.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus._get_next_action,_get_next_action() -> str,L5:__init__,,__future__,pure,no,13,What to do next to graduate.,Internal Helper,medium,private function
policies,L5,learning_proof_engine,M25GraduationStatus.gate1_passed,gate1_passed() -> bool,L5:__init__,,__future__,pure,no,3,Gate 1: At least one prevention recorded.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus.gate2_passed,gate2_passed() -> bool,L5:__init__,,__future__,pure,no,3,Gate 2: At least one regret-driven rollback.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus.gate3_passed,gate3_passed() -> bool,L5:__init__,len,__future__,pure,no,3,Gate 3: At least one incident shows timeline with prevention.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus.is_graduated,is_graduated() -> bool,L5:__init__,,__future__,pure,no,3,All gates passed - M25 is proven.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus.status_label,status_label() -> str,L5:__init__,sum,__future__,pure,no,7,Human-readable status.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,M25GraduationStatus.to_dashboard,to_dashboard() -> dict,L5:__init__,_get_next_action | len,__future__,pure,no,35,Dashboard display of graduation status.,Internal Helper,medium,name matches 'to_'
policies,L5,learning_proof_engine,PatternCalibration._recalibrate,_recalibrate() -> None,L5:__init__,len | sorted | sum,__future__,pure,no,24,Recalibrate thresholds based on outcomes.,Internal Helper,medium,private function
policies,L5,learning_proof_engine,PatternCalibration.accuracy,accuracy() -> float,L5:__init__,,__future__,pure,no,5,Overall accuracy for this pattern.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PatternCalibration.get_calibrated_band,get_calibrated_band(confidence: float) -> str,L5:__init__,,__future__,pure,no,8,Get band using calibrated thresholds.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PatternCalibration.is_calibrated,is_calibrated() -> bool,L5:__init__,len,__future__,pure,no,3,Has enough data for reliable calibration?,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PatternCalibration.record_outcome,"record_outcome(predicted_confidence: float, was_correct: bool) -> None",L5:__init__,_recalibrate | append | len,__future__,pure,no,17,Record a prediction outcome for calibration.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PolicyRegretTracker._trigger_demotion,_trigger_demotion(reason: str) -> None,L5:__init__,now,__future__,pure,no,4,Auto-demote policy due to excessive regret.,Internal Helper,medium,private function
policies,L5,learning_proof_engine,PolicyRegretTracker.add_regret,add_regret(event: RegretEvent) -> bool,L5:__init__,_trigger_demotion | append | len,__future__,pure,no,19,Add regret event. Returns True if auto-demotion triggered.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PolicyRegretTracker.decay_regret,decay_regret() -> None,L5:__init__,max,__future__,pure,no,3,Apply daily decay to regret score.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PolicyRegretTracker.is_demoted,is_demoted() -> bool,L5:__init__,,__future__,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PolicyRegretTracker.to_rollback_timeline,to_rollback_timeline() -> dict | None,L5:__init__,isoformat | len,__future__,pure,no,16,Format for console timeline if demoted.,Internal Helper,medium,name matches 'to_'
policies,L5,learning_proof_engine,PreventionRecord.create_prevention,"create_prevention(policy_id: str, pattern_id: str, original_incident_id: str, blocked_incident_id: str, tenant_id: str, signature_match: float, policy_age: timedelta, calls_evaluated: int) -> 'PreventionRecord'",L5:__init__,cls | now | uuid4,__future__,pure,no,25,Create a prevention record - this is evidence of learning.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionRecord.to_console_timeline,to_console_timeline() -> dict,L5:__init__,isoformat | str,__future__,pure,no,16,Format for console timeline visualization.,Internal Helper,medium,name matches 'to_'
policies,L5,learning_proof_engine,PreventionTimeline._generate_narrative,"_generate_narrative(has_prevention: bool, has_rollback: bool) -> str",L5:__init__,,__future__,pure,no,14,Generate human-readable narrative.,Internal Helper,medium,private function
policies,L5,learning_proof_engine,PreventionTimeline.add_incident_created,"add_incident_created(timestamp: datetime, details: dict) -> None",L5:__init__,append | get | isoformat,__future__,pure,no,12,Original incident that created the pattern/policy.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTimeline.add_policy_born,"add_policy_born(timestamp: datetime, policy_id: str, policy_name: str) -> None",L5:__init__,append | isoformat,__future__,pure,no,12,Policy was created from this incident.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTimeline.add_prevention,"add_prevention(timestamp: datetime, record: PreventionRecord) -> None",L5:__init__,append | isoformat,__future__,pure,no,17,The prevention event - this is the proof.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTimeline.add_regret,"add_regret(timestamp: datetime, event: RegretEvent) -> None",L5:__init__,append | isoformat,__future__,pure,no,15,Regret event if policy caused harm.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTimeline.add_rollback,"add_rollback(timestamp: datetime, tracker: PolicyRegretTracker) -> None",L5:__init__,append | isoformat,__future__,pure,no,16,Auto-rollback event.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTimeline.to_console,to_console() -> dict,L5:__init__,_generate_narrative | any | len | sorted,__future__,pure,no,21,Format for console display.,Internal Helper,medium,name matches 'to_'
policies,L5,learning_proof_engine,PreventionTracker.get_top_preventing_patterns,"get_top_preventing_patterns(n: int) -> list[tuple[str, int]]",L5:__init__,items | len | sorted,__future__,pure,no,4,Patterns that have been most effectively prevented.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTracker.has_proven_prevention,has_proven_prevention() -> bool,L5:__init__,,__future__,pure,no,3,Gate 1 check: Has at least one policy prevented one incident?,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTracker.prevention_rate,prevention_rate() -> float,L5:__init__,,__future__,pure,no,6,Overall prevention success rate.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTracker.record_failure,"record_failure(policy_id: str, pattern_id: str) -> None",L5:__init__,,__future__,pure,no,3,Record a prevention failure (policy didn't stop recurrence).,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PreventionTracker.record_prevention,record_prevention(record: PreventionRecord) -> None,L5:__init__,add | append,__future__,db_write,no,5,Record a successful prevention.,Unclassified,low,no classification rules matched
policies,L5,learning_proof_engine,PrioritizedCheckpoint.check_auto_dismiss,check_auto_dismiss() -> bool,L5:__init__,now,__future__,pure,no,10,Check and apply auto-dismiss if expired.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(name matches 'to_')
policies,L5,learning_proof_engine,PrioritizedCheckpoint.create,"create(checkpoint_type: str, incident_id: str, tenant_id: str, description: str, confidence: float, config: CheckpointConfig) -> 'PrioritizedCheckpoint'",L5:__init__,cls | get_priority | is_blocking | now | timedelta | uuid4,__future__,pure,no,30,Create checkpoint with priority from config.,Unclassified,low,no classification rules matched
policies,L5,lessons_engine,LessonsLearnedEngine.__init__,"__init__(db_url: Optional[str], driver: Optional[LessonsDriver])",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,get,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,11,Initialize the lessons learned engine.,Internal Helper,high,dunder method
policies,L5,lessons_engine,LessonsLearnedEngine._create_lesson,"_create_lesson(tenant_id: str, lesson_type: str, severity: Optional[str], source_event_id: UUID, source_event_type: str, source_run_id: Optional[UUID], title: str, description: str, proposed_action: Optional[str], detected_pattern: Optional[Dict[str, Any]], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | error | info | insert_lesson | str | utc_now | uuid4,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,51,Create a lesson record in the database.,Internal Helper,medium,private function
policies,L5,lessons_engine,LessonsLearnedEngine._generate_failure_description,"_generate_failure_description(error_code: Optional[str], error_message: Optional[str], severity: str) -> str",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,lower,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,14,Generate description for a failure lesson.,Internal Helper,medium,private function
policies,L5,lessons_engine,LessonsLearnedEngine._generate_failure_proposed_action,"_generate_failure_proposed_action(error_code: Optional[str], severity: str) -> str",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,17,Generate proposed action for a failure lesson.,Internal Helper,medium,private function
policies,L5,lessons_engine,LessonsLearnedEngine._get_driver,_get_driver() -> LessonsDriver,?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,RuntimeError | SessionLocal | create_engine | get_lessons_driver | sessionmaker,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,24,Get or create the lessons driver.,Internal Helper,medium,private function
policies,L5,lessons_engine,LessonsLearnedEngine._is_debounced,"_is_debounced(tenant_id: str, metric_type: str, lesson_type: str, threshold_band: Optional[str]) -> bool",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | fetch_debounce_count | warning,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,44,Check if a lesson of this type has been created recently (debounce).,Internal Helper,medium,private function
policies,L5,lessons_engine,LessonsLearnedEngine.convert_lesson_to_draft,"convert_lesson_to_draft(lesson_id: UUID, tenant_id: str, converted_by: str) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | error | get_lesson | info | insert_policy_proposal_from_lesson | is_valid_transition | str | update_lesson_converted | utc_now | uuid4 | warning,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,70,Convert a lesson to a draft policy proposal.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'convert')
policies,L5,lessons_engine,LessonsLearnedEngine.defer_lesson,"defer_lesson(lesson_id: UUID, tenant_id: str, defer_until: datetime) -> bool",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | error | get_lesson | info | is_valid_transition | str | update_lesson_deferred | warning,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,57,Defer a lesson until a future date.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.detect_lesson_from_critical_success,"detect_lesson_from_critical_success(run_id: UUID, tenant_id: str, success_type: str, metrics: dict[str, Any], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_create_lesson,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,55,Detect and create a lesson from a critical success event.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
policies,L5,lessons_engine,LessonsLearnedEngine.detect_lesson_from_failure,"detect_lesson_from_failure(run_id: UUID, tenant_id: str, error_code: Optional[str], error_message: Optional[str], severity: str, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_create_lesson | _generate_failure_description | _generate_failure_proposed_action,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,55,Detect and create a lesson from a failure event.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
policies,L5,lessons_engine,LessonsLearnedEngine.detect_lesson_from_near_threshold,"detect_lesson_from_near_threshold(run_id: UUID, tenant_id: str, threshold_type: str, current_value: float, threshold_value: float, utilization_percent: float, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_create_lesson | _is_debounced | debug | get_threshold_band,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,84,Detect and create a lesson from a near-threshold event.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'from_')
policies,L5,lessons_engine,LessonsLearnedEngine.dismiss_lesson,"dismiss_lesson(lesson_id: UUID, tenant_id: str, dismissed_by: str, reason: str) -> bool",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | error | get_lesson | info | is_valid_transition | str | update_lesson_dismissed | utc_now | warning,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,63,Dismiss a lesson (mark as not actionable).,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.emit_critical_success,"emit_critical_success(tenant_id: str, success_type: str, metrics: dict[str, Any], source_event_id: UUID, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,detect_lesson_from_critical_success | error | inc | labels,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,42,Worker-safe method to emit a critical success lesson.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.emit_near_threshold,"emit_near_threshold(tenant_id: str, metric: str, utilization: float, threshold_value: float, current_value: float, source_event_id: UUID, window: str, is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> Optional[UUID]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,detect_lesson_from_near_threshold | error | inc | labels,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,50,Worker-safe method to emit a near-threshold lesson.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.get_expired_deferred_lessons,"get_expired_deferred_lessons(limit: int) -> List[tuple[UUID, str]]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,UUID | _get_driver | error | fetch_expired_deferred | str,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,26,Get deferred lessons whose deferred_until has passed.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.get_lesson,"get_lesson(lesson_id: UUID, tenant_id: str) -> Optional[Dict[str, Any]]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | fetch_lesson_by_id | str,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,18,Get a specific lesson by ID.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.get_lesson_stats,"get_lesson_stats(tenant_id: str) -> Dict[str, Any]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | fetch_lesson_stats,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,36,Get lesson statistics for a tenant.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.list_lessons,"list_lessons(tenant_id: str, lesson_type: Optional[str], status: Optional[str], severity: Optional[str], include_synthetic: bool, limit: int, offset: int) -> List[Dict[str, Any]]",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | fetch_lessons_list,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,37,List lessons for a tenant with optional filters.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.reactivate_deferred_lesson,"reactivate_deferred_lesson(lesson_id: UUID, tenant_id: str) -> bool",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,_get_driver | error | get_lesson | info | is_valid_transition | str | update_lesson_reactivated | warning,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,58,Reactivate a deferred lesson back to pending status.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,LessonsLearnedEngine.reactivate_expired_deferred_lessons,reactivate_expired_deferred_lessons() -> int,?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,get_expired_deferred_lessons | info | len | reactivate_deferred_lesson,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,27,Reactivate all deferred lessons whose deferred_until has passed.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,get_lessons_learned_engine,get_lessons_learned_engine() -> LessonsLearnedEngine,?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,LessonsLearnedEngine,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,6,Get the singleton LessonsLearnedEngine instance.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,get_threshold_band,get_threshold_band(utilization: float) -> str,?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,7,Get the threshold band for a utilization percentage.,Operation,high,called by L4 orchestrator
policies,L5,lessons_engine,is_valid_transition,"is_valid_transition(from_status: str, to_status: str) -> bool",?:policy_layer | ?:policy | ?:policies_facade | ?:__init__ | ?:lessons_engine | ?:run_governance_facade | ?:incident_engine | ?:main | L5:incident_engine | L4:run_governance_facade,get | set,lessons_driver | orm | prometheus_client | sqlalchemy | sqlmodel | time,pure,no,4,Check if a state transition is valid.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'is_valid')
policies,L5,limits,Limits.is_unlimited,is_unlimited() -> bool,?:rate_limits | ?:policy_rules_crud | ?:policies | ?:aos_cus_integrations | ?:billing_gate | ?:billing_dependencies | ?:simulate | ?:__init__ | ?:override | ?:policy_limits_crud,all,,pure,no,13,Check if all limits are unlimited (None).,Unclassified,low,no classification rules matched
policies,L5,limits,derive_limits,derive_limits(limits_profile: str) -> Limits,?:rate_limits | ?:policy_rules_crud | ?:policies | ?:aos_cus_integrations | ?:billing_gate | ?:billing_dependencies | ?:simulate | ?:__init__ | ?:override | ?:policy_limits_crud,get,,pure,no,13,Derive limits from a limits profile key.,Unclassified,low,no classification rules matched
policies,L5,limits_facade,LimitCheckResult.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,,,pure,no,11,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,limits_facade,LimitConfig.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,max | round,,pure,no,19,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,limits_facade,LimitsFacade.__init__,__init__(),L4:policies_handler,,,pure,no,3,Initialize facade.,Internal Helper,high,dunder method
policies,L5,limits_facade,LimitsFacade._get_or_create_limit,"_get_or_create_limit(tenant_id: str, limit_type: str, period: str, max_value: int) -> LimitConfig",L4:policies_handler,LimitConfig | isoformat | now | str | timedelta | uuid4,,pure,no,35,Get or create a limit configuration.,Internal Helper,medium,private function
policies,L5,limits_facade,LimitsFacade.check_limit,"async check_limit(tenant_id: str, limit_type: str, increment: int) -> LimitCheckResult",L4:policies_handler,LimitCheckResult | _get_or_create_limit | fromisoformat | isoformat | max | now | replace | timedelta,,pure,yes,54,Check if a limit allows the operation.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
policies,L5,limits_facade,LimitsFacade.get_limit,"async get_limit(limit_id: str, tenant_id: str) -> Optional[LimitConfig]",L4:policies_handler,values,,pure,yes,19,Get a specific limit.,Operation,high,called by L4 orchestrator
policies,L5,limits_facade,LimitsFacade.get_usage,async get_usage(tenant_id: str) -> UsageSummary,L4:policies_handler,UsageSummary | _get_or_create_limit | append | isoformat | now | to_dict | values,,pure,yes,39,Get current usage summary.,Operation,high,called by L4 orchestrator
policies,L5,limits_facade,LimitsFacade.list_limits,"async list_limits(tenant_id: str, limit_type: Optional[str], limit: int, offset: int) -> List[LimitConfig]",L4:policies_handler,_get_or_create_limit | append | sort | values,,pure,yes,33,List limits for a tenant.,Operation,high,called by L4 orchestrator
policies,L5,limits_facade,LimitsFacade.reset_limit,"async reset_limit(tenant_id: str, limit_type: str) -> Optional[LimitConfig]",L4:policies_handler,get | info | isoformat | now,,pure,yes,30,Reset a limit's current value.,Operation,high,called by L4 orchestrator
policies,L5,limits_facade,LimitsFacade.update_limit,"async update_limit(limit_id: str, tenant_id: str, max_value: Optional[int], enabled: Optional[bool], metadata: Optional[Dict[str, Any]]) -> Optional[LimitConfig]",L4:policies_handler,isoformat | now | update | values,,pure,yes,41,Update a limit.,Operation,high,called by L4 orchestrator
policies,L5,limits_facade,UsageSummary.to_dict,"to_dict() -> Dict[str, Any]",L4:policies_handler,,,pure,no,9,Convert to dictionary.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,limits_facade,get_limits_facade,get_limits_facade() -> LimitsFacade,L4:policies_handler,LimitsFacade,,pure,no,14,Get the limits facade instance.,Operation,high,called by L4 orchestrator
policies,L5,limits_simulation_service,get_limits_simulation_service,get_limits_simulation_service(session: 'AsyncSession') -> LimitsSimulationService,L4:policies_handler,get_limits_simulation_engine,asyncio | simulation_engine,pure,no,14,Get the LimitsSimulationService instance.,Operation,high,called by L4 orchestrator
policies,L5,llm_policy_engine,LLMRateLimiter.__init__,__init__(requests_per_minute: int),L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,Lock | deque,,pure,no,5,,Internal Helper,high,dunder method
policies,L5,llm_policy_engine,LLMRateLimiter.check_and_record,check_and_record() -> bool,L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,append | len | popleft | time,,pure,no,21,Check if request is allowed and record it.,Policy/Decision,medium,name matches 'check'
policies,L5,llm_policy_engine,LLMRateLimiter.get_instance,get_instance(provider: str) -> 'LLMRateLimiter',L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,cls,,pure,no,6,Get or create rate limiter for a provider.,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,LLMRateLimiter.requests_remaining,requests_remaining() -> int,L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,len | max | popleft | time,,pure,no,11,Get number of requests remaining in current window.,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,check_safety_limits,"check_safety_limits(model: str, max_tokens: int, estimated_input_tokens: int, provider: str, max_tokens_limit: Optional[int], max_cost_cents_limit: Optional[float]) -> SafetyCheckResult",L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,SafetyCheckResult | check_and_record | estimate_cost_cents | get_instance | requests_remaining,,pure,no,86,Check safety limits before making LLM API call (L4 domain function).,Policy/Decision,medium,name matches 'check'
policies,L5,llm_policy_engine,estimate_cost_cents,"estimate_cost_cents(model: str, input_tokens: int, output_tokens: int) -> float",L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,get,,pure,no,16,Estimate cost in cents (L4 domain function).,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,estimate_tokens,estimate_tokens(text: str) -> int,L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,len,,pure,no,7,Estimate token count for text (L4 domain function).,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,get_effective_model,"get_effective_model(requested_model: Optional[str], preferred_model: str, fallback_model: str, allowed_models: List[str]) -> str",L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,,,pure,no,30,Get effective model based on request and tenant config (L4 policy decision).,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,get_model_for_task,"get_model_for_task(task_type: str, requested_model: Optional[str], tenant_allowed_models: Optional[List[str]], allow_expensive: bool) -> str",L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,get | is_expensive_model | is_model_allowed | warning,,pure,no,41,Get appropriate model for a task type (L4 policy decision).,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,is_expensive_model,is_expensive_model(model: str) -> bool,L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,,,pure,no,3,Check if a model is classified as expensive (L4 domain function).,Unclassified,low,no classification rules matched
policies,L5,llm_policy_engine,is_model_allowed,"is_model_allowed(model: str, tenant_allowed_models: Optional[List[str]]) -> bool",L3:openai_adapter | L3:tenant_config | ?:tenant_config | ?:openai_adapter,,,pure,no,21,Check if a model is allowed (L4 domain function).,Policy/Decision,medium,name matches 'allow'
policies,L5,nodes,ASTNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Accept a visitor for traversal.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTNode.location,location() -> str,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Get source location string.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_action_block,visit_action_block(node: 'ActionBlockNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit action block.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_attr_access,visit_attr_access(node: 'AttrAccessNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit attribute access.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_binary_op,visit_binary_op(node: 'BinaryOpNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit binary operation.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_condition_block,visit_condition_block(node: 'ConditionBlockNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit condition block.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_func_call,visit_func_call(node: 'FuncCallNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit function call.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_ident,visit_ident(node: 'IdentNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit identifier.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_import,visit_import(node: 'ImportNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit import statement.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_literal,visit_literal(node: 'LiteralNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit literal value.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_policy_decl,visit_policy_decl(node: 'PolicyDeclNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit policy declaration.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_priority,visit_priority(node: 'PriorityNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit priority node.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_program,visit_program(node: 'ProgramNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit program node.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_route_target,visit_route_target(node: 'RouteTargetNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit route target.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_rule_decl,visit_rule_decl(node: 'RuleDeclNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit rule declaration.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_rule_ref,visit_rule_ref(node: 'RuleRefNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit rule reference.,Unclassified,low,no classification rules matched
policies,L5,nodes,ASTVisitor.visit_unary_op,visit_unary_op(node: 'UnaryOpNode') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,,grammar,pure,no,3,Visit unary operation.,Unclassified,low,no classification rules matched
policies,L5,nodes,ActionBlockNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_action_block,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,AttrAccessNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_attr_access,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,BinaryOpNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_binary_op,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,ConditionBlockNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_condition_block,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,FuncCallNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_func_call,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,GovernanceMetadata.merge_with,merge_with(other: 'GovernanceMetadata') -> 'GovernanceMetadata',?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,GovernanceMetadata | strip,grammar,pure,no,14,"Merge governance metadata, taking higher priority.",Coordinator/Aggregator,medium,name matches 'merge'
policies,L5,nodes,IdentNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_ident,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,ImportNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_import,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,LiteralNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_literal,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,PolicyDeclNode.__post_init__,__post_init__(),?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,GovernanceMetadata | get_category_priority,grammar,pure,no,9,,Internal Helper,high,dunder method
policies,L5,nodes,PolicyDeclNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_policy_decl,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,PriorityNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_priority,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,ProgramNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_program,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,RouteTargetNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_route_target,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,RuleDeclNode.__post_init__,__post_init__(),?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,GovernanceMetadata | get_category_priority,grammar,pure,no,8,,Internal Helper,high,dunder method
policies,L5,nodes,RuleDeclNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_rule_decl,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,RuleRefNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_rule_ref,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,nodes,UnaryOpNode.accept,accept(visitor: 'ASTVisitor') -> Any,?:parser | ?:dag_sorter | ?:ir_builder | ?:visitors | ?:__init__ | ?:knowledge_plane | ?:policy_graph_engine | L5:visitors | L5:compiler_parser | L5:ir_builder,visit_unary_op,grammar,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,phase_status_invariants,InvariantCheckResponse.to_dict,"to_dict() -> dict[str, Any]",?:__init__,list,,pure,no,11,Convert to dictionary for API responses.,Internal Helper,medium,name matches 'to_'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.__init__,__init__(enforcement_enabled: bool),?:__init__,,,pure,no,8,Initialize the invariant checker.,Internal Helper,high,dunder method
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.check,"check(phase: str, status: str) -> InvariantCheckResponse",?:__init__,InvariantCheckResponse | frozenset | get_allowed_statuses | sorted | upper,,pure,no,62,Check if a phase-status combination is valid.,Policy/Decision,medium,name matches 'check'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.enforcement_enabled,enforcement_enabled() -> bool,?:__init__,,,pure,no,3,Check if enforcement is enabled.,Policy/Decision,medium,name matches 'enforce'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.ensure_valid,"ensure_valid(phase: str, status: str) -> None",?:__init__,PhaseStatusInvariantEnforcementError | check | sorted,,pure,no,28,Ensure a phase-status combination is valid or raise error.,Unclassified,low,no classification rules matched
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.from_governance_config,from_governance_config(config: Any) -> 'PhaseStatusInvariantChecker',?:__init__,cls | getattr,,pure,no,12,Create checker from GovernanceConfig.,Internal Helper,medium,name matches 'from_'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.get_allowed_statuses,get_allowed_statuses(phase: str) -> FrozenSet[str],?:__init__,frozenset | get | upper,,pure,no,11,Get allowed statuses for a phase.,Policy/Decision,medium,name matches 'allow'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.is_valid_combination,"is_valid_combination(phase: str, status: str) -> bool",?:__init__,get_allowed_statuses,,pure,no,15,Check if a phase-status combination is valid.,Policy/Decision,medium,name matches 'is_valid'
policies,L5,phase_status_invariants,PhaseStatusInvariantChecker.should_allow_transition,"should_allow_transition(phase: str, status: str) -> tuple[bool, str]",?:__init__,check,,pure,no,26,Check if a transition should be allowed.,Policy/Decision,medium,name matches 'allow'
policies,L5,phase_status_invariants,PhaseStatusInvariantEnforcementError.__init__,"__init__(message: str, phase: str, status: str, allowed_statuses: FrozenSet[str], enforcement_enabled: bool)",?:__init__,__init__ | super,,pure,no,13,,Internal Helper,high,dunder method
policies,L5,phase_status_invariants,PhaseStatusInvariantEnforcementError.to_dict,"to_dict() -> dict[str, Any]",?:__init__,list | str,,pure,no,10,Convert to dictionary for logging/API responses.,Internal Helper,medium,name matches 'to_'
policies,L5,phase_status_invariants,check_phase_status_invariant,"check_phase_status_invariant(phase: str, status: str, enforcement_enabled: bool) -> InvariantCheckResponse",?:__init__,PhaseStatusInvariantChecker | check,,pure,no,18,Quick helper to check a phase-status invariant.,Policy/Decision,medium,name matches 'check'
policies,L5,phase_status_invariants,ensure_phase_status_invariant,"ensure_phase_status_invariant(phase: str, status: str, enforcement_enabled: bool) -> None",?:__init__,PhaseStatusInvariantChecker | ensure_valid,,pure,no,18,Quick helper to ensure phase-status invariant or raise error.,Unclassified,low,no classification rules matched
policies,L5,plan,Plan.__post_init__,__post_init__() -> None,?:evidence_sink | ?:execution_envelope | ?:tenant_auth | ?:guard | ?:billing_gate | ?:billing_dependencies | ?:__init__ | ?:accounts_facade | ?:tenant_service | ?:executor,ValueError,,pure,no,8,Validate plan on creation.,Internal Helper,high,dunder method
policies,L5,plan,PlanTier.from_string,from_string(value: str) -> 'PlanTier',?:evidence_sink | ?:execution_envelope | ?:tenant_auth | ?:guard | ?:billing_gate | ?:billing_dependencies | ?:__init__ | ?:accounts_facade | ?:tenant_service | ?:executor,ValueError | lower | strip,,pure,no,8,Parse tier from string (case-insensitive).,Internal Helper,medium,name matches 'from_'
policies,L5,plan_generation_engine,PlanGenerationEngine.__init__,__init__(),?:main,get_planner | get_retriever,budget_tracker | memory | plan_inspector | planners | skills,pure,no,4,Initialize the plan generation engine.,Internal Helper,high,dunder method
policies,L5,plan_generation_engine,PlanGenerationEngine.generate,generate(context: PlanGenerationContext) -> PlanGenerationResult,?:main,PlanGenerationResult | RuntimeError | debug | dumps | error | get | get_context_for_planning | get_skill_manifest | info | join | len | plan | validate_plan | warning,budget_tracker | memory | plan_inspector | planners | skills,pure,no,96,Generate a plan for a run.,Unclassified,low,no classification rules matched
policies,L5,plan_generation_engine,generate_plan_for_run,"generate_plan_for_run(agent_id: str, goal: str, run_id: str) -> PlanGenerationResult",?:main,PlanGenerationContext | PlanGenerationEngine | generate | get_budget_tracker | get_status,budget_tracker | memory | plan_inspector | planners | skills,pure,no,35,Convenience function to generate a plan for a run.,Unclassified,low,no classification rules matched
policies,L5,policies_limits_query_engine,LimitsQueryEngine.__init__,__init__(driver: LimitsReadDriver),,,asyncio | limits_read_driver,pure,no,2,,Internal Helper,high,dunder method
policies,L5,policies_limits_query_engine,LimitsQueryEngine.get_limit_detail,"async get_limit_detail(tenant_id: str, limit_id: str) -> Optional[LimitDetailResult]",,LimitDetailResult | fetch_limit_by_id,asyncio | limits_read_driver,pure,yes,30,Get limit detail. Tenant isolation enforced.,Internal Helper,low,pure function with no callers
policies,L5,policies_limits_query_engine,LimitsQueryEngine.list_budgets,async list_budgets(tenant_id: str) -> BudgetsListResult,,BudgetDefinitionResult | BudgetsListResult | fetch_budget_limits | len,asyncio | limits_read_driver,pure,yes,43,List budget definitions for the tenant.,Internal Helper,low,pure function with no callers
policies,L5,policies_limits_query_engine,LimitsQueryEngine.list_limits,async list_limits(tenant_id: str) -> LimitsListResult,,LimitSummaryResult | LimitsListResult | fetch_limits | isoformat | len,asyncio | limits_read_driver,pure,yes,74,List limits for the tenant.,Internal Helper,low,pure function with no callers
policies,L5,policies_limits_query_engine,get_limits_query_engine,get_limits_query_engine(session: 'AsyncSession') -> LimitsQueryEngine,,LimitsQueryEngine | get_limits_read_driver,asyncio | limits_read_driver,pure,no,5,Get a LimitsQueryEngine instance.,Internal Helper,low,pure function with no callers
policies,L5,policies_proposals_query_engine,ProposalsQueryEngine.__init__,__init__(driver: ProposalsReadDriver),,,asyncio | proposals_read_driver,pure,no,2,,Internal Helper,high,dunder method
policies,L5,policies_proposals_query_engine,ProposalsQueryEngine.count_drafts,async count_drafts(tenant_id: str) -> int,,count_draft_proposals,asyncio | proposals_read_driver,pure,yes,6,Count draft proposals for badge display.,Internal Helper,low,pure function with no callers
policies,L5,policies_proposals_query_engine,ProposalsQueryEngine.get_policy_request_detail,"async get_policy_request_detail(tenant_id: str, proposal_id: str) -> Optional[PolicyRequestDetailResult]",,PolicyRequestDetailResult | fetch_proposal_by_id,asyncio | proposals_read_driver,pure,yes,27,Get policy request detail. Tenant isolation enforced.,Internal Helper,low,pure function with no callers
policies,L5,policies_proposals_query_engine,ProposalsQueryEngine.list_policy_requests,async list_policy_requests(tenant_id: str) -> PolicyRequestsListResult,,PolicyRequestResult | PolicyRequestsListResult | fetch_proposals | len,asyncio | proposals_read_driver,external_api,yes,54,List pending policy requests.,Unclassified,low,no classification rules matched
policies,L5,policies_proposals_query_engine,get_proposals_query_engine,get_proposals_query_engine(session: 'AsyncSession') -> ProposalsQueryEngine,,ProposalsQueryEngine | get_proposals_read_driver,asyncio | proposals_read_driver,pure,no,5,Get a ProposalsQueryEngine instance.,Internal Helper,low,pure function with no callers
policies,L5,policies_rules_query_engine,PolicyRulesQueryEngine.__init__,__init__(driver: PolicyRulesReadDriver),,,asyncio | policy_rules_read_driver,pure,no,2,,Internal Helper,high,dunder method
policies,L5,policies_rules_query_engine,PolicyRulesQueryEngine.count_rules,"async count_rules(tenant_id: str, status: str) -> int",,count_policy_rules,asyncio | policy_rules_read_driver,pure,yes,7,Count policy rules for tenant.,Internal Helper,low,pure function with no callers
policies,L5,policies_rules_query_engine,PolicyRulesQueryEngine.get_policy_rule_detail,"async get_policy_rule_detail(tenant_id: str, rule_id: str) -> Optional[PolicyRuleDetailResult]",,PolicyRuleDetailResult | fetch_policy_rule_by_id,asyncio | policy_rules_read_driver,pure,yes,29,Get policy rule detail. Tenant isolation enforced.,Internal Helper,low,pure function with no callers
policies,L5,policies_rules_query_engine,PolicyRulesQueryEngine.list_policy_rules,async list_policy_rules(tenant_id: str) -> PolicyRulesListResult,,PolicyRuleSummaryResult | PolicyRulesListResult | fetch_policy_rules | isoformat | len,asyncio | policy_rules_read_driver,pure,yes,69,List policy rules for the tenant.,Internal Helper,low,pure function with no callers
policies,L5,policies_rules_query_engine,get_policy_rules_query_engine,get_policy_rules_query_engine(session: 'AsyncSession') -> PolicyRulesQueryEngine,,PolicyRulesQueryEngine | get_policy_rules_read_driver,asyncio | policy_rules_read_driver,pure,no,7,Get a PolicyRulesQueryEngine instance.,Internal Helper,low,pure function with no callers
policies,L5,policy_command,_record_approval_action,_record_approval_action(result: str) -> None,L3:policy_adapter | ?:__init__,debug | record_approval_action,cost_sim | metrics | policies,pure,no,12,Record approval action metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_approval_escalation,_record_approval_escalation() -> None,L3:policy_adapter | ?:__init__,debug | record_approval_escalation,cost_sim | metrics | policies,pure,no,12,Record approval escalation metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_approval_request_created,_record_approval_request_created(policy_type: str) -> None,L3:policy_adapter | ?:__init__,debug | record_approval_request_created,cost_sim | metrics | policies,pure,no,12,Record approval request creation metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_budget_rejection,"_record_budget_rejection(resource_type: str, skill_id: str) -> None",L3:policy_adapter | ?:__init__,debug | record_budget_rejection,cost_sim | metrics | policies,pure,no,12,Record budget rejection metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_capability_violation,"_record_capability_violation(violation_type: str, skill_id: str, tenant_id: Optional[str]) -> None",L3:policy_adapter | ?:__init__,debug | record_capability_violation,cost_sim | metrics | policies,pure,no,12,Record capability violation metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_policy_decision,"_record_policy_decision(decision: str, policy_type: str) -> None",L3:policy_adapter | ?:__init__,debug | record_policy_decision,cost_sim | metrics | policies,pure,no,12,Record policy decision metric.,Internal Helper,medium,private function
policies,L5,policy_command,_record_webhook_fallback,_record_webhook_fallback() -> None,L3:policy_adapter | ?:__init__,debug | record_webhook_fallback,cost_sim | metrics | policies,pure,no,12,Record webhook fallback metric.,Internal Helper,medium,private function
policies,L5,policy_command,check_policy_violations,"async check_policy_violations(skill_id: str, tenant_id: str, agent_id: Optional[str], payload: Dict[str, Any], simulated_cost: Optional[int]) -> List[PolicyViolation]",L3:policy_adapter | ?:__init__,MinimalContext | MinimalStep | PolicyEnforcer | PolicyViolation | _record_budget_rejection | _record_capability_violation | append | check_can_execute | debug | str | type,cost_sim | metrics | policies,pure,yes,92,Check for policy violations.,Policy/Decision,medium,name matches 'check'
policies,L5,policy_command,evaluate_policy,"async evaluate_policy(skill_id: str, tenant_id: str, agent_id: Optional[str], payload: Dict[str, Any], auto_approve_max_cost_cents: int, approval_level: int) -> PolicyEvaluationResult",L3:policy_adapter | ?:__init__,PolicyEvaluationResult | _record_policy_decision | all | append | check_policy_violations | simulate_cost,cost_sim | metrics | policies,pure,yes,78,Evaluate policy for a skill execution.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,policy_command,record_approval_created,record_approval_created(policy_type: str) -> None,L3:policy_adapter | ?:__init__,_record_approval_request_created,cost_sim | metrics | policies,pure,no,8,Record that an approval request was created.,Unclassified,low,no classification rules matched
policies,L5,policy_command,record_approval_outcome,record_approval_outcome(result: str) -> None,L3:policy_adapter | ?:__init__,_record_approval_action,cost_sim | metrics | policies,pure,no,8,Record approval outcome (approved/rejected/expired).,Unclassified,low,no classification rules matched
policies,L5,policy_command,record_escalation,record_escalation() -> None,L3:policy_adapter | ?:__init__,_record_approval_escalation,cost_sim | metrics | policies,pure,no,8,Record that an escalation occurred.,Unclassified,low,no classification rules matched
policies,L5,policy_command,record_webhook_used,record_webhook_used() -> None,L3:policy_adapter | ?:__init__,_record_webhook_fallback,cost_sim | metrics | policies,pure,no,8,Record that webhook fallback was used.,Unclassified,low,no classification rules matched
policies,L5,policy_command,simulate_cost,"async simulate_cost(skill_id: str, tenant_id: str, payload: Dict[str, Any]) -> Optional[int]",L3:policy_adapter | ?:__init__,CostSimulator | debug | int | simulate | warning,cost_sim | metrics | policies,pure,yes,34,Simulate cost for a skill execution.,Unclassified,low,no classification rules matched
policies,L5,policy_conflict_resolver,create_conflict_log,"create_conflict_log(run_id: str, resolved: ResolvedAction, strategy: ConflictResolutionStrategy) -> PolicyConflictLog",,PolicyConflictLog | isoformat | now,,pure,no,24,Create audit log entry for conflict resolution.,Internal Helper,low,pure function with no callers
policies,L5,policy_conflict_resolver,get_action_severity,get_action_severity(action: str) -> int,,get | upper,,pure,no,11,Get the severity level for an action.,Internal Helper,low,pure function with no callers
policies,L5,policy_conflict_resolver,is_more_restrictive,"is_more_restrictive(action_a: str, action_b: str) -> bool",,get_action_severity,,pure,no,12,Check if action_a is more restrictive than action_b.,Internal Helper,low,pure function with no callers
policies,L5,policy_conflict_resolver,resolve_policy_conflict,"resolve_policy_conflict(actions: List[PolicyAction], strategy: ConflictResolutionStrategy) -> ResolvedAction",,ResolvedAction | get | info | len | set | sorted | upper,,pure,no,82,Resolve conflict when multiple policies trigger.,Coordinator/Aggregator,ambiguous,multi-match: Coordinator/Aggregator(name matches 'resolve'); Internal Helper(pure function with no callers)
policies,L5,policy_driver,PolicyDriver.__init__,__init__(db_url: Optional[str]),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,,engine,pure,no,10,Initialize driver with optional database URL.,Internal Helper,high,dunder method
policies,L5,policy_driver,PolicyDriver._engine,_engine(),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,PolicyEngine,engine,pure,no,6,Lazy-load policy engine.,Internal Helper,medium,private function
policies,L5,policy_driver,PolicyDriver.acknowledge_violation,"async acknowledge_violation(db, violation_id: str, notes: Optional[str]) -> bool",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,acknowledge_violation,engine,pure,yes,3,Acknowledge a violation (mark as reviewed).,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.activate_policy_version,"async activate_policy_version(db, version_id: str, activated_by: str, dry_run: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,activate_policy_version,engine,pure,yes,7,Activate a policy version with pre-activation integrity checks.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.add_dependency_with_dag_check,"async add_dependency_with_dag_check(db, source_policy: str, target_policy: str, dependency_type: str, resolution_strategy: str, priority: int, description: Optional[str])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,add_dependency_with_dag_check,engine,pure,yes,20,Add a policy dependency with DAG validation.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
policies,L5,policy_driver,PolicyDriver.clear_cooldowns,"async clear_cooldowns(db, agent_id: str, rule_name: Optional[str]) -> int",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,clear_cooldowns,engine,pure,yes,3,Clear cooldowns for an agent.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.create_policy_version,"async create_policy_version(db, description: str, created_by: str)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,create_policy_version,engine,pure,yes,3,Create a new policy version snapshot.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.create_temporal_policy,"async create_temporal_policy(db, data: Dict)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,create_temporal_policy,engine,pure,yes,3,Create a new temporal policy.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.evaluate,"async evaluate(request, db, dry_run: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,debug | evaluate | str,engine,pure,yes,17,Evaluate a request against all applicable policies.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
policies,L5,policy_driver,PolicyDriver.evaluate_with_context,"async evaluate_with_context(db, action_type, policy_context, proposed_action: Optional[str], target_resource: Optional[str], estimated_cost: Optional[float], data_categories: Optional[List[str]], context: Optional[Dict[str, Any]])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,evaluate_with_context,engine,pure,yes,22,Context-aware policy evaluation.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'evaluate')
policies,L5,policy_driver,PolicyDriver.get_active_cooldowns,"async get_active_cooldowns(db, agent_id: Optional[str])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_active_cooldowns,engine,pure,yes,3,List all active cooldowns.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_current_version,async get_current_version(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_current_version,engine,pure,yes,3,Get the currently active policy version.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_dependency_graph,async get_dependency_graph(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_dependency_graph,engine,pure,yes,3,Get the policy dependency graph.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_ethical_constraints,"async get_ethical_constraints(db, include_inactive: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_ethical_constraints,engine,pure,yes,3,List all ethical constraints.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_metrics,"async get_metrics(db, hours: int)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_metrics,engine,pure,yes,3,Get policy engine metrics for the specified time window.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_policy_conflicts,"async get_policy_conflicts(db, include_resolved: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_policy_conflicts,engine,pure,yes,3,List policy conflicts.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_policy_versions,"async get_policy_versions(db, limit: int, include_inactive: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_policy_versions,engine,pure,yes,3,List all policy versions.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_risk_ceiling,"async get_risk_ceiling(db, ceiling_id: str)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_risk_ceiling,engine,pure,yes,3,Get a specific risk ceiling.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_risk_ceilings,"async get_risk_ceilings(db, tenant_id: Optional[str], include_inactive: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_risk_ceilings,engine,pure,yes,8,List all risk ceilings.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_safety_rules,"async get_safety_rules(db, tenant_id: Optional[str], include_inactive: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_safety_rules,engine,pure,yes,8,List all safety rules.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_state,async get_state(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_state,engine,pure,yes,3,Get the current state of the policy layer.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_temporal_policies,"async get_temporal_policies(db, metric: Optional[str], include_inactive: bool)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_temporal_policies,engine,pure,yes,5,List temporal (sliding window) policies.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_temporal_storage_stats,async get_temporal_storage_stats(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_temporal_storage_stats,engine,pure,yes,3,Get storage statistics for temporal metrics.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_temporal_utilization,"async get_temporal_utilization(db, policy_id: str, agent_id: Optional[str])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_temporal_utilization,engine,pure,yes,5,Get current utilization for a temporal policy.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_topological_evaluation_order,get_topological_evaluation_order(dependencies: List),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_topological_evaluation_order,engine,pure,no,3,Get the topological evaluation order for policies.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_version_provenance,"async get_version_provenance(db, version_id: str)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_version_provenance,engine,pure,yes,3,Get the provenance (change history) for a policy version.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_violation,"async get_violation(db, violation_id: str)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_violation,engine,pure,yes,3,Get a specific violation by ID.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.get_violations,"async get_violations(db, violation_type, agent_id: Optional[str], tenant_id: Optional[str], severity_min: Optional[float], since: Optional[datetime], limit: int)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,get_violations,engine,pure,yes,20,Get policy violations with filtering.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.pre_check,"async pre_check(request_id: str, agent_id: str, goal: str, tenant_id: str) -> Dict[str, Any]",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,debug | pre_check,engine,pure,yes,14,Pre-check policy constraints before run creation.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'check')
policies,L5,policy_driver,PolicyDriver.prune_temporal_metrics,"async prune_temporal_metrics(db, retention_hours: int, compact_older_than_hours: int, max_events_per_policy: int)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,prune_temporal_metrics,engine,pure,yes,14,Prune and compact temporal metric events.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.reload_policies,async reload_policies(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,info | reload_policies,engine,pure,yes,4,Hot-reload policies from database.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.reset_risk_ceiling,"async reset_risk_ceiling(db, ceiling_id: str) -> bool",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,reset_risk_ceiling,engine,pure,yes,3,Reset a risk ceiling's current value to 0.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.resolve_conflict,"async resolve_conflict(db, conflict_id: str, resolution: str, resolved_by: str) -> bool",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,resolve_conflict,engine,pure,yes,5,Resolve a policy conflict.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Coordinator/Aggregator(name matches 'resolve')
policies,L5,policy_driver,PolicyDriver.rollback_to_version,"async rollback_to_version(db, target_version: str, reason: str, rolled_back_by: str)",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,rollback_to_version,engine,pure,yes,5,Rollback to a previous policy version.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Internal Helper(name matches 'to_')
policies,L5,policy_driver,PolicyDriver.update_risk_ceiling,"async update_risk_ceiling(db, ceiling_id: str, updates: Dict[str, Any])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,update_risk_ceiling,engine,pure,yes,3,Update a risk ceiling configuration.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.update_safety_rule,"async update_safety_rule(db, rule_id: str, updates: Dict[str, Any])",?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,update_safety_rule,engine,pure,yes,3,Update a safety rule configuration.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,PolicyDriver.validate_dependency_dag,async validate_dependency_dag(db),?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,validate_dependency_dag,engine,pure,yes,3,Validate that policy dependencies form a valid DAG.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'validate')
policies,L5,policy_driver,get_policy_driver,get_policy_driver(db_url: Optional[str]) -> PolicyDriver,?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,PolicyDriver,engine,pure,no,19,Get the PolicyDriver singleton.,Operation,high,called by L4 orchestrator
policies,L5,policy_driver,reset_policy_driver,reset_policy_driver() -> None,?:__init__ | ?:policy_driver | L5:governance_facade | L4:policies_handler,,engine,pure,no,4,Reset the driver singleton (for testing).,Operation,high,called by L4 orchestrator
policies,L5,policy_graph_engine,ConflictDetectionResult.to_dict,"to_dict() -> dict[str, Any]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,isoformat | len | to_dict,__future__ | policy_graph_driver,pure,no,7,,Internal Helper,medium,name matches 'to_'
policies,L5,policy_graph_engine,DependencyGraphResult.to_dict,"to_dict() -> dict[str, Any]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,isoformat | to_dict,__future__ | policy_graph_driver,pure,no,6,,Internal Helper,medium,name matches 'to_'
policies,L5,policy_graph_engine,PolicyConflict.to_dict,"to_dict() -> dict[str, Any]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,isoformat,__future__ | policy_graph_driver,pure,no,12,,Internal Helper,medium,name matches 'to_'
policies,L5,policy_graph_engine,PolicyConflictEngine.__init__,__init__(tenant_id: str),?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,,__future__ | policy_graph_driver,pure,no,2,,Internal Helper,high,dunder method
policies,L5,policy_graph_engine,PolicyConflictEngine._detect_priority_overrides,async _detect_priority_overrides(policies: list[dict]) -> list[PolicyConflict],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyConflict | append | enumerate | get | items | len,__future__ | policy_graph_driver,pure,yes,46,Detect PRIORITY_OVERRIDE conflicts.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._detect_scope_overlaps,async _detect_scope_overlaps(policies: list[dict]) -> list[PolicyConflict],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyConflict | _has_contradicting_conditions | append | enumerate | get | items | len,__future__ | policy_graph_driver,pure,yes,62,Detect SCOPE_OVERLAP conflicts.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._detect_temporal_conflicts,async _detect_temporal_conflicts(policies: list[dict]) -> list[PolicyConflict],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyConflict | _time_windows_overlap | append | enumerate | get,__future__ | policy_graph_driver,pure,yes,34,Detect TEMPORAL_CONFLICT conflicts.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._detect_threshold_contradictions,async _detect_threshold_contradictions(driver: PolicyGraphDriver) -> list[PolicyConflict],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyConflict | append | fetch_active_limits | items | len | max | min | split,__future__ | policy_graph_driver,pure,yes,47,Detect THRESHOLD_CONTRADICTION conflicts.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._has_contradicting_conditions,"_has_contradicting_conditions(cond1: dict, cond2: dict) -> bool",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,isinstance,__future__ | policy_graph_driver,pure,no,11,Check if two condition sets have explicit contradictions.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._involves_policy,"_involves_policy(policy: dict, policy_id: str) -> bool",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,get,__future__ | policy_graph_driver,pure,no,3,Check if a conflict involves a specific policy.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine._time_windows_overlap,"_time_windows_overlap(tw1: dict, tw2: dict) -> bool",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,get,__future__ | policy_graph_driver,pure,no,9,Check if two time windows overlap.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyConflictEngine.detect_conflicts,"async detect_conflicts(driver: PolicyGraphDriver, policy_id: Optional[str], severity_filter: Optional[ConflictSeverity], include_resolved: bool) -> ConflictDetectionResult",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,ConflictDetectionResult | _detect_priority_overrides | _detect_scope_overlaps | _detect_temporal_conflicts | _detect_threshold_contradictions | _involves_policy | extend | fetch_active_policies | fetch_resolved_conflicts | len,__future__ | policy_graph_driver,pure,yes,55,Detect conflicts between policies.,Unclassified,low,no classification rules matched
policies,L5,policy_graph_engine,PolicyDependency.to_dict,"to_dict() -> dict[str, Any]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,,__future__ | policy_graph_driver,pure,no,10,,Internal Helper,medium,name matches 'to_'
policies,L5,policy_graph_engine,PolicyDependencyEngine.__init__,__init__(tenant_id: str),?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,,__future__ | policy_graph_driver,pure,no,2,,Internal Helper,high,dunder method
policies,L5,policy_graph_engine,PolicyDependencyEngine._detect_explicit_dependencies,_detect_explicit_dependencies(policies: list[dict]) -> list[PolicyDependency],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyDependency | append | get,__future__ | policy_graph_driver,pure,no,44,Detect EXPLICIT dependencies.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyDependencyEngine._detect_implicit_limit_dependencies,"_detect_implicit_limit_dependencies(policies: list[dict], limits: list[dict]) -> list[PolicyDependency]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyDependency | append | startswith,__future__ | policy_graph_driver,pure,no,47,Detect IMPLICIT_LIMIT dependencies.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyDependencyEngine._detect_implicit_scope_dependencies,_detect_implicit_scope_dependencies(policies: list[dict]) -> list[PolicyDependency],?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyDependency | append | items | len,__future__ | policy_graph_driver,pure,no,55,Detect IMPLICIT_SCOPE dependencies.,Internal Helper,medium,private function
policies,L5,policy_graph_engine,PolicyDependencyEngine.check_can_activate,"async check_can_activate(driver: PolicyGraphDriver, policy_id: str) -> tuple[bool, list[str]]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,append | compute_dependency_graph | len | next,__future__ | policy_graph_driver,pure,yes,28,Check if a policy can be activated.,Policy/Decision,medium,name matches 'check'
policies,L5,policy_graph_engine,PolicyDependencyEngine.check_can_delete,"async check_can_delete(driver: PolicyGraphDriver, policy_id: str) -> tuple[bool, list[str]]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,compute_dependency_graph | get | len | next,__future__ | policy_graph_driver,pure,yes,24,Check if a policy can be deleted.,Policy/Decision,medium,name matches 'check'
policies,L5,policy_graph_engine,PolicyDependencyEngine.compute_dependency_graph,"async compute_dependency_graph(driver: PolicyGraphDriver, policy_id: Optional[str]) -> DependencyGraphResult",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,DependencyGraphResult | PolicyNode | _detect_explicit_dependencies | _detect_implicit_limit_dependencies | _detect_implicit_scope_dependencies | add | append | extend | fetch_all_limits | fetch_all_policies,__future__ | policy_graph_driver,db_write,yes,71,Compute the policy dependency graph.,Unclassified,low,no classification rules matched
policies,L5,policy_graph_engine,PolicyNode.to_dict,"to_dict() -> dict[str, Any]",?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,,__future__ | policy_graph_driver,pure,no,11,,Internal Helper,medium,name matches 'to_'
policies,L5,policy_graph_engine,get_conflict_engine,get_conflict_engine(tenant_id: str) -> PolicyConflictEngine,?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyConflictEngine,__future__ | policy_graph_driver,pure,no,3,Get a PolicyConflictEngine instance for a tenant.,Unclassified,low,no classification rules matched
policies,L5,policy_graph_engine,get_dependency_engine,get_dependency_engine(tenant_id: str) -> PolicyDependencyEngine,?:policies_facade | ?:policy_proposal | L5:policy_proposal_engine | ?:policy_conflict_result | ?:policy_node_result | ?:policy_dependency_edge | ?:dependency_graph_result,PolicyDependencyEngine,__future__ | policy_graph_driver,pure,no,3,Get a PolicyDependencyEngine instance for a tenant.,Unclassified,low,no classification rules matched
policies,L5,policy_limits_engine,PolicyLimitsService.__init__,__init__(session: 'AsyncSession'),L4:policies_handler,AuditLedgerServiceAsync | get_policy_limits_driver,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,no,4,,Internal Helper,high,dunder method
policies,L5,policy_limits_engine,PolicyLimitsService._get_limit,"async _get_limit(tenant_id: str, limit_id: str) -> Limit",L4:policies_handler,LimitNotFoundError | fetch_limit_by_id,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,yes,8,Get limit by ID with tenant check.,Internal Helper,medium,private function
policies,L5,policy_limits_engine,PolicyLimitsService._to_response,_to_response(limit: Limit) -> PolicyLimitResponse,L4:policies_handler,PolicyLimitResponse,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,no,19,Convert model to response.,Internal Helper,medium,private function
policies,L5,policy_limits_engine,PolicyLimitsService._validate_category_fields,_validate_category_fields(request: CreatePolicyLimitRequest) -> None,L4:policies_handler,LimitValidationError,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,no,11,Validate category-specific required fields.,Internal Helper,medium,private function
policies,L5,policy_limits_engine,PolicyLimitsService.create,"async create(tenant_id: str, request: CreatePolicyLimitRequest, created_by: Optional[str]) -> PolicyLimitResponse",L4:policies_handler,Decimal | Limit | LimitIntegrity | _to_response | _validate_category_fields | add_integrity | add_limit | begin | generate_uuid | limit_created | str | utc_now,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,yes,86,Create a new policy limit.,Operation,high,called by L4 orchestrator
policies,L5,policy_limits_engine,PolicyLimitsService.delete,"async delete(tenant_id: str, limit_id: str, deleted_by: Optional[str]) -> None",L4:policies_handler,_get_limit | flush | utc_now,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,db_write,yes,23,Delete (disable) a policy limit.,Operation,high,called by L4 orchestrator
policies,L5,policy_limits_engine,PolicyLimitsService.get,"async get(tenant_id: str, limit_id: str) -> PolicyLimitResponse",L4:policies_handler,_get_limit | _to_response,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,yes,20,Get a policy limit by ID.,Operation,high,called by L4 orchestrator
policies,L5,policy_limits_engine,PolicyLimitsService.update,"async update(tenant_id: str, limit_id: str, request: UpdatePolicyLimitRequest, updated_by: Optional[str]) -> PolicyLimitResponse",L4:policies_handler,_get_limit | _to_response | begin | limit_updated | str | utc_now,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_limits | policy_limits_driver | time,pure,yes,83,Update an existing policy limit.,Operation,high,called by L4 orchestrator
policies,L5,policy_mapper,MCPPolicyDecision.allow,"allow(tool_name: str, server_id: str, policy_id: Optional[str]) -> 'MCPPolicyDecision'",?:__init__ | ?:audit_evidence | L5:audit_evidence,cls,engine,pure,no,13,Create an allow decision.,Policy/Decision,medium,name matches 'allow'
policies,L5,policy_mapper,MCPPolicyDecision.deny,"deny(tool_name: str, server_id: str, reason: MCPDenyReason, message: Optional[str], policy_id: Optional[str]) -> 'MCPPolicyDecision'",?:__init__ | ?:audit_evidence | L5:audit_evidence,cls,engine,pure,no,17,Create a deny decision.,Policy/Decision,medium,name matches 'deny'
policies,L5,policy_mapper,MCPPolicyDecision.to_dict,"to_dict() -> Dict[str, Any]",?:__init__ | ?:audit_evidence | L5:audit_evidence,,engine,pure,no,11,Convert to dictionary for logging/serialization.,Internal Helper,medium,name matches 'to_'
policies,L5,policy_mapper,MCPPolicyMapper.__init__,__init__(policy_engine: Optional[Any]),?:__init__ | ?:audit_evidence | L5:audit_evidence,,engine,pure,no,10,Initialize policy mapper.,Internal Helper,high,dunder method
policies,L5,policy_mapper,MCPPolicyMapper._check_explicit_allow,"async _check_explicit_allow(tenant_id: str, server_id: str, tool_name: str) -> bool",?:__init__ | ?:audit_evidence | L5:audit_evidence,,engine,pure,yes,9,Check if tenant has explicit allow for dangerous tool.,Internal Helper,medium,private function
policies,L5,policy_mapper,MCPPolicyMapper._check_rate_limit,"async _check_rate_limit(tenant_id: str, tool_key: str, max_per_minute: int) -> bool",?:__init__ | ?:audit_evidence | L5:audit_evidence,,engine,pure,yes,9,Check if rate limit exceeded.,Internal Helper,medium,private function
policies,L5,policy_mapper,MCPPolicyMapper._evaluate_policy,"async _evaluate_policy(tenant_id: str, server_id: str, tool_name: str, run_id: str, required_permissions: List[str]) -> Any",?:__init__ | ?:audit_evidence | L5:audit_evidence,PolicyResult | _get_policy_engine | check_permission | str | warning,engine,pure,yes,55,Evaluate policy engine for required permissions.,Internal Helper,medium,private function
policies,L5,policy_mapper,MCPPolicyMapper._get_policy_engine,_get_policy_engine() -> Optional[Any],?:__init__ | ?:audit_evidence | L5:audit_evidence,debug | get_policy_engine,engine,pure,no,12,Get policy engine (lazy initialization).,Internal Helper,medium,private function
policies,L5,policy_mapper,MCPPolicyMapper.check_tool_invocation,"async check_tool_invocation(tenant_id: str, server_id: str, tool_name: str, run_id: str, input_params: Optional[Dict[str, Any]]) -> MCPPolicyDecision",?:__init__ | ?:audit_evidence | L5:audit_evidence,_check_explicit_allow | _check_rate_limit | _evaluate_policy | allow | debug | deny | get | info | warning,engine,pure,yes,126,Check if tool invocation is allowed.,Policy/Decision,medium,name matches 'check'
policies,L5,policy_mapper,MCPPolicyMapper.register_tool_policy,"async register_tool_policy(server_id: str, tool_name: str, required_permissions: Optional[List[str]], is_dangerous: bool, max_calls_per_minute: Optional[int]) -> MCPToolPolicy",?:__init__ | ?:audit_evidence | L5:audit_evidence,MCPToolPolicy | info,engine,pure,yes,42,Register policy for a tool.,Unclassified,low,no classification rules matched
policies,L5,policy_mapper,configure_mcp_policy_mapper,configure_mcp_policy_mapper(policy_engine: Optional[Any]) -> MCPPolicyMapper,?:__init__ | ?:audit_evidence | L5:audit_evidence,MCPPolicyMapper | info,engine,pure,no,22,Configure the singleton MCPPolicyMapper.,Unclassified,low,no classification rules matched
policies,L5,policy_mapper,get_mcp_policy_mapper,get_mcp_policy_mapper() -> MCPPolicyMapper,?:__init__ | ?:audit_evidence | L5:audit_evidence,MCPPolicyMapper | info,engine,pure,no,14,Get or create the singleton MCPPolicyMapper.,Unclassified,low,no classification rules matched
policies,L5,policy_mapper,reset_mcp_policy_mapper,reset_mcp_policy_mapper() -> None,?:__init__ | ?:audit_evidence | L5:audit_evidence,,engine,pure,no,4,Reset the singleton (for testing).,Unclassified,low,no classification rules matched
policies,L5,policy_proposal_engine,PolicyActivationBlockedError.__init__,"__init__(message: str, conflicts: list[dict])",,__init__ | super,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,no,3,,Internal Helper,high,dunder method
policies,L5,policy_proposal_engine,PolicyDeletionBlockedError.__init__,"__init__(message: str, dependents: list[str])",,__init__ | super,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,no,3,,Internal Helper,high,dunder method
policies,L5,policy_proposal_engine,PolicyProposalEngine.__init__,"__init__(read_driver: PolicyProposalReadDriver, write_driver: PolicyProposalWriteDriver)",,,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,no,7,,Internal Helper,high,dunder method
policies,L5,policy_proposal_engine,PolicyProposalEngine._create_policy_rule_from_proposal,"async _create_policy_rule_from_proposal(proposal: dict, approved_by: str) -> str",,check_rule_exists | create_policy_rule | get | info | replace,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,61,Create a policy_rule from an approved proposal.,Internal Helper,medium,private function
policies,L5,policy_proposal_engine,PolicyProposalEngine.check_proposal_eligibility,"async check_proposal_eligibility(tenant_id: Optional[UUID], feedback_type: Optional[str], threshold: int) -> list[dict]",,append | fetch_unacknowledged_feedback | get | info | items | len,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,61,Check if feedback patterns are eligible for policy proposals.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,policy_proposal_engine,PolicyProposalEngine.create_proposal,async create_proposal(proposal: PolicyProposalCreate) -> str,,create_proposal | info | len | str,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,33,Create a policy proposal.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,PolicyProposalEngine.delete_policy_rule,"async delete_policy_rule(session: 'AsyncSession', rule_id: str, tenant_id: str, deleted_by: str) -> bool",,PolicyDeletionBlockedError | ValueError | check_can_delete | delete_policy_rule | fetch_rule_by_id | get_dependency_engine | info | join | len | warning,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,65,Delete a policy rule with GOV-POL-002 enforcement.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,PolicyProposalEngine.get_proposal_summary,"async get_proposal_summary(tenant_id: Optional[UUID], status: Optional[str], limit: int) -> dict",,fetch_proposals | get | isoformat | len,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,52,Get policy proposal summary for ops visibility.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,PolicyProposalEngine.review_proposal,"async review_proposal(session: 'AsyncSession', proposal_id: UUID, review: PolicyApprovalRequest) -> dict",,AuditLedgerServiceAsync | PolicyActivationBlockedError | ValueError | _create_policy_rule_from_proposal | count_versions_for_proposal | create_version | detect_conflicts | fetch_proposal_by_id | get_conflict_engine | info | isoformat | len | policy_proposal_approved | policy_proposal_rejected | str,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,169,Review (approve/reject) a policy proposal.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,check_proposal_eligibility,"async check_proposal_eligibility(session: 'AsyncSession', tenant_id: Optional[UUID], feedback_type: Optional[str], threshold: int) -> list[dict]",,check_proposal_eligibility | get_policy_proposal_engine,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,13,Backward-compatible wrapper for eligibility checking.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,policy_proposal_engine,create_policy_proposal,"async create_policy_proposal(session: 'AsyncSession', proposal: PolicyProposalCreate) -> str",,create_proposal | get_policy_proposal_engine,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,7,Backward-compatible wrapper for proposal creation.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,delete_policy_rule,"async delete_policy_rule(session: 'AsyncSession', rule_id: str, tenant_id: str, deleted_by: str) -> bool",,delete_policy_rule | get_policy_proposal_engine,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,9,Backward-compatible wrapper for rule deletion.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,generate_default_rule,"generate_default_rule(policy_type: str, feedback_type: str) -> dict",,,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,no,28,Generate a default rule template based on policy type.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,get_policy_proposal_engine,get_policy_proposal_engine(session: 'AsyncSession') -> PolicyProposalEngine,,PolicyProposalEngine | get_policy_proposal_read_driver | get_policy_proposal_write_driver,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,no,6,Get a PolicyProposalEngine instance with drivers.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,get_proposal_summary,"async get_proposal_summary(session: 'AsyncSession', tenant_id: Optional[UUID], status: Optional[str], limit: int) -> dict",,get_policy_proposal_engine | get_proposal_summary,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,13,Backward-compatible wrapper for proposal summary.,Internal Helper,low,pure function with no callers
policies,L5,policy_proposal_engine,review_policy_proposal,"async review_policy_proposal(session: 'AsyncSession', proposal_id: UUID, review: PolicyApprovalRequest) -> dict",,get_policy_proposal_engine | review_proposal,asyncio | audit_ledger | audit_ledger_service_async | policy | policy_graph_engine | policy_proposal_read_driver | policy_proposal_write_driver | time,pure,yes,8,Backward-compatible wrapper for proposal review.,Internal Helper,low,pure function with no callers
policies,L5,policy_rules_engine,PolicyRulesService.__init__,__init__(session: 'AsyncSession'),L4:policies_handler,AuditLedgerServiceAsync | get_policy_rules_driver,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,no,4,,Internal Helper,high,dunder method
policies,L5,policy_rules_engine,PolicyRulesService._compute_hash,_compute_hash(rule: PolicyRule) -> str,L4:policies_handler,dumps | encode | hexdigest | sha256,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,no,14,Compute integrity hash for rule.,Internal Helper,medium,private function
policies,L5,policy_rules_engine,PolicyRulesService._get_rule,"async _get_rule(tenant_id: str, rule_id: str) -> PolicyRule",L4:policies_handler,RuleNotFoundError | fetch_rule_by_id,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,yes,8,Get rule by ID with tenant check.,Internal Helper,medium,private function
policies,L5,policy_rules_engine,PolicyRulesService._to_response,_to_response(rule: PolicyRule) -> PolicyRuleResponse,L4:policies_handler,PolicyRuleResponse,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,no,23,Convert model to response.,Internal Helper,medium,private function
policies,L5,policy_rules_engine,PolicyRulesService._validate_conditions,"_validate_conditions(conditions: dict[str, Any]) -> None",L4:policies_handler,RuleValidationError | isinstance | keys,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,no,20,Validate rule conditions syntax.,Internal Helper,medium,private function
policies,L5,policy_rules_engine,PolicyRulesService.create,"async create(tenant_id: str, request: CreatePolicyRuleRequest, created_by: Optional[str]) -> PolicyRuleResponse",L4:policies_handler,Decimal | PolicyRule | PolicyRuleIntegrity | _compute_hash | _to_response | _validate_conditions | add_integrity | add_rule | begin | generate_uuid | policy_rule_created | utc_now,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,yes,87,Create a new policy rule.,Operation,high,called by L4 orchestrator
policies,L5,policy_rules_engine,PolicyRulesService.get,"async get(tenant_id: str, rule_id: str) -> PolicyRuleResponse",L4:policies_handler,_get_rule | _to_response,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,yes,20,Get a policy rule by ID.,Operation,high,called by L4 orchestrator
policies,L5,policy_rules_engine,PolicyRulesService.update,"async update(tenant_id: str, rule_id: str, request: UpdatePolicyRuleRequest, updated_by: Optional[str]) -> PolicyRuleResponse",L4:policies_handler,RuleValidationError | _get_rule | _to_response | _validate_conditions | begin | policy_rule_modified | policy_rule_retired | retire | utc_now,asyncio | audit_ledger | audit_ledger_service_async | cross_domain | policy_control_plane | policy_rules | policy_rules_driver | time,pure,yes,105,Update an existing policy rule.,Operation,high,called by L4 orchestrator
policies,L5,prevention_engine,PolicyViolationError.__init__,__init__(result: PreventionResult),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,__init__ | super,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,3,,Internal Helper,high,dunder method
policies,L5,prevention_engine,PreventionEngine.__init__,__init__(policy_snapshot_id: Optional[str]),?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,10,Initialize prevention engine.,Internal Helper,high,dunder method
policies,L5,prevention_engine,PreventionEngine._evaluate_custom_policy,"_evaluate_custom_policy(policy: dict[str, Any], context: PreventionContext) -> PreventionResult",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,allow | block | get | str,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,37,Evaluate a custom policy rule.,Internal Helper,medium,private function
policies,L5,prevention_engine,PreventionEngine._evaluate_step_inner,_evaluate_step_inner(context: PreventionContext) -> PreventionResult,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,PolicyAction | _evaluate_custom_policy | allow | append | block | debug | get | len | resolve_policy_conflict | should_evaluate_policy | str | type | upper | warning,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,139,"Inner evaluation logic (GAP-068, GAP-031 integrated).",Internal Helper,medium,private function
policies,L5,prevention_engine,PreventionEngine.evaluate_step,evaluate_step(context: PreventionContext) -> PreventionResult,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,_evaluate_step_inner | allow | block | handle_evaluation_error | str | warning,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,49,Evaluate policy at step checkpoint.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,prevention_engine,PreventionEngine.load_snapshot,load_snapshot(snapshot_id: str) -> bool,?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,Session | error | exec | first | get_policies | get_thresholds | info | select | str | verify_integrity | warning | where,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,57,Load policy snapshot for evaluation.,Unclassified,low,no classification rules matched
policies,L5,prevention_engine,PreventionResult.allow,allow() -> 'PreventionResult',?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,cls,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,3,Create an ALLOW result.,Policy/Decision,medium,name matches 'allow'
policies,L5,prevention_engine,PreventionResult.block,"block(policy_id: str, policy_name: str, violation_type: ViolationType, threshold_value: str, actual_value: str, reason: str) -> 'PreventionResult'",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,cls,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,19,Create a BLOCK result.,Unclassified,low,no classification rules matched
policies,L5,prevention_engine,PreventionResult.warn,"warn(reason: str, policy_id: Optional[str]) -> 'PreventionResult'",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,cls,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,pure,no,7,Create a WARN result.,Unclassified,low,no classification rules matched
policies,L5,prevention_engine,create_policy_snapshot_for_run,"create_policy_snapshot_for_run(tenant_id: str, run_id: str) -> Optional[str]",?:arbitrator | ?:__init__ | ?:scope_resolver | ?:step_enforcement | L7:override_authority | L7:monitor_config | L7:threshold_signal | ?:alert_emitter | ?:authority_checker | L6:arbitrator,Session | add | create_snapshot | error | flush | info | refresh | str,binding_moment_enforcer | conflict_resolver | db | failure_mode_handler | policy_snapshot | sqlmodel,db_write,no,60,Create a policy snapshot at run start.,Unclassified,low,no classification rules matched
policies,L5,prevention_hook,PreventionContext.__post_init__,__post_init__(),?:__init__,now,content_accuracy,pure,no,3,,Internal Helper,high,dunder method
policies,L5,prevention_hook,PreventionHook.__init__,"__init__(strict_mode: bool, block_on_fail: bool, fallback_message: Optional[str])",?:__init__,ContentAccuracyValidator,content_accuracy,pure,no,14,,Internal Helper,high,dunder method
policies,L5,prevention_hook,PreventionHook.evaluate,evaluate(ctx: PreventionContext) -> PreventionResult,?:__init__,PreventionResult | int | time | validate,content_accuracy,pure,no,44,Evaluate the LLM output against policies.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,prevention_hook,PreventionHook.get_safe_response,get_safe_response(ctx: PreventionContext) -> str,?:__init__,lower,content_accuracy,pure,no,33,Generate a safe response when the original fails validation.,Unclassified,low,no classification rules matched
policies,L5,prevention_hook,PreventionResult.__post_init__,__post_init__(),?:__init__,str | uuid4,content_accuracy,pure,no,3,,Internal Helper,high,dunder method
policies,L5,prevention_hook,PreventionResult.to_dict,"to_dict() -> Dict[str, Any]",?:__init__,,content_accuracy,pure,no,12,,Internal Helper,medium,name matches 'to_'
policies,L5,prevention_hook,create_prevention_hook,"create_prevention_hook(strict_mode: bool, block_on_fail: bool) -> PreventionHook",?:__init__,PreventionHook,content_accuracy,pure,no,9,Factory function to create a prevention hook.,Unclassified,low,no classification rules matched
policies,L5,prevention_hook,evaluate_response,"evaluate_response(tenant_id: str, call_id: str, user_query: str, context_data: Dict[str, Any], llm_output: str, model: str, user_id: Optional[str]) -> PreventionResult",?:__init__,PreventionContext | evaluate | get_prevention_hook | len | split,content_accuracy,pure,no,40,Convenience function to evaluate an LLM response.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,prevention_hook,get_prevention_hook,get_prevention_hook() -> PreventionHook,?:__init__,create_prevention_hook,content_accuracy,pure,no,6,Get the global prevention hook instance.,Unclassified,low,no classification rules matched
policies,L5,protection_provider,AbuseProtectionProvider.check_all,"check_all(tenant_id: str, endpoint: str, operation: str) -> ProtectionResult",,,billing | decisions,pure,no,21,Run all protection checks in order.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,AbuseProtectionProvider.check_burst,"check_burst(tenant_id: str, endpoint: str) -> ProtectionResult",,,billing | decisions,pure,no,12,Check burst control for a tenant/endpoint combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,AbuseProtectionProvider.check_cost,"check_cost(tenant_id: str, operation: str) -> ProtectionResult",,,billing | decisions,pure,no,12,Check cost guard for a tenant/operation combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,AbuseProtectionProvider.check_rate_limit,"check_rate_limit(tenant_id: str, endpoint: str) -> ProtectionResult",,,billing | decisions,pure,no,12,Check rate limit for a tenant/endpoint combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,AbuseProtectionProvider.detect_anomaly,detect_anomaly(tenant_id: str) -> Optional[AnomalySignal],,,billing | decisions,pure,no,13,Detect usage anomaly for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,MockAbuseProtectionProvider.__init__,__init__() -> None,,,billing | decisions,pure,no,14,Initialize mock provider with in-memory state.,Internal Helper,high,dunder method
policies,L5,protection_provider,MockAbuseProtectionProvider.add_cost,"add_cost(tenant_id: str, amount: float) -> None",,get,billing | decisions,pure,no,4,Add cost to tenant's daily accumulator (mock/test only).,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,MockAbuseProtectionProvider.check_all,"check_all(tenant_id: str, endpoint: str, operation: str) -> ProtectionResult",,allow | check_burst | check_cost | check_rate_limit | detect_anomaly | info | warning,billing | decisions,pure,no,38,Run all protection checks in order.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,MockAbuseProtectionProvider.check_burst,"check_burst(tenant_id: str, endpoint: str) -> ProtectionResult",,allow | get | int | throttle | time,billing | decisions,pure,no,27,Check burst control for a tenant/endpoint combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,MockAbuseProtectionProvider.check_cost,"check_cost(tenant_id: str, operation: str) -> ProtectionResult",,allow | get | get_billing_provider | get_limits | get_plan | reject_cost_limit,billing | decisions,pure,no,27,Check cost guard for a tenant/operation combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,MockAbuseProtectionProvider.check_rate_limit,"check_rate_limit(tenant_id: str, endpoint: str) -> ProtectionResult",,allow | get | reject_rate_limit,billing | decisions,pure,no,26,Check rate limit for a tenant/endpoint combination.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'check'); Internal Helper(pure function with no callers)
policies,L5,protection_provider,MockAbuseProtectionProvider.detect_anomaly,detect_anomaly(tenant_id: str) -> Optional[AnomalySignal],,AnomalySignal | float | sum | values,billing | decisions,pure,no,23,Detect usage anomaly for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,MockAbuseProtectionProvider.reset,reset() -> None,,clear,billing | decisions,pure,no,7,Reset all mock state (for testing).,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,MockAbuseProtectionProvider.reset_rate_limits,reset_rate_limits(tenant_id: str) -> None,,,billing | decisions,pure,no,4,Reset rate limits for a tenant (for testing).,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,get_protection_provider,get_protection_provider() -> AbuseProtectionProvider,,MockAbuseProtectionProvider,billing | decisions,pure,no,11,Get the abuse protection provider instance.,Internal Helper,low,pure function with no callers
policies,L5,protection_provider,set_protection_provider,set_protection_provider(provider: AbuseProtectionProvider) -> None,,,billing | decisions,pure,no,8,Set the abuse protection provider instance.,Internal Helper,low,pure function with no callers
policies,L5,recovery_evaluation_engine,FailureContext.__post_init__,__post_init__(),?:recovery_evaluator | ?:test_m10_recovery_enhanced,now,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,5,,Internal Helper,high,dunder method
policies,L5,recovery_evaluation_engine,RecoveryDecision.to_dict,"to_dict() -> Dict[str, Any]",?:recovery_evaluator | ?:test_m10_recovery_enhanced,,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,13,,Internal Helper,medium,name matches 'to_'
policies,L5,recovery_evaluation_engine,RecoveryEvaluationEngine.__init__,__init__(),?:recovery_evaluator | ?:test_m10_recovery_enhanced,RecoveryMatcher,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,3,Initialize the evaluation engine.,Internal Helper,high,dunder method
policies,L5,recovery_evaluation_engine,RecoveryEvaluationEngine.emit_decision_record,"emit_decision_record(decision: RecoveryDecision, evaluated: bool, triggered: bool) -> None",?:recovery_evaluator | ?:test_m10_recovery_enhanced,emit_recovery_decision,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,31,Emit recovery decision record (L4 domain responsibility).,Unclassified,low,no classification rules matched
policies,L5,recovery_evaluation_engine,RecoveryEvaluationEngine.evaluate,evaluate(context: FailureContext) -> RecoveryDecision,?:recovery_evaluator | ?:test_m10_recovery_enhanced,RecoveryDecision | combine_confidences | evaluate_rules | get | info | isoformat | should_auto_execute | should_select_action | suggest | to_dict,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,84,Evaluate failure context and produce recovery decision.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,recovery_evaluation_engine,evaluate_and_execute,"async evaluate_and_execute(failure_match_id: str, error_code: str, error_message: str, **kwargs) -> 'EvaluationOutcome'",?:recovery_evaluator | ?:test_m10_recovery_enhanced,FailureContext | FailureEvent | RecoveryEvaluationEngine | RecoveryExecutor | emit_decision_record | evaluate | execute_decision | get,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,yes,74,Full entry point: evaluate failure and execute decision.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,recovery_evaluation_engine,evaluate_recovery,"evaluate_recovery(failure_match_id: str, error_code: str, error_message: str, **kwargs) -> RecoveryDecision",?:recovery_evaluator | ?:test_m10_recovery_enhanced,FailureContext | RecoveryEvaluationEngine | evaluate | get,decisions | recovery_evaluator | recovery_matcher | recovery_rule_engine,pure,no,36,Convenience function to evaluate a failure and get a decision.,Policy/Decision,medium,name matches 'evaluate'
policies,L5,runtime_command,execute_query,"execute_query(query_type: str, params: Optional[Dict[str, Any]]) -> QueryResult",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult | get | query_allowed_skills | query_execution_history | query_last_step_outcome | query_remaining_budget | query_skills_for_goal,,pure,no,34,Execute a runtime query.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,get_all_skill_descriptors,"get_all_skill_descriptors() -> Dict[str, Dict[str, Any]]",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,get,,pure,no,21,Get descriptors for all skills.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,get_capabilities,"get_capabilities(agent_id: Optional[str], tenant_id: Optional[str]) -> CapabilitiesInfo",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,CapabilitiesInfo | get | items,,pure,no,42,Get capabilities for an agent/tenant.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,get_resource_contract,get_resource_contract(resource_id: str) -> ResourceContractInfo,?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,ResourceContractInfo,,pure,no,18,Get resource contract information.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,get_skill_info,get_skill_info(skill_id: str) -> Optional[SkillInfo],?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,SkillInfo | get,,pure,no,27,Get domain information about a skill.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,get_supported_query_types,get_supported_query_types() -> List[str],?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,copy,,pure,no,10,Get list of supported query types.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,list_skills,list_skills() -> List[str],?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,keys | list,,pure,no,10,List all available skill IDs.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,query_allowed_skills,query_allowed_skills() -> QueryResult,?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult | keys | len | list,,pure,no,17,Query list of allowed skills.,Operation,ambiguous,multi-match: Operation(called by L4 orchestrator); Policy/Decision(name matches 'allow'); Operation(called by L2 (gap  should route via L4))
policies,L5,runtime_command,query_execution_history,"query_execution_history(history: Optional[List[Dict[str, Any]]]) -> QueryResult",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult,,pure,no,16,Query execution history.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,query_last_step_outcome,"query_last_step_outcome(outcome: Optional[Dict[str, Any]]) -> QueryResult",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult,,pure,no,16,Query last step outcome.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,query_remaining_budget,"query_remaining_budget(spent_cents: int, total_cents: int) -> QueryResult",?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult,,pure,no,24,Query remaining budget.,Operation,high,called by L4 orchestrator
policies,L5,runtime_command,query_skills_for_goal,query_skills_for_goal(goal: str) -> QueryResult,?:runtime | L3:runtime_adapter | L5:runtime_adapter | L2:runtime | L4:runtime_adapter | ?:__init__,QueryResult | hash | keys | list | ord | sorted | sum,,pure,no,25,Query skills available for a goal.,Operation,high,called by L4 orchestrator
policies,L5,sandbox_engine,ExecutionRecord.to_dict,"to_dict() -> Dict[str, Any]",,isoformat,sandbox_executor,pure,no,18,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
policies,L5,sandbox_engine,SandboxPolicy.to_dict,"to_dict() -> Dict[str, Any]",,list,sandbox_executor,pure,no,19,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
policies,L5,sandbox_engine,SandboxPolicy.to_resource_limits,to_resource_limits() -> ResourceLimits,,ResourceLimits,sandbox_executor,pure,no,10,Convert policy to resource limits.,Internal Helper,medium,name matches 'to_'
policies,L5,sandbox_engine,SandboxService.__init__,__init__(),,_setup_default_policies,sandbox_executor,pure,no,6,,Internal Helper,high,dunder method
policies,L5,sandbox_engine,SandboxService._check_quota,"_check_quota(tenant_id: str, policy: SandboxPolicy) -> bool",,get | len | now | strftime,sandbox_executor,pure,no,22,Check if tenant has quota remaining.,Internal Helper,medium,private function
policies,L5,sandbox_engine,SandboxService._get_executor,_get_executor(isolation_level: IsolationLevel) -> SandboxExecutor,,create_sandbox_executor,sandbox_executor,pure,no,5,Get or create an executor for the isolation level.,Internal Helper,medium,private function
policies,L5,sandbox_engine,SandboxService._get_policy,_get_policy(policy_id: Optional[str]) -> SandboxPolicy,,,sandbox_executor,pure,no,5,"Get a policy by ID, defaulting to 'standard'.",Internal Helper,medium,private function
policies,L5,sandbox_engine,SandboxService._setup_default_policies,_setup_default_policies() -> None,,SandboxPolicy,sandbox_executor,pure,no,61,Set up default sandbox policies.,Internal Helper,medium,private function
policies,L5,sandbox_engine,SandboxService._track_execution,_track_execution(tenant_id: str) -> None,,append | int | keys | max | now | str | strftime | zfill,sandbox_executor,pure,no,26,Track an execution for quota purposes.,Internal Helper,medium,private function
policies,L5,sandbox_engine,SandboxService.define_policy,"define_policy(policy_id: str, name: str, **kwargs) -> SandboxPolicy",,SandboxPolicy | info,sandbox_executor,pure,no,25,Define a new sandbox policy.,Internal Helper,low,pure function with no callers
policies,L5,sandbox_engine,SandboxService.execute,async execute(request: ExecutionRequest) -> ExecutionResult,,ExecutionRecord | ExecutionResult | _check_quota | _get_executor | _get_policy | _track_execution | append | cleanup | encode | execute | float | hexdigest | info | int | len,sandbox_executor,pure,yes,106,Execute code in a sandbox.,Internal Helper,low,pure function with no callers
policies,L5,sandbox_engine,SandboxService.get_execution_records,"get_execution_records(tenant_id: Optional[str], user_id: Optional[str], run_id: Optional[str], status: Optional[SandboxStatus], limit: int) -> List[ExecutionRecord]",,,sandbox_executor,pure,no,33,Get execution records with optional filtering.,Internal Helper,low,pure function with no callers
policies,L5,sandbox_engine,SandboxService.get_execution_stats,"get_execution_stats(tenant_id: Optional[str]) -> Dict[str, Any]",,get | len,sandbox_executor,pure,no,55,Get execution statistics.,Internal Helper,low,pure function with no callers
policies,L5,sandbox_engine,SandboxService.get_policy,get_policy(policy_id: str) -> Optional[SandboxPolicy],,get,sandbox_executor,pure,no,3,Get a policy by ID.,Internal Helper,low,pure function with no callers
policies,L5,sandbox_engine,SandboxService.list_policies,"list_policies() -> Dict[str, SandboxPolicy]",,dict,sandbox_executor,pure,no,3,List all defined policies.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotData.compute_hash,compute_hash(content: str) -> str,,encode | hexdigest | sha256,,pure,no,3,Compute SHA256 hash of content.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotData.get_policies,"get_policies() -> list[dict[str, Any]]",,loads,,pure,no,3,Deserialize policies from JSON.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotData.get_thresholds,"get_thresholds() -> dict[str, Any]",,loads,,pure,no,3,Deserialize thresholds from JSON.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotData.to_dict,"to_dict() -> dict[str, Any]",,isoformat | verify_integrity,,pure,no,20,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
policies,L5,snapshot_engine,PolicySnapshotData.verify_integrity,verify_integrity() -> bool,,compute_hash,,pure,no,5,Verify content hash matches stored data.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'verify'); Internal Helper(pure function with no callers)
policies,L5,snapshot_engine,PolicySnapshotData.verify_threshold_integrity,verify_threshold_integrity() -> bool,,compute_hash,,pure,no,4,Verify threshold hash matches threshold data.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'verify'); Internal Helper(pure function with no callers)
policies,L5,snapshot_engine,PolicySnapshotError.__init__,"__init__(message: str, snapshot_id: Optional[str], violation_type: Optional[ImmutabilityViolation])",,__init__ | super,,pure,no,10,,Internal Helper,high,dunder method
policies,L5,snapshot_engine,PolicySnapshotError.to_dict,"to_dict() -> dict[str, Any]",,,,pure,no,9,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
policies,L5,snapshot_engine,PolicySnapshotRegistry.__init__,__init__(),,,,pure,no,5,Initialize the registry.,Internal Helper,high,dunder method
policies,L5,snapshot_engine,PolicySnapshotRegistry._get_next_version,_get_next_version(tenant_id: str) -> int,,get,,pure,no,6,Get the next version number for a tenant.,Internal Helper,medium,private function
policies,L5,snapshot_engine,PolicySnapshotRegistry._supersede_active,"_supersede_active(tenant_id: str, new_snapshot_id: str) -> None",,get_active | now,,pure,no,11,Supersede the current active snapshot for a tenant.,Internal Helper,medium,private function
policies,L5,snapshot_engine,PolicySnapshotRegistry.archive,archive(snapshot_id: str) -> PolicySnapshotData,,PolicySnapshotError | get,,pure,no,23,Archive a snapshot.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.attempt_modify,"attempt_modify(snapshot_id: str, **_kwargs) -> None",,PolicySnapshotError | get,,pure,no,25,Attempt to modify a snapshot (ALWAYS FAILS).,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.clear_tenant,clear_tenant(tenant_id: str) -> int,,get | list | remove,,pure,no,13,Clear all archived snapshots for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.create,"create(tenant_id: str, policies: list[dict[str, Any]], thresholds: dict[str, Any], policy_version: Optional[str], description: Optional[str], snapshot_id: Optional[str]) -> PolicySnapshotData",,PolicySnapshotData | _get_next_version | _supersede_active | append | compute_hash | dumps | len | str | uuid4,,pure,no,72,Create an immutable policy snapshot.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.delete,delete(snapshot_id: str) -> bool,,PolicySnapshotError | get | remove,,pure,no,28,Delete a snapshot.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.get,get(snapshot_id: str) -> Optional[PolicySnapshotData],,get,,pure,no,3,Get a snapshot by ID.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.get_active,get_active(tenant_id: str) -> Optional[PolicySnapshotData],,get | reversed,,pure,no,8,Get the current active snapshot for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.get_by_version,"get_by_version(tenant_id: str, version: int) -> Optional[PolicySnapshotData]",,values,,pure,no,10,Get a snapshot by tenant and version number.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.get_history,"get_history(tenant_id: str, limit: int) -> List[PolicySnapshotData]",,sort | values,,pure,no,12,Get version history for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.get_statistics,get_statistics(tenant_id: Optional[str]) -> SnapshotRegistryStats,,SnapshotRegistryStats | add | len | set | values | verify_integrity,,db_write,no,30,Get registry statistics.,Unclassified,low,no classification rules matched
policies,L5,snapshot_engine,PolicySnapshotRegistry.list,"list(tenant_id: Optional[str], status: Optional[SnapshotStatus], limit: int, offset: int) -> List[PolicySnapshotData]",,list | sort | values,,pure,no,20,List snapshots with optional filters.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.reset,reset() -> None,,clear,,pure,no,5,Reset all state (for testing).,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,PolicySnapshotRegistry.verify,"verify(snapshot_id: str) -> dict[str, Any]",,PolicySnapshotError | get | verify_integrity | verify_threshold_integrity,,pure,no,27,Verify snapshot integrity.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'verify'); Internal Helper(pure function with no callers)
policies,L5,snapshot_engine,SnapshotRegistryStats.to_dict,"to_dict() -> dict[str, Any]",,,,pure,no,11,Convert to dictionary.,Internal Helper,medium,name matches 'to_'
policies,L5,snapshot_engine,_reset_snapshot_registry,_reset_snapshot_registry() -> None,,reset,,pure,no,6,Reset the singleton (for testing).,Internal Helper,medium,private function
policies,L5,snapshot_engine,create_policy_snapshot,"create_policy_snapshot(tenant_id: str, policies: list[dict[str, Any]], thresholds: dict[str, Any], policy_version: Optional[str], description: Optional[str]) -> PolicySnapshotData",,create | get_snapshot_registry,,pure,no,16,Create a new immutable policy snapshot.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,get_active_snapshot,get_active_snapshot(tenant_id: str) -> Optional[PolicySnapshotData],,get_active | get_snapshot_registry,,pure,no,4,Get the active policy snapshot for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,get_policy_snapshot,get_policy_snapshot(snapshot_id: str) -> Optional[PolicySnapshotData],,get | get_snapshot_registry,,pure,no,4,Get a policy snapshot by ID.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,get_snapshot_history,"get_snapshot_history(tenant_id: str, limit: int) -> List[PolicySnapshotData]",,get_history | get_snapshot_registry,,pure,no,7,Get snapshot version history for a tenant.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,get_snapshot_registry,get_snapshot_registry() -> PolicySnapshotRegistry,,PolicySnapshotRegistry,,pure,no,6,Get the singleton registry instance.,Internal Helper,low,pure function with no callers
policies,L5,snapshot_engine,verify_snapshot,"verify_snapshot(snapshot_id: str) -> dict[str, Any]",,get_snapshot_registry | verify,,pure,no,4,Verify snapshot integrity.,Policy/Decision,ambiguous,multi-match: Policy/Decision(name matches 'verify'); Internal Helper(pure function with no callers)
policies,L5,state,BillingState.allows_usage,allows_usage() -> bool,?:gateway_config | ?:console_auth | ?:gateway_middleware | ?:rbac_middleware | ?:tier_gating | ?:tenant_auth | ?:killswitch | ?:incidents | ?:lifecycle_gate | ?:billing_gate,,,pure,no,8,Check if this billing state allows product usage.,Policy/Decision,medium,name matches 'allow'
policies,L5,state,BillingState.default,default() -> 'BillingState',?:gateway_config | ?:console_auth | ?:gateway_middleware | ?:rbac_middleware | ?:tier_gating | ?:tenant_auth | ?:killswitch | ?:incidents | ?:lifecycle_gate | ?:billing_gate,,,pure,no,7,Return the default state for tenants completing onboarding.,Unclassified,low,no classification rules matched
policies,L5,state,BillingState.from_string,from_string(value: str) -> 'BillingState',?:gateway_config | ?:console_auth | ?:gateway_middleware | ?:rbac_middleware | ?:tier_gating | ?:tenant_auth | ?:killswitch | ?:incidents | ?:lifecycle_gate | ?:billing_gate,ValueError | lower | strip,,pure,no,12,Parse state from string (case-insensitive).,Internal Helper,medium,name matches 'from_'
policies,L5,state,BillingState.is_in_good_standing,is_in_good_standing() -> bool,?:gateway_config | ?:console_auth | ?:gateway_middleware | ?:rbac_middleware | ?:tier_gating | ?:tenant_auth | ?:killswitch | ?:incidents | ?:lifecycle_gate | ?:billing_gate,,,pure,no,8,Check if tenant is in good commercial standing.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Token.__repr__,__repr__() -> str,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,,,pure,no,2,,Internal Helper,high,dunder method
policies,L5,tokenizer,Token.is_action,is_action() -> bool,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,,,pure,no,3,Check if token is an action.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Token.is_category,is_category() -> bool,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,,,pure,no,9,Check if token is a category.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.__init__,__init__(source: str),?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,,,pure,no,6,,Internal Helper,high,dunder method
policies,L5,tokenizer,Tokenizer.__iter__,__iter__() -> Iterator[Token],?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,iter | tokenize,,pure,no,5,Iterate over tokens.,Internal Helper,high,dunder method
policies,L5,tokenizer,Tokenizer.advance,advance() -> str,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,,,pure,no,10,Advance to next character.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.current_char,current_char() -> Optional[str],?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,len,,pure,no,5,Get current character or None if at end.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.peek,peek(offset: int) -> Optional[str],?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,len,,pure,no,6,Peek ahead by offset characters.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.read_identifier,read_identifier() -> Token,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,Token | advance | get | isalnum,,pure,no,12,Read an identifier or keyword.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.read_number,read_number() -> Token,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,Token | advance | isdigit,,pure,no,10,Read a number literal.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.read_operator,read_operator() -> Token,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,Token | TokenizerError | advance | peek,,pure,no,38,Read an operator.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.read_string,read_string() -> Token,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,Token | TokenizerError | advance | get,,pure,no,21,Read a string literal.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.skip_comment,skip_comment() -> None,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,advance,,pure,no,5,Skip single-line comments starting with #.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.skip_whitespace,skip_whitespace() -> None,?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,advance,,pure,no,4,Skip whitespace characters (except newlines for statement separation).,Unclassified,low,no classification rules matched
policies,L5,tokenizer,Tokenizer.tokenize,tokenize() -> List[Token],?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,Token | TokenizerError | advance | append | isalpha | isdigit | read_identifier | read_number | read_operator | read_string | skip_comment | skip_whitespace,,pure,no,50,Tokenize the source code.,Unclassified,low,no classification rules matched
policies,L5,tokenizer,TokenizerError.__init__,"__init__(message: str, line: int, column: int)",?:__init__ | ?:parser | L5:compiler_parser | ?:test_m20_parser,__init__ | super,,pure,no,5,,Internal Helper,high,dunder method
policies,L5,validator,PolicyValidator.__init__,"__init__(allowed_metrics: set[str] | None, custom_rules: list[Callable[[PolicyAST], list[ValidationIssue]]] | None) -> None",?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,,__future__ | ast,pure,no,15,Initialize validator.,Internal Helper,high,dunder method
policies,L5,validator,PolicyValidator._check_warnings,_check_warnings(policy: PolicyAST) -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,ValidationIssue | append | is_block_action | is_require_approval_action,__future__ | ast,pure,no,28,Check for non-blocking issues (warnings).,Internal Helper,medium,private function
policies,L5,validator,PolicyValidator._extract_metrics,_extract_metrics(condition: Condition) -> list[str],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,_extract_metrics | append | extend | is_exists_predicate | is_logical_condition | is_predicate,__future__ | ast,pure,no,13,Extract all metric names from a condition.,Internal Helper,medium,private function
policies,L5,validator,PolicyValidator._validate_metrics,_validate_metrics(policy: PolicyAST) -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,ValidationIssue | _extract_metrics | append | enumerate,__future__ | ast,pure,no,23,Validate that all metrics are in the allowed set (if provided).,Internal Helper,medium,private function
policies,L5,validator,PolicyValidator._validate_mode_enforcement,_validate_mode_enforcement(policy: PolicyAST) -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,ValidationIssue | append | enumerate | is_block_action | is_require_approval_action,__future__ | ast,pure,no,36,Validate that actions match the policy mode.,Internal Helper,medium,private function
policies,L5,validator,PolicyValidator._validate_structure,_validate_structure(policy: PolicyAST) -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,ValidationIssue | append | enumerate,__future__ | ast,pure,no,30,Validate structural integrity (defense in depth).,Internal Helper,medium,private function
policies,L5,validator,PolicyValidator.validate,validate(policy: PolicyAST) -> ValidationResult,?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,ValidationResult | _check_warnings | _validate_metrics | _validate_mode_enforcement | _validate_structure | extend | rule | tuple,__future__ | ast,pure,no,20,Validate a policy AST.,Policy/Decision,medium,name matches 'validate'
policies,L5,validator,ValidationIssue.__str__,__str__() -> str,?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,,__future__ | ast,pure,no,3,,Internal Helper,high,dunder method
policies,L5,validator,ValidationResult.__bool__,__bool__() -> bool,?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,,__future__ | ast,pure,no,3,ValidationResult is truthy if valid.,Internal Helper,high,dunder method
policies,L5,validator,ValidationResult.__post_init__,__post_init__() -> None,?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,__setattr__ | any,__future__ | ast,pure,no,4,,Internal Helper,high,dunder method
policies,L5,validator,ValidationResult.errors,errors() -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,,__future__ | ast,pure,no,3,Return only ERROR severity issues.,Unclassified,low,no classification rules matched
policies,L5,validator,ValidationResult.warnings,warnings() -> list[ValidationIssue],?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,,__future__ | ast,pure,no,3,Return only WARNING severity issues.,Unclassified,low,no classification rules matched
policies,L5,validator,is_valid,"is_valid(policy: PolicyAST, allowed_metrics: set[str] | None) -> bool",?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,validate,__future__ | ast,pure,no,16,Quick check if a policy is valid.,Policy/Decision,medium,name matches 'is_valid'
policies,L5,validator,validate,"validate(policy: PolicyAST, allowed_metrics: set[str] | None) -> ValidationResult",?:__init__ | ?:service | ?:test_validator | ?:test_roundtrip,PolicyValidator | validate,__future__ | ast,pure,no,33,Validate a policy AST.,Policy/Decision,medium,name matches 'validate'
policies,L5,visitors,BaseVisitor.visit_action_block,visit_action_block(node: ActionBlockNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_attr_access,visit_attr_access(node: AttrAccessNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_binary_op,visit_binary_op(node: BinaryOpNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,5,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_condition_block,visit_condition_block(node: ConditionBlockNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,5,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_func_call,visit_func_call(node: FuncCallNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,5,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_ident,visit_ident(node: IdentNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_import,visit_import(node: ImportNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_literal,visit_literal(node: LiteralNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_policy_decl,visit_policy_decl(node: PolicyDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_priority,visit_priority(node: PriorityNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_program,visit_program(node: ProgramNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_route_target,visit_route_target(node: RouteTargetNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_rule_decl,visit_rule_decl(node: RuleDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_rule_ref,visit_rule_ref(node: RuleRefNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,BaseVisitor.visit_unary_op,visit_unary_op(node: UnaryOpNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,accept,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,CategoryCollector.__init__,__init__(),?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,visitors,CategoryCollector.get_categories,"get_categories() -> Dict[PolicyCategory, List[str]]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,CategoryCollector.visit_policy_decl,visit_policy_decl(node: PolicyDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,append | super | visit_policy_decl,grammar | nodes,pure,no,4,,Unclassified,low,no classification rules matched
policies,L5,visitors,CategoryCollector.visit_rule_decl,visit_rule_decl(node: RuleDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,append | super | visit_rule_decl,grammar | nodes,pure,no,7,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.__init__,__init__(),?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L5,visitors,PrintVisitor._emit,_emit(text: str) -> None,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,append,grammar | nodes,pure,no,2,,Internal Helper,medium,private function
policies,L5,visitors,PrintVisitor.get_output,get_output() -> str,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,join,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_action_block,visit_action_block(node: ActionBlockNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,3,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_attr_access,visit_attr_access(node: AttrAccessNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,6,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_binary_op,visit_binary_op(node: BinaryOpNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,8,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_condition_block,visit_condition_block(node: ConditionBlockNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,11,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_func_call,visit_func_call(node: FuncCallNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,10,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_ident,visit_ident(node: IdentNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_import,visit_import(node: ImportNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_literal,visit_literal(node: LiteralNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_policy_decl,visit_policy_decl(node: PolicyDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,6,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_priority,visit_priority(node: PriorityNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_program,visit_program(node: ProgramNode) -> str,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept | get_output,grammar | nodes,pure,no,7,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_route_target,visit_route_target(node: RouteTargetNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_rule_decl,visit_rule_decl(node: RuleDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,6,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_rule_ref,visit_rule_ref(node: RuleRefNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,PrintVisitor.visit_unary_op,visit_unary_op(node: UnaryOpNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,_emit | accept,grammar | nodes,pure,no,6,,Unclassified,low,no classification rules matched
policies,L5,visitors,RuleExtractor.__init__,__init__(),?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,4,,Internal Helper,high,dunder method
policies,L5,visitors,RuleExtractor.get_rules,"get_rules() -> Dict[str, Dict[str, Any]]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,,grammar | nodes,pure,no,2,,Unclassified,low,no classification rules matched
policies,L5,visitors,RuleExtractor.visit_condition_block,visit_condition_block(node: ConditionBlockNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,append | super | visit_condition_block,grammar | nodes,pure,no,11,,Unclassified,low,no classification rules matched
policies,L5,visitors,RuleExtractor.visit_policy_decl,visit_policy_decl(node: PolicyDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,super | visit_policy_decl,grammar | nodes,pure,no,14,,Unclassified,low,no classification rules matched
policies,L5,visitors,RuleExtractor.visit_rule_decl,visit_rule_decl(node: RuleDeclNode) -> Any,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_parser,append | super | visit_rule_decl,grammar | nodes,pure,no,16,,Unclassified,low,no classification rules matched
policies,L5,worker_execution_command,calculate_cost_cents,"calculate_cost_cents(model: str, input_tokens: int, output_tokens: int) -> int",L3:workers_adapter | L5:workers_adapter | ?:__init__,calculate_llm_cost_cents,brand | runner | worker,pure,no,20,Calculate LLM cost in cents.,Unclassified,low,no classification rules matched
policies,L5,worker_execution_command,convert_brand_request,convert_brand_request(brand_req) -> Any,L3:workers_adapter | L5:workers_adapter | ?:__init__,AudienceSegment | BrandSchema | ForbiddenClaim | ToneLevel | ToneRule | VisualIdentity | append | get_brand_schema_types,brand | runner | worker,pure,no,75,Convert API brand request to BrandSchema.,Internal Helper,medium,name matches 'convert'
policies,L5,worker_execution_command,execute_worker,"async execute_worker(task: str, brand: Optional[Any], budget: Optional[int], strict_mode: bool, depth: int, run_id: Optional[str], event_bus: Optional[Any]) -> WorkerExecutionResult",L3:workers_adapter | L5:workers_adapter | ?:__init__,BusinessBuilderWorker | WorkerExecutionResult | getattr | run,brand | runner | worker,pure,yes,67,Execute Business Builder Worker.,Unclassified,low,no classification rules matched
policies,L5,worker_execution_command,get_brand_schema_types,get_brand_schema_types(),L3:workers_adapter | L5:workers_adapter | ?:__init__,,brand | runner | worker,pure,no,26,Get brand schema types from L5.,Unclassified,low,no classification rules matched
policies,L5,worker_execution_command,replay_execution,"async replay_execution(replay_token: str, run_id: str) -> ReplayResult",L3:workers_adapter | L5:workers_adapter | ?:__init__,ReplayResult | replay,brand | runner | worker,pure,yes,37,Replay a previous execution.,Unclassified,low,no classification rules matched
policies,L6,arbitrator,PolicyArbitrator.__init__,__init__(session: Optional[Session]),L7:policy_precedence | ?:test_control_action_enhancements,,db | policy_precedence | sqlmodel,pure,no,8,Initialize policy arbitrator.,Internal Helper,high,dunder method
policies,L6,arbitrator,PolicyArbitrator._get_precedence_map,"_get_precedence_map(session: Session, policy_ids: list[str], tenant_id: str) -> dict[str, PolicyPrecedence]",L7:policy_precedence | ?:test_control_action_enhancements,all | exec | in_ | select | where,db | policy_precedence | sqlmodel,pure,no,13,Get precedence map from database.,Internal Helper,medium,private function
policies,L6,arbitrator,PolicyArbitrator._load_precedence_map,"_load_precedence_map(policy_ids: list[str], tenant_id: str) -> dict[str, PolicyPrecedence]",L7:policy_precedence | ?:test_control_action_enhancements,Session | _get_precedence_map,db | policy_precedence | sqlmodel,pure,no,11,Load precedence for all policies.,Internal Helper,medium,private function
policies,L6,arbitrator,PolicyArbitrator._resolve_action_conflict,"_resolve_action_conflict(actions: list[PolicyAction], strategy: ConflictStrategy, precedence_map: dict[str, PolicyPrecedence]) -> tuple[str, int]",L7:policy_precedence | ?:test_control_action_enhancements,PolicyPrecedence | get | len | max | sorted,db | policy_precedence | sqlmodel,pure,no,38,Resolve conflicting actions.,Internal Helper,medium,private function
policies,L6,arbitrator,PolicyArbitrator._resolve_limit_conflict,"_resolve_limit_conflict(limits: list[PolicyLimit], strategy: ConflictStrategy, precedence_map: dict[str, PolicyPrecedence]) -> tuple[Optional[float], int]",L7:policy_precedence | ?:test_control_action_enhancements,PolicyPrecedence | get | len | min | sorted,db | policy_precedence | sqlmodel,pure,no,38,Resolve conflicting limits.,Internal Helper,medium,private function
policies,L6,arbitrator,PolicyArbitrator.arbitrate,"arbitrate(policy_ids: list[str], tenant_id: str, arb_input: Optional[ArbitrationInput]) -> ArbitrationResult",L7:policy_precedence | ?:test_control_action_enhancements,ArbitrationResult | ConflictStrategy | PolicyPrecedence | _load_precedence_map | _resolve_action_conflict | _resolve_limit_conflict | dumps | encode | get | hexdigest | info | int | len | now | sha256,db | policy_precedence | sqlmodel,pure,no,114,Arbitrate between multiple policies.,Persistence/Driver,high,L6 layer = persistence
policies,L6,arbitrator,get_policy_arbitrator,get_policy_arbitrator() -> PolicyArbitrator,L7:policy_precedence | ?:test_control_action_enhancements,PolicyArbitrator,db | policy_precedence | sqlmodel,pure,no,6,Get or create PolicyArbitrator singleton.,Persistence/Driver,high,L6 layer = persistence
policies,L6,optimizer_conflict_resolver,ConflictResolver.__init__,__init__(),,,grammar | ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L6,optimizer_conflict_resolver,ConflictResolver._detect_action_conflicts,_detect_action_conflicts(module: IRModule) -> None,,PolicyConflict | _get_condition_signature | append | get | isinstance | items | keys | len | list | set | values,grammar | ir_nodes,pure,no,41,Detect conflicting actions for same conditions.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._detect_category_conflicts,_detect_category_conflicts(module: IRModule) -> None,,PolicyConflict | _might_override | append | get | items,grammar | ir_nodes,pure,no,35,Detect cross-category interactions that may conflict.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._detect_circular_dependencies,_detect_circular_dependencies(module: IRModule) -> None,,PolicyConflict | add | append | get | has_cycle | insert | isinstance | items | join | remove | set | values,grammar | ir_nodes,db_write,no,47,Detect circular route dependencies.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._detect_priority_conflicts,_detect_priority_conflicts(module: IRModule) -> None,,PolicyConflict | append | items | len,grammar | ir_nodes,pure,no,23,Detect policies with same priority in same category.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._get_actions,_get_actions(func: IRFunction) -> Set[ActionType],,add | isinstance | set | values,grammar | ir_nodes,db_write,no,8,Get all actions in a function.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._get_condition_signature,_get_condition_signature(block: IRBlock) -> str,,append | join | type,grammar | ir_nodes,pure,no,7,Get a signature for the condition pattern in a block.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._might_override,"_might_override(lower: IRFunction, higher: IRFunction) -> bool",,_get_actions,grammar | ir_nodes,pure,no,10,Check if lower-priority policy might override higher one.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._resolve_action_conflict,"_resolve_action_conflict(module: IRModule, conflict: PolicyConflict) -> None",,_get_actions | append | get | get_action_precedence,grammar | ir_nodes,pure,no,22,Resolve action conflict using action precedence.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._resolve_category_conflict,"_resolve_category_conflict(module: IRModule, conflict: PolicyConflict) -> None",,append | get | get_category_priority,grammar | ir_nodes,pure,no,21,Resolve category conflict using category precedence.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._resolve_circular_conflict,"_resolve_circular_conflict(module: IRModule, conflict: PolicyConflict) -> None",,append | float | get | len,grammar | ir_nodes,pure,no,22,Resolve circular routing by breaking the cycle.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._resolve_conflict,"_resolve_conflict(module: IRModule, conflict: PolicyConflict) -> None",,_resolve_action_conflict | _resolve_category_conflict | _resolve_circular_conflict | _resolve_priority_conflict,grammar | ir_nodes,pure,no,14,Resolve a single conflict.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver._resolve_priority_conflict,"_resolve_priority_conflict(module: IRModule, conflict: PolicyConflict) -> None",,append | enumerate | get | sorted,grammar | ir_nodes,pure,no,12,Resolve priority conflict by adjusting priorities.,Internal Helper,medium,private function
policies,L6,optimizer_conflict_resolver,ConflictResolver.resolve,"resolve(module: IRModule) -> Tuple[IRModule, List[PolicyConflict]]",,_detect_action_conflicts | _detect_category_conflicts | _detect_circular_dependencies | _detect_priority_conflicts | _resolve_conflict,grammar | ir_nodes,pure,no,24,Detect and resolve conflicts in module.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve'); Internal Helper(pure function with no callers)
policies,L6,optimizer_conflict_resolver,PolicyConflict.__str__,__str__() -> str,,,grammar | ir_nodes,pure,no,3,,Internal Helper,high,dunder method
policies,L6,policy_engine_driver,PolicyEngineDriver.__init__,__init__(db_url: str),L5:engine,,engine | sqlalchemy,pure,no,4,Initialize with database URL.,Internal Helper,high,dunder method
policies,L6,policy_engine_driver,PolicyEngineDriver._get_engine,_get_engine() -> Engine,L5:engine,create_engine,engine | sqlalchemy,pure,no,5,Lazy-load engine.,Internal Helper,medium,private function
policies,L6,policy_engine_driver,PolicyEngineDriver.activate_version,"activate_version(conn: Connection, version: str) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,22,Activate a specific version.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.cap_temporal_events,"cap_temporal_events(conn: Connection, max_per_policy: int) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,30,Cap events per policy to max limit.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.compact_temporal_events,"compact_temporal_events(conn: Connection, compact_hours: int, retention_hours: int) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,56,Compact old events into hourly aggregates.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.deactivate_all_versions,deactivate_all_versions(conn: Connection) -> None,L5:engine,execute | text,engine | sqlalchemy,pure,no,3,Deactivate all policy versions.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.delete_old_temporal_events,"delete_old_temporal_events(conn: Connection, retention_hours: int) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,23,Delete temporal events older than retention period.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_active_policies_for_integrity,"fetch_active_policies_for_integrity(conn: Connection, table: str, name_col: str) -> List[str]",L5:engine,execute | text,engine | sqlalchemy,pure,no,25,Fetch active policy names for integrity check.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_business_rules,"fetch_business_rules(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,18,Fetch all active business rules.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_conflicts,"fetch_conflicts(conn: Connection, include_resolved: bool, severity_min: Optional[float]) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,28,Fetch policy conflicts.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_current_active_version,"fetch_current_active_version(conn: Connection) -> Optional[Dict[str, Any]]",L5:engine,dict | execute | first | text,engine | sqlalchemy,pure,no,24,Fetch the currently active policy version.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_dependencies,"fetch_dependencies(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,20,Fetch all policy dependencies.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_dependency_edges,"fetch_dependency_edges(conn: Connection, active_only: bool) -> List[Tuple[str, str]]",L5:engine,execute | text,engine | sqlalchemy,pure,no,20,Fetch dependency edges for cycle detection.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_dependency_edges_with_type,"fetch_dependency_edges_with_type(conn: Connection) -> List[Tuple[str, str, str]]",L5:engine,execute | text,engine | sqlalchemy,pure,no,20,Fetch active dependency edges with dependency type for DAG validation.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_ethical_constraints,"fetch_ethical_constraints(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,20,Fetch all active ethical constraints.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_ethical_constraints_for_integrity,"fetch_ethical_constraints_for_integrity(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,20,Fetch ethical constraints for integrity check.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_policy_version_by_id,"fetch_policy_version_by_id(conn: Connection, version_id: str) -> Optional[Dict[str, Any]]",L5:engine,dict | execute | first | text,engine | sqlalchemy,pure,no,26,Fetch a policy version by ID.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_policy_version_by_id_or_version,"fetch_policy_version_by_id_or_version(conn: Connection, version_id: str) -> Optional[Tuple]",L5:engine,execute | first | text,engine | sqlalchemy,pure,no,26,Fetch a policy version by ID or version string.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_policy_versions,"fetch_policy_versions(conn: Connection, include_inactive: bool, limit: int) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,28,Fetch policy versions.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_provenance,"fetch_provenance(conn: Connection, policy_version: Optional[str], limit: int) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,31,Fetch policy provenance records.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_risk_ceilings,"fetch_risk_ceilings(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,19,Fetch all active risk ceilings.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_safety_rules,"fetch_safety_rules(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,19,Fetch all active safety rules.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_metric_sum,"fetch_temporal_metric_sum(conn: Connection, policy_id: str, window_seconds: int) -> float",L5:engine,execute | first | float | text,engine | sqlalchemy,pure,no,27,Fetch sum of temporal metric events in window.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_policies,"fetch_temporal_policies(conn: Connection, metric: Optional[str], include_inactive: bool) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,28,Fetch temporal policies.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_policies_for_integrity,"fetch_temporal_policies_for_integrity(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,20,Fetch temporal policies for integrity check.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_policy_for_utilization,"fetch_temporal_policy_for_utilization(conn: Connection, policy_id: str) -> Optional[Tuple[float, int]]",L5:engine,execute | first | text,engine | sqlalchemy,pure,no,25,Fetch temporal policy max_value and window for utilization check.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_stats,"fetch_temporal_stats(conn: Connection) -> Dict[str, int]",L5:engine,execute | first | text,engine | sqlalchemy,pure,no,20,Fetch temporal event statistics.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_temporal_storage_stats,fetch_temporal_storage_stats(conn: Connection) -> Optional[Tuple],L5:engine,execute | first | text,engine | sqlalchemy,pure,no,26,Fetch comprehensive temporal storage statistics.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_unresolved_conflicts,"fetch_unresolved_conflicts(conn: Connection) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,20,Fetch unresolved conflicts for integrity check.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_version_for_rollback,"fetch_version_for_rollback(conn: Connection, version: str) -> Optional[Dict[str, Any]]",L5:engine,dict | execute | first | text,engine | sqlalchemy,pure,no,27,Fetch version with snapshots for rollback.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_violation_by_id,"fetch_violation_by_id(conn: Connection, violation_id: str) -> Optional[Dict[str, Any]]",L5:engine,dict | execute | first | text,engine | sqlalchemy,pure,no,28,Fetch a single violation by ID.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.fetch_violations,"fetch_violations(conn: Connection, violation_type: Optional[str], agent_id: Optional[str], tenant_id: Optional[str], severity_min: Optional[float], since: Optional[datetime], limit: int) -> List[Dict[str, Any]]",L5:engine,dict | execute | text,engine | sqlalchemy,pure,no,55,Fetch violations with optional filters.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_dependency,"insert_dependency(conn: Connection, source_policy: str, target_policy: str, dependency_type: str, resolution_strategy: str, priority: int, description: str) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,39,Insert a policy dependency.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_evaluation,"insert_evaluation(conn: Connection, evaluation_id: str, action_type: str, agent_id: Optional[str], tenant_id: Optional[str], request_context: str, decision: str, decision_reason: str, modifications: str, evaluation_ms: float, policies_checked: int, rules_matched: int, evaluated_at: datetime) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,65,Insert policy evaluation record.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_policy_version,"insert_policy_version(conn: Connection, version_id: str, version: str, policy_hash: str, created_by: str, description: str) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,36,Insert a new policy version.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_provenance,"insert_provenance(conn: Connection, policy_id: str, policy_type: str, action: str, changed_by: str, policy_version: str, reason: str) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,39,Insert provenance record.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_temporal_policy,"insert_temporal_policy(conn: Connection, name: str, description: Optional[str], temporal_type: str, metric: str, max_value: float, window_seconds: int, breach_action: str, cooldown_on_breach: int) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,47,Insert a temporal policy.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.insert_violation,"insert_violation(conn: Connection, violation_id: str, evaluation_id: str, policy_name: str, violation_type: str, severity: str, description: str, evidence: str, agent_id: Optional[str], tenant_id: Optional[str], action_attempted: str, routed_to_governor: bool, governor_action: Optional[str], detected_at: datetime) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,68,Insert policy violation record.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.mark_version_rolled_back,"mark_version_rolled_back(conn: Connection, by: str) -> None",L5:engine,execute | text,engine | sqlalchemy,pure,no,22,Mark current active version as rolled back.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.reset_risk_ceiling,"reset_risk_ceiling(conn: Connection, ceiling_id: str) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,26,Reset a risk ceiling's current value to 0.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.resolve_conflict,"resolve_conflict(conn: Connection, conflict_id: str, resolution: str, resolved_by: str) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,30,Resolve a policy conflict.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
policies,L6,policy_engine_driver,PolicyEngineDriver.update_risk_ceiling,"update_risk_ceiling(conn: Connection, ceiling_id: str, updates: Dict[str, Any]) -> None",L5:engine,append | execute | items | join | text,engine | sqlalchemy,pure,no,32,Update a risk ceiling.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.update_safety_rule,"update_safety_rule(conn: Connection, rule_id: str, updates: Dict[str, Any]) -> None",L5:engine,append | execute | items | join | text,engine | sqlalchemy,pure,no,38,Update a safety rule.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,PolicyEngineDriver.update_violation_acknowledged,"update_violation_acknowledged(conn: Connection, violation_id: str, notes: Optional[str]) -> int",L5:engine,execute | text,engine | sqlalchemy,pure,no,29,Acknowledge a violation.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_engine_driver,get_policy_engine_driver,get_policy_engine_driver(db_url: str) -> PolicyEngineDriver,L5:engine,PolicyEngineDriver,engine | sqlalchemy,pure,no,3,Factory function for PolicyEngineDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_graph_driver,PolicyGraphDriver.__init__,__init__(session: AsyncSession),L5:policy_graph_engine,,asyncio | sqlalchemy,pure,no,3,Initialize driver with async session.,Internal Helper,high,dunder method
policies,L6,policy_graph_driver,PolicyGraphDriver.fetch_active_limits,"async fetch_active_limits(tenant_id: str) -> list[dict[str, Any]]",L5:policy_graph_engine,execute | fetchall | str | text,asyncio | sqlalchemy,db_write,yes,33,Fetch all active limits for a tenant.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_graph_driver,PolicyGraphDriver.fetch_active_policies,"async fetch_active_policies(tenant_id: str) -> list[dict[str, Any]]",L5:policy_graph_engine,execute | fetchall | str | text,asyncio | sqlalchemy,db_write,yes,37,Fetch all active policies for a tenant.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_graph_driver,PolicyGraphDriver.fetch_all_limits,"async fetch_all_limits(tenant_id: str) -> list[dict[str, Any]]",L5:policy_graph_engine,execute | fetchall | str | text,asyncio | sqlalchemy,db_write,yes,34,Fetch all limits for a tenant (including inactive).,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_graph_driver,PolicyGraphDriver.fetch_all_policies,"async fetch_all_policies(tenant_id: str) -> list[dict[str, Any]]",L5:policy_graph_engine,execute | fetchall | str | text,asyncio | sqlalchemy,db_write,yes,38,Fetch all policies for a tenant (including inactive).,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_graph_driver,PolicyGraphDriver.fetch_resolved_conflicts,"async fetch_resolved_conflicts() -> set[tuple[str, str]]",L5:policy_graph_engine,execute | fetchall | set | str | text,asyncio | sqlalchemy,db_write,yes,17,Get set of resolved conflict pairs.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
policies,L6,policy_graph_driver,get_policy_graph_driver,get_policy_graph_driver(session: AsyncSession) -> PolicyGraphDriver,L5:policy_graph_engine,PolicyGraphDriver,asyncio | sqlalchemy,pure,no,3,Get a PolicyGraphDriver instance.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:policy_proposal_engine,,asyncio | feedback | policy | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.check_rule_exists,async check_rule_exists(rule_id: str) -> bool,L6:__init__ | L5:policy_proposal_engine,execute | scalar_one_or_none | text,asyncio | feedback | policy | sqlalchemy,db_write,yes,10,Check if a policy rule exists by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'check')
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.count_versions_for_proposal,async count_versions_for_proposal(proposal_id: UUID) -> int,L6:__init__ | L5:policy_proposal_engine,count | execute | scalar | select | select_from | where,asyncio | feedback | policy | sqlalchemy,db_write,yes,11,Count existing versions for a proposal.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.fetch_proposal_by_id,async fetch_proposal_by_id(proposal_id: UUID) -> Optional[dict],L6:__init__ | L5:policy_proposal_engine,execute | getattr | scalar_one_or_none | select | str | where,asyncio | feedback | policy | sqlalchemy,db_write,yes,30,Fetch a proposal by ID. Returns None if not found.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.fetch_proposal_status,async fetch_proposal_status(proposal_id: UUID) -> Optional[str],L6:__init__ | L5:policy_proposal_engine,execute | scalar_one_or_none | select | where,asyncio | feedback | policy | sqlalchemy,db_write,yes,9,Fetch just the status of a proposal.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.fetch_proposals,"async fetch_proposals(tenant_id: Optional[UUID], status: Optional[str], limit: int) -> list[dict]",L6:__init__ | L5:policy_proposal_engine,all | desc | execute | limit | order_by | scalars | select | str | where,asyncio | feedback | policy | sqlalchemy,db_write,yes,35,Fetch proposals with optional filters.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.fetch_rule_by_id,"async fetch_rule_by_id(rule_id: str, tenant_id: str) -> Optional[dict]",L6:__init__ | L5:policy_proposal_engine,execute | fetchone | text,asyncio | feedback | policy | sqlalchemy,db_write,yes,19,Fetch a policy rule by ID with tenant check.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,PolicyProposalReadDriver.fetch_unacknowledged_feedback,"async fetch_unacknowledged_feedback(tenant_id: Optional[UUID], feedback_type: Optional[str]) -> list[dict]",L6:__init__ | L5:policy_proposal_engine,all | execute | scalars | select | str | where,asyncio | feedback | policy | sqlalchemy,db_write,yes,31,Fetch unacknowledged pattern feedback records.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_read_driver,get_policy_proposal_read_driver,get_policy_proposal_read_driver(session: AsyncSession) -> PolicyProposalReadDriver,L6:__init__ | L5:policy_proposal_engine,PolicyProposalReadDriver,asyncio | feedback | policy | sqlalchemy,pure,no,3,Factory function for PolicyProposalReadDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:policy_proposal_engine,,asyncio | policy | sqlalchemy | time,pure,no,2,,Internal Helper,high,dunder method
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.create_policy_rule,"async create_policy_rule(rule_id: str, tenant_id: str, name: str, description: str, rule_type: str, conditions: dict[str, Any], actions: dict[str, Any], source_incident_id: Optional[str], is_synthetic: bool, synthetic_scenario_id: Optional[str]) -> str",L6:__init__ | L5:policy_proposal_engine,dumps | execute | text | utc_now,asyncio | policy | sqlalchemy | time,db_write,yes,67,Create a policy rule from an approved proposal.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.create_proposal,"async create_proposal(tenant_id: str, proposal_name: str, proposal_type: str, rationale: str, proposed_rule: dict[str, Any], triggering_feedback_ids: list[str]) -> str",L6:__init__ | L5:policy_proposal_engine,PolicyProposal | add | flush | str | utc_now,asyncio | policy | sqlalchemy | time,db_write,yes,29,Create a new policy proposal in draft status.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.create_version,"async create_version(proposal_id: UUID, version_number: int, rule_snapshot: dict[str, Any], created_by: str, change_reason: str) -> str",L6:__init__ | L5:policy_proposal_engine,PolicyVersion | add | flush | str | utc_now,asyncio | policy | sqlalchemy | time,db_write,yes,26,Create a policy version snapshot.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.delete_policy_rule,"async delete_policy_rule(rule_id: str, tenant_id: str) -> bool",L6:__init__ | L5:policy_proposal_engine,execute | text,asyncio | policy | sqlalchemy | time,db_write,yes,19,Delete a policy rule.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,PolicyProposalWriteDriver.update_proposal_status,"async update_proposal_status(proposal_id: UUID, new_status: str, reviewed_at: Optional[datetime], reviewed_by: Optional[str], review_notes: Optional[str], effective_from: Optional[datetime]) -> bool",L6:__init__ | L5:policy_proposal_engine,execute | update | values | where,asyncio | policy | sqlalchemy | time,db_write,yes,30,Update a proposal's status and review metadata.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_proposal_write_driver,get_policy_proposal_write_driver,get_policy_proposal_write_driver(session: AsyncSession) -> PolicyProposalWriteDriver,L6:__init__ | L5:policy_proposal_engine,PolicyProposalWriteDriver,asyncio | policy | sqlalchemy | time,pure,no,5,Factory function for PolicyProposalWriteDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_read_driver,PolicyReadDriver.__init__,__init__(session: Session),L6:__init__ | L5:customer_policy_read_engine,,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,3,Initialize with database session.,Internal Helper,high,dunder method
policies,L6,policy_read_driver,PolicyReadDriver._to_guardrail_dto,_to_guardrail_dto(guardrail: DefaultGuardrail) -> GuardrailDTO,L6:__init__ | L5:customer_policy_read_engine,GuardrailDTO,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,11,Transform ORM model to DTO.,Internal Helper,medium,private function
policies,L6,policy_read_driver,PolicyReadDriver.get_guardrail_by_id,get_guardrail_by_id(guardrail_id: str) -> Optional[GuardrailDTO],L6:__init__ | L5:customer_policy_read_engine,_to_guardrail_dto | exec | first | select | where,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,20,Get a single guardrail by ID.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'guard')
policies,L6,policy_read_driver,PolicyReadDriver.get_tenant_budget_settings,get_tenant_budget_settings(tenant_id: str) -> Optional[TenantBudgetDataDTO],L6:__init__ | L5:customer_policy_read_engine,TenantBudgetDataDTO | exec | first | getattr | select | where,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,30,Get raw tenant budget settings.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_read_driver,PolicyReadDriver.get_usage_sum_since,"get_usage_sum_since(tenant_id: str, since: datetime) -> UsageSumDTO",L6:__init__ | L5:customer_policy_read_engine,UsageSumDTO | and_ | coalesce | exec | first | int | select | sum | where,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,25,Get total usage in cents since a given time.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_read_driver,PolicyReadDriver.list_all_guardrails,list_all_guardrails() -> List[GuardrailDTO],L6:__init__ | L5:customer_policy_read_engine,_to_guardrail_dto | exec | list | order_by | select,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,11,List all guardrails ordered by priority.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Policy/Decision(name matches 'guard')
policies,L6,policy_read_driver,get_policy_read_driver,get_policy_read_driver(session: Session) -> PolicyReadDriver,L6:__init__ | L5:customer_policy_read_engine,PolicyReadDriver,killswitch | pydantic | sqlalchemy | sqlmodel | tenant,pure,no,11,Get PolicyReadDriver instance.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_driver,PolicyRulesDriver.__init__,__init__(session: AsyncSession),L5:policy_rules_engine,,asyncio | policy_control_plane | sqlalchemy,pure,no,2,,Internal Helper,high,dunder method
policies,L6,policy_rules_driver,PolicyRulesDriver.add_integrity,add_integrity(integrity: 'PolicyRuleIntegrity') -> None,L5:policy_rules_engine,add,asyncio | policy_control_plane | sqlalchemy,db_write,no,8,Add an integrity record to the session.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_driver,PolicyRulesDriver.add_rule,add_rule(rule: 'PolicyRule') -> None,L5:policy_rules_engine,add,asyncio | policy_control_plane | sqlalchemy,db_write,no,8,Add a rule to the session.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_driver,PolicyRulesDriver.fetch_rule_by_id,"async fetch_rule_by_id(tenant_id: str, rule_id: str) -> Optional['PolicyRule']",L5:policy_rules_engine,execute | scalar_one_or_none | select | where,asyncio | policy_control_plane | sqlalchemy,db_write,yes,23,Fetch a rule by ID with tenant scope.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_driver,PolicyRulesDriver.flush,async flush() -> None,L5:policy_rules_engine,flush,asyncio | policy_control_plane | sqlalchemy,db_write,yes,3,Flush pending changes without committing.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_driver,get_policy_rules_driver,get_policy_rules_driver(session: AsyncSession) -> PolicyRulesDriver,L5:policy_rules_engine,PolicyRulesDriver,asyncio | policy_control_plane | sqlalchemy,pure,no,3,Factory function for PolicyRulesDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_read_driver,PolicyRulesReadDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:policies_rules_query_engine,,asyncio | policy_control_plane | sqlalchemy | time,pure,no,2,,Internal Helper,high,dunder method
policies,L6,policy_rules_read_driver,PolicyRulesReadDriver.count_policy_rules,"async count_policy_rules(tenant_id: str, status: str) -> int",L6:__init__ | L5:policies_rules_query_engine,count | execute | scalar | select | where,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,13,Count policy rules for tenant.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_read_driver,PolicyRulesReadDriver.fetch_policy_rule_by_id,"async fetch_policy_rule_by_id(tenant_id: str, rule_id: str) -> Optional[dict]",L6:__init__ | L5:policies_rules_query_engine,coalesce | count | execute | first | getattr | group_by | join | label | max | outerjoin | select | subquery | timedelta | utc_now | where,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,69,Fetch policy rule detail. Returns None if not found.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_read_driver,PolicyRulesReadDriver.fetch_policy_rules,"async fetch_policy_rules(tenant_id: str) -> tuple[list[dict], int]",L6:__init__ | L5:policies_rules_query_engine,all | and_ | coalesce | count | desc | dict | execute | group_by | join | label | limit | max | nullslast | offset | order_by,asyncio | policy_control_plane | sqlalchemy | time,db_write,yes,117,Fetch policy rules with filters and pagination.,Persistence/Driver,high,L6 layer = persistence
policies,L6,policy_rules_read_driver,get_policy_rules_read_driver,get_policy_rules_read_driver(session: AsyncSession) -> PolicyRulesReadDriver,L6:__init__ | L5:policies_rules_query_engine,PolicyRulesReadDriver,asyncio | policy_control_plane | sqlalchemy | time,pure,no,3,Factory function for PolicyRulesReadDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,proposals_read_driver,ProposalsReadDriver.__init__,__init__(session: AsyncSession),L6:__init__ | L5:policies_proposals_query_engine,,asyncio | policy | sqlalchemy | time,pure,no,2,,Internal Helper,high,dunder method
policies,L6,proposals_read_driver,ProposalsReadDriver.count_draft_proposals,async count_draft_proposals(tenant_id: str) -> int,L6:__init__ | L5:policies_proposals_query_engine,and_ | count | execute | is_ | scalar | select | select_from | where,asyncio | policy | sqlalchemy | time,db_write,yes,18,Count draft proposals (for badge display).,Persistence/Driver,high,L6 layer = persistence
policies,L6,proposals_read_driver,ProposalsReadDriver.fetch_proposal_by_id,"async fetch_proposal_by_id(tenant_id: str, proposal_id: str) -> Optional[dict]",L6:__init__ | L5:policies_proposals_query_engine,and_ | execute | isinstance | len | now | replace | scalar_one_or_none | select | str | where,asyncio | policy | sqlalchemy | time,db_write,yes,44,Fetch a single proposal by ID. Returns None if not found.,Persistence/Driver,high,L6 layer = persistence
policies,L6,proposals_read_driver,ProposalsReadDriver.fetch_proposals,"async fetch_proposals(tenant_id: str) -> tuple[list[dict], int]",L6:__init__ | L5:policies_proposals_query_engine,all | and_ | append | count | desc | execute | is_ | isinstance | len | limit | now | offset | order_by | replace | scalar,asyncio | policy | sqlalchemy | time,db_write,yes,86,Fetch policy proposals with filters and pagination.,Persistence/Driver,high,L6 layer = persistence
policies,L6,proposals_read_driver,get_proposals_read_driver,get_proposals_read_driver(session: AsyncSession) -> ProposalsReadDriver,L6:__init__ | L5:policies_proposals_query_engine,ProposalsReadDriver,asyncio | policy | sqlalchemy | time,pure,no,3,Factory function for ProposalsReadDriver.,Persistence/Driver,high,L6 layer = persistence
policies,L6,recovery_matcher,RecoveryMatcher.__init__,__init__(session: 'Session'),?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,8,Initialize matcher with required database session.,Internal Helper,high,dunder method
policies,L6,recovery_matcher,RecoveryMatcher._calculate_time_weight,_calculate_time_weight(age_days: float) -> float,?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,exp,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,3,Calculate time decay weight using exponential decay.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._compute_confidence,"_compute_confidence(matches: List[Dict[str, Any]], occurrences: int, has_exact_match: bool) -> Tuple[float, Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,_calculate_time_weight | fromisoformat | get | isinstance | len | max | min | now | replace | round | total_seconds,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,70,Compute confidence score using weighted time-decay algorithm.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._count_occurrences,"_count_occurrences(error_code: str, days: int) -> int",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,execute | scalar | text | warning,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,no,23,Count occurrences of error code in recent history.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._escalate_to_llm,"async _escalate_to_llm(error_code: str, error_message: str, context: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,AsyncClient | get | getenv | group | info | json | loads | post | sanitize_error_message | search | warning,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,external_api,yes,73,Layer 3: LLM reasoning for complex/novel failures.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._find_similar_by_embedding,"async _find_similar_by_embedding(error_message: str, limit: int) -> List[Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,execute | fetchall | float | get_embedding | info | join | len | sanitize_error_message | str | text | warning,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,yes,71,Layer 2: Vector similarity search for similar failures.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._find_similar_failures,"_find_similar_failures(error_code: str, error_signature: str, limit: int) -> List[Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,execute | fetchall | str | text | warning,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,no,45,Find similar failures from history.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._generate_suggestion,"_generate_suggestion(error_code: str, error_message: str, similar_recoveries: List[str]) -> str",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,items | startswith | upper,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,22,Generate recovery suggestion text.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._get_cached_recovery,"_get_cached_recovery(error_signature: str) -> Optional[Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,debug | from_url | get | getenv | loads,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,25,Layer 1: Check in-memory/Redis cache for recovery suggestion.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._normalize_error,"_normalize_error(payload: Dict[str, Any]) -> Tuple[str, str]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,encode | get | hexdigest | lower | sanitize_error_message | sha256 | str | strip,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,21,Normalize failure payload for matching.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._set_cached_recovery,"_set_cached_recovery(error_signature: str, recovery: Dict[str, Any]) -> None",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,debug | dumps | from_url | getenv | setex,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,14,Store recovery suggestion in cache.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher._upsert_candidate,"_upsert_candidate(failure_match_id: str, suggestion: str, confidence: float, explain: Dict[str, Any], error_code: str, error_signature: str, matched_entry: Optional[Dict[str, Any]], source: str) -> int",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,dumps | execute | fetchone | int | scalar | text,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,no,94,Upsert recovery candidate with occurrence counting.,Internal Helper,medium,private function
policies,L6,recovery_matcher,RecoveryMatcher.approve_candidate,"approve_candidate(candidate_id: int, approved_by: str, decision: str, note: str) -> Dict[str, Any]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,ValueError | execute | fetchone | isinstance | isoformat | loads | str | text,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,no,113,Approve or reject a recovery candidate.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_matcher,RecoveryMatcher.get_candidates,"get_candidates(status: str, limit: int, offset: int) -> List[Dict[str, Any]]",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,execute | fetchall | isinstance | isoformat | loads | str | text,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,db_write,no,58,List recovery candidates by status.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_matcher,RecoveryMatcher.suggest,"suggest(request: Dict[str, Any]) -> MatchResult",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,MatchResult | _compute_confidence | _count_occurrences | _find_similar_failures | _generate_suggestion | _normalize_error | _upsert_candidate | error | get | info | str,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,no,84,Generate recovery suggestion for a failure.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_matcher,RecoveryMatcher.suggest_hybrid,"async suggest_hybrid(request: Dict[str, Any]) -> MatchResult",?:recovery | ?:workers | ?:worker | ?:recovery_matcher | ?:__init__ | ?:recovery_evaluation_engine | L5:recovery_evaluation_engine | L2:recovery | L2:workers | ?:check_priority5_intent,MatchResult | _escalate_to_llm | _find_similar_by_embedding | _get_cached_recovery | _normalize_error | _set_cached_recovery | get | info | min | str | suggest,httpx | infra | redis | sanitize | sqlalchemy | sqlmodel | vector_store,pure,yes,107,Hybrid ML recovery suggestion using 3-layer lookup.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_write_driver,RecoveryWriteService.__init__,__init__(session: Session),L2:recovery | L2:recovery_ingest,,infra | sqlalchemy | sqlmodel,pure,no,2,,Internal Helper,high,dunder method
policies,L6,recovery_write_driver,RecoveryWriteService.enqueue_evaluation_db_fallback,"enqueue_evaluation_db_fallback(candidate_id: int, idempotency_key: str) -> bool",L2:recovery | L2:recovery_ingest,execute | text,infra | sqlalchemy | sqlmodel,db_write,no,34,Enqueue evaluation to DB fallback via stored function.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_write_driver,RecoveryWriteService.get_candidate_by_idempotency_key,"get_candidate_by_idempotency_key(idempotency_key: str) -> Optional[Tuple[int, str]]",L2:recovery | L2:recovery_ingest,execute | fetchone | str | text,infra | sqlalchemy | sqlmodel,db_write,no,24,Get candidate by idempotency key (for conflict handling).,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_write_driver,RecoveryWriteService.insert_suggestion_provenance,"insert_suggestion_provenance(suggestion_id: int, event_type: str, details_json: str, action_id: Optional[int], confidence_before: float, actor: str) -> None",L2:recovery | L2:recovery_ingest,execute | text,infra | sqlalchemy | sqlmodel,db_write,no,39,Insert provenance record for a suggestion update.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_write_driver,RecoveryWriteService.update_recovery_candidate,"update_recovery_candidate(candidate_id: int, updates: list, params: Dict[str, Any]) -> None",L2:recovery | L2:recovery_ingest,execute | join | text,infra | sqlalchemy | sqlmodel,db_write,no,18,Update recovery candidate with dynamic field list.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,recovery_write_driver,RecoveryWriteService.upsert_recovery_candidate,"upsert_recovery_candidate(failure_match_id: str, suggestion: str, confidence: float, explain_json: str, error_code: str, error_signature: str, source: str, idempotency_key: str) -> Tuple[int, bool, int]",L2:recovery | L2:recovery_ingest,execute | fetchone | text,infra | sqlalchemy | sqlmodel,db_write,no,78,Atomic upsert: INSERT ... ON CONFLICT DO UPDATE RETURNING.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Operation(called by L2 (gap  should route via L4))
policies,L6,scope_resolver,ScopeResolutionResult.to_snapshot,to_snapshot() -> dict,L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,,db | policy_scope | sqlmodel,pure,no,17,Convert to snapshot dict for immutable storage.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Internal Helper(name matches 'to_')
policies,L6,scope_resolver,ScopeResolver.__init__,__init__(session: Optional[Session]),L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,,db | policy_scope | sqlmodel,pure,no,8,Initialize scope resolver.,Internal Helper,high,dunder method
policies,L6,scope_resolver,ScopeResolver._get_scope,"_get_scope(session: Session, policy_id: str, tenant_id: str) -> Optional[PolicyScope]",L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,exec | first | select | where,db | policy_scope | sqlmodel,pure,no,13,Get scope from database.,Internal Helper,medium,private function
policies,L6,scope_resolver,ScopeResolver._load_scopes,"_load_scopes(session: Session, tenant_id: str) -> list[PolicyScope]",L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,all | exec | list | select | where,db | policy_scope | sqlmodel,pure,no,5,Load all scopes for a tenant.,Internal Helper,medium,private function
policies,L6,scope_resolver,ScopeResolver.get_scope_for_policy,"get_scope_for_policy(policy_id: str, tenant_id: str) -> Optional[PolicyScope]",L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,Session | _get_scope,db | policy_scope | sqlmodel,pure,no,20,Get the scope configuration for a specific policy.,Persistence/Driver,high,L6 layer = persistence
policies,L6,scope_resolver,ScopeResolver.matches_scope,"matches_scope(scope: PolicyScope, context: RunContext) -> bool",L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,matches,db | policy_scope | sqlmodel,pure,no,16,Check if a single scope matches the run context.,Persistence/Driver,high,L6 layer = persistence
policies,L6,scope_resolver,ScopeResolver.resolve_applicable_policies,resolve_applicable_policies(context: RunContext) -> ScopeResolutionResult,L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,ScopeResolutionResult | ScopeType | Session | _load_scopes | append | info | isoformat | len | list | matches_scope | now | set,db | policy_scope | sqlmodel,pure,no,76,Resolve all policies that apply to the given run context.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
policies,L6,scope_resolver,get_scope_resolver,get_scope_resolver() -> ScopeResolver,L7:policy_scope | ?:test_export_scope_resolution | ?:test_scope_selector,ScopeResolver,db | policy_scope | sqlmodel,pure,no,6,Get or create ScopeResolver singleton.,Persistence/Driver,ambiguous,multi-match: Persistence/Driver(L6 layer = persistence); Coordinator/Aggregator(name matches 'resolve')
policies,L6,symbol_table,Scope.define,define(symbol: Symbol) -> None,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,ValueError,grammar,pure,no,5,Define a symbol in this scope.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,Scope.get_all_symbols,"get_all_symbols() -> Dict[str, Symbol]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,get_all_symbols | update,grammar,pure,no,7,Get all visible symbols including parent scopes.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,Scope.lookup,"lookup(name: str, local_only: bool) -> Optional[Symbol]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,lookup,grammar,pure,no,16,Look up a symbol by name.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,Scope.lookup_by_category,lookup_by_category(category: PolicyCategory) -> List[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,extend | lookup_by_category | values,grammar,pure,no,6,Get all symbols in a category.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,Symbol.__repr__,__repr__() -> str,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,,grammar,pure,no,3,,Internal Helper,high,dunder method
policies,L6,symbol_table,SymbolTable.__init__,__init__(),?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,Scope | _define_builtins,grammar,pure,no,10,,Internal Helper,high,dunder method
policies,L6,symbol_table,SymbolTable.__str__,__str__() -> str,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,append | join | values,grammar,pure,no,7,,Internal Helper,high,dunder method
policies,L6,symbol_table,SymbolTable._define_builtins,_define_builtins() -> None,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,Symbol | define,grammar,pure,no,29,Define built-in symbols.,Internal Helper,medium,private function
policies,L6,symbol_table,SymbolTable.add_reference,"add_reference(name: str, referenced_from: str) -> None",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,append | lookup,grammar,pure,no,5,Track a reference to a symbol.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.define,define(symbol: Symbol) -> None,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,append | define,grammar,pure,no,9,Define a symbol in current scope.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.enter_scope,"enter_scope(name: str, category: Optional[PolicyCategory]) -> Scope",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,Scope | append,grammar,pure,no,20,Enter a new scope.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.exit_scope,exit_scope() -> Scope,?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,ValueError | len | pop,grammar,pure,no,12,"Exit current scope, returning to parent.",Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.get_policies,get_policies() -> List[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,values,grammar,pure,no,3,Get all policy symbols.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.get_rules,get_rules() -> List[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,extend | values,grammar,pure,no,6,Get all rule symbols.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.get_symbols_by_category,"get_symbols_by_category(category: PolicyCategory, symbol_type: Optional[SymbolType]) -> List[Symbol]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,get | sorted,grammar,pure,no,17,Get all symbols in a category.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.get_unreferenced_symbols,get_unreferenced_symbols() -> List[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,append | values,grammar,pure,no,8,Get symbols that are never referenced (for dead code analysis).,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.lookup,lookup(name: str) -> Optional[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,lookup,grammar,pure,no,3,Look up a symbol by name.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.lookup_policy,lookup_policy(name: str) -> Optional[Symbol],?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,lookup,grammar,pure,no,6,Look up a policy symbol specifically.,Persistence/Driver,high,L6 layer = persistence
policies,L6,symbol_table,SymbolTable.lookup_rule,"lookup_rule(name: str, policy: Optional[str]) -> Optional[Symbol]",?:ir_builder | ?:__init__ | L5:ir_builder | ?:test_m20_ir,lookup | lookup_policy,grammar,pure,no,24,Look up a rule symbol.,Persistence/Driver,high,L6 layer = persistence
