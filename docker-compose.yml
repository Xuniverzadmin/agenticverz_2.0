services:
  db:
    image: postgres:15
    container_name: nova_db
    environment:
      POSTGRES_USER: nova
      POSTGRES_PASSWORD: novapass
      POSTGRES_DB: nova_aos
    ports:
      - "127.0.0.1:5433:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nova -d nova_aos"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  backend:
    build: ./backend
    image: nova_agent_manager
    container_name: nova_agent_manager
    # NOTE: network_mode: host required on this VPS due to systemd-resolved + Tailscale
    # blocking Docker's embedded DNS resolver. See PROJECT_NOTES.md for details.
    # On environments without this issue, remove network_mode and use bridge networking.
    network_mode: host
    depends_on:
      db:
        condition: service_healthy
    volumes:
      # Mount auth module for hot-reload during development
      - ./backend/app/auth:/app/app/auth:ro
    environment:
      # NOTE: Using Neon PostgreSQL (managed, pooled) - M8 migration
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL:-redis://localhost:6379/0}
      AOS_API_KEY: ${AOS_API_KEY}
      # Operator Console Auth (M22 GA Lock)
      AOS_OPERATOR_TOKEN: ${AOS_OPERATOR_TOKEN:-}
      # Clerk Auth (M8)
      CLERK_SECRET_KEY: ${CLERK_SECRET_KEY:-}
      CLERK_ISSUER_URL: ${CLERK_ISSUER_URL:-}
      # SECURITY: Bind to all interfaces - publicly accessible
      HOST: 0.0.0.0
      PORT: "8000"
      # Tenancy (set to false for dev, true for production)
      ENFORCE_TENANCY: "false"
      # LLM Planner Configuration
      PLANNER_BACKEND: anthropic
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      # RBAC Configuration (M5)
      RBAC_ENABLED: ${RBAC_ENABLED:-false}
      RBAC_ENFORCE: ${RBAC_ENFORCE:-false}
      MACHINE_SECRET_TOKEN: ${MACHINE_SECRET_TOKEN:-}
      # Webhook Key Versioning (M5)
      WEBHOOK_KEY_VERSION: ${WEBHOOK_KEY_VERSION:-v1}
      WEBHOOK_KEY_GRACE_VERSIONS: ${WEBHOOK_KEY_GRACE_VERSIONS:-}
      # OIDC Configuration (Clerk - Production)
      OIDC_ISSUER_URL: ${OIDC_ISSUER_URL:-https://suitable-quail-68.clerk.accounts.dev}
      OIDC_JWKS_URL: ${OIDC_JWKS_URL:-https://suitable-quail-68.clerk.accounts.dev/.well-known/jwks.json}
      OIDC_CLIENT_ID: ${OIDC_CLIENT_ID:-aos-backend}
      OIDC_VERIFY_SSL: ${OIDC_VERIFY_SSL:-true}
      # OpenAI Embeddings (M9+)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      EMBEDDING_PROVIDER: ${EMBEDDING_PROVIDER:-openai}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-text-embedding-3-small}
      EMBEDDING_DIMENSIONS: ${EMBEDDING_DIMENSIONS:-1536}
      EMBEDDING_DAILY_QUOTA: ${EMBEDDING_DAILY_QUOTA:-10000}
      # Trace Storage (M8)
      USE_POSTGRES_TRACES: "true"
      # GitHub Integration (M8 - Mismatch Issue Automation)
      GITHUB_TOKEN: ${GITHUB_TOKEN:-}
      GITHUB_REPO: ${GITHUB_REPO:-}
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import httpx; r=httpx.get('http://localhost:8000/health'); exit(0 if r.status_code==200 else 1)\""]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  # Worker service - separate process for run execution
  worker:
    image: nova_agent_manager
    container_name: nova_worker
    network_mode: host
    depends_on:
      db:
        condition: service_healthy
      backend:
        condition: service_healthy
    environment:
      # NOTE: Using Neon PostgreSQL (managed, pooled) - M8 migration
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL:-redis://localhost:6379/0}
      WORKER_CONCURRENCY: "4"
      WORKER_POLL_INTERVAL: "2.0"
      RUN_MAX_ATTEMPTS: "5"
      EVENT_PUBLISHER: logging
      # LLM Planner Configuration
      PLANNER_BACKEND: anthropic
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      # Tenancy (set to false for dev, true for production)
      ENFORCE_TENANCY: "false"
    command: ["python", "-m", "app.worker.pool"]
    restart: unless-stopped

  # PgBouncer for connection pooling (M5)
  pgbouncer:
    image: pgbouncer/pgbouncer:latest
    container_name: nova_pgbouncer
    network_mode: host
    depends_on:
      db:
        condition: service_healthy
    environment:
      DATABASES_HOST: 127.0.0.1
      DATABASES_PORT: "5433"
      DATABASES_USER: nova
      DATABASES_PASSWORD: novapass
      DATABASES_DBNAME: nova_aos
      PGBOUNCER_LISTEN_PORT: "6432"
      PGBOUNCER_POOL_MODE: transaction
      PGBOUNCER_MAX_CLIENT_CONN: "200"
      PGBOUNCER_DEFAULT_POOL_SIZE: "20"
      PGBOUNCER_RESERVE_POOL_SIZE: "5"
      PGBOUNCER_MAX_DB_CONNECTIONS: "50"
      PGBOUNCER_SERVER_IDLE_TIMEOUT: "600"
      PGBOUNCER_QUERY_TIMEOUT: "300"
      PGBOUNCER_AUTH_TYPE: any
    healthcheck:
      test: ["CMD-SHELL", "nc -z 127.0.0.1 6432 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  # Redis for rate limiting and concurrent runs tracking
  # NOTE: Using system Redis (already running on localhost:6379)
  # Uncomment below if you need containerized Redis
  # redis:
  #   image: redis:7-alpine
  #   container_name: nova_redis
  #   ports:
  #     - "127.0.0.1:6379:6379"
  #   volumes:
  #     - redis_data:/data
  #   command: ["redis-server", "--appendonly", "yes", "--maxmemory", "256mb", "--maxmemory-policy", "allkeys-lru"]
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #   restart: unless-stopped

  # Optional NATS service (commented by default; enable only for local dev with care)
  # nats:
  #   image: nats:2.10.3
  #   container_name: nova_nats
  #   ports:
  #     - "127.0.0.1:4222:4222"
  #   command: ["-DV"]
  #   restart: unless-stopped

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: nova_prometheus
    # NOTE: Using host network to scrape backend at localhost:8000
    network_mode: host
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.listen-address=127.0.0.1:9090'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  # Alertmanager for alert notifications
  # Supports two modes:
  #   1. Simple mode (current): uses config.yml directly
  #   2. Secrets mode: uses entrypoint.sh + config.yml.tmpl with Docker secrets
  # To enable secrets mode, uncomment the secrets section and entrypoint below
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: nova_alertmanager
    network_mode: host
    volumes:
      - ./monitoring/alertmanager:/etc/alertmanager:ro
      - alertmanager_data:/alertmanager
    # Uncomment for secrets-based config (requires secrets files in ./secrets/)
    # entrypoint: ["/bin/sh", "/etc/alertmanager/entrypoint.sh"]
    # secrets:
    #   - alert_slack_webhook
    #   - alert_smtp_smarthost
    #   - alert_smtp_user
    #   - alert_smtp_pass
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--web.listen-address=127.0.0.1:9093'
    restart: unless-stopped

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:10.2.0
    container_name: nova_grafana
    # NOTE: Using host network for consistency with other services
    network_mode: host
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_HTTP_ADDR=127.0.0.1
      - GF_SERVER_HTTP_PORT=3000
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    restart: unless-stopped

volumes:
  db_data:
  redis_data:
  prometheus_data:
  grafana_data:
  alertmanager_data:

# Uncomment to enable Docker secrets for Alertmanager
# secrets:
#   alert_slack_webhook:
#     file: ./secrets/alert_slack_webhook.txt
#   alert_smtp_smarthost:
#     file: ./secrets/alert_smtp_smarthost.txt
#   alert_smtp_user:
#     file: ./secrets/alert_smtp_user.txt
#   alert_smtp_pass:
#     file: ./secrets/alert_smtp_pass.txt
