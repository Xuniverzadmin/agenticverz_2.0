# AgenticVerz Behavior Library v1
#
# Executable, not prose
# Triggerable from Claude outputs
# Enforceable by validator
# Append-only (institutional learning)
#
# Reference: PIN-201

version: 1
effective: "2025-12-27"
status: ACTIVE

library:
  # =========================================================================
  # BL-BOOT-001: Session Playbook Bootstrap (MANDATORY FIRST)
  # Incident: Session resumed without loading constraints, caused regression
  # Solution: SESSION_PLAYBOOK.yaml as single source of truth
  # Principle: Memory decays. Contracts don't.
  #            Sessions must boot like systems, not humans.
  # =========================================================================
  - id: BL-BOOT-001
    name: Session Playbook Bootstrap
    severity: BLOCKER
    class: session_bootstrap
    priority: 0  # Must be checked before all other rules

    playbook:
      source: docs/playbooks/SESSION_PLAYBOOK.yaml
      version_field: session_playbook_version

    triggers:
      # Triggers on ANY first substantive response in a session
      # Validator checks: if no SESSION_BOOTSTRAP_CONFIRMATION in first response → BLOCK
      first_response: true

    requires:
      sections:
        - SESSION_BOOTSTRAP_CONFIRMATION
      fields:
        - playbook_version
        - loaded_documents
        - restrictions_acknowledged
        - current_phase
      documents:
        # These are loaded from SESSION_PLAYBOOK.yaml mandatory_load
        - CLAUDE_BOOT_CONTRACT.md
        - behavior_library.yaml
        - visibility_contract.yaml
        - LESSONS_ENFORCED.md
        - PIN-199-pb-s1-retry-immutability.md
        - PIN-202-pb-s2-crash-recovery.md
        - PIN-203-pb-s3-controlled-feedback-loops.md
        - PIN-204-pb-s4-policy-evolution-with-provenance.md
        - PIN-205-pb-s5-prediction-without-determinism-loss.md

    forbid:
      - "proceeding without session bootstrap"
      - "skipping playbook load"
      - "assuming constraints are loaded"
      - "partial document loading"
      - "work before bootstrap confirmation"

    evidence:
      required_fields:
        - playbook_version
        - loaded_documents_count
        - all_documents_loaded
        - restrictions_acknowledged
        - current_phase

    validator:
      script: scripts/ops/session_bootstrap_validator.py
      playbook: docs/playbooks/SESSION_PLAYBOOK.yaml

    message_on_fail: >
      BL-BOOT-001 VIOLATION: Session bootstrap required.

      Your first response must be SESSION_BOOTSTRAP_CONFIRMATION.

      Required format:
        SESSION_BOOTSTRAP_CONFIRMATION
        - playbook_version: 1.0
        - loaded_documents:
          - CLAUDE_BOOT_CONTRACT.md
          - behavior_library.yaml
          - visibility_contract.yaml
          - LESSONS_ENFORCED.md
          - [all Phase B frozen PINs]
        - restrictions_acknowledged: YES
        - current_phase: [A/B/C]

      No work is allowed until bootstrap is complete.
      Memory decays. Contracts don't.
      Sessions must boot like systems, not humans.

  # =========================================================================
  # BL-DEPLOY-001: Deploy After Rebuild (MANDATORY)
  # Incident: Code rebuilt but not deployed, user could not see/test changes
  # Principle: Build without deploy = invisible work = wasted time
  # =========================================================================
  - id: BL-DEPLOY-001
    name: Deploy After Rebuild
    severity: BLOCKER
    class: deployment_discipline

    triggers:
      any_of:
        - keyword: "npm run build"
        - keyword: "npm build"
        - keyword: "vite build"
        - keyword: "docker compose up -d --build"
        - keyword: "docker compose build"
        - pattern: "built in \\d+\\.\\d+s"
        - pattern: "Build complete"

    requires:
      sections:
        - DEPLOYMENT_CONFIRMATION
      commands_frontend:
        - "npm run build"
        - "cp -r dist/* dist-preflight/"
        - "sudo systemctl reload apache2"
      commands_backend:
        - "docker compose up -d --build backend"
        - "docker compose ps (verify healthy)"

    forbid:
      - "build without deploy"
      - "rebuild complete (without deploy step)"
      - "assuming user can see changes after build"

    evidence:
      required_fields:
        - build_type: "frontend | backend | both"
        - deploy_command_run: "YES"
        - service_healthy: "YES"

    deployment_commands:
      frontend:
        build: "cd /root/agenticverz2.0/website/app-shell && npm run build"
        deploy: "cp -r dist/* dist-preflight/ && sudo systemctl reload apache2"
      backend:
        build_and_deploy: "docker compose up -d --build backend"
        verify: "docker compose ps"

    message_on_fail: >
      BL-DEPLOY-001 VIOLATION: Build completed but not deployed.

      After ANY rebuild, you MUST deploy:

      Frontend:
        cp -r dist/* dist-preflight/ && sudo systemctl reload apache2

      Backend:
        docker compose up -d --build backend

      User cannot see/test changes until deployed.
      Build without deploy = invisible work.

  # =========================================================================
  # BL-ENV-001: Runtime Sync Before Test
  # Incident: Tested endpoint with stale container, wasted 2+ hours debugging
  # =========================================================================
  - id: BL-ENV-001
    name: Runtime Sync Before Test
    severity: BLOCKER
    class: environment_drift

    triggers:
      any_of:
        - keyword: "curl http://"
        - keyword: "curl localhost"
        - keyword: "curl 127.0.0.1"
        - keyword: "POST /admin/"
        - keyword: "test endpoint"
        - keyword: "testing endpoint"
        - file_glob: "backend/app/*.py"

    requires:
      sections:
        - RUNTIME_SYNC
      commands:
        - "docker compose config --services"
        - "docker compose up -d --build <service>"
        - "health check == healthy"

    forbid:
      - "testing before runtime sync"
      - "assuming container is current"
      - "ignoring health check"

    evidence:
      required_fields:
        - services_enumerated
        - target_service
        - rebuild_command
        - health_status
        - auth_headers_verified

    message_on_fail: >
      BL-ENV-001 VIOLATION: Runtime sync missing.
      Rebuild target service and wait for healthy before testing.

  # =========================================================================
  # BL-AUTH-001: Auth Contract Enumeration
  # Incident: Tested with wrong headers, got 401/403 loops
  # =========================================================================
  - id: BL-AUTH-001
    name: Auth Contract Enumeration
    severity: BLOCKER
    class: auth_mismatch

    triggers:
      any_of:
        - keyword: "/admin/"
        - keyword: "RBAC"
        - keyword: "verify_api_key"
        - keyword: "X-AOS-Key"
        - keyword: "X-Machine-Token"
        - keyword: "401"
        - keyword: "403"
        - keyword: "forbidden"
        - keyword: "unauthorized"

    requires:
      sections:
        - AUTH_CONTRACT
      fields:
        - endpoint
        - required_headers
        - auth_path
        - rbac_policy

    forbid:
      - "testing without knowing auth contract"
      - "guessing auth headers"
      - "assuming headers from other endpoints"

    evidence:
      required_fields:
        - endpoint
        - endpoint_auth
        - rbac_policy
        - required_headers
        - test_command

    message_on_fail: >
      BL-AUTH-001 VIOLATION: Auth contract not enumerated.
      List endpoint auth dependencies, RBAC policy, and required headers.

  # =========================================================================
  # BL-TIME-001: Timestamp Semantics
  # Incident: Used timezone-aware datetime with TIMESTAMP WITHOUT TIME ZONE
  # =========================================================================
  - id: BL-TIME-001
    name: Timestamp Semantics
    severity: BLOCKER
    class: timezone_mismatch

    triggers:
      any_of:
        - keyword: "datetime"
        - keyword: "utc_now"
        - keyword: "datetime.now"
        - keyword: "datetime.utcnow"
        - keyword: "timezone.utc"
        - keyword: "TIMESTAMP WITHOUT TIME ZONE"
        - keyword: "TIMESTAMP WITH TIME ZONE"
        - file_glob: "backend/app/models/*.py"

    requires:
      sections:
        - TIME_SEMANTICS
      fields:
        - column_type
        - datetime_kind

    constraints:
      - when: "TIMESTAMP WITHOUT TIME ZONE"
        require: "naive_utc"
      - when: "TIMESTAMP WITH TIME ZONE"
        require: "aware_utc"

    forbid:
      - "using aware datetime with WITHOUT TIME ZONE"
      - "using naive datetime with WITH TIME ZONE"
      - "mixing datetime semantics"
      - "implicit timezone assumptions"

    evidence:
      required_fields:
        - table
        - column_type
        - python_helper
        - alignment_verified

    message_on_fail: >
      BL-TIME-001 VIOLATION: Timestamp semantics mismatch.
      Declare column type and datetime kind. Match aware/naive to column.

  # =========================================================================
  # BL-DEPLOY-001: Service Name Verification
  # Incident: Used wrong service name in docker compose command
  # =========================================================================
  - id: BL-DEPLOY-001
    name: Service Name Verification
    severity: ERROR
    class: service_name_mismatch

    triggers:
      any_of:
        - keyword: "docker compose up"
        - keyword: "docker compose restart"
        - keyword: "docker compose build"
        - keyword: "docker exec"
        - keyword: "docker logs"

    requires:
      sections:
        - SERVICE_ENUM
      commands:
        - "docker compose config --services"
        - "docker ps --format '{{.Names}}'"

    forbid:
      - "assuming service name equals container name"
      - "using container name in compose commands"
      - "using service name in docker exec"

    evidence:
      required_fields:
        - compose_services
        - running_containers
        - target_service
        - target_container
        - command_uses

    message_on_fail: >
      BL-DEPLOY-001 VIOLATION: Service name not verified.
      Enumerate services before build/run.

  # =========================================================================
  # BL-MIG-001: Migration Head Verification
  # Incident: Created migration with wrong parent, caused multi-head chaos
  # =========================================================================
  - id: BL-MIG-001
    name: Migration Head Verification
    severity: BLOCKER
    class: migration_fork

    triggers:
      any_of:
        - keyword: "alembic revision"
        - keyword: "alembic upgrade"
        - keyword: "op.add_column"
        - keyword: "op.create_table"
        - keyword: "op.drop"
        - keyword: "migration"

    requires:
      sections:
        - MIGRATION_HEAD
      commands:
        - "alembic current"
        - "alembic heads"

    forbid:
      - "creating migration without checking heads"
      - "assuming parent revision"
      - "ignoring multiple heads warning"
      - "running upgrade with multiple heads"

    evidence:
      required_fields:
        - current
        - heads
        - single_head
        - parent_for_new

    message_on_fail: >
      BL-MIG-001 VIOLATION: Migration heads not verified.
      Check current state and verify single head before proceeding.

  # =========================================================================
  # BL-MIG-002: Single Migration Head Enforcement
  # Incident: Migration 051 skipped 049/050, created fork requiring merge
  # =========================================================================
  - id: BL-MIG-002
    name: Single Migration Head Enforcement
    severity: BLOCKER
    class: migration_fork

    triggers:
      any_of:
        - keyword: "alembic revision"
        - keyword: "alembic upgrade"
        - keyword: "down_revision"
        - keyword: "create migration"
        - keyword: "new migration"
        - file_glob: "backend/alembic/versions/*.py"

    requires:
      sections:
        - SINGLE_HEAD_CHECK
      commands:
        - "scripts/ops/check_migration_heads.sh"
        - "alembic heads"
      assertions:
        - "head_count == 1"

    forbid:
      - "creating migration with multiple heads"
      - "skipping revisions in down_revision"
      - "proceeding with migration fork"
      - "ignoring multiple heads"

    evidence:
      required_fields:
        - heads_output
        - head_count
        - single_head_verified
        - script_exit_code

    remediation:
      - "Run: alembic merge heads -m 'merge_description'"
      - "Apply: alembic upgrade head"
      - "Verify: alembic heads (must show single head)"

    allow:
      - when:
          purpose: "merge_heads"
        require:
          - command: "alembic merge"
          - section: MERGE_JUSTIFICATION

    message_on_fail: >
      BL-MIG-002 VIOLATION: Multiple migration heads detected!
      Cannot proceed with migration work until fork is resolved.
      Exception: merge migrations allowed with MERGE_JUSTIFICATION section.

  # =========================================================================
  # BL-TEST-001: Test Execution Prerequisites
  # Incident: Ran tests with unhealthy backend, got false failures
  # =========================================================================
  - id: BL-TEST-001
    name: Test Execution Prerequisites
    severity: BLOCKER
    class: test_prerequisites

    triggers:
      any_of:
        - keyword: "pytest"
        - keyword: "python -m pytest"
        - keyword: "python3 -m pytest"
        - keyword: "run tests"
        - keyword: "test suite"

    requires:
      sections:
        - TEST_PREREQ
      commands:
        - "psql $DATABASE_URL -c 'SELECT 1'"
        - "curl localhost:8000/health"
        - "alembic current"

    forbid:
      - "running tests with unhealthy backend"
      - "running tests with pending migrations"
      - "running tests without database access"
      - "assuming prerequisites are met"

    evidence:
      required_fields:
        - database_accessible
        - backend_healthy
        - migrations_current
        - required_fixtures

    message_on_fail: >
      BL-TEST-001 VIOLATION: Test prerequisites not verified.
      Complete prerequisites before running tests.

  # =========================================================================
  # BL-ACC-001: Acceptance Mode Immutability
  # Incident: Fixed timezone bug mid-PB-S2, mutated scenario under test
  # =========================================================================
  - id: BL-ACC-001
    name: Acceptance Mode Immutability
    severity: BLOCKER
    class: acceptance_violation

    triggers:
      any_of:
        - keyword: "PB-S1"
        - keyword: "PB-S2"
        - keyword: "acceptance"
        - keyword: "acceptance test"
        - keyword: "crash test"
        - keyword: "validation scenario"

    requires:
      sections:
        - ACCEPTANCE_PRECHECK

    forbid:
      - "code modification during acceptance test"
      - "hotfix to proceed"
      - "migration during scenario"
      - "fixing bugs to make test pass"
      - "editing production code mid-test"

    evidence:
      required_fields:
        - scenario_name
        - code_freeze_declared
        - preconditions_verified

    message_on_fail: >
      BL-ACC-001 VIOLATION: Acceptance tests cannot modify code.
      If precondition fails, STOP and report blocker.
      Do not fix-to-proceed. File the blocker and exit.

  # =========================================================================
  # BL-RDY-001: Runtime Readiness Checklist
  # Incident: Mixed local DB with container's Neon DB, FK failures
  # =========================================================================
  - id: BL-RDY-001
    name: Runtime Readiness Checklist
    severity: BLOCKER
    class: environment_drift

    triggers:
      any_of:
        - keyword: "PB-S1"
        - keyword: "PB-S2"
        - keyword: "worker run"
        - keyword: "create run"
        - keyword: "start run"
        - keyword: "POST /api/v1/workers"

    requires:
      sections:
        - RUNTIME_READINESS
      commands:
        - "docker exec <container> env | grep DATABASE"
        - "SELECT id FROM tenants LIMIT 1"
        - "SELECT id FROM worker_registry LIMIT 1"

    forbid:
      - "assuming container uses same DB as local"
      - "inserting without checking tenant exists"
      - "inserting without checking worker_registry"
      - "blind INSERT attempts"

    evidence:
      required_fields:
        - authoritative_db
        - container_db_match
        - tenants_present
        - worker_registry_populated

    message_on_fail: >
      BL-RDY-001 VIOLATION: Runtime readiness not verified.
      Check container DATABASE_URL, verify tenants exist, verify worker_registry populated.
      Do not proceed until all fields are YES.

  # =========================================================================
  # BL-EXEC-001: Execution Topology Awareness
  # Incident: Crashed wrong component (worker instead of backend)
  # =========================================================================
  - id: BL-EXEC-001
    name: Execution Topology Awareness
    severity: BLOCKER
    class: architecture_assumption

    triggers:
      any_of:
        - keyword: "crash"
        - keyword: "SIGKILL"
        - keyword: "docker kill"
        - keyword: "docker stop"
        - keyword: "crash test"
        - keyword: "crash scenario"

    requires:
      sections:
        - EXECUTION_TOPOLOGY
      evidence:
        - code_path_verified
        - async_model_identified

    forbid:
      - "assuming which component executes work"
      - "crashing without verifying executor"
      - "guessing async model"

    evidence:
      required_fields:
        - executor
        - async_model
        - crash_target
        - verification_source

    message_on_fail: >
      BL-EXEC-001 VIOLATION: Execution topology not declared.
      Before crashing anything, identify: executor (backend/worker/external),
      async model (inline/background_task/queue), and crash target.
      Verify by reading code or docker inspect.

  # =========================================================================
  # BL-OBS-001: Observability Completeness Gate
  # Incident: Phase B completed at DB+service layer but NOT at web layer
  # Gap: pattern_feedback, policy_proposals, prediction_events had NO API/UI
  # =========================================================================
  - id: BL-OBS-001
    name: Observability Completeness Gate
    severity: BLOCKER
    class: observability_gap

    triggers:
      any_of:
        - keyword: "pattern_feedback"
        - keyword: "policy_proposals"
        - keyword: "prediction_events"
        - keyword: "PB-S3"
        - keyword: "PB-S4"
        - keyword: "PB-S5"
        - keyword: "scenario complete"
        - keyword: "FROZEN"
        - keyword: "freeze"

    requires:
      sections:
        - WEB_PROPAGATION_CHECK
      assertions:
        - "O1_endpoint == YES"
        - "O2_list_visible == YES"
        - "O3_detail_accessible == YES"
        - "O4_execution_unchanged == YES"

    forbid:
      - "marking scenario complete without API endpoint"
      - "marking scenario complete without UI visibility"
      - "freezing without O1-O4 verification"
      - "data exists but is invisible"
      - "truth exists but cannot be observed"

    evidence:
      required_fields:
        - O1_endpoint
        - O2_list_visible
        - O3_detail_accessible
        - O4_execution_unchanged
        - api_urls
        - ui_route_names

    message_on_fail: >
      BL-OBS-001 VIOLATION: Observability completeness not verified.
      Phase B scenarios require O1-O4 propagation to web pages.
      Data that exists but cannot be observed violates the acceptance contract.
      Cannot mark scenario FROZEN until all O1-O4 checks pass.

  # =========================================================================
  # BL-WEB-001: Web Propagation Contract (Visibility Contract Layer)
  # Purpose: Enforce that all data artifacts have declared visibility
  # Reference: docs/contracts/visibility_contract.yaml
  # Principle: Data existence ≠ Data observability
  # =========================================================================
  - id: BL-WEB-001
    name: Web Propagation Contract
    severity: BLOCKER
    class: visibility_contract

    triggers:
      any_of:
        - keyword: "new table"
        - keyword: "new model"
        - keyword: "CREATE TABLE"
        - keyword: "op.create_table"
        - keyword: "class.*Base"
        - keyword: "__tablename__"
        - keyword: "migration"
        - keyword: "domain model"
        - keyword: "phase artifact"
        - keyword: "new artifact"

    requires:
      sections:
        - WEB_VISIBILITY_CONTRACT_CHECK
      contracts:
        - "visibility_contract.yaml entry exists"
      assertions:
        - "visibility_declared == YES"
        - "O1_through_O4_explicit == YES"
        - "console_visibility_explicit == YES"
        - "api_endpoints_declared == YES"

    forbid:
      - "creating table without visibility declaration"
      - "new artifact without visibility contract entry"
      - "data exists but visibility not declared"
      - "implicit visibility assumptions"
      - "O4 REQUIRED for non-execution data"

    evidence:
      required_fields:
        - artifact_name
        - visibility_contract_entry
        - O1_visibility
        - O2_visibility
        - O3_visibility
        - O4_visibility
        - console_ops
        - console_guard
        - console_founder
        - console_user
        - api_endpoints

    validator:
      script: scripts/ops/visibility_validator.py
      contract_file: docs/contracts/visibility_contract.yaml

    message_on_fail: >
      BL-WEB-001 VIOLATION: Visibility contract not satisfied.
      New data artifact detected without visibility declaration.

      Required action:
      1. Add entry to docs/contracts/visibility_contract.yaml
      2. Declare O1-O4 visibility (REQUIRED/OPTIONAL/FORBIDDEN)
      3. Declare console visibility (ops/guard/founder/user)
      4. Implement required API endpoints
      5. Verify with visibility validator

      Truth anchor: If data exists, its visibility must be contractual - not accidental.

  # =========================================================================
  # BL-QUERY-AUTH-001: Query Authority Required (BLOCKING)
  # Incident: Panels queried backend without authority check, caused 403 noise
  # Root Cause: Four consoles without explicit query authority = 403 factory
  # Solution: query_authority in projection, checked before API call
  # Principle: Query authority is declarative. 403 is truth, not error.
  # Reference: PIN-390, docs/governance/QUERY_AUTHORITY_MODEL.md
  # =========================================================================
  - id: BL-QUERY-AUTH-001
    name: Query Authority Required
    severity: BLOCKER
    class: query_authority
    priority: 5

    triggers:
      # Triggers when working with projection panels or UI data fetching
      patterns:
        - "panel"
        - "query_authority"
        - "canQuery"
        - "403"
        - "permission denied"
        - "API call"
        - "data fetch"

    requires:
      sections:
        - QUERY_AUTHORITY_CHECK
      fields:
        - panel_id
        - authority_level
        - console_kind
        - environment
        - allowed
        - failure_mode

    authority_levels:
      - USER        # Tenant-scoped, customer-safe data
      - SYSTEM      # Engine / control-plane derived data
      - SYNTHETIC   # Test, injected, SDSR-derived data
      - INTERNAL    # Staff-only / governance / debugging (never in projection)

    four_console_matrix:
      customer_preflight:
        USER: true
        SYSTEM: false
        SYNTHETIC: false
        INTERNAL: false
      customer_production:
        USER: true
        SYSTEM: false
        SYNTHETIC: false
        INTERNAL: false
      founder_preflight:
        USER: true
        SYSTEM: true
        SYNTHETIC: true
        INTERNAL: false
      founder_production:
        USER: true
        SYSTEM: true
        SYNTHETIC: false  # SYNTHETIC is NEVER allowed in production
        INTERNAL: false

    forbid:
      - "inferring query authority from endpoint name"
      - "guessing authority from domain placement"
      - "assuming founder has all access"
      - "retrying on 403"
      - "logging 403 as error"
      - "SYNTHETIC in production"
      - "INTERNAL in projection"
      - "API call before authority check"

    evidence:
      required_fields:
        - panel_id
        - authority_level
        - console_kind
        - environment
        - matrix_lookup
        - allowed
        - failure_mode

    validator:
      schema: docs/schemas/query_authority_schema.json
      governance: docs/governance/QUERY_AUTHORITY_MODEL.md

    message_on_fail: |
      BL-QUERY-AUTH-001 VIOLATION: Query authority not satisfied.

      Panel attempted API call without proper authority check.

      Required action:
      1. Verify panel has query_authority in projection
      2. Check authority level: USER, SYSTEM, SYNTHETIC, INTERNAL
      3. Verify allow_in matrix for console × environment
      4. Use canQuery() before any API call
      5. Show appropriate boundary if denied (HIDE, DISABLE, EXPLAIN)

      Key invariants:
      - SYNTHETIC is NEVER allowed in production
      - INTERNAL is never projection-exposed
      - 403 is truth, not error
      - UI must check before calling, not retry after denial

      Reference: PIN-390, docs/governance/QUERY_AUTHORITY_MODEL.md

  # =========================================================================
  # BL-ARCH-001: Architecture Correctness Priority (PRIME DIRECTIVE)
  # Incident: CI-green-but-wrong fixes passed silently, caused auth leaks
  # Solution: Architecture correctness > test pass rate > delivery speed
  # Principle: Red CI with correct design beats green CI with workaround
  # Reference: PIN-410, CLAUDE_AUTHORITY.md Section 12
  # =========================================================================
  - id: BL-ARCH-001
    name: Architecture Correctness Priority
    severity: BLOCKER
    class: architecture_prime
    priority: 1

    triggers:
      any_of:
        - keyword: "workaround"
        - keyword: "quick fix"
        - keyword: "bypass"
        - keyword: "skip validation"
        - keyword: "for now"
        - keyword: "temporarily"
        - keyword: "just make it pass"
        - pattern: "if.*env.*!=.*prod"
        - pattern: "if.*preflight.*bypass"
        - pattern: "if not.*roles.*assign"

    requires:
      sections:
        - ARCHITECTURE_CORRECTNESS_CHECK
      assertions:
        - "workaround_introduced == NO"
        - "invariant_weakened == NO"
        - "authority_flow_unchanged == YES"

    forbid:
      - "green CI with workaround"
      - "patch to make tests pass"
      - "bypass for convenience"
      - "weaken invariant to proceed"
      - "implement then rationalize"
      - "environment-conditional authority"

    evidence:
      required_fields:
        - change_type
        - invariants_affected
        - workaround_introduced
        - design_justified

    message_on_fail: |
      BL-ARCH-001 VIOLATION: Architecture correctness compromised.

      Prime Directive: Architecture correctness > test pass rate > delivery speed

      If forced to choose:
      - RED CI with correct design → ACCEPT
      - GREEN CI with workaround → REJECT

      You must STOP and escalate, not patch.

  # =========================================================================
  # BL-ARCH-002: No Workaround Rules (ABSOLUTE)
  # Incident: Default roles added for convenience, caused privilege escalation
  # Solution: Explicit list of forbidden patterns, hard block
  # Principle: If a test can't pass without workaround, design is incomplete
  # Reference: PIN-410, CLAUDE_AUTHORITY.md Section 12.3
  # =========================================================================
  - id: BL-ARCH-002
    name: No Workaround Rules
    severity: BLOCKER
    class: workaround_prevention
    priority: 2

    triggers:
      any_of:
        - pattern: "if not roles"
        - pattern: "default.*role"
        - pattern: "assign.*role.*convenience"
        - pattern: "bypass.*auth"
        - pattern: "skip.*validation"
        - pattern: "mock.*auth"
        - pattern: "patch.*context"
        - keyword: "publicMetadata.role"
        - keyword: "jwt claims role"

    forbidden_patterns:
      - pattern: "if not roles: assign"
        reason: "Default role assignment is privilege escalation"
      - pattern: "if preflight: bypass"
        reason: "Preflight changes visibility, never authority"
      - pattern: "if env != prod: allow"
        reason: "Environment must not change authority"
      - pattern: "mock_auth_context"
        reason: "Mock authority hides real failures"

    forbid:
      - "adding fallback roles"
      - "skipping aud/iss/exp/nbf verification"
      - "mock contexts to fix tests"
      - "editing tests to accept wrong behavior"
      - "environment flags changing authority"

    message_on_fail: |
      BL-ARCH-002 VIOLATION: Forbidden workaround pattern detected.

      Claude is EXPLICITLY FORBIDDEN from:
      - Adding fallbacks like: if not roles: assign dev role
      - Skipping verification: aud, iss, exp, nbf
      - Introducing mock contexts to "fix tests"
      - Editing tests to accept wrong behavior
      - Using environment flags to change authority

      If a failing test requires any of the above → STOP.

  # =========================================================================
  # BL-ARCH-003: Design-First Enforcement
  # Incident: Code implemented then design rationalized post-hoc
  # Solution: Mandatory design order: invariants → layers → docs → implement
  # Principle: Design precedes implementation, always
  # Reference: PIN-410, CLAUDE_AUTHORITY.md Section 12.5
  # =========================================================================
  - id: BL-ARCH-003
    name: Design-First Enforcement
    severity: BLOCKER
    class: design_discipline
    priority: 3

    requires:
      order:
        - "1. Identify invariant(s)"
        - "2. Validate layer boundaries"
        - "3. Design correct abstraction"
        - "4. Update architecture docs"
        - "5. Implement"
        - "6. Fix tests"

    forbid:
      - "implement then rationalize"
      - "patch tests then backfill design"
      - "code first document later"
      - "assume layer boundaries"

    message_on_fail: |
      BL-ARCH-003 VIOLATION: Design-first order violated.

      Claude must follow this order ALWAYS:
      1. Identify invariant(s)
      2. Validate layer boundaries
      3. Design correct abstraction
      4. Update architecture docs
      5. Implement
      6. Fix tests

  # =========================================================================
  # BL-ARCH-004: Test Integrity Rules
  # Incident: Tests mocked authority, real auth bugs passed silently
  # Solution: Tests must reflect real execution paths, no mocking authority
  # Principle: If test can't pass without workaround, design is incomplete
  # Reference: PIN-410, CLAUDE_AUTHORITY.md Section 12.7
  # =========================================================================
  - id: BL-ARCH-004
    name: Test Integrity Rules
    severity: BLOCKER
    class: test_integrity
    priority: 4

    tests_must:
      - "Reflect real execution paths"
      - "Use real tokens or real providers"
      - "Fail loudly when architecture breaks"

    tests_must_not:
      - "Mock authority"
      - "Patch auth contexts"
      - "Bypass middleware"
      - "Depend on execution order"

    message_on_fail: |
      BL-ARCH-004 VIOLATION: Test integrity compromised.

      Tests MUST:
      - Reflect real execution paths
      - Use real tokens or real providers
      - Fail loudly when architecture breaks

      Tests MUST NOT:
      - Mock authority
      - Patch auth contexts
      - Bypass middleware
      - Depend on execution order

  # =========================================================================
  # BL-ARCH-005: Mandatory Escalation Stop Conditions
  # Incident: Authority flow changed without human approval
  # Solution: Hard stop conditions requiring explicit human decision
  # Principle: Claude must halt and ask, never assume
  # Reference: PIN-410, CLAUDE_AUTHORITY.md Section 12.4
  # =========================================================================
  - id: BL-ARCH-005
    name: Mandatory Escalation Stop Conditions
    severity: BLOCKER
    class: escalation_required
    priority: 0

    stop_conditions:
      - "fix requires changing authority flow"
      - "fix requires adding default permissions"
      - "fix relies on test-only behavior"
      - "fix weakens an invariant"
      - "fix changes security behavior by environment"

    escalation_format: |
      STOP — Architectural decision required.

      Invariant impacted: <INVARIANT_ID>
      Reason workaround is unsafe: <why>
      Proposed correct design change: <design>

    message_on_fail: |
      BL-ARCH-005 VIOLATION: Escalation required but not performed.

      Claude must HALT AND ASK when:
      - Fix requires changing authority flow
      - Fix requires adding default permissions
      - Fix relies on test-only behavior
      - Fix weakens an invariant
      - Fix changes security behavior by environment

      NO IMPLEMENTATION UNTIL APPROVED.

# Section templates for Claude output
section_templates:
  RUNTIME_SYNC: |
    RUNTIME SYNC CHECK
    - Services enumerated: YES / NO
    - Target service: <name>
    - Rebuild command: <command executed>
    - Health status: healthy / unhealthy
    - Auth headers verified: <list>

  AUTH_CONTRACT: |
    AUTH CONTRACT CHECK
    - Endpoint: <path>
    - Endpoint auth: <Depends(...)>
    - RBAC policy: <resource:action>
    - Required headers: <list>
    - Test command: <curl with all headers>

  TIME_SEMANTICS: |
    TIMESTAMP SEMANTICS CHECK
    - Table: <name>
    - Column type: WITH TIME ZONE / WITHOUT TIME ZONE
    - Python helper: datetime.utcnow() / datetime.now(timezone.utc)
    - Alignment verified: YES / NO

  SERVICE_ENUM: |
    DOCKER NAME CHECK
    - Compose services: <list>
    - Running containers: <list>
    - Target service: <name>
    - Target container: <name>
    - Command uses: SERVICE / CONTAINER (correct?)

  MIGRATION_HEAD: |
    MIGRATION HEAD CHECK
    - Current: <revision>
    - Heads: <list>
    - Single head: YES / NO
    - Parent for new migration: <revision>

  SINGLE_HEAD_CHECK: |
    SINGLE HEAD ENFORCEMENT CHECK
    - Script: scripts/ops/check_migration_heads.sh
    - Exit code: 0 (success) / 1 (multiple heads)
    - Heads output: <revision(s)>
    - Head count: <number>
    - Single head verified: YES / NO (BLOCKER if NO)

  MERGE_JUSTIFICATION: |
    MERGE JUSTIFICATION (exception to BL-MIG-002)
    - Reason: resolving existing fork
    - Heads to merge: <list of head revisions>
    - Merge command: alembic merge <heads> -m "<description>"
    - Post-merge verification: alembic heads (must show single)

  TEST_PREREQ: |
    TEST PREREQUISITES CHECK
    - Database accessible: YES / NO
    - Backend healthy: YES / NO
    - Migrations current: YES / NO
    - Required fixtures: <present / missing>

  ACCEPTANCE_PRECHECK: |
    ACCEPTANCE PRECHECK (BL-ACC-001)
    - Scenario: <name>
    - Code freeze: YES (no modifications allowed during test)
    - Migrations allowed: NO (any schema change = STOP)
    - Config changes allowed: NO (any env/config edit = STOP)
    - All preconditions verified: YES / NO
    - If ANY field is not as required: STOP and report blocker

  RUNTIME_READINESS: |
    RUNTIME READINESS (BL-RDY-001)
    - Authoritative DB: <output of: docker exec <backend> env | grep DATABASE_URL>
    - Container DB match: YES / NO (all queries use container's DATABASE_URL)
    - DB connect proof: <output of: psql $DATABASE_URL -c "SELECT 1">
    - Tenants present: YES / NO (query result)
    - Worker registry populated: YES / NO (query result)
    - Required NOT NULL fields known: YES / NO

  EXECUTION_TOPOLOGY: |
    EXECUTION TOPOLOGY (BL-EXEC-001)
    - Executor: backend / worker / external
    - Async model: inline / background_task / queue
    - Crash target: <component to crash>
    - Verified by: <code path or docker inspect>

  SESSION_BOOTSTRAP_CONFIRMATION: |
    SESSION_BOOTSTRAP_CONFIRMATION (BL-BOOT-001)
    - playbook_version: 1.0
    - loaded_documents:
      - CLAUDE_BOOT_CONTRACT.md
      - behavior_library.yaml
      - visibility_contract.yaml
      - LESSONS_ENFORCED.md
      - PIN-199-pb-s1-retry-immutability.md
      - PIN-202-pb-s2-crash-recovery.md
      - PIN-203-pb-s3-controlled-feedback-loops.md
      - PIN-204-pb-s4-policy-evolution-with-provenance.md
      - PIN-205-pb-s5-prediction-without-determinism-loss.md
    - restrictions_acknowledged: YES
    - current_phase: A / B / C

  WEB_PROPAGATION_CHECK: |
    WEB PROPAGATION CHECK (BL-OBS-001)
    - O1 endpoint exists: YES / NO
    - O2 list visible: YES / NO
    - O3 detail view accessible: YES / NO
    - O4 execution pages unchanged: YES
    Evidence:
    - API URLs: <list of GET endpoints>
    - UI route names: <list of frontend routes or "N/A - API only">
    - Curl verification: <command to verify O1-O3>

  WEB_VISIBILITY_CONTRACT_CHECK: |
    WEB VISIBILITY CONTRACT CHECK (BL-WEB-001)
    Artifact: <name>
    Contract entry: docs/contracts/visibility_contract.yaml

    Declared Visibility:
    - O1 (Aggregates/Counters): REQUIRED / OPTIONAL / FORBIDDEN
    - O2 (Lists/Index views):   REQUIRED / OPTIONAL / FORBIDDEN
    - O3 (Detail/Inspect):      REQUIRED / OPTIONAL / FORBIDDEN
    - O4 (Execution/Core):      REQUIRED / OPTIONAL / FORBIDDEN

    Declared Consoles:
    - ops:     REQUIRED / OPTIONAL / FORBIDDEN
    - guard:   REQUIRED / OPTIONAL / FORBIDDEN
    - founder: REQUIRED / OPTIONAL / FORBIDDEN
    - user:    REQUIRED / OPTIONAL / FORBIDDEN

    API Endpoints:
    - <list of required endpoints from contract>

    Verification:
    - Contract entry exists: YES / NO
    - REQUIRED surfaces implemented: YES / NO
    - FORBIDDEN surfaces blocked: YES / NO
    - All assertions pass: YES / NO

    Truth anchor: If data exists, its visibility must be contractual.

  QUERY_AUTHORITY_CHECK: |
    QUERY AUTHORITY CHECK (BL-QUERY-AUTH-001)
    Panel: <panel_id>

    Authority Declaration:
    - Level: USER / SYSTEM / SYNTHETIC / INTERNAL
    - Permissions required: <list>
    - Roles required: <list or "none">

    Console Context:
    - Console kind: customer / founder
    - Environment: preflight / production

    Matrix Lookup:
    - <console>_<environment> + <level> = ALLOWED / DENIED

    Result:
    - Query allowed: YES / NO
    - Failure mode: HIDE / DISABLE / EXPLAIN / N/A
    - API call made: YES / NO (must be NO if denied)

    Invariants verified:
    - SYNTHETIC in production: NO (must be NO)
    - INTERNAL in projection: NO (must be NO)
    - Authority check before API call: YES

    Truth anchor: 403 is truth, not error. Check before call, not after.

  # Section templates for architecture guardrails (BL-ARCH-*)
  ARCHITECTURE_CORRECTNESS_CHECK: |
    ARCHITECTURE CORRECTNESS CHECK (BL-ARCH-001)
    - Change type: <feature / bugfix / refactor>
    - Invariants affected: <list or "none">
    - Workaround introduced: NO (must be NO)
    - Design justified: YES
    - Authority flow unchanged: YES (must be YES)

  ESCALATION_STOP_CHECK: |
    ESCALATION STOP CHECK (BL-ARCH-005)
    - Stop condition detected: <description or "none">
    - Invariant impacted: <INVARIANT_ID or "none">
    - Escalation required: YES / NO
    - Human approval received: YES / NO / PENDING

    If escalation required:
      STOP — Architectural decision required.
      Invariant impacted: <INVARIANT_ID>
      Reason workaround is unsafe: <why>
      Proposed correct design change: <design>
