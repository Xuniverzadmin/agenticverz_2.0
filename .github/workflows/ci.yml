# AOS CI Pipeline
# Runs on every push and PR
# Enforces quality gates before merge
#
# Database Strategy:
# - If NEON_API_KEY + NEON_PROJECT_ID secrets are set: Creates ephemeral Neon branch per run (fully isolated)
# - Otherwise: Falls back to Docker Postgres (for forks/external PRs)

name: CI

on:
  push:
    branches: [main, develop, 'feature/*']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      skip_slow_tests:
        description: 'Skip slow tests'
        required: false
        default: 'false'

env:
  PYTHONPATH: backend

jobs:
  # ============================================================================
  # SETUP: Create ephemeral Neon branch for isolated testing
  # ============================================================================
  setup-neon-branch:
    runs-on: ubuntu-latest
    outputs:
      # Note: database_url cannot be passed as output because GitHub blocks secrets
      # Each job must construct its own connection string using neonctl
      branch_name: ${{ steps.set-outputs.outputs.branch_name }}
      use_neon: ${{ steps.set-outputs.outputs.use_neon }}
    steps:
      - name: Check if Neon secrets are available
        id: check-secrets
        run: |
          if [ -n "${{ secrets.NEON_API_KEY }}" ] && [ -n "${{ secrets.NEON_PROJECT_ID }}" ]; then
            echo "use_neon=true" >> $GITHUB_OUTPUT
            echo "âœ… Neon secrets available - will create ephemeral branch"
          else
            echo "use_neon=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Neon secrets not available - jobs will use Docker Postgres"
          fi

      - name: Setup Neon CLI
        if: steps.check-secrets.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Create ephemeral Neon branch
        if: steps.check-secrets.outputs.use_neon == 'true'
        id: create-branch
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          BRANCH_NAME="ci-${{ github.run_id }}-${{ github.run_attempt }}"
          echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
          echo "Creating Neon branch: $BRANCH_NAME"

          # Create branch from default branch (parent)
          neonctl branches create \
            --project-id ${{ secrets.NEON_PROJECT_ID }} \
            --name "$BRANCH_NAME" \
            --parent "Agenticverz-AOS" \
            --api-key $NEON_API_KEY \
            || {
              # Branch might exist from failed previous run, try to delete and recreate
              echo "Branch creation failed, attempting cleanup..."
              neonctl branches delete "$BRANCH_NAME" \
                --project-id ${{ secrets.NEON_PROJECT_ID }} \
                --api-key $NEON_API_KEY 2>/dev/null || true
              sleep 2
              neonctl branches create \
                --project-id ${{ secrets.NEON_PROJECT_ID }} \
                --name "$BRANCH_NAME" \
                --parent "Agenticverz-AOS" \
                --api-key $NEON_API_KEY
            }

          echo "âœ… Branch created: $BRANCH_NAME"

      - name: Verify Neon branch is ready
        if: steps.check-secrets.outputs.use_neon == 'true'
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          BRANCH_NAME="ci-${{ github.run_id }}-${{ github.run_attempt }}"
          echo "Waiting for branch endpoint to be ready..."
          sleep 5

          # Verify we can get a connection string
          CONN=$(neonctl connection-string "$BRANCH_NAME" \
            --project-id ${{ secrets.NEON_PROJECT_ID }} \
            --api-key $NEON_API_KEY \
            --database-name neondb \
            --role-name neondb_owner 2>&1)

          if [[ ! "$CONN" =~ ^postgresql:// ]]; then
            echo "::error::Failed to get valid connection string"
            exit 1
          fi

          echo "âœ… Branch is ready for connections"

      - name: Set final outputs
        id: set-outputs
        run: |
          USE_NEON="${{ steps.check-secrets.outputs.use_neon }}"

          if [ "$USE_NEON" == "true" ]; then
            echo "branch_name=${{ steps.create-branch.outputs.branch_name }}" >> $GITHUB_OUTPUT
            echo "use_neon=true" >> $GITHUB_OUTPUT
            echo "âœ… Neon ephemeral branch ready: ${{ steps.create-branch.outputs.branch_name }}"
          else
            echo "branch_name=" >> $GITHUB_OUTPUT
            echo "use_neon=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Using Docker PostgreSQL fallback"
          fi

  # ============================================================================
  # RUN MIGRATIONS ONCE (prevents concurrent migration race condition)
  # ============================================================================
  run-migrations:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch]
    if: needs.setup-neon-branch.outputs.use_neon == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          echo "âœ… Configuring Neon connection for migrations"
          BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
          CONN=$(neonctl connection-string "$BRANCH_NAME" \
            --project-id ${{ secrets.NEON_PROJECT_ID }} \
            --api-key $NEON_API_KEY \
            --database-name neondb \
            --role-name neondb_owner)
          if [[ "$CONN" != *"sslmode="* ]]; then
            CONN="${CONN}?sslmode=require"
          fi
          echo "DATABASE_URL=$CONN" >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run Alembic migrations (single source of truth)
        run: |
          cd backend
          echo "=== Running migrations on Neon ephemeral branch ==="
          echo "This is the ONLY job that runs migrations on Neon"
          echo ""
          echo "Current head:"
          alembic current || echo "No migrations applied yet"
          echo ""
          echo "Upgrading to head..."
          alembic upgrade head
          echo ""
          echo "Final state:"
          alembic current
          echo "âœ… Migrations complete"

  # ============================================================================
  # FAST JOBS (No DB required)
  # ============================================================================

  # Migration drift guard - verifies all migrations are committed
  migration-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check for uncommitted migrations
        run: |
          echo "=== Migration Drift Guard ==="
          ALEMBIC_DIR="backend/alembic/versions"

          # Check for uncommitted migration files
          UNCOMMITTED=$(git ls-files --others --exclude-standard "$ALEMBIC_DIR" 2>/dev/null | grep -v "__pycache__" || true)
          MODIFIED=$(git diff --name-only "$ALEMBIC_DIR" 2>/dev/null | grep -v "__pycache__" || true)

          if [[ -n "$UNCOMMITTED" ]]; then
            echo "::error::Uncommitted migration files found!"
            echo "$UNCOMMITTED"
            exit 1
          fi

          if [[ -n "$MODIFIED" ]]; then
            echo "::error::Modified migration files not staged!"
            echo "$MODIFIED"
            exit 1
          fi

          # List committed migrations
          echo "Migration files in repository:"
          ls -1 "$ALEMBIC_DIR"/*.py 2>/dev/null | grep -v "__pycache__" | xargs -I {} basename {} | sort
          echo ""
          echo "OK: All migrations committed"

  # Secret scanning - validate no new secrets introduced
  secrets-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python for detect-secrets
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install detect-secrets
        run: pip install detect-secrets

      - name: Validate secrets baseline exists
        run: |
          if [ ! -f .secrets.baseline ]; then
            echo "::error::Missing .secrets.baseline file"
            echo "Run: detect-secrets scan > .secrets.baseline"
            exit 1
          fi
          echo "âœ… Secrets baseline exists"

      - name: Validate baseline is valid JSON
        run: |
          if ! jq empty .secrets.baseline 2>/dev/null; then
            echo "::error::Invalid JSON in .secrets.baseline"
            exit 1
          fi
          echo "âœ… Baseline is valid JSON"

      - name: Check for new secrets
        run: |
          echo "=== Secret Scanning ==="
          # Scan for new secrets not in baseline
          detect-secrets scan --baseline .secrets.baseline --list-all-plugins > /tmp/new_secrets.json 2>&1 || true

          # Check if any new secrets were found
          if jq -e '.results | length > 0' /tmp/new_secrets.json > /dev/null 2>&1; then
            NEW_COUNT=$(jq '[.results[] | length] | add // 0' /tmp/new_secrets.json)
            if [ "$NEW_COUNT" -gt 0 ]; then
              echo "::error::$NEW_COUNT new potential secret(s) detected!"
              echo ""
              echo "Files with new secrets:"
              jq -r '.results | keys[]' /tmp/new_secrets.json
              echo ""
              echo "To fix:"
              echo "  1. Remove the secrets from code"
              echo "  2. Or if false positive: detect-secrets scan --update .secrets.baseline"
              echo "  3. Then audit: detect-secrets audit .secrets.baseline"
              exit 1
            fi
          fi

          echo "âœ… No new secrets detected"

      - name: Check for unverified secrets in baseline
        run: |
          # Count secrets not marked as verified (is_verified != true)
          UNVERIFIED=$(jq '[.results[][] | select(.is_verified != true)] | length' .secrets.baseline 2>/dev/null || echo "0")

          if [ "$UNVERIFIED" -gt 0 ]; then
            echo "::warning::$UNVERIFIED unverified secret(s) in baseline"
            echo "Files with unverified secrets:"
            jq -r '.results | to_entries[] | select(.value[] | .is_verified != true) | .key' .secrets.baseline | sort -u
            echo ""
            echo "Run: detect-secrets audit .secrets.baseline"
          fi

          # Check for actual secrets (is_secret == true)
          ACTUAL=$(jq '[.results[][] | select(.is_secret == true)] | length' .secrets.baseline 2>/dev/null || echo "0")

          if [ "$ACTUAL" -gt 0 ]; then
            echo "::error::$ACTUAL actual secret(s) marked in baseline - these must be removed!"
            jq -r '.results | to_entries[] | select(.value[] | .is_secret == true) | .key' .secrets.baseline | sort -u
            exit 1
          fi

          echo "âœ… All baseline secrets are verified false positives"

  # M25 Frozen Files Guard - prevents modification of frozen graduation components
  frozen-files-guard:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check for frozen file modifications
        run: |
          echo "=== M25 Frozen Files Guard ==="
          echo "These files are frozen per PIN-140 and require explicit approval to modify."
          echo ""

          # List of frozen files (M25_FROZEN)
          FROZEN_FILES=(
            "backend/app/integrations/events.py"
            "scripts/ops/m25_graduation_delta.py"
            "backend/app/integrations/prevention_contract.py"
          )

          # Check if any frozen files were modified in this PR/push
          MODIFIED_FROZEN=""
          for file in "${FROZEN_FILES[@]}"; do
            if git diff --name-only origin/main...HEAD 2>/dev/null | grep -q "^${file}$"; then
              MODIFIED_FROZEN="${MODIFIED_FROZEN}${file}\n"
            fi
          done

          # Also check direct commit comparison for pushes to main
          if [ -z "$MODIFIED_FROZEN" ]; then
            for file in "${FROZEN_FILES[@]}"; do
              if git diff --name-only HEAD~1 HEAD 2>/dev/null | grep -q "^${file}$"; then
                MODIFIED_FROZEN="${MODIFIED_FROZEN}${file}\n"
              fi
            done
          fi

          if [ -n "$MODIFIED_FROZEN" ]; then
            # Check for override flag in commit message
            COMMIT_MSG=$(git log -1 --pretty=%B)
            if echo "$COMMIT_MSG" | grep -q "M25_REOPEN"; then
              echo "âš ï¸ M25_REOPEN flag detected - frozen file modification allowed"
              echo "Modified frozen files:"
              echo -e "$MODIFIED_FROZEN"
              echo ""
              echo "WARNING: This change invalidates prior M25 graduation evidence."
            else
              echo "::error::Frozen files modified without M25_REOPEN flag!"
              echo ""
              echo "Modified frozen files:"
              echo -e "$MODIFIED_FROZEN"
              echo ""
              echo "These files are frozen per PIN-140 (M25 Complete - Rollback Safe)."
              echo "To modify, add 'M25_REOPEN' to your commit message and get approval."
              exit 1
            fi
          else
            echo "âœ… No frozen files modified"
          fi

  # ============================================================================
  # MYPY TYPE CHECKING (PIN-121 PREV-14) - Non-blocking, tracks regressions
  # ============================================================================
  mypy-check:
    runs-on: ubuntu-latest
    continue-on-error: true  # Non-blocking per PIN-121
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install mypy types-PyYAML types-redis types-requests
          cd backend
          pip install -r requirements.txt

      - name: Run mypy
        id: mypy
        run: |
          echo "=== Mypy Type Checking (PIN-121) ==="
          echo "Baseline: 572 errors (2025-12-22)"
          echo ""

          cd backend
          mypy app/ --ignore-missing-imports --show-error-codes 2>&1 | tee /tmp/mypy-output.txt || true

          ERROR_COUNT=$(grep -c ": error:" /tmp/mypy-output.txt || echo "0")
          echo ""
          echo "Total errors: $ERROR_COUNT"
          echo "error_count=$ERROR_COUNT" >> $GITHUB_OUTPUT

          # Warn if errors increased from baseline
          if [ "$ERROR_COUNT" -gt 600 ]; then
            echo "::warning::Mypy errors increased significantly ($ERROR_COUNT > 600)"
          fi

      - name: Generate mypy summary
        if: always()
        run: |
          echo "## ðŸ” Mypy Type Check (PIN-121)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          ERROR_COUNT="${{ steps.mypy.outputs.error_count }}"
          BASELINE=572
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Current Errors | $ERROR_COUNT |" >> $GITHUB_STEP_SUMMARY
          echo "| Baseline (2025-12-22) | $BASELINE |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "$ERROR_COUNT" -le "$BASELINE" ]; then
            echo "âœ… Type safety maintained or improved" >> $GITHUB_STEP_SUMMARY
          else
            DIFF=$((ERROR_COUNT - BASELINE))
            echo "âš ï¸ $DIFF new type errors introduced" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See PIN-121 for remediation plan." >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # PYRIGHT TYPE CHECKING (Prevention Blueprint) - Catches tuple/arg errors mypy misses
  # ============================================================================
  pyright-check:
    runs-on: ubuntu-latest
    continue-on-error: true  # Non-blocking initially - builds enforcement
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install pyright
          cd backend
          pip install -r requirements.txt

      - name: Run pyright
        id: pyright
        run: |
          echo "=== Pyright Type Checking (Prevention Blueprint) ==="
          echo "Catches: tuple unpacking, wrong arg counts, incompatible overloads"
          echo ""

          cd backend
          pyright app/ --outputjson 2>&1 | tee /tmp/pyright-output.json || true

          # Parse error count
          ERROR_COUNT=$(jq '.summary.errorCount // 0' /tmp/pyright-output.json 2>/dev/null || echo "0")
          WARNING_COUNT=$(jq '.summary.warningCount // 0' /tmp/pyright-output.json 2>/dev/null || echo "0")

          echo ""
          echo "Errors: $ERROR_COUNT"
          echo "Warnings: $WARNING_COUNT"
          echo "error_count=$ERROR_COUNT" >> $GITHUB_OUTPUT
          echo "warning_count=$WARNING_COUNT" >> $GITHUB_OUTPUT

      - name: Generate pyright summary
        if: always()
        run: |
          echo "## ðŸ” Pyright Type Check (Prevention Blueprint)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Errors | ${{ steps.pyright.outputs.error_count }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Warnings | ${{ steps.pyright.outputs.warning_count }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Pyright catches tuple/arg errors that mypy misses." >> $GITHUB_STEP_SUMMARY

  # UI Hygiene Check - blocks merge on stale buttons, orphaned pages, silent mutations
  ui-hygiene:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install console dependencies
        run: |
          cd website/aos-console/console
          npm ci

      - name: Run UI Hygiene Check (CI mode)
        id: hygiene
        run: |
          cd website/aos-console/console
          echo "ðŸ” Running UI Hygiene Check v2.0 (CI mode)"
          echo ""
          echo "CI mode enforces:"
          echo "  - ORPHANED_PAGE â†’ ERROR (dead code blocks build)"
          echo "  - Warning budget cap (regression detection)"
          echo ""

          # Run hygiene check in CI mode
          node scripts/ui-hygiene-check.cjs --ci 2>&1 | tee hygiene-output.txt

          # Capture exit code
          EXIT_CODE=${PIPESTATUS[0]}

          # Extract counts for summary
          ERRORS=$(grep -oP 'Found \K\d+(?= errors)' hygiene-output.txt || echo "0")
          WARNINGS=$(grep -oP 'Found \d+ errors, \K\d+(?= warnings)' hygiene-output.txt || echo "0")

          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT

          exit $EXIT_CODE

      - name: Generate hygiene summary
        if: always()
        run: |
          echo "## ðŸ” UI Hygiene Check" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          ERRORS="${{ steps.hygiene.outputs.errors }}"
          WARNINGS="${{ steps.hygiene.outputs.warnings }}"

          if [ "$ERRORS" == "0" ]; then
            echo "âœ… **No blocking errors**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **$ERRORS blocking errors found**" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Errors | $ERRORS |" >> $GITHUB_STEP_SUMMARY
          echo "| Warnings | $WARNINGS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Budget: 35 warnings max" >> $GITHUB_STEP_SUMMARY

      - name: Upload hygiene report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ui-hygiene-report
          path: |
            website/aos-console/console/hygiene-report.json
            website/aos-console/console/hygiene-output.txt
          if-no-files-found: ignore

  # Fast unit tests (no external deps)
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run unit tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/schemas -v -m "not slow" --maxfail=3

      - name: Run skill tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/skills -v --maxfail=3

  # Determinism certification (critical)
  determinism:
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run replay certification
        run: |
          cd backend
          PYTHONPATH=. pytest tests/workflow/test_replay_certification.py -v

      - name: Run registry snapshot test
        run: |
          cd backend
          PYTHONPATH=. pytest tests/integration/test_registry_snapshot.py -v

  # ============================================================================
  # ðŸ”’ GOLDEN REPLAY GUARD (MANDATORY - BLOCKS MERGE)
  # ============================================================================
  # Run â†’ Replay â†’ Diff artifacts/logs
  # Fail CI if ANY byte differs
  # Protects M4 determinism moat from silent regressions
  golden-replay-guard:
    runs-on: ubuntu-latest
    needs: determinism
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Run Golden Replay Tests (M4, M6, M14, M17, M18, M19)
        run: |
          echo "ðŸ”’ GOLDEN REPLAY GUARD - MANDATORY CHECK"
          echo "Protects determinism moat from silent regressions"
          echo ""
          PYTHONPATH=backend python3 scripts/ops/golden_test.py --json > golden_results.json

          # Parse results and fail on any diff
          FAILED=$(jq '.failed' golden_results.json)
          PASSED=$(jq '.passed' golden_results.json)
          TOTAL=$(jq '.total' golden_results.json)

          echo ""
          echo "Results: $PASSED/$TOTAL passed"

          if [ "$FAILED" -gt 0 ]; then
            echo "::error::ðŸš« GOLDEN REPLAY FAILED - $FAILED test(s) differ from snapshots"
            echo ""
            echo "Diffs detected:"
            jq -r '.results[] | select(.passed == false) | "  - [\(.milestone)] \(.test_name): \(.error)"' golden_results.json
            echo ""
            echo "To update snapshots (if intentional change):"
            echo "  PYTHONPATH=backend python3 scripts/ops/golden_test.py --update"
            exit 1
          fi

          echo "âœ… All golden tests passed - determinism verified"

      - name: Upload golden results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: golden-replay-results
          path: golden_results.json

  # M4: Workflow Engine tests (critical for determinism)
  workflow-engine:
    runs-on: ubuntu-latest
    needs: golden-replay-guard
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run workflow engine smoke tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/workflow/test_engine_smoke.py -v

      - name: Run checkpoint store tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/workflow/test_checkpoint_store.py -v

      - name: Run golden-file pipeline tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/workflow/test_workflow_golden_pipeline.py -v

  # M4: Golden-file replay check (blocks merge on diff)
  workflow-golden-check:
    runs-on: ubuntu-latest
    needs: workflow-engine
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run golden replay verification
        env:
          GOLDEN_SECRET: ${{ secrets.GOLDEN_SECRET }}
        run: |
          cd backend
          PYTHONPATH=. pytest tests/workflow/test_workflow_golden_pipeline.py -v -k "compare"

      - name: Upload golden artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: golden-diff
          path: backend/artifacts/golden-diff/

  # Lint Prometheus rules
  lint-alerts:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Validate Prometheus rules
        run: |
          if [ -f ops/prometheus_rules/alerts.yml ]; then
            echo "Prometheus rules file exists"
          else
            echo "::error::Prometheus rules file missing"
            exit 1
          fi

  # ============================================================================
  # DB-DEPENDENT JOBS (Use ephemeral Neon branch or Docker fallback)
  # ============================================================================

  # Integration tests
  integration:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, determinism]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.determinism.result == 'success'
    services:
      # Docker Postgres - only used when Neon is not available
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      REDIS_URL: redis://localhost:6379/0
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            # Ensure sslmode=require is present
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          alembic upgrade head

      - name: Verify migrations at head (Neon)
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        run: |
          cd backend
          echo "Migrations already run by run-migrations job"
          alembic current

      - name: Run integration tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/test_integration.py -v -m "not slow"

  # M6: CostSim V2 Circuit Breaker tests
  costsim:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, unit-tests]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.unit-tests.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      COSTSIM_DISABLE_FILE: /tmp/aos/costsim_v2_disabled
      COSTSIM_INCIDENT_DIR: /tmp/aos/costsim_incidents
      COSTSIM_ARTIFACTS_DIR: /tmp/aos/costsim_artifacts
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx asyncpg

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          alembic upgrade head

      - name: Run circuit breaker tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/test_circuit_breaker.py -v --tb=long

      - name: Run async circuit breaker tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/test_circuit_breaker_async.py -v

      - name: Run leader election tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/test_leader.py -v

      - name: Run canary tests
        env:
          COSTSIM_V2_SANDBOX: "true"
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/test_canary.py -v

      - name: Run alert worker tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/test_alert_worker.py -v

      - name: Run all costsim tests (comprehensive)
        env:
          COSTSIM_V2_SANDBOX: "true"
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/ -v --tb=short --ignore=tests/costsim/test_integration_real_db.py

  # M6: CostSim Integration Tests with real DB + Alertmanager
  costsim-integration:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, costsim]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.costsim.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      alertmanager:
        image: prom/alertmanager:latest
        ports:
          - 9093:9093
        options: >-
          --health-cmd "wget -q --spider http://localhost:9093/-/healthy || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      ALERTMANAGER_URL: http://localhost:9093
      COSTSIM_V2_SANDBOX: "true"
      COSTSIM_DISABLE_FILE: /tmp/aos/costsim_v2_disabled
      COSTSIM_INCIDENT_DIR: /tmp/aos/costsim_incidents
      COSTSIM_ARTIFACTS_DIR: /tmp/aos/costsim_artifacts
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx asyncpg

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          alembic upgrade head

      - name: Run CB integration tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/ -v --tb=short --ignore=tests/costsim/test_integration_real_db.py

  # M6: CostSim Tests with WireMock
  costsim-wiremock:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, unit-tests]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.unit-tests.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd "pg_isready -U nova -d nova_aos"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      ALERTMANAGER_URL: http://localhost:8080/api/v2/alerts
      COSTSIM_V2_SANDBOX: "true"
      COSTSIM_DISABLE_FILE: /tmp/aos/costsim_v2_disabled
      COSTSIM_INCIDENT_DIR: /tmp/aos/costsim_incidents
      COSTSIM_ARTIFACTS_DIR: /tmp/aos/costsim_artifacts
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx asyncpg

      - name: Start WireMock with mounted mappings
        run: |
          docker run -d --name wiremock \
            -p 8080:8080 \
            -v ${{ github.workspace }}/tools/wiremock/mappings:/home/wiremock/mappings:ro \
            -v ${{ github.workspace }}/tools/wiremock/__files:/home/wiremock/__files:ro \
            wiremock/wiremock:3.3.1 \
            --verbose --global-response-templating

          echo "Waiting for WireMock to start..."
          for i in {1..30}; do
            if curl -sf http://localhost:8080/__admin/health > /dev/null 2>&1; then
              echo "WireMock is ready!"
              break
            fi
            echo "Attempt $i/30..."
            sleep 1
          done

          echo "WireMock mappings loaded:"
          curl -s http://localhost:8080/__admin/mappings | jq '.mappings | length'

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          alembic upgrade head

      - name: Run circuit breaker integration tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/integration/test_circuit_breaker.py -v --tb=short

      - name: Run all costsim tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/costsim/ -v --tb=short --ignore=tests/costsim/test_integration_real_db.py

      - name: Verify WireMock received requests
        run: |
          echo "=== WireMock Request Log ==="
          REQUESTS=$(curl -s http://localhost:8080/__admin/requests)
          echo "$REQUESTS" | jq '.requests | length'

      - name: Cleanup WireMock
        if: always()
        run: docker stop wiremock || true

  # E2E tests (full stack with running server)
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, unit-tests]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.unit-tests.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd "pg_isready -U nova -d nova_aos"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      REDIS_URL: redis://localhost:6379/0
      AOS_API_KEY: ${{ secrets.AOS_API_KEY || 'test-e2e-key' }}
      MEMORY_FAIL_OPEN_OVERRIDE: "true"
      COSTSIM_DISABLE_FILE: /tmp/aos/costsim_v2_disabled
      COSTSIM_INCIDENT_DIR: /tmp/aos/costsim_incidents
      COSTSIM_ARTIFACTS_DIR: /tmp/aos/costsim_artifacts
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -U pip
          pip install -r backend/requirements.txt
          pip install pytest pytest-asyncio httpx asyncpg

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations with rollback test (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          echo "=== Step 1: Upgrade to head ==="
          alembic upgrade head

          echo ""
          echo "=== Step 2: Downgrade to base (rollback test) ==="
          alembic downgrade base || {
            echo "WARNING: Downgrade failed - some migrations may not be reversible"
            echo "Continuing with upgrade-only test..."
          }

          echo ""
          echo "=== Step 3: Re-upgrade to head ==="
          alembic upgrade head

          echo ""
          echo "=== Migration Test Complete ==="
          alembic current

      - name: Verify migrations at head (Neon)
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        run: |
          cd backend
          echo "Migrations already run by run-migrations job"
          alembic current

      - name: Schema audit (drift detection)
        run: |
          cd backend
          echo "Running schema audit to detect drift..."
          PYTHONPATH=. python ../scripts/ops/schema_audit.py || {
            echo "WARNING: Schema audit found issues (non-blocking for now)"
            echo "Review schema_audit.py output above"
          }

      - name: Start application server
        run: |
          cd backend
          nohup python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 > server.log 2>&1 &
          echo "Waiting for server to start..."
          for i in {1..30}; do
            if curl -sf http://localhost:8000/health > /dev/null 2>&1; then
              echo "Server is ready!"
              exit 0
            fi
            if [ $i -eq 15 ]; then
              echo "=== Server startup logs (debugging slow startup) ==="
              cat server.log 2>/dev/null || true
            fi
            echo "Attempt $i/30..."
            sleep 2
          done
          echo "=== Final server logs ==="
          cat server.log 2>/dev/null || true
          echo "Server failed to start"
          exit 1

      - name: Start worker (required for run execution)
        env:
          PYTHONPATH: .
          PYTHONUNBUFFERED: "1"
        run: |
          cd backend
          nohup python -u -m app.worker.pool > worker.log 2>&1 &
          WORKER_PID=$!
          echo "Worker started (PID: $WORKER_PID)"
          echo "WORKER_PID=$WORKER_PID" >> $GITHUB_ENV

          # Wait for worker to fully initialize (look for poll loop start)
          echo "Waiting for worker to start polling..."
          for i in {1..15}; do
            sleep 2
            if grep -q "worker_pool_starting\|poll_and_dispatch" worker.log 2>/dev/null; then
              echo "âœ… Worker poll loop started"
              break
            fi
            if ! ps -p $WORKER_PID > /dev/null 2>&1; then
              echo "âŒ Worker crashed during startup!"
              cat worker.log 2>/dev/null || true
              exit 1
            fi
            echo "  Attempt $i/15 - waiting..."
          done

          # Final verification
          if ps -p $WORKER_PID > /dev/null 2>&1; then
            echo "âœ… Worker is running (PID: $WORKER_PID)"
            echo "=== Worker logs (last 50 lines) ==="
            tail -50 worker.log
          else
            echo "âŒ Worker process is not running!"
            cat worker.log 2>/dev/null || true
            exit 1
          fi

      - name: Worker health check
        run: |
          echo "Verifying worker process is healthy..."
          if pgrep -f "app.worker.pool" > /dev/null; then
            echo "âœ… Worker process found"
            pgrep -af "app.worker.pool"
          else
            echo "âŒ Worker process not found!"
            echo "Processes running:"
            ps aux | grep python || true
            exit 1
          fi

      - name: Metrics endpoint validation
        run: |
          echo "Validating /metrics endpoint..."
          # Check endpoint is reachable
          if curl -sf http://localhost:8000/metrics > /tmp/metrics.txt 2>&1; then
            echo "âœ… Metrics endpoint reachable"
            METRIC_COUNT=$(grep -c "^nova_" /tmp/metrics.txt || echo "0")
            echo "   Found $METRIC_COUNT nova_* metrics"

            # Check for critical metrics
            for metric in nova_runs_total nova_skills_executed_total; do
              if grep -q "$metric" /tmp/metrics.txt 2>/dev/null; then
                echo "   âœ… $metric present"
              else
                echo "   âš ï¸  $metric not found (may be zero)"
              fi
            done
          else
            echo "âš ï¸  Metrics endpoint not available (non-blocking)"
          fi

      - name: Run E2E tests
        env:
          RUN_E2E_TESTS: "1"
        run: |
          cd backend
          PYTHONPATH=. pytest tests/test_phase4_e2e.py -v --tb=short -m e2e

      - name: Show worker logs (debug)
        if: always()
        run: |
          cd backend
          echo "=== Worker process status ==="
          ps aux | grep worker || echo "No worker process found"
          echo ""
          echo "=== Full worker.log ==="
          cat worker.log 2>/dev/null || echo "No worker.log found"
          echo ""
          echo "=== Checking for runs in DB ==="
          PYTHONPATH=. python -c "
          from app.db import engine
          from sqlmodel import Session, select
          from app.db import Run
          with Session(engine) as s:
              runs = s.exec(select(Run)).all()
              for r in runs:
                  print(f'Run {r.id}: status={r.status}, created={r.created_at}, started={r.started_at}')
          " 2>/dev/null || echo "Could not query runs"

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-logs
          path: |
            backend/server.log
            backend/worker.log
          if-no-files-found: ignore

  # M10: Combined Tests
  m10-tests:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, integration]
    if: always() && (needs.setup-neon-branch.result == 'success' || needs.setup-neon-branch.result == 'skipped') && needs.integration.result == 'success'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: nova
          POSTGRES_PASSWORD: novapass
          POSTGRES_DB: nova_aos
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    env:
      REDIS_URL: redis://localhost:6379/0
    steps:
      - uses: actions/checkout@v4

      - name: Setup Neon CLI
        if: needs.setup-neon-branch.outputs.use_neon == 'true'
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Configure database connection
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          if [ "${{ needs.setup-neon-branch.outputs.use_neon }}" == "true" ]; then
            echo "âœ… Using Neon PostgreSQL (ephemeral branch)"
            BRANCH_NAME="${{ needs.setup-neon-branch.outputs.branch_name }}"
            CONN=$(neonctl connection-string "$BRANCH_NAME" \
              --project-id ${{ secrets.NEON_PROJECT_ID }} \
              --api-key $NEON_API_KEY \
              --database-name neondb \
              --role-name neondb_owner)
            if [[ "$CONN" != *"sslmode="* ]]; then
              CONN="${CONN}?sslmode=require"
            fi
            echo "DATABASE_URL=$CONN" >> $GITHUB_ENV
          else
            echo "âš ï¸ Using Docker PostgreSQL (fallback mode)"
            echo "DATABASE_URL=postgresql://nova:novapass@localhost:5433/nova_aos" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Install redis-tools
        run: |
          sudo apt-get update
          sudo apt-get install -y redis-tools

      - name: Check Redis configuration
        run: |
          cd backend
          echo "=== M10 Redis Configuration Check ==="
          PYTHONPATH=. python -m scripts.ops.check_redis_config --json || true
          redis-cli XADD m10:ci:test '*' test_key test_value > /dev/null
          RESULT=$(redis-cli XLEN m10:ci:test)
          redis-cli DEL m10:ci:test > /dev/null
          if [ "$RESULT" -ge 1 ]; then
            echo "âœ“ Redis stream operations working"
          else
            echo "::error::Redis stream operations not working"
            exit 1
          fi

      - name: Wait for PostgreSQL (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          echo "Waiting for Docker PostgreSQL to accept connections..."
          for i in {1..30}; do
            if PGPASSWORD=novapass psql -h localhost -p 5433 -U nova -d nova_aos -c "SELECT 1" > /dev/null 2>&1; then
              echo "PostgreSQL is ready!"
              exit 0
            fi
            echo "Attempt $i/30 - PostgreSQL not ready yet..."
            sleep 2
          done
          echo "PostgreSQL failed to become ready"
          exit 1

      - name: Run Alembic migrations (Docker fallback only)
        if: needs.setup-neon-branch.outputs.use_neon != 'true'
        run: |
          cd backend
          alembic upgrade head

      - name: Run M10 leader election tests
        run: |
          cd backend
          echo "=== M10 Leader Election Tests ==="
          PYTHONPATH=. pytest tests/test_m10_leader_election.py -v --tb=short

      - name: Run M10 production hardening tests
        run: |
          cd backend
          echo "=== M10 Production Hardening Tests ==="
          PYTHONPATH=. pytest tests/test_m10_production_hardening.py -v --tb=short -k "not chaos and not high_volume"

      - name: Verify M10 metrics registered
        run: |
          cd backend
          echo "=== M10 Metrics Check ==="
          PYTHONPATH=. pytest tests/test_m10_metrics.py -v --tb=short -k "test_m10_metrics_defined or test_m10_metrics_in_registry"

      - name: Run outbox E2E tests
        if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[outbox]') || contains(github.event.head_commit.message, '[m10]')
        run: |
          cd backend
          echo "=== M10 Outbox E2E Tests ==="
          PYTHONPATH=. pytest tests/test_m10_outbox_e2e.py -v --tb=short

  # ============================================================================
  # CONDITIONAL JOBS
  # ============================================================================

  # Chaos tests (nightly or on demand)
  chaos:
    runs-on: ubuntu-latest
    needs: integration
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[chaos]')
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run chaos tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/chaos -v -m chaos

  # Legacy tests (nightly only, warn on failure)
  legacy:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Run legacy tests
        run: |
          cd backend
          PYTHONPATH=. pytest tests/legacy -v || echo "::warning::Legacy tests failed - scheduled for removal"

  # ============================================================================
  # POSTFLIGHT: Code quality check after all tests pass
  # ============================================================================
  postflight:
    name: Post-Flight Hygiene Check
    runs-on: ubuntu-latest
    needs: [integration, costsim, e2e-tests]
    if: always() && needs.integration.result == 'success'

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run full postflight check
        id: postflight
        run: |
          echo "ðŸ” Running full post-flight hygiene check..."
          chmod +x ./scripts/ops/postflight.py

          # Run full check with JSON output
          python3 ./scripts/ops/postflight.py --full --json > /tmp/postflight.json 2>&1 || true

          # Parse results
          ERRORS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('errors',0))" 2>/dev/null || echo "0")
          WARNINGS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('warnings',0))" 2>/dev/null || echo "0")
          SUGGESTIONS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('suggestions',0))" 2>/dev/null || echo "0")

          echo "postflight_errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "postflight_warnings=$WARNINGS" >> $GITHUB_OUTPUT
          echo "postflight_suggestions=$SUGGESTIONS" >> $GITHUB_OUTPUT

          # Show summary
          echo ""
          echo "ðŸ“Š Postflight Summary:"
          echo "  Errors: $ERRORS"
          echo "  Warnings: $WARNINGS"
          echo "  Suggestions: $SUGGESTIONS"

          # Fail on errors (security issues, syntax errors)
          if [ "$ERRORS" -gt 0 ]; then
            echo "::error::Postflight check found $ERRORS error(s)"
            python3 ./scripts/ops/postflight.py --full
            exit 1
          fi

          # Warn but don't fail on high warning count
          if [ "$WARNINGS" -gt 50 ]; then
            echo "::warning::High warning count ($WARNINGS) - consider addressing some issues"
          fi

          echo "âœ… Postflight check passed"

      - name: Check route conflicts
        run: |
          echo "ðŸ” Verifying no route conflicts..."
          OUTPUT=$(python3 ./scripts/ops/preflight.py --routes 2>&1)
          echo "$OUTPUT"

          if echo "$OUTPUT" | grep -q "Route conflict:"; then
            echo "::error::Route conflicts found after tests passed - this should not happen"
            exit 1
          fi

          echo "âœ… No route conflicts"

      - name: Generate hygiene report
        if: always()
        run: |
          echo "## ðŸ” Code Hygiene Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f /tmp/postflight.json ]; then
            ERRORS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('errors',0))" 2>/dev/null || echo "?")
            WARNINGS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('warnings',0))" 2>/dev/null || echo "?")
            SUGGESTIONS=$(python3 -c "import json; d=json.load(open('/tmp/postflight.json')); print(d.get('summary',{}).get('suggestions',0))" 2>/dev/null || echo "?")

            echo "| Category | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸ”´ Errors | $ERRORS |" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸŸ¡ Warnings | $WARNINGS |" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸ’¡ Suggestions | $SUGGESTIONS |" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Postflight report not available" >> $GITHUB_STEP_SUMMARY
          fi

  # ============================================================================
  # CLEANUP: Delete ephemeral Neon branch
  # ============================================================================
  cleanup-neon-branch:
    runs-on: ubuntu-latest
    needs: [setup-neon-branch, run-migrations, integration, costsim, costsim-integration, costsim-wiremock, e2e-tests, m10-tests]
    if: always() && needs.setup-neon-branch.outputs.use_neon == 'true'
    steps:
      - name: Setup Neon CLI
        uses: nhedger/setup-neon@v1
        with:
          version: latest

      - name: Delete ephemeral Neon branch
        env:
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
        run: |
          BRANCH_NAME="ci-${{ github.run_id }}-${{ github.run_attempt }}"
          echo "Deleting Neon branch: $BRANCH_NAME"

          neonctl branches delete "$BRANCH_NAME" \
            --project-id ${{ secrets.NEON_PROJECT_ID }} \
            --api-key $NEON_API_KEY \
            || echo "âš ï¸ Branch deletion failed (may already be deleted)"

          echo "âœ… Cleanup complete"
